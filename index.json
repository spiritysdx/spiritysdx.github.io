[{"categories":["机器学习","Python"],"content":"conda默认的python环境版本过高，需要降级默认的Python环境 假设原始环境是Python12的环境 直接使用 conda install python==3.11 类似上述方法指定python版本下载，注意这个命令要在conda的虚拟环境中执行才会替换当前python版本。 ","date":"2024-06-07","objectID":"/20240607/:1:0","tags":["linux","ubuntu","gpu","conda"],"title":"conda使用GPU时的一些陷阱","uri":"/20240607/"},{"categories":["机器学习","Python"],"content":"环境存在冲突，但非报错提示，需要手动指定环境 例子： 安装了pytorch，但安装了pytorch-geometric后，pytorch的版本从GPU版本变成CPU版本了，这是怎么回事呢？ 查看官网： https://pytorch-geometric.readthedocs.io/en/latest/install/installation.html 查看说明才知道pyg的cuda版本在conda中是默认识别不到的，如果使用： conda install pyg -c pyg 下载的是仅CPU版本，所以安装中会更换Pytorch的版本，导致Pytorch的版本从GPU版本变成仅CPU版本了。 解决办法：指定cu进行cuda版本的安装，不要使用conda的默认安装。 conda install pyg=*=*cu* -c pyg 这样安装得到的版本就是GPU版本了，不会影响pytorch的版本。 由此可见有些第三方包在conda中是默认找不到GPU版本的(或者说conda的默认安装环境配置中gpu版本不是首选)，需要手动指定cu版本安装。 ","date":"2024-06-07","objectID":"/20240607/:2:0","tags":["linux","ubuntu","gpu","conda"],"title":"conda使用GPU时的一些陷阱","uri":"/20240607/"},{"categories":["机器学习","Python"],"content":"python的第三方包调用了被屏蔽的网址 https://github.com/mzz2017/gg 安装后使用对应命令再调用python解释器 ","date":"2024-06-07","objectID":"/20240607/:3:0","tags":["linux","ubuntu","gpu","conda"],"title":"conda使用GPU时的一些陷阱","uri":"/20240607/"},{"categories":["电脑技巧"],"content":"前言 由于机房的服务器(下称宿主机)都是没有公网IP的(只有NAT的IPV4网络)，所以需要通过跳板机进行连接。 由于Pycharm的远程连接是通过SSH进行连接的，使用SFTP协议，所以仅使用22端口即可。 ","date":"2024-05-14","objectID":"/20240515/:1:0","tags":["linux","ubuntu","lxd","ssh","sftp","机房"],"title":"给机房的LXD容器配置跳板机进行连接","uri":"/20240515/"},{"categories":["电脑技巧"],"content":"解除跳板机进程限制 由于到时候需要在跳板机上搭建很多映射，需要提前解放进程限制，在跳板机上执行以下命令 # 更新 /etc/security/limits.conf 文件 echo \"更新 /etc/security/limits.conf 文件...\" sed -i '/^root soft nofile /d' /etc/security/limits.conf sed -i '/^root hard nofile /d' /etc/security/limits.conf sed -i '/^\\* soft nofile /d' /etc/security/limits.conf sed -i '/^\\* hard nofile /d' /etc/security/limits.conf echo \"root soft nofile 1000000\" \u003e\u003e /etc/security/limits.conf echo \"root hard nofile 1000000\" \u003e\u003e /etc/security/limits.conf echo \"* soft nofile 1000000\" \u003e\u003e /etc/security/limits.conf echo \"* hard nofile 1000000\" \u003e\u003e /etc/security/limits.conf # 更新 /etc/pam.d/common-session 文件 echo \"更新 /etc/pam.d/common-session 文件...\" if ! grep -q \"session required pam_limits.so\" /etc/pam.d/common-session; then echo \"session required pam_limits.so\" \u003e\u003e /etc/pam.d/common-session fi # 更新 /etc/pam.d/common-session-noninteractive 文件 echo \"更新 /etc/pam.d/common-session-noninteractive 文件...\" if ! grep -q \"session required pam_limits.so\" /etc/pam.d/common-session-noninteractive; then echo \"session required pam_limits.so\" \u003e\u003e /etc/pam.d/common-session-noninteractive fi # 更新 /etc/systemd/system.conf 文件 echo \"更新 /etc/systemd/system.conf 文件...\" sed -i '/^DefaultLimitNOFILE=/d' /etc/systemd/system.conf echo \"DefaultLimitNOFILE=1000000\" \u003e\u003e /etc/systemd/system.conf # 更新 /etc/systemd/user.conf 文件 echo \"更新 /etc/systemd/user.conf 文件...\" sed -i '/^DefaultLimitNOFILE=/d' /etc/systemd/user.conf echo \"DefaultLimitNOFILE=1000000\" \u003e\u003e /etc/systemd/user.conf sleep 1 systemctl daemon-reload 然重启跳板机，再执行 ulimit -n 查询当前进程限制，应当显示1000000 ","date":"2024-05-14","objectID":"/20240515/:2:0","tags":["linux","ubuntu","lxd","ssh","sftp","机房"],"title":"给机房的LXD容器配置跳板机进行连接","uri":"/20240515/"},{"categories":["电脑技巧"],"content":"端口转发配置 首先需要将容器的内网22端口映射到宿主机的公共端口上，我选择将user1容器的22端口映射到宿主机的10022端口上。 宿主机执行： ctname=\"user1\" ctssh=\"10022\" lxc config device add \"$ctname\" ssh-port proxy listen=tcp:0.0.0.0:$ctssh connect=tcp:127.0.0.1:22 然后需要将宿主机的10022端口映射出来，映射到跳板机上的10022端口上。 跳板机执行： tb_port=\"10022\" # 跳板机上的端口 sz_port=\"10022\" # 宿主机上的端口 sudo proxy server -r \":${tb_port}@:${sz_port}\" -P \"127.0.0.1:8800\" -C proxy.crt -K proxy.key --log proxy.log --daemon 其他端口也按照对应的方式映射，自行修改端口号即可。 ","date":"2024-05-14","objectID":"/20240515/:3:0","tags":["linux","ubuntu","lxd","ssh","sftp","机房"],"title":"给机房的LXD容器配置跳板机进行连接","uri":"/20240515/"},{"categories":["电脑技巧"],"content":"后言 上述在跳板机上的所有配置均为一次性配置，务必在重启跳板机后，重新执行这些映射命令，不会自动保留映射关系。 重启跳板机后务必事先设置本地监听端口8800，我的配置如下 sudo proxy bridge -p \":8800\" -C proxy.crt -K proxy.key --forever --log proxy.log --daemon 然后再进行端口映射等操作。 ","date":"2024-05-14","objectID":"/20240515/:4:0","tags":["linux","ubuntu","lxd","ssh","sftp","机房"],"title":"给机房的LXD容器配置跳板机进行连接","uri":"/20240515/"},{"categories":["电脑技巧"],"content":"前言 相信通过前面教程，大部分问题都解决了，目前就剩一个Pycharm怎么连接远程的LXC容器运行Python项目的问题了。 (为什么不用VSCODE？因为它没有官方支持的远程开发/SSH开发的功能，只有相关的第三方插件实现了类似的功能但并不好用，所以我选择了Pycharm) (还有一个原因是我有开源证书，所以Pycharm专业版可以免费使用) ","date":"2024-05-14","objectID":"/20240514/:1:0","tags":["linux","ubuntu","lxd","ssh","sftp","pycharm","机房"],"title":"在Pycharm上连接远程虚拟环境进行使用","uri":"/20240514/"},{"categories":["电脑技巧"],"content":"步骤 打开Pycharm，点击菜单栏的File，选择Settings 在弹出的窗口中，选择Project:xxx，然后选择Project Interpreter，然后选择Add Interpreter，在下拉窗口中选择On SSH 按照下面的图示填写信息即可 下面这一步得等一会，它要测试远程连接和环境 这里一定要选择Existing，点那三个点自己增加已有的conda解释器，而不是pycharm导入解释器或者是容器本地的解释器，我需要使用虚拟环境。 这里输入conda虚拟环境解释器的路径，在容器内可使用以下命令查询 (base) root@user2:~# command -v python /root/miniconda3/bin/python 我在base环境中查询到解释器路径是/root/miniconda3/bin/python，如果你也是使用 https://www.spiritysdx.top/20240513/ 配置的LXD多用户容器，那么路径应该和我一致。 这里是修改远程容器保存项目代码的路径，我选择保存在容器内的/root/item1文件夹里，你可以自行修改。 全部OK点击完毕后，在解释器选择页面会看到类似如下的输出。 如果想要每次启动Pycharm自动登录到容器，那么需要在这里配置记住密码，每次打开Pycharm自动登录SSH。 建议参考： https://blog.csdn.net/pianchengxiaobai/article/details/136660228 (由于我的Pycharm是开源证书的专业版，所以有该功能，社区版本未尝试不知道有没有) 配置完毕后在这里进入容器的SSH界面/Conda的Python界面，你可以在SSH上面执行ls查看是不是有你之前映射的项目文件夹。 我的执行结果是 Last login: Tue May 14 07:56:28 2024 from 127.0.0.1 (base) root@user2:~# ls item1 miniconda3 Miniconda3-latest-Linux-x86_64.sh nezha.sh NVIDIA-Linux-x86_64-535.171.04.run sharefile snap 确实有item1这个文件夹了。 ","date":"2024-05-14","objectID":"/20240514/:2:0","tags":["linux","ubuntu","lxd","ssh","sftp","pycharm","机房"],"title":"在Pycharm上连接远程虚拟环境进行使用","uri":"/20240514/"},{"categories":["电脑技巧"],"content":"后言 注意这里的连接速度受跳板机到机房宿主机的网络的影响，国内机房的宿主机开设的LXD多用户容器务必使用境内/香港服务器做跳板机，否则你的网络延迟会非常大，无法使用。 本人推荐使用腾讯云的境内服务器跳转，阿里云跳转的同价位的服务器CPU会比较弱一些，在多用户使用的时候可能出现CPU占用过高的情况。 (北京/上海/广州比较好，香港也还行，这些地方有骨干网的POP点，延迟会低一些) 下一篇讲解如何给机房的LXD容器配置跳板机进行连接。 ","date":"2024-05-14","objectID":"/20240514/:3:0","tags":["linux","ubuntu","lxd","ssh","sftp","pycharm","机房"],"title":"在Pycharm上连接远程虚拟环境进行使用","uri":"/20240514/"},{"categories":["电脑技巧"],"content":"前言 为什么使用LXD？ 因为宿主机不支持嵌套虚拟化，没有硬件加速没法搞PVE的虚拟机，开容器比较好。由于宿主机是Ubuntu22，自然选择LXD而不是INCUS了，因为后者在ubuntu24以上以及debian13以上才有官方支持包，其他低版本的系统只有第三方编译的包，有问题难处理。 为什么使用官方的WEB端？因为官方支持最完善，虽然其实也就一个壳子，但社区会有管理员管管问题，其他第三方的WEB端更新缓慢且无社区支持。 ","date":"2024-05-13","objectID":"/20240513/:1:0","tags":["linux","ubuntu","lxd","incus","https","gpu","LTS","conda","nvidia","pytorch","cuda","机房"],"title":"给机房的Ubuntu22.04安装LXD共享GPU资源","uri":"/20240513/"},{"categories":["电脑技巧"],"content":"安装LXD snap install lxd -y apt install zfsutils-linux bridge-utils -y 如果要删除 lxd snap remove --purge lxd rm -rf /var/lib/lxd ","date":"2024-05-13","objectID":"/20240513/:2:0","tags":["linux","ubuntu","lxd","incus","https","gpu","LTS","conda","nvidia","pytorch","cuda","机房"],"title":"给机房的Ubuntu22.04安装LXD共享GPU资源","uri":"/20240513/"},{"categories":["电脑技巧"],"content":"初始化LXD /snap/bin/lxd init 下面这些选项很重要请手动指定，其他选项未列出的回车使用默认值 Name of the storage backend to use (ceph, dir, lvm, zfs, btrfs) [default=zfs]: zfs Would you like to use an existing empty block device (e.g. a disk or partition)? (yes/no) [default=no]: no Size in GiB of the new loop device (1GiB minimum) [default=30GiB]: 填你的空闲硬盘大小，我的有1T，所以填1024GiB Would you like stale cached images to be updated automatically? (yes/no) [default=yes]: no 增加第三方镜像源 lxc remote add opsmaru https://images.opsmaru.dev/spaces/9bfad87bd318b8f06012059a --public --protocol simplestreams 设置CGROUP配置 snap set lxd lxcfs.loadavg=true snap set lxd lxcfs.pidfd=true snap set lxd lxcfs.cfs=true systemctl restart snap.lxd.daemon 设置镜像不更新 lxc config unset images.auto_update_interval lxc config set images.auto_update_interval 0 解除进程数限制 if [ -f \"/etc/security/limits.conf\" ]; then if ! grep -q \"* hard nproc unlimited\" /etc/security/limits.conf; then echo '* hard nproc unlimited' | sudo tee -a /etc/security/limits.conf fi if ! grep -q \"* soft nproc unlimited\" /etc/security/limits.conf; then echo '* soft nproc unlimited' | sudo tee -a /etc/security/limits.conf fi fi if [ -f \"/etc/systemd/logind.conf\" ]; then if ! grep -q \"UserTasksMax=infinity\" /etc/systemd/logind.conf; then echo 'UserTasksMax=infinity' | sudo tee -a /etc/systemd/logind.conf fi fi ufw disable 然后此时建议重启服务器以解放线程限制 ","date":"2024-05-13","objectID":"/20240513/:3:0","tags":["linux","ubuntu","lxd","incus","https","gpu","LTS","conda","nvidia","pytorch","cuda","机房"],"title":"给机房的Ubuntu22.04安装LXD共享GPU资源","uri":"/20240513/"},{"categories":["电脑技巧"],"content":"启动WEB lxc config set core.https_address 0.0.0.0:8443 snap set lxd ui.enable=true systemctl reload snap.lxd.daemon 由于是机房，需要内穿端口，所以我在跳板机上的服务端(非机房的服务器)执行映射 sudo proxy server -r \":8443@:8443\" -P \"127.0.0.1:8800\" -C proxy.crt -K proxy.key --log proxy.log --daemon 这条命令看不懂的看我上篇博客 ","date":"2024-05-13","objectID":"/20240513/:4:0","tags":["linux","ubuntu","lxd","incus","https","gpu","LTS","conda","nvidia","pytorch","cuda","机房"],"title":"给机房的Ubuntu22.04安装LXD共享GPU资源","uri":"/20240513/"},{"categories":["电脑技巧"],"content":"配置WEB 打开跳板机的https协议的8443端口，正常进入设置 官方演示视频： https://www.youtube.com/watch?v=wqEH_d8LC1k 通过 Generate Create a new certificate 生成证书(生成过程中建议跳过密码验证)，这个证书务必保管好，因为后面要用到。 设置界面有讲解每个主流浏览器的证书设置方法，以下我说的浏览器设置的方法为EDGE，其他浏览器类似，可参考上面的官方演示视频。 两个证书文件，一个crt一个pfx，前者在机房的机器里用，后者在你的浏览器里用。 crt证书文件你可以打开后复制粘贴在机房的机器里创建一个一样内容一样名字的crt文件，这样就不用麻烦的上传crt文件了。crt证书存在后，你在机房的机器中执行下述命令验证 lxc config trust add 那个证书名字 然后在浏览器中导入pfx证书，注意，其中有一步是问你密码的，留空继续即可，因为前面选生成的时候跳过了，还有一步问你证书保存地址的，选择根据证书类型，自动选择证书存储(U)即可。 ","date":"2024-05-13","objectID":"/20240513/:5:0","tags":["linux","ubuntu","lxd","incus","https","gpu","LTS","conda","nvidia","pytorch","cuda","机房"],"title":"给机房的Ubuntu22.04安装LXD共享GPU资源","uri":"/20240513/"},{"categories":["电脑技巧"],"content":"刷新浏览器进入 因为之前进入浏览器是忽略证书校验了，此时刷新也会忽略证书校验，点击不安全那里，然后点击 你的证书选择 选择 LXD UI开头的名字的证书即可，选择后会自动刷新浏览器进入控制台。 ","date":"2024-05-13","objectID":"/20240513/:6:0","tags":["linux","ubuntu","lxd","incus","https","gpu","LTS","conda","nvidia","pytorch","cuda","机房"],"title":"给机房的Ubuntu22.04安装LXD共享GPU资源","uri":"/20240513/"},{"categories":["电脑技巧"],"content":"开设LXC容器 如下图所示进行开设，注意，Ubuntu 系统最好选择带 LTS 标签的，否则软件源可能出现问题。 设置完点create就开始创建了 ","date":"2024-05-13","objectID":"/20240513/:7:0","tags":["linux","ubuntu","lxd","incus","https","gpu","LTS","conda","nvidia","pytorch","cuda","机房"],"title":"给机房的Ubuntu22.04安装LXD共享GPU资源","uri":"/20240513/"},{"categories":["电脑技巧"],"content":"两种设置显卡的方式 ","date":"2024-05-13","objectID":"/20240513/:8:0","tags":["linux","ubuntu","lxd","incus","https","gpu","LTS","conda","nvidia","pytorch","cuda","机房"],"title":"给机房的Ubuntu22.04安装LXD共享GPU资源","uri":"/20240513/"},{"categories":["电脑技巧"],"content":"使用命令设置 或在机房的机器上使用命令设置(ctnmae我设置为mother，实际请改成自己的容器名字) ctname=\"mother\" sudo lxc config device add $ctname gpu gpu sudo lxc config set $ctname security.nesting true 不建议启用特权容器 # 启用特权容器的命令 ctname=\"mother\" sudo lxc config set $ctname security.privileged true 启用特权容器应该会在lxc.log中报错 ERROR conf - ../src/src/lxc/conf.c:turn_into_dependent_mounts:3451 - No such file or directory - Failed to recursively turn old root mount tree into dependent mount. Continuing... 如果具有多个显卡，务必指定该容器使用哪张显卡(id后跟显卡序号) ctname=\"mother\" sudo lxc config device add $ctname gpu-tmp gpu id=0 ","date":"2024-05-13","objectID":"/20240513/:8:1","tags":["linux","ubuntu","lxd","incus","https","gpu","LTS","conda","nvidia","pytorch","cuda","机房"],"title":"给机房的Ubuntu22.04安装LXD共享GPU资源","uri":"/20240513/"},{"categories":["电脑技巧"],"content":"使用yaml文件 devices: gpu: type: gpu config: security.nesting: \"true\" security.privileged: \"true\" 或指定显卡序号(通过id指定序号) devices: gpu-tmp: id: \"0\" type: gpu config: security.nesting: \"true\" security.privileged: \"true\" ","date":"2024-05-13","objectID":"/20240513/:8:2","tags":["linux","ubuntu","lxd","incus","https","gpu","LTS","conda","nvidia","pytorch","cuda","机房"],"title":"给机房的Ubuntu22.04安装LXD共享GPU资源","uri":"/20240513/"},{"categories":["电脑技巧"],"content":"容器安装SSH和设置root密码验证登录 进入容器 lxc exec mother -- /bin/bash 使用我维护的仓库的一键脚本进行配置，使用我的cdn进行加速 仓库：https://github.com/oneclickvirt/lxd 下载脚本: apt update \u0026\u0026 apt install dos2unix -y curl -o ssh_bash.sh https://cdn.spiritlhl.net/https://raw.githubusercontent.com/oneclickvirt/lxd/main/scripts/ssh_bash.sh \u0026\u0026 chmod 777 ssh_bash.sh \u0026\u0026 dos2unix ssh_bash.sh 因为是国内服务器，不需要更改DNS，所以需要删除5~10行的内容: sed -i '5,10d' ssh_bash.sh 执行脚本： ./ssh_bash.sh 你想要设置的密码 设置完毕后按ctrl+a+d退出容器或执行 exit 退出容器回到机房的机器(宿主机) 再执行 lxc list 查询对应容器的IPV4地址替换下面的10.228.242.7测试SSH连接 ssh root@10.228.242.7 然后应该会询问是否继续，输入yes后再输入你刚刚设置的容器密码即可，若能正常进入容器，那么证明这一步无问题 ","date":"2024-05-13","objectID":"/20240513/:9:0","tags":["linux","ubuntu","lxd","incus","https","gpu","LTS","conda","nvidia","pytorch","cuda","机房"],"title":"给机房的Ubuntu22.04安装LXD共享GPU资源","uri":"/20240513/"},{"categories":["电脑技巧"],"content":"容器内安装GPU驱动 容器和宿主机的显卡驱动必须保持一致，否则无法正常使用GPU，所以必须在容器内外进行驱动查询。 ","date":"2024-05-13","objectID":"/20240513/:10:0","tags":["linux","ubuntu","lxd","incus","https","gpu","LTS","conda","nvidia","pytorch","cuda","机房"],"title":"给机房的Ubuntu22.04安装LXD共享GPU资源","uri":"/20240513/"},{"categories":["电脑技巧"],"content":"容器内外查询显卡驱动 容器外执行 nvidia-smi 可能的显示为 root@a12-ThinkStation-P620:~/lxd# nvidia-smi Mon May 13 23:42:04 2024 +---------------------------------------------------------------------------------------+ | NVIDIA-SMI 535.171.04 Driver Version: 535.171.04 CUDA Version: 12.2 | |-----------------------------------------+----------------------+----------------------+ | GPU Name Persistence-M | Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap | Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |=========================================+======================+======================| | 0 NVIDIA RTX A6000 Off | 00000000:61:00.0 Off | Off | | 30% 27C P8 11W / 300W | 168MiB / 49140MiB | 0% Default | | | | N/A | +-----------------------------------------+----------------------+----------------------+ +---------------------------------------------------------------------------------------+ | Processes: | | GPU GI CI PID Type Process name GPU Memory | | ID ID Usage | |=======================================================================================| | 0 N/A N/A 1713 G /usr/lib/xorg/Xorg 75MiB | | 0 N/A N/A 2108 G /usr/bin/gnome-shell 61MiB | +---------------------------------------------------------------------------------------+ 可以看到宿主机的驱动版本为535.171.04 执行 lxc exec mother -- /bin/bash 进入mother容器内执行 nvidia-smi 查询显卡驱动 可能显示如下 root@mother:~# nvidia-smi Command 'nvidia-smi' not found, but can be installed with: apt install nvidia-utils-510 # version 510.60.02-0ubuntu1, or apt install nvidia-utils-510-server # version 510.47.03-0ubuntu3 apt install nvidia-utils-390 # version 390.157-0ubuntu0.22.04.2 apt install nvidia-utils-418-server # version 418.226.00-0ubuntu5~0.22.04.1 apt install nvidia-utils-450-server # version 450.248.02-0ubuntu0.22.04.1 apt install nvidia-utils-470 # version 470.223.02-0ubuntu0.22.04.1 apt install nvidia-utils-470-server # version 470.223.02-0ubuntu0.22.04.1 apt install nvidia-utils-525 # version 525.147.05-0ubuntu0.22.04.1 apt install nvidia-utils-525-server # version 525.147.05-0ubuntu0.22.04.1 apt install nvidia-utils-535 # version 535.129.03-0ubuntu0.22.04.1 apt install nvidia-utils-535-server # version 535.129.03-0ubuntu0.22.04.1 可以看到容器内的驱动最多支持到535.129.03，容器内外显卡驱动的版本是不同的，不能直接进行安装. ","date":"2024-05-13","objectID":"/20240513/:10:1","tags":["linux","ubuntu","lxd","incus","https","gpu","LTS","conda","nvidia","pytorch","cuda","机房"],"title":"给机房的Ubuntu22.04安装LXD共享GPU资源","uri":"/20240513/"},{"categories":["电脑技巧"],"content":"容器内外显卡驱动版本一致时使用官方命令安装 如果你查询得到的版本一致，那么可以使用 apt install nvidia-utils-535 -y 进行安装，而我的驱动版本不一致，不能这么安装 ","date":"2024-05-13","objectID":"/20240513/:10:2","tags":["linux","ubuntu","lxd","incus","https","gpu","LTS","conda","nvidia","pytorch","cuda","机房"],"title":"给机房的Ubuntu22.04安装LXD共享GPU资源","uri":"/20240513/"},{"categories":["电脑技巧"],"content":"使用Nvidia官方包安装显卡驱动 打开官方网站：https://www.nvidia.cn/Download/Find.aspx?lang=cn 按照你的显卡版本进行选择，我的配置如下，你的与我一般不一致 然后点击搜索进行搜索，我搜索结果如下 出现下面这个界面后，别急着点击下载 右键点击同意并开始下载复制下载链接，在容器内使用wget下载(不是宿主机！) 然后执行(我下到的是NVIDIA-Linux-x86_64-535.171.04.run文件) bash NVIDIA-Linux-x86_64-535.171.04.run --no-kernel-module 由于容器和宿主机需要共享GPU，所以在安装容器的显卡驱动时需要添加--no-kernel-module参数。 安装选项都选择no即可，安装好显卡驱动后执行nvidia-smi查看显卡驱动是否和宿主机的版本一致。 ","date":"2024-05-13","objectID":"/20240513/:10:3","tags":["linux","ubuntu","lxd","incus","https","gpu","LTS","conda","nvidia","pytorch","cuda","机房"],"title":"给机房的Ubuntu22.04安装LXD共享GPU资源","uri":"/20240513/"},{"categories":["电脑技巧"],"content":"测试是否安装成功 容器内执行下述命令安装Miniconda3，安装成功后重启容器 wget https://repo.anaconda.com/miniconda/Miniconda3-lamother-Linux-x86_64.sh bash Miniconda3-lamother-Linux-x86_64.sh -b -u echo 'export PATH=\"$PATH:$HOME/miniconda3/bin:$HOME/miniconda3/condabin\"' \u003e\u003e~/.bashrc echo 'export PATH=\"$PATH:$HOME/.local/share/jupyter\"' \u003e\u003e~/.bashrc source ~/.bashrc sleep 1 echo 'export PATH=\"/home/user/miniconda3/bin:$PATH\"' \u003e\u003e~/.bashrc source ~/.bashrc sleep 1 export PATH=\"/home/user/miniconda3/bin:$PATH\" conda init 重启后： 退出base环境 conda deactivate 启动base环境 conda activate base 接下来安装pytorch，方便测试GPU是否已共享成功 打开 https://pytorch.org/get-started/locally/ 或 https://pytorch.org/get-started/previous-versions/ 查看对应版本安装，由于我的cuda版本是12.2，所以我执行了以下命令，其他版本自行查询 (下面pytorch-cuda用的12.1这个版本是因为没有12.2的版本，所以只能退而求其次使用低一个版本的) conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia 安装过程中一直按回车即可 测试是否可以调用显卡，下面的命令执行显示true则没问题 (base) root@mother:~# python Python 3.12.2 | packaged by Anaconda, Inc. | (main, Feb 27 2024, 17:35:02) [GCC 11.2.0] on linux Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. \u003e\u003e\u003e import torch \u003e\u003e\u003e print(torch.cuda.is_available()) True \u003e\u003e\u003e 测试没问题，按ctrl+z退出conda的python窗口 ","date":"2024-05-13","objectID":"/20240513/:10:4","tags":["linux","ubuntu","lxd","incus","https","gpu","LTS","conda","nvidia","pytorch","cuda","机房"],"title":"给机房的Ubuntu22.04安装LXD共享GPU资源","uri":"/20240513/"},{"categories":["电脑技巧"],"content":"共享容器文件夹和宿主机文件夹 为方便文件的传输与节约内存使用，需要设置共享文件夹来实现宿主机与容器之间的文件传输。 在宿主机的/root路径下执行下述命令创建文件夹和设置权限 mkdir sharefile chmod 777 sharefile 在宿主机创建共享区域share-host lxc profile create share-host lxc profile set share-host security.privileged true 检查是否创建成功 lxc profile show share-host 将文件夹添加到制定LXD容器mother中 ctname=\"mother\" lxc config device add $ctname share-host disk source=/root/sharefile path=/root/sharefile ","date":"2024-05-13","objectID":"/20240513/:11:0","tags":["linux","ubuntu","lxd","incus","https","gpu","LTS","conda","nvidia","pytorch","cuda","机房"],"title":"给机房的Ubuntu22.04安装LXD共享GPU资源","uri":"/20240513/"},{"categories":["电脑技巧"],"content":"多用户创建 模板容器mother已经配置好了，执行lxc stop mother以停止容器方便复制 克隆容器 参数一为模板容器名称，参数二为目标容器名称 lxc copy mother user1 启动用户1的容器 lxc start user1 一定要保证模板容器在copy前是stopped状态，否则你复制会复制带上内网IP地址，复制会导致冲突。 ","date":"2024-05-13","objectID":"/20240513/:12:0","tags":["linux","ubuntu","lxd","incus","https","gpu","LTS","conda","nvidia","pytorch","cuda","机房"],"title":"给机房的Ubuntu22.04安装LXD共享GPU资源","uri":"/20240513/"},{"categories":["电脑技巧"],"content":"后言 至于多用户下的容器，对应容器需要映射不同的端口，后续专门写一篇讲讲怎么配置 ","date":"2024-05-13","objectID":"/20240513/:13:0","tags":["linux","ubuntu","lxd","incus","https","gpu","LTS","conda","nvidia","pytorch","cuda","机房"],"title":"给机房的Ubuntu22.04安装LXD共享GPU资源","uri":"/20240513/"},{"categories":["电脑技巧"],"content":"前言 因为机房的机器没有公网IP，所以需要跳板机进行IP映射内穿，所以需要2样东西： 服务器A - 服务端 - 一个有公网IPV4地址的云服务器，IPV4地址本教程假设为 x.x.x.x 服务器B - 客户端 - 机房内的Ubuntu22.04系统的机器 这里选用goproxy进行IP内穿 初始环境本教程选择sudo -i后的/root目录下进行 ","date":"2024-05-12","objectID":"/20240512/:1:0","tags":["linux","ubuntu","goproxy","proxy","port","内穿","映射端口","机房"],"title":"给机房的Ubuntu22.04的Linux进行内穿映射端口","uri":"/20240512/"},{"categories":["电脑技巧"],"content":"下载goproxy以及预安装proxy 在 https://github.com/snail007/goproxy/releases 下载最新的 本教程下载 v14.5 版本，服务器A和服务器B这个东西都得下 (建议下载时进入一个空文件夹中，因为后续这个文件夹会用得到，别直接下载到root目录下) mkdir -p goproxy cd goproxy wget -O proxy-linux-amd64.tar.gz https://cdn.spiritlhl.net/https://github.com/snail007/goproxy/releases/download/v14.5/proxy-linux-amd64.tar.gz \u0026\u0026 chmod 777 proxy-linux-amd64.tar.gz 然后在服务器A中执行 wget https://cdn.spiritlhl.net/https://raw.githubusercontent.com/snail007/goproxy/master/install.sh chmod +x install.sh ./install.sh rm -rf install.sh 执行完毕后执行 proxy --version 查看是否已安装成功 在服务器A和B中都执行 tar -zxvf proxy-linux-amd64.tar.gz 解压本体(注意解压到哪个文件夹，下面配置文件中会用到) ","date":"2024-05-12","objectID":"/20240512/:2:0","tags":["linux","ubuntu","goproxy","proxy","port","内穿","映射端口","机房"],"title":"给机房的Ubuntu22.04的Linux进行内穿映射端口","uri":"/20240512/"},{"categories":["电脑技巧"],"content":"服务器A中生成服务器凭证 在服务器A中的解压出来的那个文件夹内执行 sudo proxy keygen -C proxy 命令会在本地生成两个文件proxy.crt，proxy.key, 相当于账号和密码，用于服务连接的验证。 ","date":"2024-05-12","objectID":"/20240512/:3:0","tags":["linux","ubuntu","goproxy","proxy","port","内穿","映射端口","机房"],"title":"给机房的Ubuntu22.04的Linux进行内穿映射端口","uri":"/20240512/"},{"categories":["电脑技巧"],"content":"启动和配置服务端的服务器A 在云服务器也就是服务器A中启动goproxy的server端 这里设定goproxy服务端与客户端的通信端口为8800，实际可以自行替换自定义 我需要映射服务器B的22到8822端口上，在A中执行下面的命令启动通信监听 sudo proxy bridge -p \":8800\" -C proxy.crt -K proxy.key --forever --log proxy.log --daemon 执行下述命令启动映射 sudo proxy server -r \":8822@:22\" -P \"127.0.0.1:8800\" -C proxy.crt -K proxy.key --forever --log proxy.log --daemon 上述命令不是永久生效的，如果你的云服务器重启了，这些命令需要重新执行，所以务必保管好你执行过的命令 ","date":"2024-05-12","objectID":"/20240512/:4:0","tags":["linux","ubuntu","goproxy","proxy","port","内穿","映射端口","机房"],"title":"给机房的Ubuntu22.04的Linux进行内穿映射端口","uri":"/20240512/"},{"categories":["电脑技巧"],"content":"启动和配置客户端的服务器B 服务器B不需要安装proxy，解压后的文件直接就可以使用了 但需要注意的是，需要上传之前生成的服务器凭证proxy.crt和proxy.key，上传到与解压后的文件的同一文件夹下，或者cat后自己写同样名字的文件同样的内容到服务器B中 不知道本地路径的执行 pwd 进行查看，本教程假设为/root/goproxy，如果查询不一致，请自己修改后面的文件夹路径 然后需要创建守护进程设置一直运行，需要创建一个systemd的配置文件 nano /etc/systemd/system/goproxy_client.service [Unit] Description=goproxy client After=network.target [Service] Type=simple WorkingDirectory=/root/goproxy ExecStart=/root/goproxy/proxy client -P x.x.x.x:8800 -C proxy.crt -K proxy.key User=root Restart=always Environment=\"RUNNER_ALLOW_RUNASROOT=1\" [Install] WantedBy=multi-user.target 保存退出后执行下面的命令启动守护进程 systemctl daemon-reload systemctl start goproxy_client.service 查看守护进程 systemctl status goproxy_client.service 我查询我的服务器B显示 root@a12-ThinkStation-P620:~/goproxy# systemctl status goproxy_client.service ● goproxy_client.service - goproxy client Loaded: loaded (/etc/systemd/system/goproxy_client.service; disabled; vendor preset: enabled) Active: active (running) since Mon 2024-05-13 16:36:46 CST; 8s ago Main PID: 12311 (proxy) Tasks: 20 (limit: 308965) Memory: 26.3M CPU: 104ms CGroup: /system.slice/goproxy_client.service └─12311 /root/goproxy/proxy client -P x.x.x.x:8800 -C proxy.crt -K proxy.key 5月 13 16:36:46 a12-ThinkStation-P620 proxy[12311]: 2024/05/13 16:36:46.967 INFO session worker[3] started 5月 13 16:36:46 a12-ThinkStation-P620 proxy[12311]: 2024/05/13 16:36:46.967 INFO session worker[4] started 5月 13 16:36:46 a12-ThinkStation-P620 proxy[12311]: 2024/05/13 16:36:46.967 INFO session worker[5] started 5月 13 16:36:46 a12-ThinkStation-P620 proxy[12311]: 2024/05/13 16:36:46.967 INFO session worker[6] started 5月 13 16:36:46 a12-ThinkStation-P620 proxy[12311]: 2024/05/13 16:36:46.967 INFO session worker[7] started 5月 13 16:36:46 a12-ThinkStation-P620 proxy[12311]: 2024/05/13 16:36:46.967 INFO session worker[8] started 5月 13 16:36:46 a12-ThinkStation-P620 proxy[12311]: 2024/05/13 16:36:46.967 INFO session worker[9] started 5月 13 16:36:46 a12-ThinkStation-P620 proxy[12311]: 2024/05/13 16:36:46.967 INFO session worker[10] started 5月 13 16:36:46 a12-ThinkStation-P620 proxy[12311]: 2024/05/13 16:36:46.968 INFO your system ulimit 524288 is too small, max value is: 524288, try set to 1000000 5月 13 16:36:46 a12-ThinkStation-P620 proxy[12311]: 2024/05/13 16:36:46.968 INFO the result ulimit is: 1000000 这就是正常的 你的无问题后执行ctrl+c退出查询 开启守护进程开机自启 systemctl enable goproxy_client.service 如果你需要改动映射的命令，那么修改/etc/systemd/system/goproxy_client.service文件后，记得执行 systemctl daemon-reload systemctl restart goproxy_client.service 重载配置文件和重启守护进程 ","date":"2024-05-12","objectID":"/20240512/:5:0","tags":["linux","ubuntu","goproxy","proxy","port","内穿","映射端口","机房"],"title":"给机房的Ubuntu22.04的Linux进行内穿映射端口","uri":"/20240512/"},{"categories":["电脑技巧"],"content":"后言 其他相关说明：https://github.com/snail007/goproxy/blob/master/README_ZH.md ","date":"2024-05-12","objectID":"/20240512/:6:0","tags":["linux","ubuntu","goproxy","proxy","port","内穿","映射端口","机房"],"title":"给机房的Ubuntu22.04的Linux进行内穿映射端口","uri":"/20240512/"},{"categories":["电脑技巧"],"content":"废话少说 sed -i 's/.*precedence ::ffff:0:0\\/96.*/precedence ::ffff:0:0\\/96 100/g' /etc/gai.conf apt update apt install openssh-server -y systemctl enable --now ssh systemctl status ssh sed -i 's/^#\\?Port.*/Port 22/g' /etc/ssh/sshd_config sed -i 's/^#\\?PermitRootLogin.*/PermitRootLogin yes/g' /etc/ssh/sshd_config sed -i 's/^#\\?PasswordAuthentication.*/PasswordAuthentication yes/g' /etc/ssh/sshd_config sed -i 's/#ListenAddress 0.0.0.0/ListenAddress 0.0.0.0/' /etc/ssh/sshd_config sed -i 's/#ListenAddress ::/ListenAddress ::/' /etc/ssh/sshd_config sed -i 's/#AddressFamily any/AddressFamily any/' /etc/ssh/sshd_config sed -i '/^#UsePAM\\|UsePAM/c #UsePAM no' /etc/ssh/sshd_config sed -i 's/^#\\?PubkeyAuthentication.*/PubkeyAuthentication no/g' /etc/ssh/sshd_config sed -i '/^AuthorizedKeysFile/s/^/#/' /etc/ssh/sshd_config systemctl restart sshd systemctl restart ssh ","date":"2024-05-11","objectID":"/20240511/:1:0","tags":["linux","ubuntu","ssh","server","机房"],"title":"给机房的Ubuntu22.04的Linux安装SSH的server","uri":"/20240511/"},{"categories":["电脑技巧"],"content":"前置条件 cd /root apt update apt install curl sudo -y ","date":"2024-05-10","objectID":"/20240510/:1:0","tags":["linux","ubuntu","debian","github","runner","docker","root","机房"],"title":"在root权限下使用守护进程自托管Github的Runners","uri":"/20240510/"},{"categories":["电脑技巧"],"content":"安装 执行下述命令 export RUNNER_ALLOW_RUNASROOT=1 执行后正常安装至于./config那一步，然后不要使用官方的启动方式，而是使用守护进程启动，做到runner开机自启以及日志记录 nano /etc/systemd/system/github-runner.service 添加内容 [Unit] Description=GitHub Actions Runner [Service] Type=simple WorkingDirectory=/root/actions-runner ExecStart=/root/actions-runner/run.sh User=root Restart=always Environment=\"RUNNER_ALLOW_RUNASROOT=1\" [Install] WantedBy=multi-user.target 按ctrl+x然后按y保存然后按两次enter退出编辑 然后执行 sudo systemctl daemon-reload sudo systemctl start github-runner 启动守护进程 执行 sudo systemctl status github-runner 查看守护进程状态，如果状态为active则说明启动成功，否则就需要排障 查看完毕按ctrl+c退出查询，然后执行 sudo systemctl enable github-runner 设置开机自启 ","date":"2024-05-10","objectID":"/20240510/:2:0","tags":["linux","ubuntu","debian","github","runner","docker","root","机房"],"title":"在root权限下使用守护进程自托管Github的Runners","uri":"/20240510/"},{"categories":["电脑技巧"],"content":"后言 这样通过守护进程启动runner可以确保重启服务器后自动启动runner，且日志有记录在守护进程的日志中，也方便查看该进程占用的资源大小 注意，这种方法将在root环境中部署runner，你的action直接在root环境下执行，如果action有问题将可能导致root环境出问题，务必保证使用该runner时action无环境问题。 ","date":"2024-05-10","objectID":"/20240510/:3:0","tags":["linux","ubuntu","debian","github","runner","docker","root","机房"],"title":"在root权限下使用守护进程自托管Github的Runners","uri":"/20240510/"},{"categories":["电脑技巧"],"content":"前言 前置条件以及一些碎碎念： 至少两块硬盘，一块硬盘已安装Windows11，另一块硬盘用于安装Ubuntu22.04，两块硬盘保证系统不会互相影响出奇怪的问题 为什么选择Ubuntu22.04？因为前不久刚发布了新的LTS版本24.04，不敢追新怕出现什么奇葩问题没有先验的经验，所以还是使用第二新的LTS版本22.04保险一些，保证系统稳定易于维护。 Ubuntu22.04下载地址(4.7GB-下载到你的本地，不是U盘中)： https://releases.ubuntu.com/22.04/ 一个读写速率比较好的U盘，用于制作启动盘，由于启动盘需要使用rufus进行启动盘制作，所以需要U盘格式化，需要确保U盘制作前为空U盘 rufus下载地址(下载到你的本地，不是U盘中)： https://rufus.ie/zh/ 或 https://github.com/pbatard/rufus 安装过程中需要选择引导方式，两个选择：Windows Boot Manager或Grub，前者需要windows下面添加引导条目，后者需要手动分区，在安装后添加grub引导条目。 不管选择何种引导方式，都不要相信和*****共存的选项，因为是装的双系统，需要保留WIN系统的相关分区，Ubuntu在安装时会提示和Windows Boot Manager共存，如果选择该项，那么硬盘上就真的只剩Ubuntu相关分区和Windows Boot Manager了，WIN系统相关分区直接没了。 为了保险，推荐安装双系统前整机进入BIOS中GOST备份(睡觉前挂上，运行非常慢)。然后安装时手动进行分区(不要相信自动分区的鬼话，那是给纯净的机器用的，不是给双系统用的)，然后在GRUB手写一个WIN11的启动项。(不要瞎转换硬盘格式) 这里推荐使用https://linux.cn/article-14699-1.html作为前置教程，进行相关流程了解。 ","date":"2024-05-09","objectID":"/20240509/:1:0","tags":["linux","windows11","rufus","双系统","BIOS","GOST","UEFI","GPU","easyuefi","ubuntu","机房"],"title":"给机房的windows11系统安装Ubuntu22.04的Linux双系统","uri":"/20240509/"},{"categories":["电脑技巧"],"content":"制作U盘引导盘 选择使用DD写入U盘 点击开始后等待几分钟即可，DD写入成功后，正常安全退出U盘即可。(启动盘制作完成，回退回普通U盘的方法后续会介绍) ","date":"2024-05-09","objectID":"/20240509/:2:0","tags":["linux","windows11","rufus","双系统","BIOS","GOST","UEFI","GPU","easyuefi","ubuntu","机房"],"title":"给机房的windows11系统安装Ubuntu22.04的Linux双系统","uri":"/20240509/"},{"categories":["电脑技巧"],"content":"切分分区 按下 Windows + R 组合键来打开磁盘管理器实用程序 输入 diskmgmt.msc 打开磁盘管理器，如下图 下面可选从已有的盘中分一部分出来用，或者选择整个盘拿来用(注意，这里千万不能使用C盘，因为C盘是windows系统盘，如果C盘被Linux拿来用，那么windows系统很可能就无法正常使用了，所以千万不能使用C盘) 1.选择一个卷(里面的数据的全部不需要了)进行压缩卷处理，如下图 划分25G硬盘给Linux使用 2.如果这个盘你想要整个盘用作Linux使用，那么直接点击删除卷即可，如下图 由于这次我安装的工作站硬盘很大，4TSATA+2TSSD，我选择将整个2T大小的D盘作为Linux系统使用，所以我使用了方法2。 ","date":"2024-05-09","objectID":"/20240509/:3:0","tags":["linux","windows11","rufus","双系统","BIOS","GOST","UEFI","GPU","easyuefi","ubuntu","机房"],"title":"给机房的windows11系统安装Ubuntu22.04的Linux双系统","uri":"/20240509/"},{"categories":["电脑技巧"],"content":"引导安装 上述两个方法选其一操作，操作完毕后就有了可用做Linux使用的空间，现在将可启动 USB 驱动器插入到你的电脑 ，重新启动你的电脑。启动过程中狂按F12进入 BIOS 设置修改启动优先级，来使 USB 驱动器成为第一优先级，保存 BIOS 更改并继续启动。(我实际测试中工作站是直接显示可选使用哪个UEFI项启动，选择对应U盘的UEFI项启动即可，如下图) 选择USB对应的UEFI启动后，进入GRUB选择Try or Install Ubuntu按回车 Ubuntu 22.04 将开始加载，这最多需要一分钟时间进入Ubuntu的图形界面。 更改引导的语言为简体中文，然后点击安装Ubuntu 此时会进入选择键盘设置的界面，可如下图选英文键盘，也可以如后一个图一样选中文键盘，没什么区别 选完点继续，进入安装选择，勾选如下图，再点继续 ","date":"2024-05-09","objectID":"/20240509/:4:0","tags":["linux","windows11","rufus","双系统","BIOS","GOST","UEFI","GPU","easyuefi","ubuntu","机房"],"title":"给机房的windows11系统安装Ubuntu22.04的Linux双系统","uri":"/20240509/"},{"categories":["电脑技巧"],"content":"手动划分分区 此时下图是重点中的重点，一点要选择其他选项(Something else)，千万不要选择共存(共存就擦除WIN系统了)，这个千万别勾选错，然后点继续 这里可以看到空闲区间，如果你没有看到空闲区间，那么你需要在这个页面上勾选你之前选择的盘对应的路径，然后点减号删除分区(重点：一定要通过之前分区的大小和空闲区间的大小来判断，哪个分区是你之前选择做Linux系统的，千万别删错删了WIN系统盘，不然就救不回来了，切记切记) 然后就是点击那个空闲分区，点加号，手动划分分区 针对 Ubuntu 22.04 ，将创建下面的分区(注意创建的顺序，不要搞错了)： /boot – 1024MB - 1GB /home – 10240MB - 10GB 交换分区 – 65535MB - 64GB - 因为我实际物理内存64G，SWAP开等大的即可 EFI – 300 MB / – 空闲分区余下的空间 创建后如下，然后点现在安装 遇到下面的界面，点继续 过一会就要选择地区，这里填shanghai，或者直接鼠标点中国地图那就行，然后点继续 再过一会就是填写登录信息，填写完毕务必记录登录的密码和用户名，因为后续我需要长期使用，所以勾选了自动登录，不勾选自动登录，勾选登陆时需要密码也可，然后点继续 后续安装进度条跑满大概需要10~30分钟，然后出现下图提示 点现在重启即可，进入重启且黑屏后，拔掉U盘即可，然后启动时应该以装好的Ubuntu的GRUB界面引导启动如下 此时按回车即可启动Ubuntu系统 如果要切换回windows11系统，GRUB界面选择Windows Boot Manager，然后按回车即可 ` 在WIN系统中可见D盘不可获取大小，因为我已经将整个D盘分配给Linux使用了 ","date":"2024-05-09","objectID":"/20240509/:5:0","tags":["linux","windows11","rufus","双系统","BIOS","GOST","UEFI","GPU","easyuefi","ubuntu","机房"],"title":"给机房的windows11系统安装Ubuntu22.04的Linux双系统","uri":"/20240509/"},{"categories":["电脑技巧"],"content":"更改启动项 实际机房的工作站默认给WIN系统配了第一优先级，我需要修改为Ubuntu系统为第一优先级，方法有两个： 启动机器时，狂按F1或者F2按键，进入BIOS界面，设置主要启动顺序 在WIN系统中使用easyuefi直接设置启动顺序 由于机房使用PXE部署了噢易系统，所以上述方法修改启动项都是无用的，千万不能再启动WIN11了，否则就永远也无法进入Ubuntu系统了，只能重新安装Ubuntu系统 ","date":"2024-05-09","objectID":"/20240509/:6:0","tags":["linux","windows11","rufus","双系统","BIOS","GOST","UEFI","GPU","easyuefi","ubuntu","机房"],"title":"给机房的windows11系统安装Ubuntu22.04的Linux双系统","uri":"/20240509/"},{"categories":["电脑技巧"],"content":"后言 后续将教授怎么使用Ubuntu系统通过LXD开设LXC容器共享宿主机资源(含GPU资源)、内穿机房端口至于公网IPV4上、部署Github的Runner等内容 ","date":"2024-05-09","objectID":"/20240509/:7:0","tags":["linux","windows11","rufus","双系统","BIOS","GOST","UEFI","GPU","easyuefi","ubuntu","机房"],"title":"给机房的windows11系统安装Ubuntu22.04的Linux双系统","uri":"/20240509/"},{"categories":["Golang","Python"],"content":"前言 之前有使用 FastAPI 开发过一套后端，但占用属实有点大，最近使用 Gin-Vue-Admin 进行重构，在构建爬虫模块的时候，发现了一些有趣的事情，Python的重定向比Golang的重定向次数要少 ","date":"2024-03-28","objectID":"/20240328/:1:0","tags":["requests","gorequest","重定向"],"title":"Golang的重定向比Python的重定向次数要多","uri":"/20240328/"},{"categories":["Golang","Python"],"content":"复现 package main import ( \"fmt\" \"net/http\" ) func main() { url := \"https://my.speedypage.com/aff.php?aff=4\u0026pid=58\" // 创建一个 HTTP 客户端 client := \u0026http.Client{ CheckRedirect: func(req *http.Request, via []*http.Request) error { // 打印重定向信息 fmt.Printf(\"Redirected to: %s, Status Code: %d\\n\", req.URL, req.Response.StatusCode) return nil }, } // 发送 GET 请求 response, err := client.Get(url) if err != nil { fmt.Println(\"Error:\", err) return } defer response.Body.Close() // 打印最终的 URL 和状态码 fmt.Println(\"Final URL:\", response.Request.URL) fmt.Printf(\"Final Status Code: %d\\n\", response.StatusCode) } 输出为 Redirected to: https://my.speedypage.com/cart.php?a=add\u0026pid=58, Status Code: 302 Redirected to: https://my.speedypage.com/store/sg-vps/sg-kvm-1g, Status Code: 302 Redirected to: https://my.speedypage.com/cart.php?a=confproduct\u0026i=0, Status Code: 302 Redirected to: https://my.speedypage.com/cart.php, Status Code: 302 Redirected to: https://my.speedypage.com/store/web-hosting, Status Code: 302 Final URL: https://my.speedypage.com/store/web-hosting Final Status Code: 200 于此同时 import requests def main(): url = \"https://my.speedypage.com/aff.php?aff=4\u0026pid=58\" redirect_count = 0 response = requests.get(url, allow_redirects=True) print(\"Final URL:\", response.url) for redirect in response.history: redirect_count += 1 print( f\"Redirected to: {redirect.url}, Status Code: {redirect.status_code}\") print( f\"Total Redirects: {redirect_count}, Final Status Code: {response.status_code}\" ) if __name__ == \"__main__\": main() 输出为 Final URL: https://my.speedypage.com/cart.php?a=confproduct\u0026i=0 Redirected to: https://my.speedypage.com/aff.php?aff=4\u0026pid=58, Status Code: 302 Redirected to: https://my.speedypage.com/cart.php?a=add\u0026pid=58, Status Code: 302 Redirected to: https://my.speedypage.com/store/sg-vps/sg-kvm-1g, Status Code: 302 Total Redirects: 3, Final Status Code: 200 发现了没有，这里的302重定向，在python中是3次，在golang中是5次，最后的200状态码的最终地址居然是不一样的！ ","date":"2024-03-28","objectID":"/20240328/:2:0","tags":["requests","gorequest","重定向"],"title":"Golang的重定向比Python的重定向次数要多","uri":"/20240328/"},{"categories":["Golang","Python"],"content":"原因 查询了相关资料，没有进行实际的摸索，但我猜测是重定向过程中，某些参数设置失效或不同造成的，极大可能和 https://stackoverflow.com/questions/76095713/a-request-made-in-go-lang-gets-blocked-when-python-requests-and-curl-works 是同样或类似的原因，默认很多参数配置同Python的不一致(非cookie)，导致302重定向没有在应该在的目标地址返回200状态码。 ","date":"2024-03-28","objectID":"/20240328/:3:0","tags":["requests","gorequest","重定向"],"title":"Golang的重定向比Python的重定向次数要多","uri":"/20240328/"},{"categories":["Golang","Python"],"content":"修复方法 不要使用默认的http包构建请求，使用第三方封装的gorequests就能解决这个问题，虽然问题原因不清楚，但是解决了（ package main import ( \"fmt\" \"github.com/parnurzeal/gorequest\" ) func main() { url := \"https://my.speedypage.com/aff.php?aff=4\u0026pid=58\" request := gorequest.New() resp, body, err := request.Get(url).End() if err != nil { fmt.Println(\"Error creating request:\", err) return } fmt.Println(\"Final URL:\", resp.Request.URL) fmt.Println(\"Final Status Code:\", resp.StatusCode) fmt.Println(\"Response Body:\", string(body)) } ","date":"2024-03-28","objectID":"/20240328/:4:0","tags":["requests","gorequest","重定向"],"title":"Golang的重定向比Python的重定向次数要多","uri":"/20240328/"},{"categories":["Golang","Python"],"content":"后言 后续有空也许会追加对这方面的摸索，看看具体是啥原因造成的 ","date":"2024-03-28","objectID":"/20240328/:5:0","tags":["requests","gorequest","重定向"],"title":"Golang的重定向比Python的重定向次数要多","uri":"/20240328/"},{"categories":["电脑技巧"],"content":"前言 最近在玩IPV6，遇到不少没人记录和讨论过的问题，做做记录和吐槽。 ","date":"2024-01-11","objectID":"/20240111/:1:0","tags":["linux","pve","vps","kvm","virtual","qemu","ipv6","debian","slaac","DHCPV6"],"title":"一些关于IPV6分配和使用的闲聊","uri":"/20240111/"},{"categories":["电脑技巧"],"content":"pve proxmox-ve虽然是开源的受大多数人使用的平台，但在网络管理方面还是一塌糊涂 缺点1： 如果更改/etc/network/interfaces文件，添加大于或等于3个vmbr开头的虚拟网卡，那么会导致WEB面板该区域管理失效，最终只能通过修改对应文件后重启网络加载，没法web端操作配置了，属实难绷，这个BUG不知道什么时候能被修复了。 缺点2：不支持IPV4/IPV6以auto方式自动分配，起码在PVE安装前是不能这么配置的，否则会导致ifupdown/ifupdown2安装失败，这个包安装失败会卡死PVE剩余的安装导致后续安装都出错，所以安装前PVE只能接受静态或手动配置状态的网络。 缺点3：对Windows开设的支持极其的差，使用cloudbase做cloudinit的替代品也还是得修改PVE底层源码，patch部分代码后才能正常使用，否则根本读取不到密码配置，极其的麻烦，官方似乎也没啥动作去适配，社区维护的第三方patch不能通杀所有版本，还得下对应PVE版本才能patch修复，实在令人心累。 优点的话不少，各种自定义的东西都能应用到上面去，比如配合 https://github.com/oneclickvirt/6in4 分配各种隧道给开设出的虚拟机/容器啥的 ","date":"2024-01-11","objectID":"/20240111/:2:0","tags":["linux","pve","vps","kvm","virtual","qemu","ipv6","debian","slaac","DHCPV6"],"title":"一些关于IPV6分配和使用的闲聊","uri":"/20240111/"},{"categories":["电脑技巧"],"content":"ipv6分配 各服务器厂商的自动分配协议无非两种：DHCPV6和SLAAC。 前者还好说，转为静态配置可以直接使用，后者就不好说了，因为SLAAC分配的IPV6地址是动态生成的，写死的话重启服务器可能导致物理地址更改连带对应原本的IPV6更改为新的IPV6地址，然后整个V6的网络就没了，DNS解析直接失效，DNS地址都ping不通，然后如果v4和v6厂商连带设置的话，那么二者的DNS都将失效，域名都无法解析了，倒是SSH登录没啥问题。 SLAAC的IPV6地址有三种特点，详见： https://github.com/spiritLHLS/pve/blob/main/scripts/check_kernal.sh#L310 如果遇到，IPV6网络厂商可能给你用也可能不给你用当前子网下的别的地址。 有的厂商可能做的好，分配/128地址，避免你手动附加IPV6地址后仍能ping通，而有的厂商就随意的不行，直接写的/112或者/64，然后你附加IPV6地址后即便能ping通，过一段时间后也会被掐掉网络，别问我为啥知道的… ","date":"2024-01-11","objectID":"/20240111/:3:0","tags":["linux","pve","vps","kvm","virtual","qemu","ipv6","debian","slaac","DHCPV6"],"title":"一些关于IPV6分配和使用的闲聊","uri":"/20240111/"},{"categories":["电脑技巧"],"content":"ipv6使用 不得不吐槽大多数厂商给IPV6的网络做了MAC地址校验，非对应的请求不回复，也就是说直接分配V6给开设出的虚拟机/容器的话是不通的。但不少人通过技术手段，可以绕过这个限制，这里总结一下两种方式。 方法1：不去分配，而是做全端口NAT映射，子网内的一个公网V6地址直接通过ip6tables映射给一个虚拟机/容器的内网IPV6地址，并添加对应的IPV6路由，这样可以绕过地址校验限制。还有一个好处是这种方式不需要细究很多奇葩的网络拓扑结构，只需要确保宿主机本身可以使用子网内的IPV6地址就行了，不会有别的奇奇怪怪的问题。缺点就是不雅观，每加一个虚拟机/容器就要多一条映射规则，而且需要额外配置NAT规则，如果哪条NAT规则配置不正确，那么整个宿主机的映射可能会出问题。然后重启后路由会消失，需要重新配置，这块最好写到网络配置文件中自动添加路由。 方法2：要去分配，所以要解决两个问题–MAC地址校验和NDP邻居发现协议的问题。具体问题怎么来的缘由我就不说了，这里只说解决思路。MAC地址校验可以通过使用本子网下的IPV6地址(通常是宿主机现在本身已附加上的IPV6地址)做下游虚拟机/容器的IPV6的gateway地址，而不直接使用宿主机的IPV6的gateway地址，然后创建一个新的纯IPV6的虚拟网关，这样就绕过了第一个问题。NDP邻居发现协议问题可以通过魔改的 https://github.com/yoursunny/ndpresponder 解决，原理类同原始的 [ndppd][ndppd] ，优点在于不仅限于docker网络，可以使用在别的网络里。 当然肯定还有别的解决方法，比如在dhcpv6协议下如何解决，肯定也有不同的方案。 以上方法仅限于宿主机本身使用静态类型的IPV6网络，非dhcpv6也非SLAAC，如果宿主机本身使用的是SLAAC，大概率只能用方法1了。 我在 https://www.spiritlhl.net/ 中使用了上述所有方法，验证了在PVE、LXD、Docker下都能行得通，且基本都使用方法2，方法1仅在LXD环境下测试过没问题，也仅LXD可选方法1。 ","date":"2024-01-11","objectID":"/20240111/:4:0","tags":["linux","pve","vps","kvm","virtual","qemu","ipv6","debian","slaac","DHCPV6"],"title":"一些关于IPV6分配和使用的闲聊","uri":"/20240111/"},{"categories":["电脑技巧"],"content":"后言 IPV6的免费隧道最近才知道 https://tunnelbroker.net/ 有提供 /48 的子网，但每日仅能申请一次 跳转 这个子网大小是我见过的免费隧道中最大的，最难得的还没被 cloudflare 封禁解析，属实难得，就是不知道能撑到啥时候喽 ","date":"2024-01-11","objectID":"/20240111/:5:0","tags":["linux","pve","vps","kvm","virtual","qemu","ipv6","debian","slaac","DHCPV6"],"title":"一些关于IPV6分配和使用的闲聊","uri":"/20240111/"},{"categories":["机器学习","Python"],"content":"GNN ","date":"2023-11-09","objectID":"/20231101/:1:0","tags":["机器学习","深度学习","图神经网络","GNN","GIN","CS244W"],"title":"神经网络(GNN)的表达能力","uri":"/20231101/"},{"categories":["机器学习","Python"],"content":"GIN ","date":"2023-11-09","objectID":"/20231101/:2:0","tags":["机器学习","深度学习","图神经网络","GNN","GIN","CS244W"],"title":"神经网络(GNN)的表达能力","uri":"/20231101/"},{"categories":["电脑技巧"],"content":"前言 众所周知的原因，服务器大厂的监控一直是介于保护隐私和侵犯隐私的边缘的，所以为了去除掉这些烦人的监控，我开发了下面的脚本进行一键卸载 ","date":"2023-10-25","objectID":"/20231025/:1:0","tags":["linux"],"title":"阿里云、腾讯云、甲骨文云、华为云、UCLOUD的监控卸载","uri":"/20231025/"},{"categories":["电脑技巧"],"content":"脚本 脚本仓库：https://github.com/spiritLHLS/one-click-installation-script 一键删除平台监控 一键移除大多数云服务器监控 涵盖阿里云、腾讯云、华为云、UCLOUD、甲骨文云、京东云 国际： curl -L https://raw.githubusercontent.com/spiritLHLS/one-click-installation-script/main/install_scripts/dlm.sh -o dlm.sh \u0026\u0026 chmod +x dlm.sh \u0026\u0026 bash dlm.sh 国内 curl -L https://cdn0.spiritlhl.top/https://raw.githubusercontent.com/spiritLHLS/one-click-installation-script/main/install_scripts/dlm.sh -o dlm.sh \u0026\u0026 chmod +x dlm.sh \u0026\u0026 bash dlm.sh 或 curl -L https://ghproxy.com/https://raw.githubusercontent.com/spiritLHLS/one-click-installation-script/main/install_scripts/dlm.sh -o dlm.sh \u0026\u0026 chmod +x dlm.sh \u0026\u0026 bash dlm.sh ","date":"2023-10-25","objectID":"/20231025/:2:0","tags":["linux"],"title":"阿里云、腾讯云、甲骨文云、华为云、UCLOUD的监控卸载","uri":"/20231025/"},{"categories":["电脑技巧"],"content":"后言 卸载后，无论怎么重启服务器监控都不会启动了，目前网上的其他教程重启后仍旧会自启动监控，这是本脚本对比它们的优化之处 ","date":"2023-10-25","objectID":"/20231025/:3:0","tags":["linux"],"title":"阿里云、腾讯云、甲骨文云、华为云、UCLOUD的监控卸载","uri":"/20231025/"},{"categories":["机器学习","Python"],"content":"GAT 原文： ","date":"2023-10-24","objectID":"/20231024/:1:0","tags":["机器学习","深度学习","图神经网络","GAT","MPNN","CS244W"],"title":"GAT 详解","uri":"/20231024/"},{"categories":["机器学习","Python"],"content":"流程 上面这个是计算每个邻居节点和当前节点之间的重要性，下面这里是softmax这些值，计算每个节点和当前节点之间的权重，权重和为1. 上面这里的a是一个函数，进去两个嵌入，吐出e(重要性)(也可以是一个新嵌入)。 这个a函数是可以自行设定的，上面示例中是直接concat后做一个线性变换这两步加起来叫做a函数，实际可以替换为别的方式。 上面这种机制相当于同时学习同一对节点，不同a函数(不同的重要性计算方式)的重要性，然后最后再聚合起来。 ","date":"2023-10-24","objectID":"/20231024/:2:0","tags":["机器学习","深度学习","图神经网络","GAT","MPNN","CS244W"],"title":"GAT 详解","uri":"/20231024/"},{"categories":["机器学习","Python"],"content":"总结 优点： 每对节点可并行计算。 这里的a函数是可学习的，在迁移新图时，原有的参数的模型会保存有一些关系，这些关系在新图中部分存在，会减少新图的训练时间，是可共享的参数。 可以应用在完全没有训练过的新图上，因为某些重要性的关系是类似或者相同的，原有的a函数模型已经保存了这些关系，新图上也可以用。 GCN使用节点的度做为归一化的权重，而GAT使用自己学习到邻居的重要性去作为归一化的权重。 ","date":"2023-10-24","objectID":"/20231024/:3:0","tags":["机器学习","深度学习","图神经网络","GAT","MPNN","CS244W"],"title":"GAT 详解","uri":"/20231024/"},{"categories":["机器学习","Python"],"content":"拓展 以下为常用GNN技术 ","date":"2023-10-24","objectID":"/20231024/:4:0","tags":["机器学习","深度学习","图神经网络","GAT","MPNN","CS244W"],"title":"GAT 详解","uri":"/20231024/"},{"categories":["机器学习","Python"],"content":"前言 空域提出 –\u003e 频域提出 –\u003e 图神经网络提出 –\u003e 主要回到空域发展 图表示学习 和 图神经网络 平行的两个方向，互补的方向。 ","date":"2023-10-23","objectID":"/20231023/:1:0","tags":["机器学习","深度学习","图神经网络","GraphSAGE","MPNN","CS244W"],"title":"GraphSAGE 详解","uri":"/20231023/"},{"categories":["机器学习","Python"],"content":"MPNN 后面两个图神经网络都是基于 MPNN 进行改进的。 ","date":"2023-10-23","objectID":"/20231023/:2:0","tags":["机器学习","深度学习","图神经网络","GraphSAGE","MPNN","CS244W"],"title":"GraphSAGE 详解","uri":"/20231023/"},{"categories":["机器学习","Python"],"content":"GraphSAGE 原文：Inductive Representation Learning on Large Graphs 解决 GCN 需要将该节点的整个邻居输入显存进行聚合这个问题的优化，不使用所有邻居进行采样和聚合。 思路：每次更新嵌入时，不使用所有邻居节点进行更新，更新中加入采样(Sample)过程，使用采样后的邻居节点去更新节点的邻居信息。 这里如何采样和聚合是需要自己去定义的。 这里最简单的方式是按距离去采样，聚合则使用一个前馈神经网络。 从这开始 GCN 才能说是有了归纳式学习的特性，之前的 GCN 是直推式学习。 ","date":"2023-10-23","objectID":"/20231023/:3:0","tags":["机器学习","深度学习","图神经网络","GraphSAGE","MPNN","CS244W"],"title":"GraphSAGE 详解","uri":"/20231023/"},{"categories":["机器学习","Python"],"content":"特点 方便在大图上使用，可以随时新增节点，无需重新训练就可以得到嵌入。 训练过程中用到了节点本身的信息，以往的embedding都是用了所有邻居的信息，太多了，所以这里进行了采样。 以往的embedding大多才有SUM聚合邻居信息，没有偏重，GAT给每个边赋予权重，SUM的时候有重要性之分，但这里的GraphSAGE会用别的函数做聚合。 采样的时候，固定了这一层中的邻居数量的最大值，该层邻居数量不能比这个数多。 上面这里无监督的方式还是使用 Random Walk 去确定需要采样哪些节点，有监督的话是使用的一般的MLP做，且可以部分邻居无监督，部分邻居有监督。 上面这里的聚合函数，需要尽量与邻居聚合的顺序无关(symmetric)，需要尽量可训练(trainable)，但可能不同时满足，但第一个性质一定满足。 三个聚合函数： 第一个是取平均值保证了顺序不变性，直接concat后取平均，注意是先平均嵌入后再进行训练，称为 GraphSAGE-mean 方法。 这里也有一种方法，不进行concat，而是使用它们做类似 GCN 的操作，然后直接取平均，被称作 GraphSAGE-GCN 方法。 第二个是多次随机顺序进行LSTM，保证最后学到的模型对顺序依赖尽量低，被称为 GraphSAGE-LSTM 方法。 第三个是取最大值，也与顺序无关，注意是训练后再进行取最大值的操作，被称为 GraphSAGE-pool 方法。 上面这里的表现可以看到，DW学到的参数迁移新的图时，又要重新训练了，而GraphSAGE学到的参数迁移到新的图时，已有的参数有学到一些消息传递聚合的结构，适配新图时很迅速。 同时，这里为了兼顾F1，选择了两层计算图，第一层25第二层10个邻居，来达到表现最好的情况。 ","date":"2023-10-23","objectID":"/20231023/:3:1","tags":["机器学习","深度学习","图神经网络","GraphSAGE","MPNN","CS244W"],"title":"GraphSAGE 详解","uri":"/20231023/"},{"categories":["机器学习","Python"],"content":"相关资料 https://arxiv.org/pdf/1706.02216.pdf https://docs.google.com/presentation/d/1ipsFHlW4-kwjkPhJlMg4kLKRtmvcXBidBQgBS5lOaAM/edit#slide=id.g225699dd435_0_170 https://zhuanlan.zhihu.com/p/62750137 https://colah.github.io/posts/2015-08-Understanding-LSTMs/ ","date":"2023-10-23","objectID":"/20231023/:4:0","tags":["机器学习","深度学习","图神经网络","GraphSAGE","MPNN","CS244W"],"title":"GraphSAGE 详解","uri":"/20231023/"},{"categories":["机器学习","Python"],"content":"前言 GCN 可以说是一个函数拟合器。 每个计算图就是一个样本 感受野是指神经网络中某一层输出的单元对输入的局部区域的敏感程度。实际上层数不宜过多，否则后续层数感受野会越来越相似。 求和节点本身属性构成的0层向量，然后取平均。 这一步求了一层的 embedding 。 ","date":"2023-10-22","objectID":"/20231022/:1:0","tags":["机器学习","深度学习","图神经网络","CNN","GCN","CS244W"],"title":"GCN 详解","uri":"/20231022/"},{"categories":["机器学习","Python"],"content":"空域中讨论GCN的求解过程 这是从图论那套玩意中延展出来的。 简单直接求平均其实不好，没有体现各节点的重要程度，可以按照各节点的度按比例分配。 还得约束特征值在-1到1之间，但最大特征值能到1，前者到不了1. 总结为一下图，其实就是用代数语言描绘每层的计算图之间怎么计算的，左边是数学表达式，聚合邻居的embedding求平均，右边是线性代数的表达式，只不过描绘的更详细，考虑了节点之间不通的重要程度用节点的度去刻画。 这个 Á 其实就是邻接矩阵替换了值，权值不再是0或1，而是根据我的连接数和对方的连接数，算出来的一个新的权值。 只要图已经构建出来了，这个 Á 就是固定的了，不需要学习就已给定。 图卷积原文提及的： l+1层的嵌入通过l层的嵌入左乘Á(Nomilarization adjacency matrix)右乘神经网络权重然后经过非线性激活函数就得到了。可学习的参数只有神经网络的权重矩阵。 ","date":"2023-10-22","objectID":"/20231022/:2:0","tags":["机器学习","深度学习","图神经网络","CNN","GCN","CS244W"],"title":"GCN 详解","uri":"/20231022/"},{"categories":["机器学习","Python"],"content":"频域(谱域)里讨论GCN的求解过程 这是从信号与图像处理那套玩意延展出来的。 GCN（Graph Convolutional Network）是一种用于处理图数据的神经网络，它试图解决CNN（Convolutional Neural Network）在处理图数据时缺乏置换不变性的问题。 在CNN中，卷积操作是基于局部相邻区域的权重共享，这在图数据上并不直接适用，因为图数据的结构是任意的，节点之间的连接并非固定。GCN通过引入图卷积操作，考虑节点与其相邻节点之间的关系，以捕捉图结构的信息。 关于置换不变性，GCN通过采用图拉普拉斯矩阵来实现。图拉普拉斯矩阵考虑了节点之间的连接关系，因此在一定程度上提供了置换不变性。通过对图拉普拉斯矩阵进行归一化和转换，GCN能够在学习节点表示时保持一定的置换不变性。 总体来说，GCN通过在图结构上引入卷积操作，结合图拉普拉斯矩阵来考虑节点之间的关系，以解决CNN在图数据上缺乏置换不变性的问题。 谱分解 = 特征值分解 = 对角化 都是同一个意思 ","date":"2023-10-22","objectID":"/20231022/:3:0","tags":["机器学习","深度学习","图神经网络","CNN","GCN","CS244W"],"title":"GCN 详解","uri":"/20231022/"},{"categories":["机器学习","Python"],"content":"计算图 改进 加一个自己引向自己的信息。 扩展：邻域节点一套权重，selfembedding一套权重。(还是同一个网络，只不过有两套权重) Bk去掉才是残差连接(Resnet 那种)，这里不是那种连接。 此处红色是邻域信息汇聚，蓝色是自己信息的转换。 ","date":"2023-10-22","objectID":"/20231022/:4:0","tags":["机器学习","深度学习","图神经网络","CNN","GCN","CS244W"],"title":"GCN 详解","uri":"/20231022/"},{"categories":["机器学习","Python"],"content":"如何训练图神经网络(GCN) 可通过有监督学习、无监督学习(自监督学习)的方式训练。 ","date":"2023-10-22","objectID":"/20231022/:5:0","tags":["机器学习","深度学习","图神经网络","CNN","GCN","CS244W"],"title":"GCN 详解","uri":"/20231022/"},{"categories":["机器学习","Python"],"content":"监督学习 ","date":"2023-10-22","objectID":"/20231022/:5:1","tags":["机器学习","深度学习","图神经网络","CNN","GCN","CS244W"],"title":"GCN 详解","uri":"/20231022/"},{"categories":["机器学习","Python"],"content":"无监督学习 本身没有标签，用图自身结构作为自监督的标注。 ","date":"2023-10-22","objectID":"/20231022/:5:2","tags":["机器学习","深度学习","图神经网络","CNN","GCN","CS244W"],"title":"GCN 详解","uri":"/20231022/"},{"categories":["机器学习","Python"],"content":"图神经网络(GNN)的优点(注意不是只有GCN的优点) GCN（图卷积网络）属于直推式学习（transductive learning）。在直推式学习中，模型在训练和测试过程中都可以访问整个图结构，从而能够对图中的节点进行有效的表示学习。这与归纳式学习不同，归纳式学习在测试阶段只能访问训练时未见过的数据。 GCN相较于传统的机器学习方法，使用了节点的属性信息做特征，计算图又学习到了结构信息，这是优点。 新节点来了，可以马上获得新节点的嵌入和预测结果，在推荐系统中称呼为 冷启动 。 哪怕未经训练，仅计算原始的图嵌入，就已经大致可分类了： CNN 不具备置换不变性，GCN 解决了这个问题。 Tansformers 可以看作是词图上的全连接GNN。 ","date":"2023-10-22","objectID":"/20231022/:5:3","tags":["机器学习","深度学习","图神经网络","CNN","GCN","CS244W"],"title":"GCN 详解","uri":"/20231022/"},{"categories":["机器学习","Python"],"content":"总结 ","date":"2023-10-22","objectID":"/20231022/:6:0","tags":["机器学习","深度学习","图神经网络","CNN","GCN","CS244W"],"title":"GCN 详解","uri":"/20231022/"},{"categories":["电脑技巧"],"content":"给轻量应用腾讯云服务器加上IPV6地址隧道 这里使用6in4方法解决宿主机本身没有IPV6地址的问题。 给宿主机附加免费的IPV6地址段 有的机器本身没有IPV6的/64子网，这里给出一个方法免费附加IPV6的子网。 这里是使用6in4方法解决宿主机本身没有IPV6地址的问题。 以下是2023年目前还在运行的免费提供IPV6子网的平台 支持的平台 对应需要的安装包 协议 通道/子网数量 tunnelbroker.net ifupdown 或 ifupdown2 v4tunnel 或 sit 3✖/64 或 5✖/64 tunnelbroker.ch ifupdown 或 ifupdown2 v4tunnel 或 sit 3✖/64 ip4market.ru ifupdown 或 ifupdown2 v4tunnel 或 sit 1✖/64 netassist.ua ifupdown 或 ifupdown2 v4tunnel 或 sit 1✖/64 https://github.com/oneclickvirt/6in4 ifupdown2 sit、gre、ipip 自定义 免费的平台只解决IPV6有没有的问题，不提供优质的IPV6带宽。 如需优质的带宽，请自建隧道，当ifupdown和ifupdown2都可时，先尝试ifupdown是否可安装成功，否则就安装ifupdown2. 安装完毕后，安装了哪个包后面就选择哪个包进行格式转换。 ","date":"2023-09-29","objectID":"/20211231/:0:0","tags":["linux","ipv6"],"title":"给轻量应用腾讯云服务器或阿里云服务器加上IPV6地址隧道(2023)","uri":"/20211231/"},{"categories":["电脑技巧"],"content":"初始环境修改 执行 touch /etc/cloud/cloud-init.disabled 关闭cloud-init的自动化覆写先，然后查看本机使用什么管理网络，执行 systemctl is-active systemd-networkd 和 systemctl is-active networking 看看属于哪种情况，如果是前者active，后者inactive，你需要重装/DD一个不是这样配置的系统，或者切换本机使用ifupdown/ifupdown2管理网络 # 是否需要禁用原网络管理自行评判 # systemctl stop systemd-networkd # systemctl disable systemd-networkd # systemctl stop systemd-networkd.socket # systemctl disable systemd-networkd.socket 如果需要安装的是ifupdown控制网络，这个工具一般的主流linux系统都有 apt-get install ifupdown -y 如果需要安装的是ifupdown2进行网络管理，而这个工具一般只在debian系上可安装使用 apt-get install ifupdown2 -y 安装完毕后，安装了哪个包后面就选择哪个包进行格式转换。 systemctl start networking systemctl enable networking 然后重启服务器，检验机器的网络是否会因为修改出现重启失联的情况，且执行uptime观察启动已超过1分钟后，再进行后续步骤 如果是是前者inactive，后者active，则不需要切换网络管理程序，直接进行后续操作即可。 由于部分服务器存在默认的内网IPV6路由会与隧道冲突，此时可使用以下命令删除默认的IPV6路由 default_route=$(ip -6 route show | awk '/default via/{print $3}') \u0026\u0026 [ -n \"$default_route\" ] \u0026\u0026 ip -6 route del default via $default_route dev eth0 这里假设了你的客户端的服务器的默认网卡是eth0，你可以使用ip -6 route查看默认的路由并替换它，默认路由以default via开头，使用dev指定默认网卡，你只需要按照这个规则找到它即可 ","date":"2023-09-29","objectID":"/20211231/:1:0","tags":["linux","ipv6"],"title":"给轻量应用腾讯云服务器或阿里云服务器加上IPV6地址隧道(2023)","uri":"/20211231/"},{"categories":["电脑技巧"],"content":"tunnelbroker_net 结合一键开设带IPV6地址的容器的脚本，就能给每个容器附加来自he的IPV6地址了 缺点是地址比较黑/脏，cloudflare的cdn极有可能套不上，自行测试 在 https://tunnelbroker.net/ 注册账户，并点击左边的 Create Regular Tunnel 红框处填写你的服务器的IPV4地址，选择物理距离近的连接点，比如机器在美国洛杉矶，就选美国西海岸的连接点，然后显示绿框提示，点Create Tunnel创建即可 等待出以下界面，点击Example Configurations然后选择对应的系统，比如LXD的宿主机那肯定就是Debian/Ubuntu了 框住的部分就是要修改的文件和需要复制的内容了 复制的时候不要带空行 转换格式后给你的网络配置文件附加IPV6的设置 然后打开 https://ipv6tunnel.spiritlhl.top/ 选择Option为TunnelBrokerNet，另一个下拉选择框选择你之前安装成功的包名，然后在输入框内粘贴你复制的内容 然后点击Covert转换格式，等待页面刷新显示转换格式后的配置文件内容 然后用vim或者vi命令修改/etc/network/interfaces文件增加内容，或者修改以下命令新增 tee -a /etc/network/interfaces \u003c\u003cEOF # 这里修改复制粘贴一下转换格式后的配置文件内容，然后执行此命令 EOF 然后你可以使用cat /etc/network/interfaces查看配置文件是否正常写入了 如果上面都没问题，就需要启用网络接口即可 apt-get install net-tools iproute2 -y systemctl restart networking 然后你就可以测试IPV6网络是否已附加 执行ifconfig命令，这时应该有一个 he-ipv6 接口，类似下面这样： 或者执行： curl ipv6.ip.sb 回传你绑定IPV6地址 NAT VPS 的额外设置 IPv4 NAT VPS 除了前面提到的替换 IP 操作以外，可能还需要一些额外的设置，否则可能还是无法访问 IPv6 网络。 apt-get install ufw -y ufw allow 41 添加相关的路由规则 route -A inet6 add ::/0 dev he-ipv6 如果不需要该IPV6网络了，想要删除 删除 he-ipv6 网络接口配置（若没有删除重启后会自动启用），记得修改/etc/network/interfaces文件，删除之前红框添加的内容 然后重启服务器，就删除了 ","date":"2023-09-29","objectID":"/20211231/:2:0","tags":["linux","ipv6"],"title":"给轻量应用腾讯云服务器或阿里云服务器加上IPV6地址隧道(2023)","uri":"/20211231/"},{"categories":["电脑技巧"],"content":"tunnelbroker_ch 类似上述的操作，先在 https://www.tunnelbroker.ch/ 注册一个账户先，注册后点击激活的邮件 然后就是填写你的服务器IPV4地址 创建后需要进入Config页面而不是详情页面 见到以下页面千万别使用，先刷新一下本页面，不要弹那个浅蓝色框后再停止刷新 记录以下页面的最后一个红框的内容，准备修改宿主机配置文件 页面的最后一个红框框住的部分复制下来，不要带空行 然后打开 https://ipv6tunnel.spiritlhl.top/ 选择Option为TunnelBrokerCh，另一个下拉选择框选择你之前安装成功的包名，然后在输入框内粘贴你复制的内容 然后点击Covert转换格式，等待页面刷新显示转换格式后的配置文件内容 然后用vim或者vi命令修改/etc/network/interfaces文件增加内容，或者修改以下命令新增 tee -a /etc/network/interfaces \u003c\u003cEOF # 这里修改一下 EOF 然后你就需要重启一下系统，或者执行 apt-get install net-tools iproute2 -y systemctl restart networking 保证环境无问题再进行别的操作了 ","date":"2023-09-29","objectID":"/20211231/:3:0","tags":["linux","ipv6"],"title":"给轻量应用腾讯云服务器或阿里云服务器加上IPV6地址隧道(2023)","uri":"/20211231/"},{"categories":["电脑技巧"],"content":"ip4market_ru 类似上述的操作，先在 https://tb.ip4market.ru 注册一个账户先，注册邮箱得是非常见邮箱，电话可随便写不验证的，IP填上你要附加的宿主机的IPV4地址 然后就是过Recaptcha的人机验证，点击注册 邮箱会收到激活邮件，里面附带有你的密码，记住它 然后在首页进行登录 然后就会进入这个页面 按住右键，然后复制红框框住的四行内容，也就是 Server IPv4: Client IPv4 Server IPv6 Client IPv6 这四行内容，按ctrl+c复制或者右键复制 然后打开 https://ipv6tunnel.spiritlhl.top/ 选择Option为ip4market，另一个下拉选择框选择你之前安装成功的包名，然后在输入框内粘贴你复制的内容 然后点击Covert转换格式 然后就会自动刷新页面出现需要自己用vim或者vi命令修改/etc/network/interfaces文件增加的内容了，或者修改以下命令新增 tee -a /etc/network/interfaces \u003c\u003cEOF # 这里修改一下 EOF 然后你就需要重启一下系统，或者执行 apt-get install net-tools iproute2 -y systemctl restart networking 保证环境无问题再进行别的操作了 ","date":"2023-09-29","objectID":"/20211231/:4:0","tags":["linux","ipv6"],"title":"给轻量应用腾讯云服务器或阿里云服务器加上IPV6地址隧道(2023)","uri":"/20211231/"},{"categories":["电脑技巧"],"content":"netassist_ua 这个平台你在切换网络管理时务必使用ifupdown2而不是ifupdown2安装包，该平台使用sit协议，而sit协议需要在ifupdown2控制的环境中使用 类似上述的操作，先在 https://tb.netassist.ua/ 注册一个账户先，注册后点击激活的邮件，激活页面会有密码显示，记得记录 然后就是填写你的服务器IPV4地址，这个后面可以自己修改，先随便填一个都没问题 然后就到了这个页面了 第一个红框是你宿主机的IPV4地址需要填写的位置，要修改就修改那里，然后点change保存 第二个下拉红框选择Linux，然后点击show 会出现上面的内容，全选框住的部分复制下来，不要带空行 然后打开 https://ipv6tunnel.spiritlhl.top/ 选择Option为NetAssist，另一个下拉选择框选择你之前安装成功的包名，然后在输入框内粘贴你复制的内容 然后点击Covert转换格式 然后就会自动刷新页面出现需要自己用vim或者vi命令修改/etc/network/interfaces文件增加的内容了，或者修改以下命令新增 tee -a /etc/network/interfaces \u003c\u003cEOF # 这里修改一下 EOF 然后你就需要重启一下系统，或者执行 apt-get install net-tools iproute2 -y systemctl restart networking 保证环境无问题再进行别的操作了 ","date":"2023-09-29","objectID":"/20211231/:5:0","tags":["linux","ipv6"],"title":"给轻量应用腾讯云服务器或阿里云服务器加上IPV6地址隧道(2023)","uri":"/20211231/"},{"categories":["电脑技巧"],"content":"转移不同服务器之间的IPV6子网 相关仓库：https://github.com/oneclickvirt/6in4 该方法将提供一种方式，将A上的IPV6网段拆分一个子ipv6网段的出来，附加到B上使用 你需要在B所在的服务器上使用本套脚本给容器一键配置IPV6地址 ","date":"2023-09-29","objectID":"/20211231/:6:0","tags":["linux","ipv6"],"title":"给轻量应用腾讯云服务器或阿里云服务器加上IPV6地址隧道(2023)","uri":"/20211231/"},{"categories":["电脑技巧"],"content":"功能 自建sit/gre/ipip协议的IPv6隧道 支持自定义要切分出来的IPV6子网大小，将自动计算出合适的CIDR格式的IPV6子网信息 自动识别服务端的IPV6子网大小 将自动设置隧道服务端并打印客户端需要执行的命令 设置IPV6隧道的方法简单易懂，易于删除 ","date":"2023-09-29","objectID":"/20211231/:6:1","tags":["linux","ipv6"],"title":"给轻量应用腾讯云服务器或阿里云服务器加上IPV6地址隧道(2023)","uri":"/20211231/"},{"categories":["电脑技巧"],"content":"环境准备 VPS(A) VPS(B) 一个IPV4地址(server_ipv4) 一个IPV4地址(clinet_ipv4) 一个IPV6子网 无IPV6地址 以下称之为服务端 以下称之为客户端 ","date":"2023-09-29","objectID":"/20211231/:6:2","tags":["linux","ipv6"],"title":"给轻量应用腾讯云服务器或阿里云服务器加上IPV6地址隧道(2023)","uri":"/20211231/"},{"categories":["电脑技巧"],"content":"使用方法 下载脚本 curl -L https://raw.githubusercontent.com/oneclickvirt/6in4/main/6in4.sh -o 6in4.sh \u0026\u0026 chmod +x 6in4.sh 执行命令 ./6in4.sh client_ipv4 \u003cmode_type\u003e \u003csubnet_size\u003e 选项 可选的选项1 可选的选项2 可选的选项3 \u003cmode_type\u003e gre sit ipip \u003csubnet_size\u003e 64 80 112 \u003cmode_type\u003e暂时只支持那三种协议，越靠前的越推荐，不填则默认为sit协议 \u003csubnet_size\u003e只要比原系统子网掩码大就行，且是8的倍数，不填则默认为80 记得client_ipv4替换为需要附加IPV6的机器的IPV4地址，执行完毕后会回传你需要在客户端执行的命令，详见执行后的说明即可 为防止忘记复制命令，命令本身也将写入到当前路径下的6in4.log文件中，可使用cat 6in4.log查询客户端需要执行的命令 复制下来的命令，务必在 https://ipv6tunnel.spiritlhl.top/ 中选择选项6in4后进行转换 然后就会自动刷新页面出现需要自己用vim或者vi命令修改/etc/network/interfaces文件增加的内容了，或者修改以下命令新增 tee -a /etc/network/interfaces \u003c\u003cEOF # 这里修改一下 EOF 然后你就需要重启一下系统，或者执行 apt-get install net-tools iproute2 -y systemctl restart networking 保证环境无问题再进行别的操作了 ","date":"2023-09-29","objectID":"/20211231/:6:3","tags":["linux","ipv6"],"title":"给轻量应用腾讯云服务器或阿里云服务器加上IPV6地址隧道(2023)","uri":"/20211231/"},{"categories":["电脑技巧"],"content":"检测服务端 systemctl status ndpresponder ip addr show ","date":"2023-09-29","objectID":"/20211231/:6:4","tags":["linux","ipv6"],"title":"给轻量应用腾讯云服务器或阿里云服务器加上IPV6地址隧道(2023)","uri":"/20211231/"},{"categories":["电脑技巧"],"content":"检测客户端 ip addr show curl ipv6.ip.sb ","date":"2023-09-29","objectID":"/20211231/:6:5","tags":["linux","ipv6"],"title":"给轻量应用腾讯云服务器或阿里云服务器加上IPV6地址隧道(2023)","uri":"/20211231/"},{"categories":["电脑技巧"],"content":"删除隧道 服务端 ip link set server-ipv6 down ip tunnel del server-ipv6 客户端 ip link set user-ipv6 down ip tunnel del user-ipv6 以上删除的方式只是临时删除，永久删除务必修改删除/etc/network/interfaces文件中你之前增加的内容 ","date":"2023-09-29","objectID":"/20211231/:6:6","tags":["linux","ipv6"],"title":"给轻量应用腾讯云服务器或阿里云服务器加上IPV6地址隧道(2023)","uri":"/20211231/"},{"categories":["机器学习","Python"],"content":"前言 ","date":"2023-09-28","objectID":"/20230928/:1:0","tags":["机器学习","深度学习","图神经网络","CS244W"],"title":"半监督节点分类","uri":"/20230928/"},{"categories":["机器学习","Python"],"content":"Label Propagation (Relational Classification) 这是一种集体分类方法。 ","date":"2023-09-28","objectID":"/20230928/:2:0","tags":["机器学习","深度学习","图神经网络","CS244W"],"title":"半监督节点分类","uri":"/20230928/"},{"categories":["机器学习","Python"],"content":"Iterative Classification 这是一种集体分类方法。 既要用到节点的连接信息，也要用到节点本身的属性信息(特征)，分别训练两个分类器解决。 我是什么类别仅取决于与我直接相连的节点是什么类别，而间接的邻居与我无关。(马尔可夫假设) 初始化所有节点类别(训练∂1) –\u003e 捕捉相关关系和连接关系(训练∂2) –\u003e 迭代去预测(传播) ","date":"2023-09-28","objectID":"/20230928/:3:0","tags":["机器学习","深度学习","图神经网络","CS244W"],"title":"半监督节点分类","uri":"/20230928/"},{"categories":["机器学习","Python"],"content":"Correct \u0026 Smooth OGB数据集：https://ogb.stanford.edu 这是一种后处理的方法，修正结果变得更好。 这里使用的soft_labels就是每个类别都有一个概率，概率之和是1。 L = D - A ā的值是超参数，越大表示更愿意相信传播过来的ERROR，越小表示更愿意相信上一时刻的ERROR。 结果求和不为一，但置信度仍较高。 ","date":"2023-09-28","objectID":"/20230928/:4:0","tags":["机器学习","深度学习","图神经网络","CS244W"],"title":"半监督节点分类","uri":"/20230928/"},{"categories":["机器学习","Python"],"content":"Loopy Belief Propagation 这是一种消息传递方法。 动态规划算法，下一时刻的状态仅取决于上一时刻。 ","date":"2023-09-28","objectID":"/20230928/:5:0","tags":["机器学习","深度学习","图神经网络","CS244W"],"title":"半监督节点分类","uri":"/20230928/"},{"categories":["机器学习","Python"],"content":"Masked Label Prediction 这是一种自监督方法。 已有的信息随机的抹除，然后用剩下的已有信息去预测，自监督地学习。 ","date":"2023-09-28","objectID":"/20230928/:6:0","tags":["机器学习","深度学习","图神经网络","CS244W"],"title":"半监督节点分类","uri":"/20230928/"},{"categories":["机器学习","Python"],"content":"总结 都是用来解决半监督节点分类问题的。 直推式（也称为演绎推理）是从特定的前提或事实中推导出具体的结论，而归纳式（也称为归纳推理）则是从一般的观察或模式中推断出普遍的结论。可以这么说，直推是由特殊到一般，而归纳是由一般到特殊。 归纳式在有新的节点出现时可以很好的使用原模型，不用重新训练，而直推式需要重新训练。 ","date":"2023-09-28","objectID":"/20230928/:7:0","tags":["机器学习","深度学习","图神经网络","CS244W"],"title":"半监督节点分类","uri":"/20230928/"},{"categories":["机器学习","Python"],"content":"PageRank节点重要度 在NetworkX中，计算有向图节点的PageRank节点重要度。 ","date":"2023-09-27","objectID":"/20230927/:0:0","tags":["机器学习","深度学习","图神经网络","PageRank","CS244W"],"title":"PageRank实战-西游记人物节点重要程度","uri":"/20230927/"},{"categories":["机器学习","Python"],"content":"参考资料 networkx官方教程：https://networkx.org/documentation/stable/tutorial.html nx.Graph https://networkx.org/documentation/stable/reference/classes/graph.html#networkx.Graph 给图、节点、连接添加属性：https://networkx.org/documentation/stable/tutorial.html#attributes 读写图：https://networkx.org/documentation/stable/reference/readwrite/index.html ","date":"2023-09-27","objectID":"/20230927/:1:0","tags":["机器学习","深度学习","图神经网络","PageRank","CS244W"],"title":"PageRank实战-西游记人物节点重要程度","uri":"/20230927/"},{"categories":["机器学习","Python"],"content":"导入工具包 import networkx as nx # 图数据挖掘 import numpy as np # 数据分析 import random # 随机数 import pandas as pd # 数据可视化 import matplotlib.pyplot as plt %matplotlib inline plt.rcParams['font.sans-serif']=['SimHei'] # 用来正常显示中文标签 plt.rcParams['axes.unicode_minus']=False # 用来正常显示负号 G = nx.star_graph(7) nx.draw(G, with_labels = True) ","date":"2023-09-27","objectID":"/20230927/:2:0","tags":["机器学习","深度学习","图神经网络","PageRank","CS244W"],"title":"PageRank实战-西游记人物节点重要程度","uri":"/20230927/"},{"categories":["机器学习","Python"],"content":"计算PageRank节点重要度 数据下载地址：http://www.openkg.cn/dataset/ch4masterpieces pagerank = nx.pagerank(G, alpha=0.8) pagerank {0: 0.4583348922684132,\r1: 0.07738072967594098,\r2: 0.07738072967594098,\r3: 0.07738072967594098,\r4: 0.07738072967594098,\r5: 0.07738072967594098,\r6: 0.07738072967594098,\r7: 0.07738072967594098}\r# 导入 csv 文件定义的有向图 df = pd.read_csv('./triples.csv') df head\rtail\rrelation\rlabel\r0\r金蝉子\r唐僧\rpast_life\r前世\r1\r孙悟空\r唐僧\rapprentice\r徒弟\r2\r猪八戒\r唐僧\rapprentice\r徒弟\r3\r沙僧\r唐僧\rapprentice\r徒弟\r4\r白龙马\r唐僧\rapprentice\r徒弟\r...\r...\r...\r...\r...\r104\r毗蓝婆菩萨\r昴日星官\rmother\r母亲\r105\r嫦娥\r后羿\rwife\r妻\r106\r敖摩昂\r敖闰\rson\r儿\r107\r哪吒\r李靖\rson\r儿\r108\r哪吒\r如来\rapprentice\r徒弟\r109 rows × 4 columns edges = [edge for edge in zip(df['head'], df['tail'])] G = nx.DiGraph() G.add_edges_from(edges) # 可视化 plt.figure(figsize=(15,14)) pos = nx.spring_layout(G, iterations=3, seed=5) #设置为基于弹簧布局，迭代次数为3，次数越多，根据节点之间的相互作用力找到的节点位置越合理 nx.draw(G, pos, with_labels=True) plt.show() pagerank = nx.pagerank(G, # NetworkX graph 有向图，如果是无向图则自动转为双向有向图 alpha=0.85, # Damping Factor，阻尼系数，理解这个得理解谷歌矩阵，也就是明白算法本身才行 personalization=None, # 是否开启Personalized PageRank，随机传送至指定节点集合的概率更高或更低 max_iter=100, # 最大迭代次数 tol=1e-06, # 判定收敛的误差 nstart=None, # 每个节点初始PageRank值 dangling=None, # Dead End死胡同节点 ) sorted(pagerank.items(), key=lambda x: x[1], reverse=True) [('唐僧', 0.13349105557884888),\r('孙悟空', 0.10498354112014094),\r('白龙马', 0.09531260474698808),\r('猪八戒', 0.09247797536009736),\r('沙僧', 0.07627154154696374),\r('李世民', 0.052002919751408624),\r('观音菩萨', 0.026625716774094633),\r('高翠兰', 0.02579183411604112),\r('卵二姐', 0.01860884001045803),\r('太上老君', 0.014430996933862522),\r('如来', 0.013334300311185142),\r('牛魔王', 0.010256020230003658),\r('哪吒', 0.009171370913926254),\r('灵吉菩萨', 0.007800320258156309),\r('宼栋', 0.007432108638238391),\r('昴日星官', 0.007432108638238391),\r('后羿', 0.007432108638238391),\r('李靖', 0.006787403654483575),\r('殷温娇', 0.005344620286308959),\r('寇梁', 0.005344620286308959),\r('袁天罡', 0.005344620286308959),\r('金角', 0.005344620286308959),\r('银角', 0.005344620286308959),\r('西海龙王太子', 0.005344620286308959),\r('弥勒佛', 0.005344620286308959),\r('毗蓝婆菩萨', 0.005344620286308959),\r('文殊菩萨', 0.005344620286308959),\r('普贤菩萨', 0.005344620286308959),\r('太乙救苦天尊', 0.005344620286308959),\r('嫦娥', 0.005344620286308959),\r('南极寿星', 0.005344620286308959),\r('东来佛祖笑和尚', 0.005344620286308959),\r('敖闰', 0.005344620286308959),\r('木吒', 0.004812288400108432),\r('金吒', 0.004812288400108432),\r('高玉兰', 0.004116770300385284),\r('金蝉子', 0.0028889203144616088),\r('陈光蕊', 0.0028889203144616088),\r('法明和尚', 0.0028889203144616088),\r('殷开山', 0.0028889203144616088),\r('菩提老祖', 0.0028889203144616088),\r('镇元子', 0.0028889203144616088),\r('蛟魔王', 0.0028889203144616088),\r('鹏魔王', 0.0028889203144616088),\r('狮驼王', 0.0028889203144616088),\r('猕猴王', 0.0028889203144616088),\r('禺狨王', 0.0028889203144616088),\r('天蓬元帅', 0.0028889203144616088),\r('卷帘大将', 0.0028889203144616088),\r('西海龙王', 0.0028889203144616088),\r('西海龙母', 0.0028889203144616088),\r('敖摩昂太子', 0.0028889203144616088),\r('西海龙女', 0.0028889203144616088),\r('李渊', 0.0028889203144616088),\r('李建成', 0.0028889203144616088),\r('李元吉', 0.0028889203144616088),\r('王珪', 0.0028889203144616088),\r('秦琼', 0.0028889203144616088),\r('萧瑀', 0.0028889203144616088),\r('傅奕', 0.0028889203144616088),\r('魏征', 0.0028889203144616088),\r('李玉英', 0.0028889203144616088),\r('房玄龄', 0.0028889203144616088),\r('杜如晦', 0.0028889203144616088),\r('徐世绩', 0.0028889203144616088),\r('徐茂公', 0.0028889203144616088),\r('许敬宗', 0.0028889203144616088),\r('马三宝', 0.0028889203144616088),\r('段志贤', 0.0028889203144616088),\r('程咬金', 0.0028889203144616088),\r('虞世南', 0.0028889203144616088),\r('张道源', 0.0028889203144616088),\r('张士衡', 0.0028889203144616088),\r('高太公', 0.0028889203144616088),\r('高香兰', 0.0028889203144616088),\r('寇洪', 0.0028889203144616088),\r('袁守诚', 0.0028889203144616088),\r('正元龙', 0.0028889203144616088),\r('二十四路诸天', 0.0028889203144616088),\r('守山大神', 0.0028889203144616088),\r('善财童子', 0.0028889203144616088),\r('捧珠龙女', 0.0028889203144616088),\r('红孩儿', 0.0028889203144616088),\r('黑风怪', 0.0028889203144616088),\r('黄风怪', 0.0028889203144616088),\r('黄毛貂鼠', 0.0028889203144616088),\r('铁扇公主', ","date":"2023-09-27","objectID":"/20230927/:3:0","tags":["机器学习","深度学习","图神经网络","PageRank","CS244W"],"title":"PageRank实战-西游记人物节点重要程度","uri":"/20230927/"},{"categories":["机器学习","Python"],"content":"Links as votes 使用In-coming links作为投票，也就是别人引用了我，即一个节点被多少其他节点指向，那么这个节点被多少用户点击的概率就越大。 pagerank假设 In-Links 之间也是不一样，重要网站引用我和无名小将引用我肯定前者更重要。 所以这是一个递归问题。 ","date":"2023-09-26","objectID":"/20230926/:1:0","tags":["机器学习","深度学习","图神经网络","PageRank","CS244W"],"title":"PageRank","uri":"/20230926/"},{"categories":["机器学习","Python"],"content":"PageRank求解节点重要度 ","date":"2023-09-26","objectID":"/20230926/:2:0","tags":["机器学习","深度学习","图神经网络","PageRank","CS244W"],"title":"PageRank","uri":"/20230926/"},{"categories":["机器学习","Python"],"content":"5个角度理解该问题 连立线性方程组迭代求解 迭代左乘M矩阵 左乘的这个矩阵是M矩阵，右边向量叫做pagerank向量： 矩阵的特征向量：矩阵M代表一种线性变换(原点不变的变换)，特征向量也即是变换过程中方向不变的向量，特征值就是变换过后，特征向量前后缩放的系数。(非特征向量线性变换后反向和原来不一样了) 随机游走 随机游走，每访问一个节点该节点计数+1，最后归一化整个有向图的节点得到概率，值就是pagerank值。 马尔科夫链 ","date":"2023-09-26","objectID":"/20230926/:2:1","tags":["机器学习","深度学习","图神经网络","PageRank","CS244W"],"title":"PageRank","uri":"/20230926/"},{"categories":["机器学习","Python"],"content":"复杂度 pagerank向量此时刻与上一时刻差值小于某个值就认为是收敛了 ","date":"2023-09-26","objectID":"/20230926/:2:2","tags":["机器学习","深度学习","图神经网络","PageRank","CS244W"],"title":"PageRank","uri":"/20230926/"},{"categories":["机器学习","Python"],"content":"收敛性分析 不可约且非周期的马尔科夫链是收敛的。 可约的 –\u003e 孤立的首尾相连环的节点 周期的 –\u003e 两个节点互连 收敛是收敛了，是否收敛到的是网页重要度的值呢？ 以上两种情况会导致收敛是收敛，但不会是重要度的值(都为0或都为1了) 这种情况则是直接不收敛，因为连通域互相独立 PageRank需要解决上述问题 遇到爬虫仅指向自己的节点(spider trap)，解决方法： 有β概率被传送回去 有1-β的概率被传送到其他节点(任意一个节点) β在0.8到0.9之间随机 遇到死胡同(dead end)节点，解决方法： 就让其100%被传送走到其他节点(任意一个节点，任意节点概率相等) 谷歌的解决方案 –\u003e Damping Factor(阻尼系数) ","date":"2023-09-26","objectID":"/20230926/:2:3","tags":["机器学习","深度学习","图神经网络","PageRank","CS244W"],"title":"PageRank","uri":"/20230926/"},{"categories":["机器学习","Python"],"content":"总结 ","date":"2023-09-26","objectID":"/20230926/:2:4","tags":["机器学习","深度学习","图神经网络","PageRank","CS244W"],"title":"PageRank","uri":"/20230926/"},{"categories":["机器学习","Python"],"content":"PageRank求解节点相似度 ","date":"2023-09-26","objectID":"/20230926/:3:0","tags":["机器学习","深度学习","图神经网络","PageRank","CS244W"],"title":"PageRank","uri":"/20230926/"},{"categories":["机器学习","Python"],"content":"基于PageRank的变种 以上数字反映了与起点节点Q的相似度 ","date":"2023-09-26","objectID":"/20230926/:3:1","tags":["机器学习","深度学习","图神经网络","PageRank","CS244W"],"title":"PageRank","uri":"/20230926/"},{"categories":["机器学习","Python"],"content":"总结 ","date":"2023-09-26","objectID":"/20230926/:3:2","tags":["机器学习","深度学习","图神经网络","PageRank","CS244W"],"title":"PageRank","uri":"/20230926/"},{"categories":["机器学习","Python"],"content":"基于原文作的个人笔记，在此展出 建议按住ctrl然后滑动鼠标滑轮放大查看，笔记做的很小，图片分辨率很高，放大也不会糊 原文：Combinatorial Optimization with Graph Convolutional Networks and Guided Tree Search 原文链接：https://arxiv.org/abs/1810.10659 ","date":"2023-09-25","objectID":"/20230925/:1:0","tags":["机器学习","深度学习","图神经网络","树搜索","组合优化","局部搜索","图缩减"],"title":"用图卷积和树搜索解决组合优化问题(含笔记)","uri":"/20230925/"},{"categories":["机器学习","Python"],"content":"前言 DeepWalk 仅能反映相邻节点的社群相似信息，无法反映节点的功能角色相似的信息，因为DeespWalk仅使用连接信息(结构信息)学习。 ","date":"2023-09-24","objectID":"/20230924/:1:0","tags":["机器学习","深度学习","图神经网络","Node2Vec","CS244W"],"title":"Node2Vec","uri":"/20230924/"},{"categories":["机器学习","Python"],"content":"有偏随机游走 通过p和q的参数，可以控制随机游走时，游走方向和游走距离。区别在于更偏向DFS还是BFS。 二阶随机游走，下一个节点不仅取决于当前节点，也取决于上一节点，区别于deepwalk的一阶随机游走仅取决于当前节点。 DeepWalk可看作p=1和q=1的特例。 后续神经网络需要输入的数据的特征内含丰富、有分类区分性且相互独立。 编码的方式： 手动设计构造特征 基于矩阵分解(PCA) 基于随机游走 基于图神经网络 条件独立 = 马尔可夫假设 ","date":"2023-09-24","objectID":"/20230924/:2:0","tags":["机器学习","深度学习","图神经网络","Node2Vec","CS244W"],"title":"Node2Vec","uri":"/20230924/"},{"categories":["机器学习","Python"],"content":"alias sampling 用于产生下一个随机游走节点 时间复杂度O(1)，用空间(预处理)(O(n))换时间 大量反复抽样的情况下优势更突出 离散分布抽样转化为均匀分布抽样，生成连续随机数对离散世界采样。 ","date":"2023-09-24","objectID":"/20230924/:3:0","tags":["机器学习","深度学习","图神经网络","Node2Vec","CS244W"],"title":"Node2Vec","uri":"/20230924/"},{"categories":["机器学习","Python"],"content":"具体代码实现 import warnings warnings.filterwarnings('ignore') import argparse import numpy as np import networkx as nx #import node2vec from gensim.models import Word2Vec import random def read_graph(input,weighted,directed): ''' Reads the input network in networkx. ''' # 权重图 if weighted: G = nx.read_edgelist(input, nodetype=int, data=(('weight', float),), create_using=nx.DiGraph()) # 无权图 else: G = nx.read_edgelist(input, nodetype=int, create_using=nx.DiGraph()) for edge in G.edges(): G[edge[0]][edge[1]]['weight'] = 1 # 无向操作 if not directed: G = G.to_undirected() return G nx_G = read_graph('karate.edgelist',False,False) print (len(nx_G)) 34\rimport matplotlib.pyplot as plt nx.draw(nx_G, with_labels=True) plt.show() ","date":"2023-09-24","objectID":"/20230924/:4:0","tags":["机器学习","深度学习","图神经网络","Node2Vec","CS244W"],"title":"Node2Vec","uri":"/20230924/"},{"categories":["机器学习","Python"],"content":"实现alias-sampling class Graph(): # 出事化设置参数 def __init__(self, nx_G, is_directed, p, q): self.G = nx_G self.is_directed = is_directed self.p = p self.q = q def node2vec_walk(self, walk_length, start_node): ''' Simulate a random walk starting from start node. ''' G = self.G # 上一步计算出的alias table，完成O(1)的采样 alias_nodes = self.alias_nodes alias_edges = self.alias_edges walk = [start_node] # 直到生成长度为walk_length的节点序列位为止 while len(walk) \u003c walk_length: cur = walk[-1] # 对邻居节点排序，目的是和alias table计算时的顺序对应起来 cur_nbrs = sorted(G.neighbors(cur)) if len(cur_nbrs) \u003e 0: # 节点序列只有一个节点的情况 if len(walk) == 1: # 直接使用alias——node对应的结果 walk.append(cur_nbrs[alias_draw(alias_nodes[cur][0], alias_nodes[cur][1])]) # 节点序列大于一个节点的情况 else: # 看前一个节点,prev是论文中的节点t prev = walk[-2] next = cur_nbrs[alias_draw(alias_edges[(prev, cur)][0], alias_edges[(prev, cur)][1])] walk.append(next) else: break return walk def simulate_walks(self, num_walks, walk_length): ''' Repeatedly simulate random walks from each node. ''' G = self.G walks = [] nodes = list(G.nodes()) print ('Walk iteration:') for walk_iter in range(num_walks): print (str(walk_iter+1), '/', str(num_walks)) # 打乱节点顺序 random.shuffle(nodes) for node in nodes: # node2vec_walk是一次有偏的随机游走 walks.append(self.node2vec_walk(walk_length=walk_length, start_node=node)) return walks def get_alias_edge(self, src, dst): ''' Get the alias edge setup lists for a given edge. ''' G = self.G p = self.p q = self.q unnormalized_probs = [] # 论文3.2.2节核心算法 for dst_nbr in sorted(G.neighbors(dst)): if dst_nbr == src: unnormalized_probs.append(G[dst][dst_nbr]['weight']/p) elif G.has_edge(dst_nbr, src): unnormalized_probs.append(G[dst][dst_nbr]['weight']) else: unnormalized_probs.append(G[dst][dst_nbr]['weight']/q) # 归一化 norm_const = sum(unnormalized_probs) normalized_probs = [float(u_prob)/norm_const for u_prob in unnormalized_probs] return alias_setup(normalized_probs) def preprocess_transition_probs(self): ''' Preprocessing of transition probabilities for guiding the random walks. ''' G = self.G is_directed = self.is_directed alias_nodes = {} # 节点概率alias sampling和归一化 for node in G.nodes(): unnormalized_probs = [G[node][nbr]['weight'] for nbr in sorted(G.neighbors(node))] norm_const = sum(unnormalized_probs) normalized_probs = [float(u_prob)/norm_const for u_prob in unnormalized_probs] alias_nodes[node] = alias_setup(normalized_probs) # 信息展示 if node == 2: print (unnormalized_probs) print (norm_const) print (normalized_probs) print (alias_nodes[node]) alias_edges = {} triads = {} # 边概率alias sampling和归一化 if is_directed: for edge in G.edges(): alias_edges[edge] = self.get_alias_edge(edge[0], edge[1]) else: for edge in G.edges(): alias_edges[edge] = self.get_alias_edge(edge[0], edge[1]) alias_edges[(edge[1], edge[0])] = self.get_alias_edge(edge[1], edge[0]) print ('edges alias') print (alias_edges[(2, 3)]) self.alias_nodes = alias_nodes self.alias_edges = alias_edges return p = 1 q= 1 directed = False G = Graph(nx_G, directed, p, q) def alias_setup(probs): ''' Compute utility lists for non-uniform sampling from discrete distributions. Refer to https://hips.seas.harvard.edu/blog/2013/03/03/the-alias-method-efficient-sampling-with-many-discrete-outcomes/ for details ''' # 总过K个长度 K = len(probs) # q个0 q = np.zeros(K) J = np.zeros(K, dtype=np.int_) smaller = [] larger = [] # 将各个概率分成两组，一组的概率值大于1，另一组的概率值小于1 for kk, prob in enumerate(probs): q[kk] = K*prob if q[kk] \u003c 1.0: smaller.append(kk) else: larger.append(kk) # 使用贪心算法，将概率值小于1的不断填满 # pseudo code step 3 while len(smaller) \u003e 0 and len(larger) \u003e 0: small = smaller.pop() large = larger.pop() J[small] = large # 更新概率值 q[large] = q[large] + q[small] - 1.0 if q[large] \u003c 1.0: smaller.append(large) else: larger.append(large) return J, q def alias_draw(J, q): ''' Draw sample from a non-uniform discrete distribution using alias sampling. ''' K = len(J) kk = int(np.floor(np.random.rand()*K)) # 取自己 if np.random.rand() \u003c q[kk]: return kk # 取alias table存的节点 else: return J[kk] G.preprocess_transition_probs() [1, 1, 1, ","date":"2023-09-24","objectID":"/20230924/:5:0","tags":["机器学习","深度学习","图神经网络","Node2Vec","CS244W"],"title":"Node2Vec","uri":"/20230924/"},{"categories":["机器学习","Python"],"content":"训练embedding def learn_embeddings(walks,dimensions,window_size,workers,iter): ''' Learn embeddings by optimizing the Skipgram objective using SGD. ''' # 将node的类型int转化为string # walks = [map(str, walk) for walk in walks] walk_lol = [] for walk in walks: tmp = [] for node in walk: tmp.append(str(node)) walk_lol.append(tmp) # 调用gensim包运行word2vec model = Word2Vec(walk_lol, vector_size=dimensions, window=window_size, min_count=0, sg=1, workers=workers, epochs=iter) # model.save_word2vec_format(args.output) # 保存embedding信息 # model.wv.save_word2vec_format(args.output) return model model = learn_embeddings(walks,16,3,-1,10) print ('finished') finished\rimport matplotlib.pyplot as plt nx.draw(nx_G, with_labels=True) plt.show() # # 找到和节点最相似的一组点 print (model.wv.most_similar('34')) [('31', 0.49450308084487915), ('2', 0.48848462104797363), ('21', 0.4063515067100525), ('27', 0.3625999391078949), ('29', 0.3572307527065277), ('26', 0.32403403520584106), ('4', 0.3191637098789215), ('16', 0.31352993845939636), ('17', 0.2968163788318634), ('13', 0.18988074362277985)]\rtype(model) gensim.models.word2vec.Word2Vec\rmodel \u003cgensim.models.word2vec.Word2Vec at 0x7f33c7208450\u003e\rfrom scipy import spatial # 余弦相似度 def cos_similarity(v1, v2): return 1 - spatial.distance.cosine(v1, v2) # 相似节点组1 print(cos_similarity(model.wv['17'], model.wv['6'])) print(cos_similarity(model.wv['7'], model.wv['6'])) print(cos_similarity(model.wv['7'], model.wv['5'])) # # 相似节点组2 # print (cos_similarity(model.wv['34'], model.wv['33'])) # print (cos_similarity(model.wv['34'], model.wv['9'])) # print (cos_similarity(model.wv['34'], model.wv['31'])) # # 不相似节点组 # print (cos_similarity(model.wv['17'], model.wv['25'])) # print (cos_similarity(model.wv['7'], model.wv['25'])) -0.19091002643108368\r0.38975000381469727\r-0.3603137731552124\r# k-means聚类 from sklearn import cluster from sklearn.metrics import adjusted_rand_score from sklearn.model_selection import train_test_split import pandas as pd embedding_node=[] for i in range(1,35): j=str(i) embedding_node.append(model.wv[j]) embedding_node=np.array(embedding_node).reshape((34,-1)) y_pred = cluster.KMeans(n_clusters=3, random_state=9).fit_predict(embedding_node) # 调用 test_RandomForestClassifier y_pred array([0, 2, 0, 1, 1, 1, 2, 0, 0, 0, 0, 2, 1, 0, 1, 1, 2, 1, 1, 0, 1, 1,\r1, 0, 1, 2, 1, 1, 0, 0, 1, 1, 1, 1], dtype=int32)\rimport matplotlib.pyplot as plt nx.draw(nx_G, with_labels=True) plt.show() ","date":"2023-09-24","objectID":"/20230924/:6:0","tags":["机器学习","深度学习","图神经网络","Node2Vec","CS244W"],"title":"Node2Vec","uri":"/20230924/"},{"categories":["机器学习","Python"],"content":"参考资料 https://www.analyticsvidhya.com/blog/2019/11/graph-feature-extraction-deepwalk/ https://github.com/prateekjoshi565/DeepWalk ","date":"2023-09-23","objectID":"/20230923/:1:0","tags":["机器学习","深度学习","图神经网络","DeepWalk","CS244W"],"title":"DeepWalk实战-维基百科词条图嵌入可视化","uri":"/20230923/"},{"categories":["机器学习","Python"],"content":"安装工具包 !pip install networkx gensim pandas numpy tqdm scikit-learn matplotlib Collecting networkx\rDownloading networkx-3.1-py3-none-any.whl (2.1 MB)\r\u001b[2K \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\r\u001b[?25hCollecting gensim\rObtaining dependency information for gensim from https://files.pythonhosted.org/packages/22/40/7d2cce3ad4ad5d02aa68e253e6ea5f0acc381f02f594e235fe00a274faff/gensim-4.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\rDownloading gensim-4.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.3 kB)\rCollecting pandas\rObtaining dependency information for pandas from https://files.pythonhosted.org/packages/de/ce/b5d9c7ce1aaf9023b823c81932a50cd5e8f407198a696b0d1c6025a40b03/pandas-2.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\rDownloading pandas-2.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\rCollecting numpy\rObtaining dependency information for numpy from https://files.pythonhosted.org/packages/c4/36/161e2f8110f8c49e59f6107bd6da4257d30aff9f06373d0471811f73dcc5/numpy-1.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\rDownloading numpy-1.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\r\u001b[2K \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\u001b[?25hCollecting tqdm\rObtaining dependency information for tqdm from https://files.pythonhosted.org/packages/00/e5/f12a80907d0884e6dff9c16d0c0114d81b8cd07dc3ae54c5e962cc83037e/tqdm-4.66.1-py3-none-any.whl.metadata\rDownloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\r\u001b[2K \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\u001b[?25hCollecting scikit-learn\rObtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/8f/87/5969092159207f583481ad80a03f09e2d4af1ebd197f4530ca4e906c947e/scikit_learn-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\rDownloading scikit_learn-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\rCollecting matplotlib\rObtaining dependency information for matplotlib from https://files.pythonhosted.org/packages/65/5b/3b8fd7d66043f0638a35fa650570cbe69efd42fe169e5024f9307598b47e/matplotlib-3.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\rDownloading matplotlib-3.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\rCollecting scipy\u003e=1.7.0 (from gensim)\rObtaining dependency information for scipy\u003e=1.7.0 from https://files.pythonhosted.org/packages/ef/1b/7538792254aec6850657d5b940fd05fe60582af829ffe40d6c054f065f34/scipy-1.11.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\rDownloading scipy-1.11.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\r\u001b[2K \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\u001b[?25hCollecting smart-open\u003e=1.8.1 (from gensim)\rObtaining dependency information for smart-open\u003e=1.8.1 from https://files.pythonhosted.org/packages/fc/d9/d97f1db64b09278aba64e8c81b5d322d436132df5741c518f3823824fae0/smart_open-6.4.0-py3-none-any.whl.metadata\rDownloading smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\rRequirement already satisfied: python-dateutil\u003e=2.8.2 in /root/miniconda3/envs/jupyter-env/lib/python3.11/site-packages (from pandas) (2.8.2)\rRequirement already satisfied: pytz\u003e=2020.1 in /root/miniconda3/envs/jupyter-env/lib/python3.11/site-packages (from pandas) (2023.3.post1)\rCollecting tzdata\u003e=2022.1 (from pandas)\rDownloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\r\u001b[2K \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\u001b[?25hCollecting joblib\u003e=1.1.1 (from scikit-learn)\rObtaining depend","date":"2023-09-23","objectID":"/20230923/:2:0","tags":["机器学习","深度学习","图神经网络","DeepWalk","CS244W"],"title":"DeepWalk实战-维基百科词条图嵌入可视化","uri":"/20230923/"},{"categories":["机器学习","Python"],"content":"导入工具包 import networkx as nx # 图数据挖掘 # 数据分析 import pandas as pd import numpy as np import random # 随机数 from tqdm import tqdm # 进度条 # 数据可视化 import matplotlib.pyplot as plt %matplotlib inline plt.rcParams['font.sans-serif']=['SimHei'] # 用来正常显示中文标签 plt.rcParams['axes.unicode_minus']=False # 用来正常显示负号 ","date":"2023-09-23","objectID":"/20230923/:3:0","tags":["机器学习","深度学习","图神经网络","DeepWalk","CS244W"],"title":"DeepWalk实战-维基百科词条图嵌入可视化","uri":"/20230923/"},{"categories":["机器学习","Python"],"content":"获取维基百科网页引用关联数据 1.打开网站https://densitydesign.github.io/strumentalia-seealsology 2.Distance设置为4 3.输入以下链接 https://en.wikipedia.org/wiki/Computer_vision https://en.wikipedia.org/wiki/Deep_learning https://en.wikipedia.org/wiki/Convolutional_neural_network https://en.wikipedia.org/wiki/Decision_tree https://en.wikipedia.org/wiki/Support-vector_machine 4.点击START CRAWLING，爬取1000个网页之后，点击STOP \u0026 CLEAR QUEUE 5.Download-下载TSV文件，保存至代码相同目录，命名为seealsology-data.tsv df = pd.read_csv(\"seealsology-data.tsv\", sep = \"\\t\") df.head() source\rtarget\rdepth\r0\rsupport-vector machine\rin situ adaptive tabulation\r1\r1\rsupport-vector machine\rkernel machines\r1\r2\rsupport-vector machine\rfisher kernel\r1\r3\rsupport-vector machine\rplatt scaling\r1\r4\rsupport-vector machine\rpolynomial kernel\r1\rdf.shape (13211, 3)\r","date":"2023-09-23","objectID":"/20230923/:4:0","tags":["机器学习","深度学习","图神经网络","DeepWalk","CS244W"],"title":"DeepWalk实战-维基百科词条图嵌入可视化","uri":"/20230923/"},{"categories":["机器学习","Python"],"content":"构建无向图 G = nx.from_pandas_edgelist(df, \"source\", \"target\", edge_attr=True, create_using=nx.Graph()) # 节点个数 len(G) 8560\r","date":"2023-09-23","objectID":"/20230923/:5:0","tags":["机器学习","深度学习","图神经网络","DeepWalk","CS244W"],"title":"DeepWalk实战-维基百科词条图嵌入可视化","uri":"/20230923/"},{"categories":["机器学习","Python"],"content":"因节点数过多，省去可视化步骤 # # 可视化 # plt.figure(figsize=(15,14)) # nx.draw(G) # plt.show() ","date":"2023-09-23","objectID":"/20230923/:6:0","tags":["机器学习","深度学习","图神经网络","DeepWalk","CS244W"],"title":"DeepWalk实战-维基百科词条图嵌入可视化","uri":"/20230923/"},{"categories":["机器学习","Python"],"content":"生成随机游走节点序列的函数 def get_randomwalk(node, path_length): ''' 输入起始节点和路径长度，生成随机游走节点序列 ''' random_walk = [node] for i in range(path_length-1): # 汇总邻接节点 temp = list(G.neighbors(node)) temp = list(set(temp) - set(random_walk)) if len(temp) == 0: break # 从邻接节点中随机选择下一个节点 random_node = random.choice(temp) random_walk.append(random_node) node = random_node return random_walk all_nodes = list(G.nodes()) all_nodes ['support-vector machine',\r'in situ adaptive tabulation',\r'kernel machines',\r'fisher kernel',\r'platt scaling',\r'polynomial kernel',\r'predictive analytics',\r'regularization perspectives on support-vector machines',\r'relevance vector machine',\r'sequential minimal optimization',\r'space mapping',\r'winnow (algorithm)',\r'decision tree',\r'behavior tree (artificial intelligence, robotics and control)',\r'boosting (machine learning)',\r'decision cycle',\r'decision list',\r'decision matrix',\r'decision table',\r'decision tree model',\r'design rationale',\r'drakon',\r'markov chain',\r'random forest',\r'odds algorithm',\r'topological combinatorics',\r'truth table',\r'convolutional neural network',\r'attention (machine learning)',\r'convolution',\r'deep learning',\r'natural-language processing',\r'neocognitron',\r'scale-invariant feature transform',\r'time delay neural network',\r'vision processing unit',\r'applications of artificial intelligence',\r'comparison of deep learning software',\r'compressed sensing',\r'differentiable programming',\r'echo state network',\r'liquid state machine',\r'reservoir computing',\r'scale space',\r'sparse coding',\r'computer vision',\r'computational imaging',\r'computational photography',\r'computer audition',\r'egocentric vision',\r'machine vision glossary',\r'teknomo–fernandez algorithm',\r'vision science',\r'visual agnosia',\r'visual perception',\r'visual system',\r'achromatopsia',\r'akinetopsia',\r'apperceptive agnosia',\r'associative visual agnosia',\r'asthenopia',\r'astigmatism (eye)',\r'color blindness',\r'human echolocation',\r'helmholtz–kohlrausch effect',\r'color balance',\r'magnocellular cell',\r'memory-prediction framework',\r'prosopagnosia',\r'scotopic sensitivity syndrome',\r'recovery from blindness',\r'visual modularity',\r'visual processing',\r'color vision',\r'depth perception',\r'entoptic phenomenon',\r'gestalt psychology',\r'lateral masking',\r'looming',\r'naked eye',\r'machine vision',\r'motion perception',\r'multisensory integration',\r'interpretation (philosophy)',\r'spatial frequency',\r'visual illusion',\r'wikt:sensation',\r'hallucinogen persisting perception disorder',\r'illusory palinopsia',\r'refractive error',\r'visual snow',\r'cognitive science',\r'neuroscience',\r'ophthalmology',\r'optometry',\r'psychophysics',\r'agnosia',\r'blindness',\r'color agnosia',\r'gestaltzerfall',\r'riddoch syndrome',\r'topographical disorientation',\r'brain',\r'color constancy',\r'eye',\r'linguistic relativity and the color naming debate',\r'neuropsychology',\r'optical illusion',\r'primary colors',\r'visual cortex',\r'visual neuroscience',\r'adaptive control',\r'cognitive model',\r'computational electromagnetics',\r'computer-aided design',\r'engineering optimization',\r'finite element method',\r'kriging',\r'linear approximation',\r'machine learning',\r'mental model',\r'mental rotation',\r'mirror neuron',\r'model-dependent realism',\r'multiphysics',\r'performance tuning',\r'response surface methodology',\r'semiconductor device modeling',\r'spatial cognition',\r'spatial memory',\r'support vector machine',\r'theory of mind',\r'attribution bias',\r'cephalopod intelligence',\r'cetacean intelligence',\r'eliminative materialism',\r'empathy',\r'grounding in communication',\r'intentional stance',\r'joint attention',\r'mental body',\r'mentalization',\r'mini-sea',\r'origin of language',\r'perspective-taking',\r'quantum mind',\r'relational frame theory',\r'self-awareness',\r'social neuroscience',\r'embodied cognition',\r'the mind of an ape',\r'turing test',\r'type physicalism',\r'interpersonal accuracy',\r'cognitive map',\r'dissociation (neuropsychology)',\r'method of loci',\r'spatial ability',\r'visual memory',\r'mind mapping',\r'spatial contextual awareness',\r'","date":"2023-09-23","objectID":"/20230923/:7:0","tags":["机器学习","深度学习","图神经网络","DeepWalk","CS244W"],"title":"DeepWalk实战-维基百科词条图嵌入可视化","uri":"/20230923/"},{"categories":["机器学习","Python"],"content":"生成随机游走序列 gamma = 10 # 每个节点作为起始点生成随机游走序列个数 walk_length = 5 # 随机游走序列最大长度 random_walks = [] for n in tqdm(all_nodes): # 遍历每个节点 for i in range(gamma): # 每个节点作为起始点生成gamma个随机游走序列 random_walks.append(get_randomwalk(n, walk_length)) 100%|██████████| 8560/8560 [00:00\u003c00:00, 29750.07it/s]\r# 生成随机游走序列个数 len(random_walks) 85600\rrandom_walks[1] ['support-vector machine',\r'in situ adaptive tabulation',\r'support vector machine',\r'kernel machines',\r'representer theorem']\r","date":"2023-09-23","objectID":"/20230923/:8:0","tags":["机器学习","深度学习","图神经网络","DeepWalk","CS244W"],"title":"DeepWalk实战-维基百科词条图嵌入可视化","uri":"/20230923/"},{"categories":["机器学习","Python"],"content":"训练Word2Vec模型 from gensim.models import Word2Vec # 自然语言处理 model = Word2Vec(vector_size=256, # Embedding维数 window=4, # 窗口宽度 sg=1, # Skip-Gram hs=0, # 不加分层softmax negative=10, # 负采样 alpha=0.03, # 初始学习率 min_alpha=0.0007, # 最小学习率 seed=14 # 随机数种子 ) # 用随机游走序列构建词汇表 model.build_vocab(random_walks, progress_per=2) # 训练（耗时1分钟左右） model.train(random_walks, total_examples=model.corpus_count, epochs=50, report_delay=1) (16577429, 16582850)\r","date":"2023-09-23","objectID":"/20230923/:9:0","tags":["机器学习","深度学习","图神经网络","DeepWalk","CS244W"],"title":"DeepWalk实战-维基百科词条图嵌入可视化","uri":"/20230923/"},{"categories":["机器学习","Python"],"content":"分析Word2Vec结果 # 查看某个节点的Embedding model.wv.get_vector('random forest').shape (256,)\rmodel.wv.get_vector('random forest') array([ 0.23334791, -0.00155042, -0.33077806, 0.17064342, -0.1081422 ,\r0.0355994 , 0.24897015, -0.04796787, -0.75819224, 0.25839478,\r0.6178689 , 0.0565461 , -0.06071352, -0.04134927, -0.04617707,\r0.103586 , -0.36969525, 0.15610352, -0.37987182, 0.4583097 ,\r-0.33232433, -0.15699145, 0.21371919, 0.28104368, 0.10022977,\r-0.37963775, -0.03466332, 0.53544474, 0.1582788 , -0.23802406,\r0.31076565, -0.26209658, -0.5055485 , -0.09460515, 0.16454849,\r-0.34730902, 0.23466834, -0.20844714, 0.00270234, -0.3288512 ,\r-0.06863198, -0.20678101, -0.24483734, 0.10853583, 0.6155114 ,\r0.1928504 , -0.7044639 , 0.6126048 , 0.17559509, -0.19937247,\r0.4083251 , -0.2327426 , -0.04890826, 0.21921228, -0.11285872,\r-0.13407706, -0.4656657 , -0.2325841 , -0.3509935 , 0.44738993,\r0.34505916, 0.0984872 , -0.30333465, -0.3040225 , -0.15608855,\r-0.22470486, -0.14090897, 0.32624975, 0.02556773, -0.17766297,\r-0.03282307, -0.06009924, -0.8818592 , 0.25421733, 0.03796612,\r0.15704152, 1.0321482 , -0.2573714 , -0.40552002, -0.1648857 ,\r-0.22849622, -0.15332152, 0.11458287, 0.0682546 , -0.41684514,\r-0.1707345 , -0.4403224 , -0.28976214, -0.4716022 , 0.50526184,\r-0.09183959, 0.17879933, -0.2811215 , -0.03059806, 0.25511235,\r0.6181534 , 0.29505378, -0.22633915, -0.03940143, 0.06210095,\r0.21721607, -0.0526966 , -0.37159044, 0.35864654, -0.17438811,\r-0.22126454, -0.4025731 , 0.58789897, -0.41082326, 0.17033327,\r0.34257182, 0.6182118 , -0.23921025, -0.21790318, 0.30060363,\r-0.20056939, -0.36237326, 0.36493126, 0.11915668, 0.4602384 ,\r-0.08704186, -0.30845055, -0.23525943, -0.11308478, -0.10704424,\r-0.55574316, -0.20751908, 0.31260073, 0.21971068, -0.07155439,\r-0.07340603, -0.17634007, -0.0146748 , -0.28767866, 0.17059626,\r-0.35025132, 0.18504645, -0.38653925, 0.01171829, -0.9433046 ,\r-0.38610327, 0.32028997, -0.3758984 , 0.16362464, -0.0357476 ,\r-0.40415367, 0.09392213, 0.13586934, -0.18233965, 0.08914205,\r0.25584528, 0.05338218, 0.3587864 , -0.01985494, 0.17005035,\r-0.03306824, -0.04700813, -0.26085326, -0.78282183, 0.44279492,\r0.17237511, -0.08858976, -0.30706018, 0.09871512, -0.3005835 ,\r0.04916183, -0.05475043, -0.04583912, -0.11915255, 0.25339088,\r-0.37361142, -0.25820956, -0.16901338, 0.06111354, -0.22381096,\r-0.67695826, -0.03763117, 0.28279755, -0.07734507, -0.09612124,\r-0.25081888, 0.08107558, 0.3038904 , 0.23102888, -0.14562789,\r-0.169836 , -0.18778533, -0.06876044, 0.0312659 , 0.52690244,\r0.11245615, -0.19194236, -0.09534905, -0.354454 , 0.44036543,\r-0.443105 , 0.19732304, 0.31750274, 0.5105512 , -0.03289589,\r-0.1481061 , 0.38620627, -0.42837468, 0.10600033, -0.09797872,\r-0.01391832, -0.2905861 , 0.06858752, -0.31003636, 0.52351254,\r0.13377245, -0.70264685, -0.09665483, -0.16441043, -0.04715606,\r-0.1264535 , -0.11374191, 0.422727 , -0.16340947, 0.1502349 ,\r-0.07239548, -0.17635728, -0.06277203, 0.08725803, 1.0166868 ,\r0.10296601, 0.08663206, 0.21920188, 0.04908649, 0.4252364 ,\r0.17294641, 0.58820933, 1.0219544 , -0.37107244, -0.37064922,\r0.3717883 , 0.47950497, -0.37201375, -0.25528926, 0.45519346,\r0.07936895, -0.18259984, 0.05479478, 0.01196737, 0.02831526,\r-0.17895861, 0.35639855, 0.16127516, -0.59905547, 0.20060547,\r-0.18414594, 0.4863781 , 0.74616545, -0.21859436, -0.31797457,\r0.10649797], dtype=float32)\r# 找相似词语 model.wv.similar_by_word('decision tree') [('drakon', 0.7287265658378601),\r('comparison sort', 0.69761723279953),\r('decision list', 0.6575663685798645),\r('behavior trees (artificial intelligence, robotics and control)',\r0.6542879343032837),\r('behavior tree (artificial intelligence, robotics and control)',\r0.653127908706665),\r('minimum spanning tree', 0.6494240164756775),\r('decision tree model', 0.6384998559951782),\r('decision matrix', 0.627086877822876),\r('decision stump', 0.5921448469161987),\r('pseudocode', 0.5691863298416138)]\r","date":"2023-09-23","objectID":"/20230923/:10:0","tags":["机器学习","深度学习","图神经网络","DeepWalk","CS244W"],"title":"DeepWalk实战-维基百科词条图嵌入可视化","uri":"/20230923/"},{"categories":["机器学习","Python"],"content":"PCA降维可视化 ","date":"2023-09-23","objectID":"/20230923/:11:0","tags":["机器学习","深度学习","图神经网络","DeepWalk","CS244W"],"title":"DeepWalk实战-维基百科词条图嵌入可视化","uri":"/20230923/"},{"categories":["机器学习","Python"],"content":"可视化全部词条的二维Embedding X = model.wv.vectors # 将Embedding用PCA降维到2维 from sklearn.decomposition import PCA pca = PCA(n_components=2) embed_2d = pca.fit_transform(X) embed_2d.shape (8560, 2)\r# import os # import shutil # import urllib.request # import matplotlib # # 设置字体文件的URL和目标文件路径 # font_url = \"https://github.com/StellarCN/scp_zh/raw/master/fonts/SimHei.ttf\" # target_font_path = os.path.join(matplotlib.get_data_path(), \"fonts/ttf/SimHei.ttf\") # # 下载字体文件 # urllib.request.urlretrieve(font_url, target_font_path) # # 找到matplotlibrc文件的路径 # matplotlibrc_path = matplotlib.matplotlib_fname() # # 获取matplotlibrc文件所在的文件夹路径 # matplotlibrc_dir = os.path.dirname(matplotlibrc_path) # # 找到fonts/ttf目录的路径 # fonts_dir = os.path.join(matplotlib.get_data_path(), \"fonts/ttf\") # # 删除缓存文件夹中的内容 # cache_dir = matplotlib.get_cachedir() # shutil.rmtree(cache_dir, ignore_errors=True) # print(\"字体文件已下载到:\", target_font_path) # print(\"matplotlibrc文件所在目录:\", matplotlibrc_dir) # print(\"删除缓存文件夹:\", cache_dir) plt.figure(figsize=(14,14)) plt.scatter(embed_2d[:, 0], embed_2d[:, 1]) plt.show() ","date":"2023-09-23","objectID":"/20230923/:11:1","tags":["机器学习","深度学习","图神经网络","DeepWalk","CS244W"],"title":"DeepWalk实战-维基百科词条图嵌入可视化","uri":"/20230923/"},{"categories":["机器学习","Python"],"content":"可视化某个词条的二维Embedding term = 'computer vision' term_256d = model.wv[term].reshape(1,-1) term_256d.shape (1, 256)\rterm_2d = pca.transform(term_256d) term_2d array([[-0.31159213, -0.55424124]], dtype=float32)\rplt.figure(figsize=(14,14)) plt.scatter(embed_2d[:,0], embed_2d[:,1]) plt.scatter(term_2d[:,0],term_2d[:,1],c='r',s=200) plt.show() ","date":"2023-09-23","objectID":"/20230923/:11:2","tags":["机器学习","深度学习","图神经网络","DeepWalk","CS244W"],"title":"DeepWalk实战-维基百科词条图嵌入可视化","uri":"/20230923/"},{"categories":["机器学习","Python"],"content":"可视化某些词条的二维Embedding # 计算PageRank重要度 pagerank = nx.pagerank(G) # 从高到低排序 node_importance = sorted(pagerank.items(), key=lambda x:x[1], reverse=True) # 取最高的前n个节点 n = 30 terms_chosen = [] for each in node_importance[:n]: terms_chosen.append(each[0]) # 手动补充新节点 terms_chosen.extend(['computer vision','deep learning','convolutional neural network','convolution','natural-language processing','attention (machine learning)','support-vector machine','decision tree','random forest','computational imaging','machine vision','cognitive science','neuroscience','psychophysics','brain','visual cortex','visual neuroscience','cognitive model','finite difference','finite difference time domain','finite difference coefficients','finite difference methods for option pricing','iso 128','iso 10303']) terms_chosen ['graph theory',\r'chaos theory',\r'claude shannon',\r'information theory',\r'operations research',\r'quantum logic gate',\r'data mining',\r'remote sensing',\r'electromagnetic wave equation',\r'collective intelligence',\r'control theory',\r'fourier transform',\r'empathy',\r'false dilemma',\r'simulated reality',\r'superlens',\r'digital preservation',\r'wearable computer',\r'low-density parity-check code',\r'analytics',\r'spatial dependence',\r'constructed language',\r'correlation',\r'semantic web',\r'psychoacoustics',\r'collaborative software',\r'philosophy of perception',\r'cognitive science',\r'transhumanism',\r'self-awareness',\r'computer vision',\r'deep learning',\r'convolutional neural network',\r'convolution',\r'natural-language processing',\r'attention (machine learning)',\r'support-vector machine',\r'decision tree',\r'random forest',\r'computational imaging',\r'machine vision',\r'cognitive science',\r'neuroscience',\r'psychophysics',\r'brain',\r'visual cortex',\r'visual neuroscience',\r'cognitive model',\r'finite difference',\r'finite difference time domain',\r'finite difference coefficients',\r'finite difference methods for option pricing',\r'iso 128',\r'iso 10303']\r# 输入词条，输出词典中的索引号 term2index = model.wv.key_to_index # index2term = model.wv.index_to_key # term_index = np.array(term2index.values()) # 可视化全部词条和关键词条的二维Embedding plt.figure(figsize=(14,14)) plt.scatter(embed_2d[:,0], embed_2d[:,1]) for item in terms_chosen: idx = term2index[item] plt.scatter(embed_2d[idx,0], embed_2d[idx,1],c='r',s=50) plt.annotate(item, xy=(embed_2d[idx,0], embed_2d[idx,1]),c='k',fontsize=12) plt.show() ","date":"2023-09-23","objectID":"/20230923/:11:3","tags":["机器学习","深度学习","图神经网络","DeepWalk","CS244W"],"title":"DeepWalk实战-维基百科词条图嵌入可视化","uri":"/20230923/"},{"categories":["机器学习","Python"],"content":"TSNE降维可视化 ","date":"2023-09-23","objectID":"/20230923/:12:0","tags":["机器学习","深度学习","图神经网络","DeepWalk","CS244W"],"title":"DeepWalk实战-维基百科词条图嵌入可视化","uri":"/20230923/"},{"categories":["机器学习","Python"],"content":"可视化全部词条的二维Embedding¶ # 将Embedding用TSNE降维到2维 from sklearn.manifold import TSNE tsne = TSNE(n_components=2, n_iter=1000) embed_2d = tsne.fit_transform(X) plt.figure(figsize=(14,14)) plt.scatter(embed_2d[:, 0], embed_2d[:, 1]) plt.show() ","date":"2023-09-23","objectID":"/20230923/:12:1","tags":["机器学习","深度学习","图神经网络","DeepWalk","CS244W"],"title":"DeepWalk实战-维基百科词条图嵌入可视化","uri":"/20230923/"},{"categories":["机器学习","Python"],"content":"可视化全部词条和关键词条的二维Embedding plt.figure(figsize=(14,14)) plt.scatter(embed_2d[:,0], embed_2d[:,1]) for item in terms_chosen: idx = term2index[item] plt.scatter(embed_2d[idx,0], embed_2d[idx,1],c='r',s=50) plt.annotate(item, xy=(embed_2d[idx,0], embed_2d[idx,1]),c='k',fontsize=12) plt.show() embed_2d.shape (8560, 2)\r","date":"2023-09-23","objectID":"/20230923/:12:2","tags":["机器学习","深度学习","图神经网络","DeepWalk","CS244W"],"title":"DeepWalk实战-维基百科词条图嵌入可视化","uri":"/20230923/"},{"categories":["机器学习","Python"],"content":"导出TSNE降维到二维之后的Embedding terms_chosen_mask = np.zeros(X.shape[0]) for item in terms_chosen: idx = term2index[item] terms_chosen_mask[idx] = 1 df = pd.DataFrame() df['X'] = embed_2d[:,0] df['Y'] = embed_2d[:,1] df['item'] = model.wv.index_to_key df['pagerank'] = pagerank.values() df['chosen'] = terms_chosen_mask df X\rY\ritem\rpagerank\rchosen\r0\r86.368530\r19.423891\rgraph theory\r0.000289\r1.0\r1\r37.059536\r-4.361592\rinformation theory\r0.000185\r1.0\r2\r49.873173\r-24.942081\rclaude shannon\r0.000173\r1.0\r3\r-0.228913\r-9.877577\rdata mining\r0.000091\r1.0\r4\r-27.195446\r-0.748093\rchaos theory\r0.000083\r1.0\r...\r...\r...\r...\r...\r...\r8555\r-28.879446\r54.118038\rclive wearing\r0.000050\r0.0\r8556\r-37.767330\r20.450050\rshy tory factor\r0.000051\r0.0\r8557\r0.282963\r60.908173\rcollective intentionality\r0.000051\r0.0\r8558\r-13.359755\r-6.086845\rvariational bayesian methods\r0.000047\r0.0\r8559\r22.884514\r82.094078\rvocabulary learning\r0.000047\r0.0\r8560 rows × 5 columns df.to_csv('tsne_vis_2d.csv',index=False) ","date":"2023-09-23","objectID":"/20230923/:12:3","tags":["机器学习","深度学习","图神经网络","DeepWalk","CS244W"],"title":"DeepWalk实战-维基百科词条图嵌入可视化","uri":"/20230923/"},{"categories":["机器学习","Python"],"content":"可视化全部词条的三维Embedding # 将Embedding用TSNE降维到2维 from sklearn.manifold import TSNE tsne = TSNE(n_components=3, n_iter=1000) embed_3d = tsne.fit_transform(X) ","date":"2023-09-23","objectID":"/20230923/:12:4","tags":["机器学习","深度学习","图神经网络","DeepWalk","CS244W"],"title":"DeepWalk实战-维基百科词条图嵌入可视化","uri":"/20230923/"},{"categories":["机器学习","Python"],"content":"导出TSNE降维到三维之后的Embedding df = pd.DataFrame() df['X'] = embed_3d[:,0] df['Y'] = embed_3d[:,1] df['Z'] = embed_3d[:,2] df['item'] = model.wv.index_to_key df['pagerank'] = pagerank.values() df['chosen'] = terms_chosen_mask df X\rY\rZ\ritem\rpagerank\rchosen\r0\r25.126606\r-1.095677\r-5.323648\rgraph theory\r0.000289\r1.0\r1\r12.123558\r-8.145174\r-4.209531\rinformation theory\r0.000185\r1.0\r2\r12.928997\r-6.321793\r2.291451\rclaude shannon\r0.000173\r1.0\r3\r-7.868805\r-13.286612\r-14.298657\rdata mining\r0.000091\r1.0\r4\r1.674853\r-2.698683\r8.963208\rchaos theory\r0.000083\r1.0\r...\r...\r...\r...\r...\r...\r...\r8555\r-5.377722\r20.571009\r3.298291\rclive wearing\r0.000050\r0.0\r8556\r-12.325991\r19.030151\r-8.670228\rshy tory factor\r0.000051\r0.0\r8557\r4.694840\r23.837486\r-1.217674\rcollective intentionality\r0.000051\r0.0\r8558\r-11.294335\r-2.773937\r-14.848171\rvariational bayesian methods\r0.000047\r0.0\r8559\r-2.179960\r17.069071\r-16.326900\rvocabulary learning\r0.000047\r0.0\r8560 rows × 6 columns df.to_csv('tsne_vis_3d.csv',index=False) ","date":"2023-09-23","objectID":"/20230923/:12:5","tags":["机器学习","深度学习","图神经网络","DeepWalk","CS244W"],"title":"DeepWalk实战-维基百科词条图嵌入可视化","uri":"/20230923/"},{"categories":["机器学习","Python"],"content":"作业 用tsne_vis_2d.csv和tsne_vis_3d.csv做可视化 参考代码：https://echarts.apache.org/examples/zh/editor.html?c=scatter3d\u0026gl=1\u0026theme=dark ","date":"2023-09-23","objectID":"/20230923/:13:0","tags":["机器学习","深度学习","图神经网络","DeepWalk","CS244W"],"title":"DeepWalk实战-维基百科词条图嵌入可视化","uri":"/20230923/"},{"categories":["机器学习","Python"],"content":"前言 深度学习思想用于图嵌入的开山之作 - DeepWalk 学习路径： Random Walk 是一种遍历图的基本方法，而 Deep Walk 则是一种利用 Random Walk 生成的序列来学习节点嵌入的具体方法。 ","date":"2023-09-22","objectID":"/20230922/:1:0","tags":["机器学习","深度学习","图神经网络","DeepWalk","CS244W"],"title":"DeepWalk","uri":"/20230922/"},{"categories":["机器学习","Python"],"content":"背景 ","date":"2023-09-22","objectID":"/20230922/:2:0","tags":["机器学习","深度学习","图神经网络","DeepWalk","CS244W"],"title":"DeepWalk","uri":"/20230922/"},{"categories":["机器学习","Python"],"content":"Embedding - 嵌入的艺术 - Representation Learning - 表示学习 类同 word2vec - 词向量 输入周围词预测中心词 - CBOW 输入中心词预测周围词 - Skip-gram 以 Skip-gram 为例： 随机游走 - Random Walk 编码前后可对比分类是否可区分，原图中相近的节点嵌入后依然相近，就证明是有效的。 编码后的D维向量再给算法操作，才是真正的机器学习。 ","date":"2023-09-22","objectID":"/20230922/:3:0","tags":["机器学习","深度学习","图神经网络","DeepWalk","CS244W"],"title":"DeepWalk","uri":"/20230922/"},{"categories":["机器学习","Python"],"content":"PPT 讲解 原作者讲解视频： https://dl.acm.org/doi/10.1145/2623330.2623732 原作者PPT： http://www.perozzi.net/publications/14_kdd_deepwalk-slides.pdf ","date":"2023-09-22","objectID":"/20230922/:4:0","tags":["机器学习","深度学习","图神经网络","DeepWalk","CS244W"],"title":"DeepWalk","uri":"/20230922/"},{"categories":["机器学习","Python"],"content":"正文 机器学习最怕的就是数据是稀疏的 Deep Walk 参考NLP的word2vec，学习到连接的结构信息，每个节点都有向量表示。 i,i,d. 独立同分布假设 Deep Walk 没有使用节点本身的属性(label) 要求： 可扩展性 反映原图的结构信息 生成的向量低维度，低纬度嵌入有助于防止过拟合 连续的，细微差异导致的结构就不同了，拟合的边界是平滑的决策边界 实际网络是无标度网络(Scale-Free Network)，网络的节点数和度数分布验证不均匀，少数的Hub中枢节点拥有极多的连接，大部分节点只有很少的连接，服从幂律分布。 Node degree 服从幂律分布，某一个Node在随机游走序列出现的次数页服从幂律分布。 ","date":"2023-09-22","objectID":"/20230922/:5:0","tags":["机器学习","深度学习","图神经网络","DeepWalk","CS244W"],"title":"DeepWalk","uri":"/20230922/"},{"categories":["机器学习","Python"],"content":"方法 一个随机游走生成器和一个迭代优化器。 优化计算损失函数的复杂度，分层softmax操作 使用霍夫曼树，n个叶子节点产生n-1个内部节点(逻辑回归)，每个有D个权重，每个内部节点有n个分支，每个分支指向一个叶子节点。 DeepWalk 有两套权重，N个节点的D维Embedding和N-1个逻辑回归，每个有D个权重。 ","date":"2023-09-22","objectID":"/20230922/:6:0","tags":["机器学习","深度学习","图神经网络","DeepWalk","CS244W"],"title":"DeepWalk","uri":"/20230922/"},{"categories":["机器学习","Python"],"content":"如何嵌入 ","date":"2023-09-21","objectID":"/20230921/:1:0","tags":["机器学习","深度学习","图神经网络","DeepWalk","Node2Vec","CS244W"],"title":"嵌入整张图","uri":"/20230921/"},{"categories":["机器学习","Python"],"content":"全图进行编码嵌入 ","date":"2023-09-21","objectID":"/20230921/:1:1","tags":["机器学习","深度学习","图神经网络","DeepWalk","Node2Vec","CS244W"],"title":"嵌入整张图","uri":"/20230921/"},{"categories":["机器学习","Python"],"content":"引入虚拟节点 ","date":"2023-09-21","objectID":"/20230921/:1:2","tags":["机器学习","深度学习","图神经网络","DeepWalk","Node2Vec","CS244W"],"title":"嵌入整张图","uri":"/20230921/"},{"categories":["机器学习","Python"],"content":"匿名随机游走 https://arxiv.org/pdf/1805.11921.pdf 只要是新节点就标记新的一号，认号不认原来的节点标识。 使用不同匿名随机游走序列的个数构成的向量作为全图随机游走的向量。 ","date":"2023-09-21","objectID":"/20230921/:1:3","tags":["机器学习","深度学习","图神经网络","DeepWalk","Node2Vec","CS244W"],"title":"嵌入整张图","uri":"/20230921/"},{"categories":["机器学习","Python"],"content":"给每种匿名随机游走的序列单独学习一个嵌入编码，全图也单独学习一个嵌入编码 ","date":"2023-09-21","objectID":"/20230921/:1:4","tags":["机器学习","深度学习","图神经网络","DeepWalk","Node2Vec","CS244W"],"title":"嵌入整张图","uri":"/20230921/"},{"categories":["机器学习","Python"],"content":"总结 实际还有一种方法：分层聚类 ","date":"2023-09-21","objectID":"/20230921/:2:0","tags":["机器学习","深度学习","图神经网络","DeepWalk","Node2Vec","CS244W"],"title":"嵌入整张图","uri":"/20230921/"},{"categories":["机器学习","Python"],"content":"前言 矩阵分解和随机游走在数学上意义是一样的。 ","date":"2023-09-20","objectID":"/20230920/:1:0","tags":["机器学习","深度学习","图神经网络","DeepWalk","Node2Vec","CS244W"],"title":"矩阵分解角度 - 图嵌入(节点嵌入)和随机游走","uri":"/20230920/"},{"categories":["机器学习","Python"],"content":"矩阵分解计算 矩阵分解这里可能解析解不能直接求得，且可能不唯一，所以实际计算用的数值解。 具体的证明和推导：https://arxiv.org/pdf/1710.02971.pdf ","date":"2023-09-20","objectID":"/20230920/:2:0","tags":["机器学习","深度学习","图神经网络","DeepWalk","Node2Vec","CS244W"],"title":"矩阵分解角度 - 图嵌入(节点嵌入)和随机游走","uri":"/20230920/"},{"categories":["机器学习","Python"],"content":"缺点 适合静态图而对于动态图过拟合，不能很快的泛化 仅探索节点相邻的局部信息，采样只能采样邻近位置的节点，远处节点可能也相似但没采样到 仅利用了连接信息，没使用节点本身的信息(属性信息) ","date":"2023-09-20","objectID":"/20230920/:3:0","tags":["机器学习","深度学习","图神经网络","DeepWalk","Node2Vec","CS244W"],"title":"矩阵分解角度 - 图嵌入(节点嵌入)和随机游走","uri":"/20230920/"},{"categories":["机器学习","Python"],"content":"总结 图用矩阵形式表现出来是关键。 ","date":"2023-09-20","objectID":"/20230920/:4:0","tags":["机器学习","深度学习","图神经网络","DeepWalk","Node2Vec","CS244W"],"title":"矩阵分解角度 - 图嵌入(节点嵌入)和随机游走","uri":"/20230920/"},{"categories":["机器学习","Python"],"content":"前言 本文讲述映射成D维向量的基于随机游走方法。 学习路径： ","date":"2023-09-19","objectID":"/20230919/:1:0","tags":["机器学习","深度学习","图神经网络","MiniBatch","RandomWalk","Node2Vec","CS244W"],"title":"Random Walk \u0026 Node2vec - 图表示学习起始","uri":"/20230919/"},{"categories":["机器学习","Python"],"content":"图嵌入 - Node Embedding 把节点映射为一个D维向量。 图表示学习用表示学习替代手工的特征工程，自动化特征的提取。 由于向量维数远小于图的节点数，所以当用D维向量表示某个节点时，相当于低维的一个向量嵌入了高维空间中表示一个点。 图嵌入示例(Deep Walk)： 只要前面图嵌入提取特征提取的好，后面需要做分类或者预测都会效果更好 ","date":"2023-09-19","objectID":"/20230919/:2:0","tags":["机器学习","深度学习","图神经网络","MiniBatch","RandomWalk","Node2Vec","CS244W"],"title":"Random Walk \u0026 Node2vec - 图表示学习起始","uri":"/20230919/"},{"categories":["机器学习","Python"],"content":"图嵌入的基本框架 - 编码器和解码器 - ENC \u0026 DEC 先设置示例图： 编码器设计： 解码器设计： 这里的点乘 = 余弦相似度 的前提应该是节点值为1，向量模长为1。 这里的节点相似度也就是如果直接相连就为1表示极其相似，也就是两个向量互相平行，如果二者完全不相似就为0表示二者正交，也就是两个向量互相垂直。 这里的目标是让高相似的节点的函数值大，低相似的节点的函数值小，具体什么函数需要自己定义，虽然这里使用了余弦相似度，但这不是固定的，函数可选其他的。 最简单的编码器 - 查表 又称为 浅编码器 区别于 深度学习方法 - 深编码器 Z矩阵的每一列表示一个节点，行数就是向量的维度 ","date":"2023-09-19","objectID":"/20230919/:3:0","tags":["机器学习","深度学习","图神经网络","MiniBatch","RandomWalk","Node2Vec","CS244W"],"title":"Random Walk \u0026 Node2vec - 图表示学习起始","uri":"/20230919/"},{"categories":["机器学习","Python"],"content":"随机游走 - Random Walk 如何采样随机游走序列(节点串起来的序列)： 图机器学习和NLP有异曲同工之妙，二者哪边有新进展一般能在对面找到对应的东西 这里的余弦相似度不关心模长了，因为做完内积后模长通过softmax已经是同一数量级了(如上图)，所以这里只关系方向的相似度(使用内积表示)： 这里得到的随机游走序列是万金油向量，而且它没有用到任何节点本身的标签： 上面这里的N是从u节点出发的节点序列的随机游走策略是R。 这里的似然目标函数就是极大似然估计，让u节点出发的前提下，跟它出现在同一个随机游走序列中节点们出现的概率最大化。(找共线/相似的节点) 其实似然目标函数就是希望所有样本被预测正确这个事件的概率最大化，因为是独立通分布，所以是每个样本预测正确的事件的概率累乘，但由于都是在0到1上的概率(softmax)，累乘不好算，所以取对数变成了累加，由于累乘累加的转变没有改变单调性，所以依然是取最大。这就是极大似然估计，所以这个函数称为似然目标函数。 这里的P就是softmax的计算方法： 展开就是： 这里有两个地方要遍历所有节点： 所以该方法复杂度是节点数的平方，实际还是比较大的。 这里有两个优化方法，一个是分层softmax，一个是负采样。 负采样可以解决softmax难算的问题，在之前的原始softmax中，需要算u节点和其他所有节点的向量的数量积再，现在负采样只算u节点和k个负样本的数量积。(算n个变成算k个了，计算量大大减轻了) k该如何选择：(一般5到20就行，太大太小都不好) ","date":"2023-09-19","objectID":"/20230919/:4:0","tags":["机器学习","深度学习","图神经网络","MiniBatch","RandomWalk","Node2Vec","CS244W"],"title":"Random Walk \u0026 Node2vec - 图表示学习起始","uri":"/20230919/"},{"categories":["机器学习","Python"],"content":"随机梯度下降 - 优化过程 - 最小化损失函数 两种方法，一种是求全局的随机梯度下降(Gradient Descent)，一种是求局部梯度下降(Stochastic Gradient Descent)。 用全局梯度去优化： 每个随机游走序列都优化一次： 区别： 这里就引申出 MiniBatch 了，MiniBatch 就是每次只取一部分数据去优化，这样速度会快很多，但是准确率会下降，不取全局也不一个个序列取，，只取几个序列一起求梯度。实际上这才是最常用的优化方法。 总结： 该方法的策略是随机的，实际可优化策略 - Node2Vec ","date":"2023-09-19","objectID":"/20230919/:5:0","tags":["机器学习","深度学习","图神经网络","MiniBatch","RandomWalk","Node2Vec","CS244W"],"title":"Random Walk \u0026 Node2vec - 图表示学习起始","uri":"/20230919/"},{"categories":["机器学习","Python"],"content":"Node2Vec 一个参数q控制要不要回上一个节点，一个参数p控制要不要走向更远的节点： 由于每个节点都记得上一个节点是谁，所以叫2阶的随机游走： 两个控制参数大小不同时的区别： 探索远方应该是对应word2vec中生成句子下文，相当于找到所有有关联的词语。探索近邻其实是以一个中心词在不断生成句子，那么更关注这个中心词在文章中的作用。相同的中心词表示在文中有相类似地位的词。 具体算法： 其他方法： ","date":"2023-09-19","objectID":"/20230919/:6:0","tags":["机器学习","深度学习","图神经网络","MiniBatch","RandomWalk","Node2Vec","CS244W"],"title":"Random Walk \u0026 Node2vec - 图表示学习起始","uri":"/20230919/"},{"categories":["机器学习","Python"],"content":"总结 ","date":"2023-09-19","objectID":"/20230919/:7:0","tags":["机器学习","深度学习","图神经网络","MiniBatch","RandomWalk","Node2Vec","CS244W"],"title":"Random Walk \u0026 Node2vec - 图表示学习起始","uri":"/20230919/"},{"categories":["机器学习","Python"],"content":"北京上海地铁站图数据挖掘 上海、北京地铁站点图数据挖掘，计算地铁站点的最短路径、节点重要度、集群系数、连通性。 ","date":"2023-09-18","objectID":"/20230918/:0:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实战","uri":"/20230918/"},{"categories":["机器学习","Python"],"content":"导入工具包 import networkx as nx import pandas as pd import matplotlib.pyplot as plt import matplotlib.colors as mcolors %matplotlib inline ","date":"2023-09-18","objectID":"/20230918/:1:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实战","uri":"/20230918/"},{"categories":["机器学习","Python"],"content":"可视化辅助函数 def draw(G, pos, measures, measure_name): plt.figure(figsize=(20, 20)) nodes = nx.draw_networkx_nodes(G, pos, node_size=250, cmap=plt.cm.plasma, node_color=list(measures.values()), nodelist=measures.keys()) nodes.set_norm(mcolors.SymLogNorm(linthresh=0.01, linscale=1, base=10)) # labels = nx.draw_networkx_labels(G, pos) edges = nx.draw_networkx_edges(G, pos) plt.title(measure_name, fontsize=30) # plt.colorbar(nodes) plt.axis('off') plt.show() ","date":"2023-09-18","objectID":"/20230918/:2:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实战","uri":"/20230918/"},{"categories":["机器学习","Python"],"content":"字典按值排序辅助函数 def dict_sort_by_value(dict_input): ''' 输入字典，输出按值排序的字典 ''' return sorted(dict_input.items(),key=lambda x : x[1], reverse=True) ","date":"2023-09-18","objectID":"/20230918/:3:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实战","uri":"/20230918/"},{"categories":["机器学习","Python"],"content":"导入地铁站连接表 数据来源： 上海地铁线路图：http://www.shmetro.com 上海地铁时刻表：http://service.shmetro.com/hcskb/index.htm 北京地铁线路图：https://map.bjsubway.com 北京地铁时刻表：https://www.bjsubway.com/station/smcsj # 上海地铁站点连接表 df = pd.read_csv('shanghai_subway.csv') # 北京地铁站点连接表 # df = pd.read_csv('beijing_subway.csv') df 前一站\r后一站\r地铁线\r时间（分钟）\r0\r莘庄\r外环路\r1\r2\r1\r外环路\r莲花路\r1\r2\r2\r莲花路\r锦江乐园\r1\r3\r3\r锦江乐园\r上海南站\r1\r3\r4\r上海南站\r漕宝路\r1\r3\r...\r...\r...\r...\r...\r487\r抚顺路\r国权路\r18\r2\r488\r国权路\r复旦大学\r18\r3\r489\r复旦大学\r上海财经大学\r18\r2\r490\r上海财经大学\r殷高路\r18\r2\r491\r殷高路\r长江南路\r18\r2\r492 rows × 4 columns ","date":"2023-09-18","objectID":"/20230918/:4:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实战","uri":"/20230918/"},{"categories":["机器学习","Python"],"content":"创建图 # 创建无向图 G = nx.Graph() ","date":"2023-09-18","objectID":"/20230918/:5:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实战","uri":"/20230918/"},{"categories":["机器学习","Python"],"content":"从连接表创建图 for idx, row in df.iterrows(): # 遍历表格的每一行 G.add_edges_from([(row['前一站'], row['后一站'])], line=row['地铁线'], time=row['时间（分钟）']) # for idx, row in df.iterrows(): # 遍历表格的每一行 # G.add_edges_from([ # (row['前一站'], row['后一站'], {'line': row['地铁线'], 'time':row['时间（分钟）']}) # ]) ","date":"2023-09-18","objectID":"/20230918/:6:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实战","uri":"/20230918/"},{"categories":["机器学习","Python"],"content":"检查是否导入成功 # 节点个数 len(G) 402\r# 节点个数 len(G.nodes) 402\r# 连接个数 len(G.edges) 480\r# 查看连接属性特征 G.edges[('同济大学', '四平路')] {'line': 10, 'time': 2}\r","date":"2023-09-18","objectID":"/20230918/:7:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实战","uri":"/20230918/"},{"categories":["机器学习","Python"],"content":"可视化 # 节点排版布局-默认弹簧布局 pos = nx.spring_layout(G, seed=123) # 节点排版布局-每个节点单独设置坐标 # pos = {1: [0.1, 0.9], 2: [0.4, 0.8], 3: [0.8, 0.9], 4: [0.15, 0.55], # 5: [0.5, 0.5], 6: [0.8, 0.5], 7: [0.22, 0.3], 8: [0.30, 0.27], # 9: [0.38, 0.24], 10: [0.7, 0.3], 11: [0.75, 0.35]} plt.figure(figsize=(15,15)) nx.draw(G, pos=pos) ","date":"2023-09-18","objectID":"/20230918/:8:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实战","uri":"/20230918/"},{"categories":["机器学习","Python"],"content":"Shortest Path 最短路径 NetworkX-最短路径算法：https://networkx.org/documentation/stable/reference/algorithms/shortest_paths.html # 任意两节点之间是否存在路径 nx.has_path(G, source='昌吉东路', target='同济大学') True\r# 任意两节点之间的最短路径 nx.shortest_path(G, source='昌吉东路', target='同济大学', weight='time') ['昌吉东路',\r'上海赛车场',\r'嘉定新城',\r'马陆',\r'陈翔公路',\r'南翔',\r'桃浦新村',\r'武威路',\r'祁连山路',\r'李子园',\r'上海西站',\r'真如',\r'枫桥路',\r'曹杨路',\r'镇坪路',\r'中潭路',\r'上海火车站',\r'宝山路',\r'海伦路',\r'邮电新村',\r'四平路',\r'同济大学']\r# 任意两节点之间的最短路径长度 nx.shortest_path_length(G, source='昌吉东路', target='同济大学', weight='time') 59\r# 全图平均最短路径 nx.average_shortest_path_length(G, weight='time') 41.06494956638255\r# # 某一站去其他站的最短路径 # nx.single_source_shortest_path(G, source='同济大学') # 某一站去其他站的最短路径长度 # nx.single_source_shortest_path_length(G, source='同济大学') ","date":"2023-09-18","objectID":"/20230918/:9:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实战","uri":"/20230918/"},{"categories":["机器学习","Python"],"content":"地铁导航系统 # 指定起始站和终点站 A_station = '昌吉东路' B_station = '同济大学' # 获取最短路径 shortest_path_list = nx.shortest_path(G, source=A_station, target=B_station, weight='time') for i in range(len(shortest_path_list)-1): previous_station = shortest_path_list[i] next_station = shortest_path_list[i+1] line_id = G.edges[(previous_station, next_station)]['line'] # 地铁线编号 time = G.edges[(previous_station, next_station)]['time'] # 时间 print('{}---\u003e{} {}号线 {}分钟'.format(previous_station, next_station, line_id, time)) # 输出结果 # 最短路径长度 print('共计 {} 分钟'.format(nx.shortest_path_length(G, source=A_station, target=B_station, weight='time'))) 昌吉东路---\u003e上海赛车场 11号线 4分钟\r上海赛车场---\u003e嘉定新城 11号线 4分钟\r嘉定新城---\u003e马陆 11号线 3分钟\r马陆---\u003e陈翔公路 11号线 4分钟\r陈翔公路---\u003e南翔 11号线 3分钟\r南翔---\u003e桃浦新村 11号线 3分钟\r桃浦新村---\u003e武威路 11号线 3分钟\r武威路---\u003e祁连山路 11号线 2分钟\r祁连山路---\u003e李子园 11号线 3分钟\r李子园---\u003e上海西站 11号线 2分钟\r上海西站---\u003e真如 11号线 3分钟\r真如---\u003e枫桥路 11号线 2分钟\r枫桥路---\u003e曹杨路 11号线 2分钟\r曹杨路---\u003e镇坪路 4号线 3分钟\r镇坪路---\u003e中潭路 4号线 2分钟\r中潭路---\u003e上海火车站 4号线 3分钟\r上海火车站---\u003e宝山路 4号线 4分钟\r宝山路---\u003e海伦路 4号线 3分钟\r海伦路---\u003e邮电新村 10号线 2分钟\r邮电新村---\u003e四平路 10号线 2分钟\r四平路---\u003e同济大学 10号线 2分钟\r共计 59 分钟\r","date":"2023-09-18","objectID":"/20230918/:10:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实战","uri":"/20230918/"},{"categories":["机器学习","Python"],"content":"Node Degree # dict(G.degree()) # dict_sort_by_value(dict(G.degree())) draw(G, pos, dict(G.degree()), 'Node Degree') ","date":"2023-09-18","objectID":"/20230918/:11:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实战","uri":"/20230918/"},{"categories":["机器学习","Python"],"content":"Degree Centrality # nx.degree_centrality(G) # dict_sort_by_value(nx.degree_centrality(G)) draw(G, pos, nx.degree_centrality(G), 'Degree Centrality') ","date":"2023-09-18","objectID":"/20230918/:12:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实战","uri":"/20230918/"},{"categories":["机器学习","Python"],"content":"Eigenvector Centrality（可能不收敛） # nx.eigenvector_centrality(G) dict_sort_by_value(nx.eigenvector_centrality(G)) [('南京西路', 0.34518830475920503),\r('人民广场', 0.32714367869804883),\r('陕西南路', 0.29476635705907395),\r('一大会址·黄陂南路', 0.27634308858888684),\r('静安寺', 0.27321037099703027),\r('汉中路', 0.23555647374614153),\r('大世界', 0.22428268234399096),\r('常熟路', 0.18814941101791502),\r('曲阜路', 0.17433210873324256),\r('南京东路', 0.16614884934649515),\r('一大会址·新天地', 0.15807115407289815),\r('豫园', 0.1560268098793676),\r('老西门', 0.14902071652673546),\r('自然博物馆', 0.1433653828402798),\r('新闸路', 0.13890944689388865),\r('嘉善路', 0.13046505843944672),\r('江苏路', 0.12516435598675363),\r('淮海中路', 0.12423759493693706),\r('肇嘉浜路', 0.12087703703752431),\r('徐家汇', 0.10860529839818872),\r('天潼路', 0.0972848797028609),\r('上海图书馆', 0.0957967326770932),\r('交通大学', 0.09326712605450173),\r('陆家嘴', 0.09259583711035488),\r('武定路', 0.0869184732746459),\r('昌平路', 0.08492332314892047),\r('隆德路', 0.08405180976485153),\r('武宁路', 0.07885946996469545),\r('曹杨路', 0.07765153506881935),\r('上海火车站', 0.07677540807840737),\r('江宁路', 0.07562534195479777),\r('衡山路', 0.07326580131695953),\r('马当路', 0.07228575502247306),\r('长寿路', 0.070782329141782),\r('陆家浜路', 0.06528067406662807),\r('宜山路', 0.0633384339774855),\r('大木桥路', 0.06276223702141297),\r('东安路', 0.06238176849565273),\r('金沙江路', 0.058751965444709536),\r('中山公园', 0.056441377217852876),\r('上海体育馆', 0.056272028186685856),\r('打浦桥', 0.05005398149819857),\r('虹桥路', 0.048190584835098596),\r('镇坪路', 0.04729440444519273),\r('中兴路', 0.046209625938393645),\r('龙华中路', 0.03972543191788755),\r('上海游泳馆', 0.03284216844978234),\r('中潭路', 0.0306300344668945),\r('上海体育场', 0.029297614084239275),\r('四川北路', 0.02775006843829703),\r('东昌路', 0.026993861657928154),\r('漕宝路', 0.026648571941170006),\r('浦东南路', 0.02592997856476124),\r('国际客运中心', 0.02586095375191745),\r('延安西路', 0.02583496933801722),\r('西藏南路', 0.02488675862249297),\r('宝山路', 0.024541259007936158),\r('龙华', 0.024403908411204447),\r('桂林路', 0.022912025965744074),\r('枫桥路', 0.022769743149125294),\r('中宁路', 0.022769743149125294),\r('鲁班路', 0.021639260802360106),\r('漕溪路', 0.020527666807312838),\r('中山北路', 0.020274763838109527),\r('大渡河路', 0.019805076597075946),\r('龙漕路', 0.019788994948518823),\r('世博会博物馆', 0.01940734737404672),\r('娄山关路', 0.018847854611684107),\r('小南门', 0.01824826459592638),\r('桂林公园', 0.017013822697997696),\r('世纪大道', 0.016756099978825333),\r('海伦路', 0.015128915024740227),\r('上海南站', 0.01483211996475074),\r('真如', 0.014565008548043375),\r('西藏北路', 0.012857640018257952),\r('宋园路', 0.01272971743342056),\r('岚皋路', 0.012491658380544748),\r('浦东大道', 0.012446070401746818),\r('后滩', 0.011346417324877846),\r('长风公园', 0.00954424219179578),\r('商城路', 0.00864086121103916),\r('石龙路', 0.008550854087711803),\r('东宝兴路', 0.007508673168681236),\r('提篮桥', 0.007476289289692376),\r('铜川路', 0.007249426679812461),\r('中华艺术宫', 0.007232801738549839),\r('梅岭北路', 0.006680680656542667),\r('南浦大桥', 0.006657191218658478),\r('云锦路', 0.006473532928517094),\r('吴中路', 0.0063746443228935214),\r('世博大道', 0.006328898598717274),\r('长清路', 0.0062286609139391115),\r('上海西站', 0.006195443108502219),\r('漕河泾开发区', 0.0060533904113758644),\r('虹口足球场', 0.005875555718867289),\r('杨高中路', 0.005778121061354283),\r('红宝石路', 0.005370142786911231),\r('延长路', 0.005354109068034759),\r('真北路', 0.00523168023322469),\r('威宁路', 0.004978825017992365),\r('源深体育中心', 0.004969251340305569),\r('临平路', 0.004827039756296572),\r('浦电路', 0.004572594456108166),\r('虹漕路', 0.0044957409194985466),\r('上海科技馆', 0.004480147523162711),\r('大连路', 0.0044254553108306685),\r('耀华路', 0.0044110460960415845),\r('邮电新村', 0.004167930947709774),\r('杨树浦路', 0.004164635049643304),\r('锦江乐园', 0.003919476448894465),\r('华东理工大学', 0.003919476448893693),\r('源深路', 0.003569512135038515),\r('民生路', 0.0033753044571646325),\r('伊犁路', 0.003362845014875709),\r('新村路', 0.0032994414915865394),\r('成山路', 0.0031411487140143774),\r('姚虹路', 0.0029004082761595966),\r('塘桥', 0.0020799150248948127),\r('昌邑路', 0.0020146473642981126),\r('真光路', 0.0019152696299063227),\r('曲阳路', 0.001883693955659403),\r('龙耀路', 0.001811408766047648),\r('蓝村路', 0.0017682199268821354),\r('四平路', 0.001755295103356084),\r('迎春路', 0.00171413115","date":"2023-09-18","objectID":"/20230918/:13:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实战","uri":"/20230918/"},{"categories":["机器学习","Python"],"content":"Betweenness Centrality（必经之地） # nx.betweenness_centrality(G) # dict_sort_by_value(nx.betweenness_centrality(G)) draw(G, pos, nx.betweenness_centrality(G), 'Betweenness Centrality') ","date":"2023-09-18","objectID":"/20230918/:14:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实战","uri":"/20230918/"},{"categories":["机器学习","Python"],"content":"Closeness Centrality（去哪儿都近） # nx.closeness_centrality(G) # dict_sort_by_value(nx.eigenvector_centrality(G)) draw(G, pos, nx.closeness_centrality(G), 'Closeness Centrality') ","date":"2023-09-18","objectID":"/20230918/:15:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实战","uri":"/20230918/"},{"categories":["机器学习","Python"],"content":"PageRank # nx.pagerank(G) # dict_sort_by_value(nx.pagerank(G)) draw(G, pos, nx.pagerank(G, alpha=0.85), 'PageRank') ","date":"2023-09-18","objectID":"/20230918/:16:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实战","uri":"/20230918/"},{"categories":["机器学习","Python"],"content":"Katz Centrality # nx.katz_centrality(G, alpha=0.1, beta=1.0) # dict_sort_by_value(nx.katz_centrality(G, alpha=0.1, beta=1.0)) draw(G, pos, nx.katz_centrality(G, alpha=0.1, beta=1.0), 'Katz Centrality') ","date":"2023-09-18","objectID":"/20230918/:17:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实战","uri":"/20230918/"},{"categories":["机器学习","Python"],"content":"HITS Hubs and Authorities h, a = nx.hits(G) draw(G, pos, h, 'DiGraph HITS Hubs') draw(G, pos, a, 'DiGraph HITS Authorities') ","date":"2023-09-18","objectID":"/20230918/:18:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实战","uri":"/20230918/"},{"categories":["机器学习","Python"],"content":"NetworkX文档：社群属性 Clustering https://networkx.org/documentation/stable/reference/algorithms/clustering.html ","date":"2023-09-18","objectID":"/20230918/:19:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实战","uri":"/20230918/"},{"categories":["机器学习","Python"],"content":"三角形个数 # nx.triangles(G) dict_sort_by_value(nx.triangles(G)) [('曹杨路', 2),\r('大世界', 2),\r('豫园', 2),\r('隆德路', 2),\r('上海南站', 1),\r('漕宝路', 1),\r('上海体育馆', 1),\r('徐家汇', 1),\r('一大会址·黄陂南路', 1),\r('人民广场', 1),\r('汉中路', 1),\r('南京西路', 1),\r('南京东路', 1),\r('陆家嘴', 1),\r('宜山路', 1),\r('金沙江路', 1),\r('大木桥路', 1),\r('东安路', 1),\r('龙华中路', 1),\r('长清路', 1),\r('耀华路', 1),\r('成山路', 1),\r('老西门', 1),\r('上海西站', 1),\r('真如', 1),\r('桂林公园', 1),\r('武宁路', 1),\r('自然博物馆', 1),\r('铜川路', 1),\r('莘庄', 0),\r('外环路', 0),\r('莲花路', 0),\r('锦江乐园', 0),\r('衡山路', 0),\r('常熟路', 0),\r('陕西南路', 0),\r('新闸路', 0),\r('上海火车站', 0),\r('中山北路', 0),\r('延长路', 0),\r('上海马戏城', 0),\r('汶水路', 0),\r('彭浦新村', 0),\r('共康路', 0),\r('通河新村', 0),\r('呼兰路', 0),\r('共富新村', 0),\r('宝安公路', 0),\r('友谊西路', 0),\r('富锦路', 0),\r('徐泾东', 0),\r('虹桥火车站', 0),\r('虹桥2号航站楼', 0),\r('淞虹路', 0),\r('北新泾', 0),\r('威宁路', 0),\r('娄山关路', 0),\r('中山公园', 0),\r('江苏路', 0),\r('静安寺', 0),\r('东昌路', 0),\r('世纪大道', 0),\r('上海科技馆', 0),\r('世纪公园', 0),\r('龙阳路', 0),\r('张江高科', 0),\r('金科路', 0),\r('广兰路', 0),\r('唐镇', 0),\r('创新中路', 0),\r('华夏东路', 0),\r('川沙', 0),\r('凌空路', 0),\r('远东大道', 0),\r('海天三路', 0),\r('浦东国际机场', 0),\r('石龙路', 0),\r('龙漕路', 0),\r('漕溪路', 0),\r('虹桥路', 0),\r('延安西路', 0),\r('镇坪路', 0),\r('中潭路', 0),\r('宝山路', 0),\r('东宝兴路', 0),\r('虹口足球场', 0),\r('赤峰路', 0),\r('大柏树', 0),\r('江湾镇', 0),\r('殷高西路', 0),\r('长江南路', 0),\r('淞发路', 0),\r('张华浜', 0),\r('淞滨路', 0),\r('水产路', 0),\r('宝杨路', 0),\r('友谊路', 0),\r('铁力路', 0),\r('江杨北路', 0),\r('海伦路', 0),\r('临平路', 0),\r('大连路', 0),\r('杨树浦路', 0),\r('浦东大道', 0),\r('浦电路', 0),\r('蓝村路', 0),\r('塘桥', 0),\r('南浦大桥', 0),\r('西藏南路', 0),\r('鲁班路', 0),\r('上海体育场', 0),\r('春申路', 0),\r('银都路', 0),\r('颛桥', 0),\r('北桥', 0),\r('剑川路', 0),\r('东川路', 0),\r('江川路', 0),\r('西渡', 0),\r('萧塘', 0),\r('奉浦大道', 0),\r('环城东路', 0),\r('望园路', 0),\r('金海湖', 0),\r('奉贤新城', 0),\r('金平路', 0),\r('华宁路', 0),\r('文井路', 0),\r('闵行开发区', 0),\r('东方体育中心', 0),\r('灵岩南路', 0),\r('上南路', 0),\r('华夏西路', 0),\r('高青路', 0),\r('东明路', 0),\r('高科西路', 0),\r('临沂新村', 0),\r('上海儿童医学中心', 0),\r('源深体育中心', 0),\r('民生路', 0),\r('北洋泾路', 0),\r('德平路', 0),\r('云山路', 0),\r('金桥路', 0),\r('博兴路', 0),\r('五莲路', 0),\r('巨峰路', 0),\r('东靖路', 0),\r('五洲大道', 0),\r('洲海路', 0),\r('外高桥保税区南站', 0),\r('航津路', 0),\r('外高桥保税区北站', 0),\r('港城路', 0),\r('美兰湖', 0),\r('罗南新村', 0),\r('潘广路', 0),\r('刘行', 0),\r('顾村公园', 0),\r('祁华路', 0),\r('上海大学', 0),\r('南陈路', 0),\r('上大路', 0),\r('场中路', 0),\r('大场镇', 0),\r('行知路', 0),\r('大华三路', 0),\r('新村路', 0),\r('岚皋路', 0),\r('长寿路', 0),\r('昌平路', 0),\r('肇嘉浜路', 0),\r('后滩', 0),\r('云台路', 0),\r('杨高南路', 0),\r('锦绣路', 0),\r('芳华路', 0),\r('花木路', 0),\r('沈杜公路', 0),\r('联航路', 0),\r('江月路', 0),\r('浦江镇', 0),\r('芦恒路', 0),\r('凌兆新村', 0),\r('杨思', 0),\r('中华艺术宫', 0),\r('陆家浜路', 0),\r('曲阜路', 0),\r('中兴路', 0),\r('西藏北路', 0),\r('曲阳路', 0),\r('四平路', 0),\r('鞍山新村', 0),\r('江浦路', 0),\r('黄兴路', 0),\r('延吉中路', 0),\r('黄兴公园', 0),\r('翔殷路', 0),\r('嫩江路', 0),\r('市光路', 0),\r('松江南站', 0),\r('醉白池', 0),\r('松江体育中心', 0),\r('松江新城', 0),\r('松江大学城', 0),\r('洞泾', 0),\r('佘山', 0),\r('泗泾', 0),\r('九亭', 0),\r('中春路', 0),\r('七宝', 0),\r('星中路', 0),\r('合川路', 0),\r('漕河泾开发区', 0),\r('桂林路', 0),\r('嘉善路', 0),\r('打浦桥', 0),\r('马当路', 0),\r('小南门', 0),\r('商城路', 0),\r('杨高中路', 0),\r('芳甸路', 0),\r('蓝天路', 0),\r('台儿庄路', 0),\r('金桥', 0),\r('金吉路', 0),\r('金海路', 0),\r('顾唐路', 0),\r('民雷路', 0),\r('曹路', 0),\r('航中路', 0),\r('紫藤路', 0),\r('龙柏新村', 0),\r('虹桥1号航站楼', 0),\r('上海动物园', 0),\r('龙溪路', 0),\r('水城路', 0),\r('伊犁路', 0),\r('宋园路', 0),\r('交通大学', 0),\r('上海图书馆', 0),\r('一大会址·新天地', 0),\r('天潼路', 0),\r('四川北路', 0),\r('邮电新村', 0),\r('同济大学', 0),\r('国权路', 0),\r('五角场', 0),\r('江湾体育场', 0),\r('三门路', 0),\r('殷高东路', 0),\r('新江湾城', 0),\r('国帆路', 0),\r('双江路', 0),\r('高桥西', 0),\r('高桥', 0),\r('基隆路', 0),\r('花桥', 0),\r('光明路', 0),\r('兆丰路', 0),\r('安亭', 0),\r('上海汽车城', 0),\r('昌吉东路', 0),\r('上海赛车场', 0),\r('嘉定北', 0),\r('嘉定西', 0),\r('白银路', 0),\r('嘉定新城', 0),\r('马陆', 0),\r('陈翔公路', 0),\r('南翔', 0),\r('桃浦新村', 0),\r('武威路', 0),\r('祁连山路', 0),\r('李子园', 0),\r('枫桥路', 0),\r('上海游泳馆', 0),\r('龙华', 0),\r('云锦路', 0),\r('龙耀路', 0),\r('三林', 0),\r('三林东', 0),\r('浦三路', 0),\r('御桥', 0),\r('罗山路', 0),\r('秀沿路', 0),\r('康新公路', 0),\r('迪士尼', 0),\r('七莘路', 0),\r('虹莘路', 0),\r('顾戴路', 0),\r('东兰路', 0),\r('虹梅路', 0),\r('虹漕路', 0),\r('国际客运中心', 0),\r('提篮桥', 0),\r('江浦公园', 0),\r('宁国路', 0),\r('隆昌路', 0),\r('爱国路', 0),\r('复兴岛', 0),\r('东陆路', 0),\r('杨高北路', 0),\r('金京路', 0),\r('申江路', 0),\r('金运路', 0),\r('金沙江西路', 0),\r('丰庄', 0),\r('祁连山南路', 0),\r('真北路', 0),\r('大渡河路', 0),\r('江宁路', 0),\r('淮海中路', 0),\r('世博会博物馆', 0),\r('世博大道', 0),\r('华鹏路', 0),\r('下南","date":"2023-09-18","objectID":"/20230918/:20:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实战","uri":"/20230918/"},{"categories":["机器学习","Python"],"content":"Clustering Coefficient # nx.clustering(G) # dict_sort_by_value(nx.clustering(G)) draw(G, pos, nx.clustering(G), 'Clustering Coefficient') 计算全图Graphlet个数 ","date":"2023-09-18","objectID":"/20230918/:21:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实战","uri":"/20230918/"},{"categories":["机器学习","Python"],"content":"导入工具包 import networkx as nx import matplotlib.pyplot as plt %matplotlib inline import itertools ","date":"2023-09-18","objectID":"/20230918/:22:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实战","uri":"/20230918/"},{"categories":["机器学习","Python"],"content":"导入全图 G = nx.karate_club_graph() plt.figure(figsize=(10,8)) pos = nx.spring_layout(G, seed=123) nx.draw(G, pos, with_labels=True) ","date":"2023-09-18","objectID":"/20230918/:23:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实战","uri":"/20230918/"},{"categories":["机器学习","Python"],"content":"指定Graphlet target = nx.complete_graph(3) nx.draw(target) ","date":"2023-09-18","objectID":"/20230918/:24:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实战","uri":"/20230918/"},{"categories":["机器学习","Python"],"content":"匹配Graphlet，统计个数 num = 0 for sub_nodes in itertools.combinations(G.nodes(), len(target.nodes())): # 遍历全图中，符合graphlet节点个数的所有节点组合 subg = G.subgraph(sub_nodes) # 从全图中抽取出子图 if nx.is_connected(subg) and nx.is_isomorphic(subg, target): # 如果子图是完整连通域，并且符合graphlet特征，输出原图节点编号 num += 1 print(subg.edges()) [(0, 1), (0, 2), (1, 2)]\r[(0, 1), (0, 3), (1, 3)]\r[(0, 1), (0, 7), (1, 7)]\r[(0, 1), (0, 13), (1, 13)]\r[(0, 1), (0, 17), (1, 17)]\r[(0, 1), (0, 19), (1, 19)]\r[(0, 1), (0, 21), (1, 21)]\r[(0, 2), (0, 3), (2, 3)]\r[(0, 2), (0, 7), (2, 7)]\r[(0, 2), (0, 8), (8, 2)]\r[(0, 2), (0, 13), (2, 13)]\r[(0, 3), (0, 7), (3, 7)]\r[(0, 3), (0, 12), (3, 12)]\r[(0, 3), (0, 13), (3, 13)]\r[(0, 4), (0, 6), (4, 6)]\r[(0, 4), (0, 10), (10, 4)]\r[(0, 5), (0, 6), (5, 6)]\r[(0, 5), (0, 10), (10, 5)]\r[(1, 2), (1, 3), (2, 3)]\r[(1, 2), (1, 7), (2, 7)]\r[(1, 2), (1, 13), (2, 13)]\r[(1, 3), (1, 7), (3, 7)]\r[(1, 3), (1, 13), (3, 13)]\r[(2, 3), (2, 7), (3, 7)]\r[(2, 3), (2, 13), (3, 13)]\r[(8, 2), (8, 32), (2, 32)]\r[(16, 5), (16, 6), (5, 6)]\r[(8, 30), (8, 32), (32, 30)]\r[(8, 30), (8, 33), (33, 30)]\r[(8, 32), (8, 33), (33, 32)]\r[(32, 14), (32, 33), (33, 14)]\r[(32, 15), (32, 33), (33, 15)]\r[(32, 18), (32, 33), (33, 18)]\r[(32, 20), (32, 33), (33, 20)]\r[(32, 22), (32, 33), (33, 22)]\r[(33, 23), (33, 27), (27, 23)]\r[(32, 23), (32, 29), (29, 23)]\r[(33, 23), (33, 29), (29, 23)]\r[(32, 23), (32, 33), (33, 23)]\r[(24, 25), (24, 31), (25, 31)]\r[(33, 26), (33, 29), (26, 29)]\r[(33, 28), (33, 31), (28, 31)]\r[(32, 29), (32, 33), (33, 29)]\r[(32, 30), (32, 33), (33, 30)]\r[(32, 31), (32, 33), (33, 31)]\rnum 45\r拉普拉斯矩阵特征值分解 参考文档：https://networkx.org/documentation/stable/auto_examples/drawing/plot_eigenvalues.html#sphx-glr-auto-examples-drawing-plot-eigenvalues-py ","date":"2023-09-18","objectID":"/20230918/:25:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实战","uri":"/20230918/"},{"categories":["机器学习","Python"],"content":"导入工具包 # 图数据挖掘 import networkx as nx import numpy as np # 数据可视化 import matplotlib.pyplot as plt %matplotlib inline plt.rcParams['font.sans-serif']=['SimHei'] # 用来正常显示中文标签 plt.rcParams['axes.unicode_minus']=False # 用来正常显示负号 import numpy.linalg # 线性代数 ","date":"2023-09-18","objectID":"/20230918/:26:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实战","uri":"/20230918/"},{"categories":["机器学习","Python"],"content":"创建图 n = 1000 # 节点个数 m = 5000 # 连接个数 G = nx.gnm_random_graph(n, m, seed=5040) ","date":"2023-09-18","objectID":"/20230918/:27:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实战","uri":"/20230918/"},{"categories":["机器学习","Python"],"content":"邻接矩阵（Adjacency Matrix） A = nx.adjacency_matrix(G) A.shape (1000, 1000)\rA.todense() matrix([[0, 0, 0, ..., 0, 0, 0],\r[0, 0, 0, ..., 0, 0, 0],\r[0, 0, 0, ..., 0, 0, 0],\r...,\r[0, 0, 0, ..., 0, 0, 0],\r[0, 0, 0, ..., 0, 0, 0],\r[0, 0, 0, ..., 0, 0, 0]], dtype=int64)\r","date":"2023-09-18","objectID":"/20230918/:28:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实战","uri":"/20230918/"},{"categories":["机器学习","Python"],"content":"拉普拉斯矩阵（Laplacian Matrix） $$ L = D - A $$ L 为拉普拉斯矩阵（Laplacian Matrix） D 为节点degree对角矩阵 A 为邻接矩阵（Adjacency Matrix） L = nx.laplacian_matrix(G) L.shape (1000, 1000)\r# 节点degree对角矩阵 D = L + A D.todense() matrix([[12, 0, 0, ..., 0, 0, 0],\r[ 0, 6, 0, ..., 0, 0, 0],\r[ 0, 0, 8, ..., 0, 0, 0],\r...,\r[ 0, 0, 0, ..., 8, 0, 0],\r[ 0, 0, 0, ..., 0, 6, 0],\r[ 0, 0, 0, ..., 0, 0, 7]], dtype=int64)\r# G.degree() ","date":"2023-09-18","objectID":"/20230918/:29:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实战","uri":"/20230918/"},{"categories":["机器学习","Python"],"content":"归一化拉普拉斯矩阵（Normalized Laplacian Matrix） $$ L_n = D^{-\\frac{1}{2}}LD^{-\\frac{1}{2}} $$ L_n = nx.normalized_laplacian_matrix(G) L_n.shape (1000, 1000)\rL_n.todense() matrix([[1., 0., 0., ..., 0., 0., 0.],\r[0., 1., 0., ..., 0., 0., 0.],\r[0., 0., 1., ..., 0., 0., 0.],\r...,\r[0., 0., 0., ..., 1., 0., 0.],\r[0., 0., 0., ..., 0., 1., 0.],\r[0., 0., 0., ..., 0., 0., 1.]])\rplt.imshow(L_n.todense()) plt.show() type(L_n) scipy.sparse.csr.csr_matrix\r","date":"2023-09-18","objectID":"/20230918/:30:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实战","uri":"/20230918/"},{"categories":["机器学习","Python"],"content":"特征值分解 e = np.linalg.eigvals(L_n.A) e array([-3.53879524e-16, 1.59246179e+00, 1.58938840e+00, 1.58583526e+00,\r4.02846420e-01, 4.06224295e-01, 4.12963520e-01, 4.15548851e-01,\r4.16517467e-01, 1.58139953e+00, 1.58070318e+00, 4.20582471e-01,\r4.24326947e-01, 1.57786096e+00, 4.29110624e-01, 4.31464217e-01,\r1.57398179e+00, 1.57237733e+00, 4.33218297e-01, 1.57150969e+00,\r1.57095514e+00, 4.35026221e-01, 4.37026657e-01, 1.56726875e+00,\r4.40378510e-01, 4.42775893e-01, 4.45046086e-01, 1.56345866e+00,\r1.56395825e+00, 4.46753827e-01, 4.50881547e-01, 4.48717950e-01,\r4.49417823e-01, 1.56009824e+00, 1.55880096e+00, 1.55717189e+00,\r1.55698938e+00, 1.55475549e+00, 1.54908738e+00, 1.54681927e+00,\r1.54491505e+00, 1.54352783e+00, 1.54231896e+00, 1.54098279e+00,\r1.54051439e+00, 1.53578067e+00, 1.53502733e+00, 1.53439005e+00,\r1.52838134e+00, 1.53085674e+00, 1.53141471e+00, 1.52515680e+00,\r1.52512114e+00, 1.52151217e+00, 1.52011306e+00, 1.52064972e+00,\r1.51734481e+00, 1.51789644e+00, 1.51650845e+00, 1.51050284e+00,\r1.51160361e+00, 1.51266269e+00, 1.50970637e+00, 1.50786560e+00,\r1.50593131e+00, 1.50508573e+00, 1.50356363e+00, 1.50256425e+00,\r1.50143743e+00, 1.49974932e+00, 1.50033534e+00, 1.48749487e+00,\r1.48806489e+00, 1.49053530e+00, 1.49336377e+00, 1.49505706e+00,\r1.49650057e+00, 1.49229941e+00, 1.49722359e+00, 1.48940564e+00,\r4.54190661e-01, 4.55357875e-01, 4.58263114e-01, 4.57707915e-01,\r4.61849308e-01, 4.63660933e-01, 4.64660065e-01, 4.66860929e-01,\r4.69366311e-01, 4.69709000e-01, 4.73545468e-01, 4.76756569e-01,\r4.65763726e-01, 4.74333012e-01, 4.86462532e-01, 4.79394325e-01,\r4.75649819e-01, 4.80606513e-01, 4.83264820e-01, 4.84997389e-01,\r4.85154008e-01, 1.48542791e+00, 1.48490224e+00, 1.47887385e+00,\r1.48185134e+00, 1.48241248e+00, 1.47794501e+00, 1.47709645e+00,\r1.47762024e+00, 1.47552207e+00, 1.47141067e+00, 1.47388061e+00,\r1.47033271e+00, 1.44904512e+00, 1.44986013e+00, 1.45090139e+00,\r1.45216238e+00, 1.46817150e+00, 1.46566928e+00, 1.46791556e+00,\r1.45500080e+00, 1.46487844e+00, 1.46269200e+00, 1.45908676e+00,\r1.46138525e+00, 1.45410520e+00, 1.45733801e+00, 1.46156481e+00,\r1.45644004e+00, 1.45770660e+00, 4.91621993e-01, 4.90304444e-01,\r4.88729605e-01, 4.88322850e-01, 4.94845030e-01, 4.96583277e-01,\r5.00214562e-01, 5.02653227e-01, 4.95732976e-01, 5.04153801e-01,\r4.99448904e-01, 5.06512201e-01, 5.05556356e-01, 5.01180333e-01,\r1.42699849e+00, 1.42677234e+00, 1.42988927e+00, 1.43134759e+00,\r1.43260357e+00, 1.43846236e+00, 1.44014343e+00, 1.44739972e+00,\r1.43619292e+00, 1.44246039e+00, 1.44531749e+00, 1.43354375e+00,\r1.43441916e+00, 1.44589494e+00, 1.43490982e+00, 1.43713890e+00,\r1.44158907e+00, 1.44376226e+00, 5.22556927e-01, 5.09010234e-01,\r5.10154623e-01, 5.11622478e-01, 5.07002615e-01, 5.16057435e-01,\r5.14665415e-01, 5.16533531e-01, 5.18785357e-01, 5.20015126e-01,\r5.21860072e-01, 5.12797358e-01, 1.41228135e+00, 1.41347984e+00,\r1.41448341e+00, 1.41598484e+00, 1.41748057e+00, 1.41662929e+00,\r1.42320539e+00, 1.42542313e+00, 1.41961351e+00, 1.42457194e+00,\r1.42052766e+00, 1.42118742e+00, 5.23407726e-01, 5.34473212e-01,\r5.25881593e-01, 5.27322194e-01, 5.30802877e-01, 5.29711336e-01,\r5.32286178e-01, 5.28274379e-01, 5.33613821e-01, 1.39936317e+00,\r1.40196461e+00, 1.40361810e+00, 1.40415543e+00, 1.40498931e+00,\r1.40702610e+00, 1.41140670e+00, 1.40819911e+00, 1.40969057e+00,\r1.41274341e+00, 5.44579715e-01, 5.39616555e-01, 5.37113507e-01,\r5.38466485e-01, 5.40543078e-01, 5.42474931e-01, 5.42041958e-01,\r1.38748697e+00, 1.38793243e+00, 1.39757348e+00, 1.38899394e+00,\r1.39625743e+00, 1.39026791e+00, 1.39235250e+00, 1.39158171e+00,\r1.39285233e+00, 1.39073914e+00, 1.39651349e+00, 5.48067206e-01,\r5.55908434e-01, 5.47076780e-01, 5.45647110e-01, 5.51103949e-01,\r5.51314655e-01, 5.53584120e-01, 5.54656573e-01, 1.37512858e+00,\r1.37634495e+00, 1.37774739e+00, 1.37947093e+00, 1.38336173e+00,\r1.38561715e+00, 1.37881800e+00, 1.38125128e+00, 1.38474073e+00,\r1.38167394e+00, 5.57471020e-01, 5.58337114e-01, 5.60822980e-01,\r5.63088387e-01, 5.63882730e-01, 5.65472145e-01, 5.5","date":"2023-09-18","objectID":"/20230918/:31:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实战","uri":"/20230918/"},{"categories":["机器学习","Python"],"content":"特征值分布直方图 plt.figure(figsize=(12,8)) plt.hist(e, bins=100) plt.xlim(0, 2) # eigenvalues between 0 and 2 plt.title('Eigenvalue Histogram', fontsize=20) plt.ylabel('Frequency', fontsize=25) plt.xlabel('Eigenvalue', fontsize=25) plt.tick_params(labelsize=20) # 设置坐标文字大小 plt.show() ","date":"2023-09-18","objectID":"/20230918/:32:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实战","uri":"/20230918/"},{"categories":["机器学习","Python"],"content":"PageRank节点重要度 在NetworkX中，计算有向图节点的PageRank节点重要度。 ","date":"2023-09-17","objectID":"/20230917/:0:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"参考资料 networkx官方教程：https://networkx.org/documentation/stable/tutorial.html nx.Graph https://networkx.org/documentation/stable/reference/classes/graph.html#networkx.Graph 给图、节点、连接添加属性：https://networkx.org/documentation/stable/tutorial.html#attributes 读写图：https://networkx.org/documentation/stable/reference/readwrite/index.html ","date":"2023-09-17","objectID":"/20230917/:1:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"导入工具包 # 图数据挖掘 import networkx as nx # 数据可视化 import matplotlib.pyplot as plt %matplotlib inline plt.rcParams['font.sans-serif']=['SimHei'] # 用来正常显示中文标签 plt.rcParams['axes.unicode_minus']=False # 用来正常显示负号 G = nx.star_graph(7) nx.draw(G, with_labels = True) ","date":"2023-09-17","objectID":"/20230917/:2:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"计算PageRank节点重要度¶ pagerank = nx.pagerank(G, alpha=0.8) pagerank {0: 0.4583348922684132,\r1: 0.07738072967594098,\r2: 0.07738072967594098,\r3: 0.07738072967594098,\r4: 0.07738072967594098,\r5: 0.07738072967594098,\r6: 0.07738072967594098,\r7: 0.07738072967594098}\rPageRank使用networkx实际只计算有向图的重要度，但传入无向图系统默认将其转换为双向图去计算了。 节点连接数Node Degree度分析 在NetworkX中，计算并统计图中每个节点的连接数Node Degree，绘制可视化和直方图。 参考文档：https://networkx.org/documentation/stable/auto_examples/drawing/plot_degree.html#sphx-glr-auto-examples-drawing-plot-degree-py ","date":"2023-09-17","objectID":"/20230917/:3:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"导入工具包 # 图数据挖掘 import networkx as nx import numpy as np # 数据可视化 import matplotlib.pyplot as plt %matplotlib inline plt.rcParams['font.sans-serif']=['SimHei'] # 用来正常显示中文标签 plt.rcParams['axes.unicode_minus']=False # 用来正常显示负号 ","date":"2023-09-17","objectID":"/20230917/:4:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"创建图 # 创建 Erdős-Rényi 随机图，也称作 binomial graph # n-节点数 # p-任意两个节点产生连接的概率 G = nx.gnp_random_graph(100, 0.02, seed=10374196) # 初步可视化 pos = nx.spring_layout(G, seed=10) nx.draw(G, pos) ","date":"2023-09-17","objectID":"/20230917/:5:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"最大连通域子图 Gcc = G.subgraph(sorted(nx.connected_components(G), key=len, reverse=True)[0]) pos = nx.spring_layout(Gcc, seed=10396953) # nx.draw(Gcc, pos) nx.draw_networkx_nodes(Gcc, pos, node_size=20) nx.draw_networkx_edges(Gcc, pos, alpha=0.4) nx.draw_networkx? plt.figure(figsize=(12,8)) pos = nx.spring_layout(Gcc, seed=10396953) # 设置其它可视化样式 options = { \"font_size\": 12, \"node_size\": 350, \"node_color\": \"white\", \"edgecolors\": \"black\", \"linewidths\": 1, # 节点线宽 \"width\": 2, # edge线宽 } nx.draw_networkx(Gcc, pos, **options) plt.title('Connected components of G', fontsize=20) plt.axis('off') plt.show() ","date":"2023-09-17","objectID":"/20230917/:6:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"每个节点的连接数（degree） G.degree() DegreeView({0: 2, 1: 4, 2: 4, 3: 4, 4: 2, 5: 4, 6: 4, 7: 2, 8: 2, 9: 1, 10: 3, 11: 0, 12: 1, 13: 2, 14: 6, 15: 2, 16: 0, 17: 0, 18: 3, 19: 1, 20: 3, 21: 1, 22: 1, 23: 1, 24: 1, 25: 3, 26: 0, 27: 2, 28: 2, 29: 0, 30: 2, 31: 1, 32: 1, 33: 0, 34: 1, 35: 4, 36: 2, 37: 2, 38: 1, 39: 5, 40: 5, 41: 1, 42: 4, 43: 1, 44: 0, 45: 2, 46: 3, 47: 1, 48: 2, 49: 2, 50: 3, 51: 2, 52: 0, 53: 3, 54: 0, 55: 3, 56: 1, 57: 2, 58: 2, 59: 2, 60: 1, 61: 1, 62: 0, 63: 2, 64: 4, 65: 5, 66: 2, 67: 0, 68: 2, 69: 2, 70: 1, 71: 3, 72: 2, 73: 4, 74: 1, 75: 2, 76: 2, 77: 2, 78: 5, 79: 2, 80: 0, 81: 1, 82: 2, 83: 1, 84: 2, 85: 0, 86: 4, 87: 2, 88: 4, 89: 2, 90: 2, 91: 3, 92: 0, 93: 2, 94: 0, 95: 4, 96: 1, 97: 4, 98: 0, 99: 2})\rdegree_sequence = sorted((d for n, d in G.degree()), reverse=True) degree_sequence [6,\r5,\r5,\r5,\r5,\r4,\r4,\r4,\r4,\r4,\r4,\r4,\r4,\r4,\r4,\r4,\r4,\r4,\r3,\r3,\r3,\r3,\r3,\r3,\r3,\r3,\r3,\r3,\r2,\r2,\r2,\r2,\r2,\r2,\r2,\r2,\r2,\r2,\r2,\r2,\r2,\r2,\r2,\r2,\r2,\r2,\r2,\r2,\r2,\r2,\r2,\r2,\r2,\r2,\r2,\r2,\r2,\r2,\r2,\r2,\r2,\r2,\r1,\r1,\r1,\r1,\r1,\r1,\r1,\r1,\r1,\r1,\r1,\r1,\r1,\r1,\r1,\r1,\r1,\r1,\r1,\r1,\r1,\r1,\r0,\r0,\r0,\r0,\r0,\r0,\r0,\r0,\r0,\r0,\r0,\r0,\r0,\r0,\r0,\r0]\rplt.figure(figsize=(12,8)) plt.plot(degree_sequence, \"b-\", marker=\"o\") plt.title('Degree Rank Plot', fontsize=20) plt.ylabel('Degree', fontsize=25) plt.xlabel('Rank', fontsize=25) plt.tick_params(labelsize=20) # 设置坐标文字大小 plt.show() ","date":"2023-09-17","objectID":"/20230917/:7:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"节点Degree直方图 X = np.unique(degree_sequence, return_counts=True)[0] Y = np.unique(degree_sequence, return_counts=True)[1] X array([0, 1, 2, 3, 4, 5, 6])\rY array([16, 22, 34, 10, 13, 4, 1])\rplt.figure(figsize=(12,8)) # plt.bar(*np.unique(degree_sequence, return_counts=True)) plt.bar(X, Y) plt.title('Degree Histogram', fontsize=20) plt.ylabel('Number', fontsize=25) plt.xlabel('Degree', fontsize=25) plt.tick_params(labelsize=20) # 设置坐标文字大小 plt.show() plt.show() 棒棒糖图特征分析 参考文档：https://networkx.org/documentation/stable/auto_examples/basic/plot_properties.html#sphx-glr-auto-examples-basic-plot-properties-py ","date":"2023-09-17","objectID":"/20230917/:8:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"导入工具包 # 图数据挖掘 import networkx as nx # 数据可视化 import matplotlib.pyplot as plt %matplotlib inline # plt.rcParams['font.sans-serif']=['SimHei'] # 用来正常显示中文标签 plt.rcParams['axes.unicode_minus']=False # 用来正常显示负号 ","date":"2023-09-17","objectID":"/20230917/:9:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"导入图 # 第一个参数指定头部节点数，第二个参数指定尾部节点数 G = nx.lollipop_graph(4, 7) ","date":"2023-09-17","objectID":"/20230917/:10:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"可视化 pos = nx.spring_layout(G, seed=3068) nx.draw(G, pos=pos, with_labels=True) plt.show() ","date":"2023-09-17","objectID":"/20230917/:11:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"图数据分析 # 半径 nx.radius(G) 4\r# 直径 nx.diameter(G) 8\r# 偏心度：每个节点到图中其它节点的最远距离 nx.eccentricity(G) {0: 8, 1: 8, 2: 8, 3: 7, 4: 6, 5: 5, 6: 4, 7: 5, 8: 6, 9: 7, 10: 8}\r# 中心节点，偏心度与半径相等的节点 nx.center(G) [6]\r# 外围节点，偏心度与直径相等的节点 nx.periphery(G) [0, 1, 2, 10]\rnx.density? nx.density(G) 0.23636363636363636\rn为节点个数，m为连接个数 对于无向图： $$ density = \\frac{2m}{n(n-1)} $$ 对于有向图： $$ density = \\frac{m}{n(n-1)} $$ 无连接图的density为0，全连接图的density为1，Multigraph（多重连接图）和带self loop图的density可能大于1。 ","date":"2023-09-17","objectID":"/20230917/:12:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"3号节点到图中其它节点的最短距离 node_id = 3 nx.single_source_shortest_path_length(G, node_id) {3: 0, 0: 1, 1: 1, 2: 1, 4: 1, 5: 2, 6: 3, 7: 4, 8: 5, 9: 6, 10: 7}\r","date":"2023-09-17","objectID":"/20230917/:13:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"每两个节点之间的最短距离 pathlengths = [] for v in G.nodes(): spl = nx.single_source_shortest_path_length(G, v) for p in spl: print('{} --\u003e {} 最短距离 {}'.format(v, p, spl[p])) pathlengths.append(spl[p]) 0 --\u003e 0 最短距离 0\r0 --\u003e 1 最短距离 1\r0 --\u003e 2 最短距离 1\r0 --\u003e 3 最短距离 1\r0 --\u003e 4 最短距离 2\r0 --\u003e 5 最短距离 3\r0 --\u003e 6 最短距离 4\r0 --\u003e 7 最短距离 5\r0 --\u003e 8 最短距离 6\r0 --\u003e 9 最短距离 7\r0 --\u003e 10 最短距离 8\r1 --\u003e 1 最短距离 0\r1 --\u003e 0 最短距离 1\r1 --\u003e 2 最短距离 1\r1 --\u003e 3 最短距离 1\r1 --\u003e 4 最短距离 2\r1 --\u003e 5 最短距离 3\r1 --\u003e 6 最短距离 4\r1 --\u003e 7 最短距离 5\r1 --\u003e 8 最短距离 6\r1 --\u003e 9 最短距离 7\r1 --\u003e 10 最短距离 8\r2 --\u003e 2 最短距离 0\r2 --\u003e 0 最短距离 1\r2 --\u003e 1 最短距离 1\r2 --\u003e 3 最短距离 1\r2 --\u003e 4 最短距离 2\r2 --\u003e 5 最短距离 3\r2 --\u003e 6 最短距离 4\r2 --\u003e 7 最短距离 5\r2 --\u003e 8 最短距离 6\r2 --\u003e 9 最短距离 7\r2 --\u003e 10 最短距离 8\r3 --\u003e 3 最短距离 0\r3 --\u003e 0 最短距离 1\r3 --\u003e 1 最短距离 1\r3 --\u003e 2 最短距离 1\r3 --\u003e 4 最短距离 1\r3 --\u003e 5 最短距离 2\r3 --\u003e 6 最短距离 3\r3 --\u003e 7 最短距离 4\r3 --\u003e 8 最短距离 5\r3 --\u003e 9 最短距离 6\r3 --\u003e 10 最短距离 7\r4 --\u003e 4 最短距离 0\r4 --\u003e 3 最短距离 1\r4 --\u003e 5 最短距离 1\r4 --\u003e 0 最短距离 2\r4 --\u003e 1 最短距离 2\r4 --\u003e 2 最短距离 2\r4 --\u003e 6 最短距离 2\r4 --\u003e 7 最短距离 3\r4 --\u003e 8 最短距离 4\r4 --\u003e 9 最短距离 5\r4 --\u003e 10 最短距离 6\r5 --\u003e 5 最短距离 0\r5 --\u003e 4 最短距离 1\r5 --\u003e 6 最短距离 1\r5 --\u003e 3 最短距离 2\r5 --\u003e 7 最短距离 2\r5 --\u003e 0 最短距离 3\r5 --\u003e 1 最短距离 3\r5 --\u003e 2 最短距离 3\r5 --\u003e 8 最短距离 3\r5 --\u003e 9 最短距离 4\r5 --\u003e 10 最短距离 5\r6 --\u003e 6 最短距离 0\r6 --\u003e 5 最短距离 1\r6 --\u003e 7 最短距离 1\r6 --\u003e 8 最短距离 2\r6 --\u003e 4 最短距离 2\r6 --\u003e 9 最短距离 3\r6 --\u003e 3 最短距离 3\r6 --\u003e 0 最短距离 4\r6 --\u003e 1 最短距离 4\r6 --\u003e 2 最短距离 4\r6 --\u003e 10 最短距离 4\r7 --\u003e 7 最短距离 0\r7 --\u003e 8 最短距离 1\r7 --\u003e 6 最短距离 1\r7 --\u003e 9 最短距离 2\r7 --\u003e 5 最短距离 2\r7 --\u003e 10 最短距离 3\r7 --\u003e 4 最短距离 3\r7 --\u003e 3 最短距离 4\r7 --\u003e 0 最短距离 5\r7 --\u003e 1 最短距离 5\r7 --\u003e 2 最短距离 5\r8 --\u003e 8 最短距离 0\r8 --\u003e 9 最短距离 1\r8 --\u003e 7 最短距离 1\r8 --\u003e 10 最短距离 2\r8 --\u003e 6 最短距离 2\r8 --\u003e 5 最短距离 3\r8 --\u003e 4 最短距离 4\r8 --\u003e 3 最短距离 5\r8 --\u003e 0 最短距离 6\r8 --\u003e 1 最短距离 6\r8 --\u003e 2 最短距离 6\r9 --\u003e 9 最短距离 0\r9 --\u003e 8 最短距离 1\r9 --\u003e 10 最短距离 1\r9 --\u003e 7 最短距离 2\r9 --\u003e 6 最短距离 3\r9 --\u003e 5 最短距离 4\r9 --\u003e 4 最短距离 5\r9 --\u003e 3 最短距离 6\r9 --\u003e 0 最短距离 7\r9 --\u003e 1 最短距离 7\r9 --\u003e 2 最短距离 7\r10 --\u003e 10 最短距离 0\r10 --\u003e 9 最短距离 1\r10 --\u003e 8 最短距离 2\r10 --\u003e 7 最短距离 3\r10 --\u003e 6 最短距离 4\r10 --\u003e 5 最短距离 5\r10 --\u003e 4 最短距离 6\r10 --\u003e 3 最短距离 7\r10 --\u003e 0 最短距离 8\r10 --\u003e 1 最短距离 8\r10 --\u003e 2 最短距离 8\r# 平均最短距离 sum(pathlengths) / len(pathlengths) 3.2231404958677685\r","date":"2023-09-17","objectID":"/20230917/:14:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"不同距离的节点对个数 dist = {} for p in pathlengths: if p in dist: dist[p] += 1 else: dist[p] = 1 dist {0: 11, 1: 26, 2: 18, 3: 16, 4: 14, 5: 12, 6: 10, 7: 8, 8: 6}\r计算节点特征 计算无向图和有向图的节点特征。 ","date":"2023-09-17","objectID":"/20230917/:15:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"导入工具包 import networkx as nx import matplotlib.pyplot as plt import matplotlib.colors as mcolors %matplotlib inline ","date":"2023-09-17","objectID":"/20230917/:16:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"可视化辅助函数 def draw(G, pos, measures, measure_name): nodes = nx.draw_networkx_nodes(G, pos, node_size=250, cmap=plt.cm.plasma, node_color=list(measures.values()), nodelist=measures.keys()) nodes.set_norm(mcolors.SymLogNorm(linthresh=0.01, linscale=1, base=10)) # labels = nx.draw_networkx_labels(G, pos) edges = nx.draw_networkx_edges(G, pos) # plt.figure(figsize=(10,8)) plt.title(measure_name) plt.colorbar(nodes) plt.axis('off') plt.show() ","date":"2023-09-17","objectID":"/20230917/:17:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"导入无向图 G = nx.karate_club_graph() pos = nx.spring_layout(G, seed=675) nx.draw(G, pos, with_labels=True) ","date":"2023-09-17","objectID":"/20230917/:18:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"导入有向图 DiG = nx.DiGraph() DiG.add_edges_from([(2, 3), (3, 2), (4, 1), (4, 2), (5, 2), (5, 4), (5, 6), (6, 2), (6, 5), (7, 2), (7, 5), (8, 2), (8, 5), (9, 2), (9, 5), (10, 5), (11, 5)]) # dpos = {1: [0.1, 0.9], 2: [0.4, 0.8], 3: [0.8, 0.9], 4: [0.15, 0.55], # 5: [0.5, 0.5], 6: [0.8, 0.5], 7: [0.22, 0.3], 8: [0.30, 0.27], # 9: [0.38, 0.24], 10: [0.7, 0.3], 11: [0.75, 0.35]} nx.draw(DiG, pos, with_labels=True) ","date":"2023-09-17","objectID":"/20230917/:19:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"Node Degree list(nx.degree(G)) [(0, 16),\r(1, 9),\r(2, 10),\r(3, 6),\r(4, 3),\r(5, 4),\r(6, 4),\r(7, 4),\r(8, 5),\r(9, 2),\r(10, 3),\r(11, 1),\r(12, 2),\r(13, 5),\r(14, 2),\r(15, 2),\r(16, 2),\r(17, 2),\r(18, 2),\r(19, 3),\r(20, 2),\r(21, 2),\r(22, 2),\r(23, 5),\r(24, 3),\r(25, 3),\r(26, 2),\r(27, 4),\r(28, 3),\r(29, 4),\r(30, 4),\r(31, 6),\r(32, 12),\r(33, 17)]\rdict(G.degree()) {0: 16,\r1: 9,\r2: 10,\r3: 6,\r4: 3,\r5: 4,\r6: 4,\r7: 4,\r8: 5,\r9: 2,\r10: 3,\r11: 1,\r12: 2,\r13: 5,\r14: 2,\r15: 2,\r16: 2,\r17: 2,\r18: 2,\r19: 3,\r20: 2,\r21: 2,\r22: 2,\r23: 5,\r24: 3,\r25: 3,\r26: 2,\r27: 4,\r28: 3,\r29: 4,\r30: 4,\r31: 6,\r32: 12,\r33: 17}\r# 字典按值排序 sorted(dict(G.degree()).items(),key=lambda x : x[1], reverse=True) [(33, 17),\r(0, 16),\r(32, 12),\r(2, 10),\r(1, 9),\r(3, 6),\r(31, 6),\r(8, 5),\r(13, 5),\r(23, 5),\r(5, 4),\r(6, 4),\r(7, 4),\r(27, 4),\r(29, 4),\r(30, 4),\r(4, 3),\r(10, 3),\r(19, 3),\r(24, 3),\r(25, 3),\r(28, 3),\r(9, 2),\r(12, 2),\r(14, 2),\r(15, 2),\r(16, 2),\r(17, 2),\r(18, 2),\r(20, 2),\r(21, 2),\r(22, 2),\r(26, 2),\r(11, 1)]\rdraw(G, pos, dict(G.degree()), 'Node Degree') ","date":"2023-09-17","objectID":"/20230917/:20:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"NetworkX文档：节点重要度特征 Centrality https://networkx.org/documentation/stable/reference/algorithms/centrality.html ","date":"2023-09-17","objectID":"/20230917/:21:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"Degree Centrality-无向图 nx.degree_centrality(G) {0: 0.48484848484848486,\r1: 0.2727272727272727,\r2: 0.30303030303030304,\r3: 0.18181818181818182,\r4: 0.09090909090909091,\r5: 0.12121212121212122,\r6: 0.12121212121212122,\r7: 0.12121212121212122,\r8: 0.15151515151515152,\r9: 0.06060606060606061,\r10: 0.09090909090909091,\r11: 0.030303030303030304,\r12: 0.06060606060606061,\r13: 0.15151515151515152,\r14: 0.06060606060606061,\r15: 0.06060606060606061,\r16: 0.06060606060606061,\r17: 0.06060606060606061,\r18: 0.06060606060606061,\r19: 0.09090909090909091,\r20: 0.06060606060606061,\r21: 0.06060606060606061,\r22: 0.06060606060606061,\r23: 0.15151515151515152,\r24: 0.09090909090909091,\r25: 0.09090909090909091,\r26: 0.06060606060606061,\r27: 0.12121212121212122,\r28: 0.09090909090909091,\r29: 0.12121212121212122,\r30: 0.12121212121212122,\r31: 0.18181818181818182,\r32: 0.36363636363636365,\r33: 0.5151515151515151}\rdraw(G, pos, nx.degree_centrality(G), 'Degree Centrality') ","date":"2023-09-17","objectID":"/20230917/:22:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"Degree Centrality-有向图 nx.in_degree_centrality(DiG) {2: 0.7000000000000001,\r3: 0.1,\r4: 0.1,\r1: 0.1,\r5: 0.6000000000000001,\r6: 0.1,\r7: 0.0,\r8: 0.0,\r9: 0.0,\r10: 0.0,\r11: 0.0}\rnx.out_degree_centrality(DiG) {2: 0.1,\r3: 0.1,\r4: 0.2,\r1: 0.0,\r5: 0.30000000000000004,\r6: 0.2,\r7: 0.2,\r8: 0.2,\r9: 0.2,\r10: 0.1,\r11: 0.1}\rdraw(DiG, pos, nx.in_degree_centrality(DiG), 'DiGraph Degree Centrality') draw(DiG, pos, nx.out_degree_centrality(DiG), 'DiGraph Degree Centrality') ","date":"2023-09-17","objectID":"/20230917/:23:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"Eigenvector Centrality-无向图 nx.eigenvector_centrality(G) {0: 0.3554834941851943,\r1: 0.2659538704545025,\r2: 0.31718938996844476,\r3: 0.2111740783205706,\r4: 0.07596645881657382,\r5: 0.07948057788594247,\r6: 0.07948057788594247,\r7: 0.17095511498035434,\r8: 0.2274050914716605,\r9: 0.10267519030637758,\r10: 0.07596645881657381,\r11: 0.05285416945233648,\r12: 0.08425192086558088,\r13: 0.22646969838808148,\r14: 0.10140627846270832,\r15: 0.10140627846270832,\r16: 0.023634794260596875,\r17: 0.09239675666845953,\r18: 0.10140627846270832,\r19: 0.14791134007618667,\r20: 0.10140627846270832,\r21: 0.09239675666845953,\r22: 0.10140627846270832,\r23: 0.15012328691726787,\r24: 0.05705373563802805,\r25: 0.05920820250279008,\r26: 0.07558192219009324,\r27: 0.13347932684333308,\r28: 0.13107925627221215,\r29: 0.13496528673866567,\r30: 0.17476027834493085,\r31: 0.19103626979791702,\r32: 0.3086510477336959,\r33: 0.373371213013235}\rdraw(G, pos, nx.eigenvector_centrality(G), 'Eigenvector Centrality') ","date":"2023-09-17","objectID":"/20230917/:24:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"Eigenvector Centrality-有向图 nx.eigenvector_centrality_numpy(DiG) {2: 0.7071067894491988,\r3: 0.7071067729238959,\r4: 1.1016868750601816e-08,\r1: 1.1016867973445699e-08,\r5: 1.1016868778357392e-08,\r6: 1.101686872284624e-08,\r7: -5.551115123125783e-17,\r8: -2.7755575615628914e-17,\r9: -0.0,\r10: -0.0,\r11: 5.551115123125783e-17}\rdraw(DiG, pos, nx.eigenvector_centrality_numpy(DiG), 'DiGraph Eigenvector Centrality') ","date":"2023-09-17","objectID":"/20230917/:25:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"Betweenness Centrality（必经之地） nx.betweenness_centrality? nx.betweenness_centrality?? nx.betweenness_centrality(G) {0: 0.43763528138528146,\r1: 0.053936688311688304,\r2: 0.14365680615680618,\r3: 0.011909271284271283,\r4: 0.0006313131313131313,\r5: 0.02998737373737374,\r6: 0.029987373737373736,\r7: 0.0,\r8: 0.05592682780182781,\r9: 0.0008477633477633478,\r10: 0.0006313131313131313,\r11: 0.0,\r12: 0.0,\r13: 0.04586339586339586,\r14: 0.0,\r15: 0.0,\r16: 0.0,\r17: 0.0,\r18: 0.0,\r19: 0.03247504810004811,\r20: 0.0,\r21: 0.0,\r22: 0.0,\r23: 0.017613636363636363,\r24: 0.0022095959595959595,\r25: 0.0038404882154882154,\r26: 0.0,\r27: 0.02233345358345358,\r28: 0.0017947330447330447,\r29: 0.0029220779220779218,\r30: 0.014411976911976909,\r31: 0.13827561327561325,\r32: 0.145247113997114,\r33: 0.30407497594997596}\rdraw(G, pos, nx.betweenness_centrality(G), 'Betweenness Centrality') ","date":"2023-09-17","objectID":"/20230917/:26:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"Closeness Centrality（去哪儿都近） nx.closeness_centrality(G) {0: 0.5689655172413793,\r1: 0.4852941176470588,\r2: 0.559322033898305,\r3: 0.4647887323943662,\r4: 0.3793103448275862,\r5: 0.38372093023255816,\r6: 0.38372093023255816,\r7: 0.44,\r8: 0.515625,\r9: 0.4342105263157895,\r10: 0.3793103448275862,\r11: 0.36666666666666664,\r12: 0.3707865168539326,\r13: 0.515625,\r14: 0.3707865168539326,\r15: 0.3707865168539326,\r16: 0.28448275862068967,\r17: 0.375,\r18: 0.3707865168539326,\r19: 0.5,\r20: 0.3707865168539326,\r21: 0.375,\r22: 0.3707865168539326,\r23: 0.39285714285714285,\r24: 0.375,\r25: 0.375,\r26: 0.3626373626373626,\r27: 0.4583333333333333,\r28: 0.4520547945205479,\r29: 0.38372093023255816,\r30: 0.4583333333333333,\r31: 0.5409836065573771,\r32: 0.515625,\r33: 0.55}\rdraw(G, pos, nx.closeness_centrality(G), 'Closeness Centrality') ","date":"2023-09-17","objectID":"/20230917/:27:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"PageRank nx.pagerank(DiG, alpha=0.85) {2: 0.38439863456604384,\r3: 0.3429125997558898,\r4: 0.039087092099966095,\r1: 0.03278149315934399,\r5: 0.08088569323449774,\r6: 0.039087092099966095,\r7: 0.016169479016858404,\r8: 0.016169479016858404,\r9: 0.016169479016858404,\r10: 0.016169479016858404,\r11: 0.016169479016858404}\rdraw(DiG, pos, nx.pagerank(DiG, alpha=0.85), 'DiGraph PageRank') ","date":"2023-09-17","objectID":"/20230917/:28:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"Katz Centrality nx.katz_centrality(G, alpha=0.1, beta=1.0) {0: 0.3213245969592325,\r1: 0.2354842531944946,\r2: 0.2657658848154288,\r3: 0.1949132024917254,\r4: 0.12190440564948413,\r5: 0.1309722793286492,\r6: 0.1309722793286492,\r7: 0.166233052026894,\r8: 0.2007178109661081,\r9: 0.12420150029869696,\r10: 0.12190440564948413,\r11: 0.09661674181730141,\r12: 0.11610805572826272,\r13: 0.19937368057318847,\r14: 0.12513342642033795,\r15: 0.12513342642033795,\r16: 0.09067874388549631,\r17: 0.12016515915440099,\r18: 0.12513342642033795,\r19: 0.15330578770069542,\r20: 0.12513342642033795,\r21: 0.12016515915440099,\r22: 0.12513342642033795,\r23: 0.16679064809871574,\r24: 0.11021106930146936,\r25: 0.11156461274962841,\r26: 0.11293552094158042,\r27: 0.1519016658208186,\r28: 0.143581654735333,\r29: 0.15310603655041516,\r30: 0.16875361802889585,\r31: 0.19380160170200547,\r32: 0.2750851434662392,\r33: 0.3314063975218936}\rdraw(G, pos, nx.katz_centrality(G, alpha=0.1, beta=1.0), 'Katz Centrality') draw(DiG, pos, nx.katz_centrality(DiG, alpha=0.1, beta=1.0), 'DiGraph Katz Centrality') ","date":"2023-09-17","objectID":"/20230917/:29:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"HITS Hubs and Authorities h, a = nx.hits(DiG) draw(DiG, pos, h, 'DiGraph HITS Hubs') draw(DiG, pos, a, 'DiGraph HITS Authorities') ","date":"2023-09-17","objectID":"/20230917/:30:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"NetworkX文档：社群属性 Clustering https://networkx.org/documentation/stable/reference/algorithms/clustering.html nx.draw(G, pos, with_labels=True) ","date":"2023-09-17","objectID":"/20230917/:31:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"三角形个数 nx.triangles(G) {0: 18,\r1: 12,\r2: 11,\r3: 10,\r4: 2,\r5: 3,\r6: 3,\r7: 6,\r8: 5,\r9: 0,\r10: 2,\r11: 0,\r12: 1,\r13: 6,\r14: 1,\r15: 1,\r16: 1,\r17: 1,\r18: 1,\r19: 1,\r20: 1,\r21: 1,\r22: 1,\r23: 4,\r24: 1,\r25: 1,\r26: 1,\r27: 1,\r28: 1,\r29: 4,\r30: 3,\r31: 3,\r32: 13,\r33: 15}\rnx.triangles(G, 0) 18\rdraw(G, pos, nx.triangles(G), 'Triangles') ","date":"2023-09-17","objectID":"/20230917/:32:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"Clustering Coefficient nx.clustering(G) {0: 0.15,\r1: 0.3333333333333333,\r2: 0.24444444444444444,\r3: 0.6666666666666666,\r4: 0.6666666666666666,\r5: 0.5,\r6: 0.5,\r7: 1.0,\r8: 0.5,\r9: 0,\r10: 0.6666666666666666,\r11: 0,\r12: 1.0,\r13: 0.6,\r14: 1.0,\r15: 1.0,\r16: 1.0,\r17: 1.0,\r18: 1.0,\r19: 0.3333333333333333,\r20: 1.0,\r21: 1.0,\r22: 1.0,\r23: 0.4,\r24: 0.3333333333333333,\r25: 0.3333333333333333,\r26: 1.0,\r27: 0.16666666666666666,\r28: 0.3333333333333333,\r29: 0.6666666666666666,\r30: 0.5,\r31: 0.2,\r32: 0.19696969696969696,\r33: 0.11029411764705882}\rnx.clustering(G, 0) 0.15\rdraw(G, pos, nx.clustering(G), 'Clustering Coefficient') ","date":"2023-09-17","objectID":"/20230917/:33:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"Bridges 如果某个连接断掉，会使连通域个数增加，则该连接是bridge。 bridge连接不属于环的一部分。 pos = nx.spring_layout(G, seed=675) nx.draw(G, pos, with_labels=True) list(nx.bridges(G)) [(0, 11)]\r","date":"2023-09-17","objectID":"/20230917/:34:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"Common Neighbors 和 Jaccard Coefficient pos = nx.spring_layout(G, seed=675) nx.draw(G, pos, with_labels=True) sorted(nx.common_neighbors(G, 0, 4)) [6, 10]\rpreds = nx.jaccard_coefficient(G, [(0, 1), (2, 3)]) for u, v, p in preds: print(f\"({u}, {v}) -\u003e {p:.8f}\") (0, 1) -\u003e 0.38888889\r(2, 3) -\u003e 0.33333333\rfor u, v, p in nx.adamic_adar_index(G, [(0, 1), (2, 3)]): print(f\"({u}, {v}) -\u003e {p:.8f}\") (0, 1) -\u003e 6.13071687\r(2, 3) -\u003e 2.15847583\r","date":"2023-09-17","objectID":"/20230917/:35:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"Katz Index 节点u到节点v，路径为k的路径个数。 import networkx as nx import numpy as np from numpy.linalg import inv G = nx.karate_club_graph() len(G.nodes) 34\r# 计算主特征向量 L = nx.normalized_laplacian_matrix(G) e = np.linalg.eigvals(L.A) print('最大特征值', max(e)) # 折减系数 beta = 1/max(e) # 创建单位矩阵 I = np.identity(len(G.nodes)) # 计算 Katz Index S = inv(I - nx.to_numpy_array(G)*beta) - I 最大特征值 1.7146113474736193\rS.shape (34, 34)\rS array([[-0.630971 , 0.03760311, -0.50718655, ..., 0.22028562,\r0.08051109, 0.0187629 ],\r[ 0.03760311, 0.0313979 , -1.09231501, ..., 0.18920621,\r-0.09098329, 0.08188737],\r[-0.50718655, -1.09231501, 0.79993439, ..., -0.4511988 ,\r0.17631358, -0.23914987],\r...,\r[ 0.22028562, 0.18920621, -0.4511988 , ..., -0.07349891,\r0.47525815, -0.0457034 ],\r[ 0.08051109, -0.09098329, 0.17631358, ..., 0.47525815,\r-0.28781332, -0.70104834],\r[ 0.0187629 , 0.08188737, -0.23914987, ..., -0.0457034 ,\r-0.70104834, -0.50717615]])\r","date":"2023-09-17","objectID":"/20230917/:36:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX实用模板案例","uri":"/20230917/"},{"categories":["机器学习","Python"],"content":"nx.draw可视化函数 ","date":"2023-09-16","objectID":"/20230916/:0:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"创建4x4网格图 G = nx.grid_2d_graph(4, 4) ","date":"2023-09-16","objectID":"/20230916/:1:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"原生可视化 pos = nx.spring_layout(G, seed=123) nx.draw(G, pos) ","date":"2023-09-16","objectID":"/20230916/:2:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"不显示节点 nx.draw(G, pos, node_size=0, with_labels=False) ","date":"2023-09-16","objectID":"/20230916/:3:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"设置颜色 len(G.edges()) 24\rnx.draw( G, pos, node_color='#A0CBE2', # 节点颜色 edgecolors='red', # 节点外边缘的颜色 edge_color=\"blue\", # edge的颜色 # edge_cmap=plt.cm.coolwarm, # 配色方案 node_size=800, with_labels=False, width=3, ) ","date":"2023-09-16","objectID":"/20230916/:4:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"有向图 nx.draw( G.to_directed(), pos, node_color=\"tab:orange\", node_size=400, with_labels=False, edgecolors=\"tab:gray\", arrowsize=10, width=2, ) ","date":"2023-09-16","objectID":"/20230916/:5:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"设置每个节点的坐标 ","date":"2023-09-16","objectID":"/20230916/:6:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"无向图 G = nx.Graph() G.add_edge(1, 2) G.add_edge(1, 3) G.add_edge(1, 5) G.add_edge(2, 3) G.add_edge(3, 4) G.add_edge(4, 5) nx.draw(G, with_labels=True) # 设置每个节点可视化时的坐标 pos = {1: (0, 0), 2: (-1, 0.3), 3: (2, 0.17), 4: (4, 0.255), 5: (5, 0.03)} # 设置其它可视化样式 options = { \"font_size\": 36, \"node_size\": 3000, \"node_color\": \"white\", \"edgecolors\": \"black\", \"linewidths\": 5, # 节点线宽 \"width\": 5, # edge线宽 } nx.draw_networkx(G, pos, **options) ax = plt.gca() ax.margins(0.20) # 在图的边缘留白，防止节点被截断 plt.axis(\"off\") plt.show() ","date":"2023-09-16","objectID":"/20230916/:6:1","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"有向图 G = nx.DiGraph([(0, 3), (1, 3), (2, 4), (3, 5), (3, 6), (4, 6), (5, 6)]) nx.draw(G, with_labels=True) # 可视化时每一列包含的节点 left_nodes = [0, 1, 2] middle_nodes = [3, 4] right_nodes = [5, 6] # 可视化时每个节点的坐标 pos = {n: (0, i) for i, n in enumerate(left_nodes)} pos.update({n: (1, i + 0.5) for i, n in enumerate(middle_nodes)}) pos.update({n: (2, i + 0.5) for i, n in enumerate(right_nodes)}) pos {0: (0, 0),\r1: (0, 1),\r2: (0, 2),\r3: (1, 0.5),\r4: (1, 1.5),\r5: (2, 0.5),\r6: (2, 1.5)}\rnx.draw_networkx(G, pos, **options) ax = plt.gca() ax.margins(0.20) # 在图的边缘留白，防止节点被截断 plt.axis(\"off\") plt.show() ","date":"2023-09-16","objectID":"/20230916/:6:2","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"再来一个案例 G = nx.house_graph() nx.draw(G, with_labels=True) # 设置节点坐标 pos = {0: (0, 0), 1: (1, 0), 2: (0, 1), 3: (1, 1), 4: (0.5, 2.0)} plt.figure(figsize=(10,8)) # 绘制“墙角”的四个节点 nx.draw_networkx_nodes(G, pos, node_size=3000, nodelist=[0, 1, 2, 3], node_color=\"tab:blue\") # 绘制“屋顶”节点 nx.draw_networkx_nodes(G, pos, node_size=2000, nodelist=[4], node_color=\"tab:orange\") # 绘制连接 nx.draw_networkx_edges(G, pos, alpha=0.5, width=6) plt.axis(\"off\") # 去掉坐标轴 plt.show() 美国128城市交通关系无向图可视化 ","date":"2023-09-16","objectID":"/20230916/:6:3","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"导入工具包 # 图数据挖掘 import networkx as nx import numpy as np # 数据可视化 import matplotlib.pyplot as plt %matplotlib inline # plt.rcParams['font.sans-serif']=['SimHei'] # 用来正常显示中文标签 plt.rcParams['axes.unicode_minus']=False # 用来正常显示负号 import gzip import re import warnings warnings.simplefilter(\"ignore\") ","date":"2023-09-16","objectID":"/20230916/:7:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"构建图 fh = gzip.open(\"knuth_miles.txt.gz\", \"r\") G = nx.Graph() G.position = {} G.population = {} cities = [] for line in fh.readlines(): # 遍历文件中的每一行 line = line.decode() if line.startswith(\"*\"): # 其它行，跳过 continue numfind = re.compile(r\"^\\d+\") if numfind.match(line): # 记录城市间距离的行 dist = line.split() for d in dist: G.add_edge(city, cities[i], weight=int(d)) i = i + 1 else: # 记录城市经纬度、人口的行 i = 1 (city, coordpop) = line.split(\"[\") cities.insert(0, city) (coord, pop) = coordpop.split(\"]\") (y, x) = coord.split(\",\") G.add_node(city) # assign position - Convert string to lat/long x = -float(x) / 100 y = float(y) / 100 G.position[city] = (x, y) pop = float(pop) / 1000 G.population[city] = pop ","date":"2023-09-16","objectID":"/20230916/:8:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"查看图 print(G) Graph with 128 nodes and 8128 edges\rG.nodes NodeView(('Youngstown, OH', 'Yankton, SD', 'Yakima, WA', 'Worcester, MA', 'Wisconsin Dells, WI', 'Winston-Salem, NC', 'Winnipeg, MB', 'Winchester, VA', 'Wilmington, NC', 'Wilmington, DE', 'Williston, ND', 'Williamsport, PA', 'Williamson, WV', 'Wichita Falls, TX', 'Wichita, KS', 'Wheeling, WV', 'West Palm Beach, FL', 'Wenatchee, WA', 'Weed, CA', 'Waycross, GA', 'Wausau, WI', 'Waukegan, IL', 'Watertown, SD', 'Watertown, NY', 'Waterloo, IA', 'Waterbury, CT', 'Washington, DC', 'Warren, PA', 'Walla Walla, WA', 'Waco, TX', 'Vincennes, IN', 'Victoria, TX', 'Vicksburg, MS', 'Vancouver, BC', 'Valley City, ND', 'Valdosta, GA', 'Utica, NY', 'Uniontown, PA', 'Tyler, TX', 'Twin Falls, ID', 'Tuscaloosa, AL', 'Tupelo, MS', 'Tulsa, OK', 'Tucson, AZ', 'Trinidad, CO', 'Trenton, NJ', 'Traverse City, MI', 'Toronto, ON', 'Topeka, KS', 'Toledo, OH', 'Texarkana, TX', 'Terre Haute, IN', 'Tampa, FL', 'Tallahassee, FL', 'Tacoma, WA', 'Syracuse, NY', 'Swainsboro, GA', 'Sumter, SC', 'Stroudsburg, PA', 'Stockton, CA', 'Stevens Point, WI', 'Steubenville, OH', 'Sterling, CO', 'Staunton, VA', 'Springfield, OH', 'Springfield, MO', 'Springfield, MA', 'Springfield, IL', 'Spokane, WA', 'South Bend, IN', 'Sioux Falls, SD', 'Sioux City, IA', 'Shreveport, LA', 'Sherman, TX', 'Sheridan, WY', 'Seminole, OK', 'Selma, AL', 'Sedalia, MO', 'Seattle, WA', 'Scranton, PA', 'Scottsbluff, NE', 'Schenectady, NY', 'Savannah, GA', 'Sault Sainte Marie, MI', 'Sarasota, FL', 'Santa Rosa, CA', 'Santa Fe, NM', 'Santa Barbara, CA', 'Santa Ana, CA', 'San Jose, CA', 'San Francisco, CA', 'Sandusky, OH', 'San Diego, CA', 'San Bernardino, CA', 'San Antonio, TX', 'San Angelo, TX', 'Salt Lake City, UT', 'Salisbury, MD', 'Salinas, CA', 'Salina, KS', 'Salida, CO', 'Salem, OR', 'Saint Paul, MN', 'Saint Louis, MO', 'Saint Joseph, MO', 'Saint Joseph, MI', 'Saint Johnsbury, VT', 'Saint Cloud, MN', 'Saint Augustine, FL', 'Saginaw, MI', 'Sacramento, CA', 'Rutland, VT', 'Roswell, NM', 'Rocky Mount, NC', 'Rock Springs, WY', 'Rockford, IL', 'Rochester, NY', 'Rochester, MN', 'Roanoke, VA', 'Richmond, VA', 'Richmond, IN', 'Richfield, UT', 'Rhinelander, WI', 'Reno, NV', 'Regina, SK', 'Red Bluff, CA', 'Reading, PA', 'Ravenna, OH'))\r","date":"2023-09-16","objectID":"/20230916/:9:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"128城市经纬度坐标 G.position {'Youngstown, OH': (-80.65, 41.1),\r'Yankton, SD': (-97.39, 42.88),\r'Yakima, WA': (-120.51, 46.6),\r'Worcester, MA': (-71.8, 42.27),\r'Wisconsin Dells, WI': (-89.77, 43.63),\r'Winston-Salem, NC': (-80.25, 36.1),\r'Winnipeg, MB': (-97.15, 49.88),\r'Winchester, VA': (-78.16, 39.19),\r'Wilmington, NC': (-77.92, 34.24),\r'Wilmington, DE': (-75.55, 39.75),\r'Williston, ND': (-103.62, 48.15),\r'Williamsport, PA': (-77.0, 41.25),\r'Williamson, WV': (-82.28, 37.68),\r'Wichita Falls, TX': (-98.49, 33.9),\r'Wichita, KS': (-97.34, 37.69),\r'Wheeling, WV': (-80.72, 40.07),\r'West Palm Beach, FL': (-80.05, 26.72),\r'Wenatchee, WA': (-120.32, 47.42),\r'Weed, CA': (-122.39, 41.42),\r'Waycross, GA': (-82.35, 31.22),\r'Wausau, WI': (-89.64, 44.96),\r'Waukegan, IL': (-87.83, 42.36),\r'Watertown, SD': (-97.11, 44.9),\r'Watertown, NY': (-75.92, 43.98),\r'Waterloo, IA': (-92.34, 42.5),\r'Waterbury, CT': (-73.05, 41.55),\r'Washington, DC': (-77.03, 38.89),\r'Warren, PA': (-79.14, 41.85),\r'Walla Walla, WA': (-118.33, 46.07),\r'Waco, TX': (-97.14, 31.55),\r'Vincennes, IN': (-87.53, 38.68),\r'Victoria, TX': (-97.01, 28.81),\r'Vicksburg, MS': (-90.88, 32.35),\r'Vancouver, BC': (-123.12, 49.27),\r'Valley City, ND': (-98.01, 46.92),\r'Valdosta, GA': (-83.28, 30.83),\r'Utica, NY': (-75.23, 43.11),\r'Uniontown, PA': (-79.73, 39.9),\r'Tyler, TX': (-95.3, 32.35),\r'Twin Falls, ID': (-114.47, 42.56),\r'Tuscaloosa, AL': (-87.57, 33.21),\r'Tupelo, MS': (-88.71, 34.26),\r'Tulsa, OK': (-95.91, 36.16),\r'Tucson, AZ': (-110.97, 32.22),\r'Trinidad, CO': (-104.51, 37.17),\r'Trenton, NJ': (-74.77, 40.23),\r'Traverse City, MI': (-85.63, 44.76),\r'Toronto, ON': (-79.38, 43.65),\r'Topeka, KS': (-95.67, 39.05),\r'Toledo, OH': (-83.54, 41.65),\r'Texarkana, TX': (-94.05, 33.43),\r'Terre Haute, IN': (-87.41, 39.47),\r'Tampa, FL': (-82.45, 27.95),\r'Tallahassee, FL': (-84.28, 30.45),\r'Tacoma, WA': (-122.43, 47.24),\r'Syracuse, NY': (-76.15, 43.05),\r'Swainsboro, GA': (-82.34, 32.6),\r'Sumter, SC': (-80.35, 33.92),\r'Stroudsburg, PA': (-75.19, 40.99),\r'Stockton, CA': (-121.29, 37.96),\r'Stevens Point, WI': (-89.57, 44.52),\r'Steubenville, OH': (-80.62, 40.36),\r'Sterling, CO': (-103.22, 40.62),\r'Staunton, VA': (-79.07, 38.15),\r'Springfield, OH': (-83.81, 39.92),\r'Springfield, MO': (-93.29, 37.22),\r'Springfield, MA': (-72.59, 42.1),\r'Springfield, IL': (-89.65, 39.8),\r'Spokane, WA': (-117.41, 47.67),\r'South Bend, IN': (-86.25, 41.68),\r'Sioux Falls, SD': (-96.73, 43.54),\r'Sioux City, IA': (-96.39, 42.49),\r'Shreveport, LA': (-93.75, 32.51),\r'Sherman, TX': (-96.61, 33.64),\r'Sheridan, WY': (-106.96, 44.8),\r'Seminole, OK': (-96.68, 35.23),\r'Selma, AL': (-87.02, 32.42),\r'Sedalia, MO': (-93.23, 38.71),\r'Seattle, WA': (-122.33, 47.6),\r'Scranton, PA': (-75.67, 41.41),\r'Scottsbluff, NE': (-103.66, 41.87),\r'Schenectady, NY': (-73.95, 42.82),\r'Savannah, GA': (-81.09, 32.08),\r'Sault Sainte Marie, MI': (-84.35, 46.49),\r'Sarasota, FL': (-82.53, 27.34),\r'Santa Rosa, CA': (-122.72, 38.44),\r'Santa Fe, NM': (-105.95, 35.68),\r'Santa Barbara, CA': (-119.7, 34.42),\r'Santa Ana, CA': (-117.87, 33.76),\r'San Jose, CA': (-121.88, 37.34),\r'San Francisco, CA': (-122.42, 37.78),\r'Sandusky, OH': (-82.71, 41.45),\r'San Diego, CA': (-117.15, 32.71),\r'San Bernardino, CA': (-117.31, 34.11),\r'San Antonio, TX': (-98.5, 29.42),\r'San Angelo, TX': (-100.44, 31.46),\r'Salt Lake City, UT': (-111.88, 40.76),\r'Salisbury, MD': (-75.6, 38.37),\r'Salinas, CA': (-121.65, 36.67),\r'Salina, KS': (-97.61, 38.84),\r'Salida, CO': (-106.0, 38.53),\r'Salem, OR': (-123.03, 44.94),\r'Saint Paul, MN': (-93.1, 44.95),\r'Saint Louis, MO': (-90.19, 38.62),\r'Saint Joseph, MO': (-94.84, 39.77),\r'Saint Joseph, MI': (-86.48, 42.1),\r'Saint Johnsbury, VT': (-72.02, 44.42),\r'Saint Cloud, MN': (-94.17, 45.57),\r'Saint Augustine, FL': (-81.32, 29.89),\r'Saginaw, MI': (-83.94, 43.43),\r'Sacramento, CA': (-121.49, 38.59),\r'Rutland, VT': (-72.97, 43.61),\r'Roswell, NM': (-104.53, 33.4),\r'Rocky Mount, NC': (-77.8, 35.94),\r'Rock Springs, WY': (-109.23, 41.59),\r'Rockford, IL': (-89.1, 42.27),\r'Roches","date":"2023-09-16","objectID":"/20230916/:10:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"128城市人口数据 G.population {'Youngstown, OH': 115.436,\r'Yankton, SD': 12.011,\r'Yakima, WA': 49.826,\r'Worcester, MA': 161.799,\r'Wisconsin Dells, WI': 2.521,\r'Winston-Salem, NC': 131.885,\r'Winnipeg, MB': 564.473,\r'Winchester, VA': 20.217,\r'Wilmington, NC': 139.238,\r'Wilmington, DE': 70.195,\r'Williston, ND': 13.336,\r'Williamsport, PA': 33.401,\r'Williamson, WV': 5.219,\r'Wichita Falls, TX': 94.201,\r'Wichita, KS': 279.835,\r'Wheeling, WV': 43.07,\r'West Palm Beach, FL': 63.305,\r'Wenatchee, WA': 17.257,\r'Weed, CA': 2.879,\r'Waycross, GA': 19.371,\r'Wausau, WI': 32.426,\r'Waukegan, IL': 67.653,\r'Watertown, SD': 15.649,\r'Watertown, NY': 27.861,\r'Waterloo, IA': 75.985,\r'Waterbury, CT': 103.266,\r'Washington, DC': 638.432,\r'Warren, PA': 12.146,\r'Walla Walla, WA': 25.618,\r'Waco, TX': 101.261,\r'Vincennes, IN': 20.857,\r'Victoria, TX': 50.695,\r'Vicksburg, MS': 25.434,\r'Vancouver, BC': 414.281,\r'Valley City, ND': 7.774,\r'Valdosta, GA': 37.596,\r'Utica, NY': 75.632,\r'Uniontown, PA': 14.51,\r'Tyler, TX': 70.508,\r'Twin Falls, ID': 26.209,\r'Tuscaloosa, AL': 75.211,\r'Tupelo, MS': 23.905,\r'Tulsa, OK': 360.919,\r'Tucson, AZ': 330.537,\r'Trinidad, CO': 9.663,\r'Trenton, NJ': 92.124,\r'Traverse City, MI': 15.516,\r'Toronto, ON': 599.217,\r'Topeka, KS': 115.266,\r'Toledo, OH': 354.635,\r'Texarkana, TX': 31.271,\r'Terre Haute, IN': 61.125,\r'Tampa, FL': 271.523,\r'Tallahassee, FL': 81.548,\r'Tacoma, WA': 158.501,\r'Syracuse, NY': 170.105,\r'Swainsboro, GA': 7.602,\r'Sumter, SC': 24.89,\r'Stroudsburg, PA': 5.148,\r'Stockton, CA': 149.779,\r'Stevens Point, WI': 22.97,\r'Steubenville, OH': 26.4,\r'Sterling, CO': 11.385,\r'Staunton, VA': 21.857,\r'Springfield, OH': 72.563,\r'Springfield, MO': 133.116,\r'Springfield, MA': 152.319,\r'Springfield, IL': 100.054,\r'Spokane, WA': 171.3,\r'South Bend, IN': 109.727,\r'Sioux Falls, SD': 81.343,\r'Sioux City, IA': 82.003,\r'Shreveport, LA': 205.82,\r'Sherman, TX': 30.413,\r'Sheridan, WY': 15.146,\r'Seminole, OK': 8.59,\r'Selma, AL': 26.684,\r'Sedalia, MO': 20.927,\r'Seattle, WA': 493.846,\r'Scranton, PA': 88.117,\r'Scottsbluff, NE': 14.156,\r'Schenectady, NY': 67.972,\r'Savannah, GA': 141.634,\r'Sault Sainte Marie, MI': 14.448,\r'Sarasota, FL': 48.868,\r'Santa Rosa, CA': 83.32,\r'Santa Fe, NM': 48.953,\r'Santa Barbara, CA': 74.414,\r'Santa Ana, CA': 204.023,\r'San Jose, CA': 629.546,\r'San Francisco, CA': 678.974,\r'Sandusky, OH': 31.36,\r'San Diego, CA': 875.538,\r'San Bernardino, CA': 118.794,\r'San Antonio, TX': 786.023,\r'San Angelo, TX': 73.24,\r'Salt Lake City, UT': 163.697,\r'Salisbury, MD': 16.429,\r'Salinas, CA': 80.479,\r'Salina, KS': 41.843,\r'Salida, CO': 44.87,\r'Salem, OR': 89.233,\r'Saint Paul, MN': 270.23,\r'Saint Louis, MO': 453.085,\r'Saint Joseph, MO': 76.691,\r'Saint Joseph, MI': 9.622,\r'Saint Johnsbury, VT': 7.15,\r'Saint Cloud, MN': 42.566,\r'Saint Augustine, FL': 11.985,\r'Saginaw, MI': 77.508,\r'Sacramento, CA': 275.741,\r'Rutland, VT': 18.436,\r'Roswell, NM': 39.676,\r'Rocky Mount, NC': 41.283,\r'Rock Springs, WY': 19.458,\r'Rockford, IL': 139.712,\r'Rochester, NY': 241.741,\r'Rochester, MN': 57.89,\r'Roanoke, VA': 100.22,\r'Richmond, VA': 219.214,\r'Richmond, IN': 41.349,\r'Richfield, UT': 5.482,\r'Rhinelander, WI': 7.873,\r'Reno, NV': 100.756,\r'Regina, SK': 162.613,\r'Red Bluff, CA': 9.49,\r'Reading, PA': 78.686,\r'Ravenna, OH': 11.987}\r","date":"2023-09-16","objectID":"/20230916/:11:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"128城市互联互通关系 G.edges EdgeView([('Youngstown, OH', 'Yankton, SD'), ('Youngstown, OH', 'Yakima, WA'), ('Youngstown, OH', 'Worcester, MA'), ('Youngstown, OH', 'Wisconsin Dells, WI'), ('Youngstown, OH', 'Winston-Salem, NC'), ('Youngstown, OH', 'Winnipeg, MB'), ('Youngstown, OH', 'Winchester, VA'), ('Youngstown, OH', 'Wilmington, NC'), ('Youngstown, OH', 'Wilmington, DE'), ('Youngstown, OH', 'Williston, ND'), ('Youngstown, OH', 'Williamsport, PA'), ('Youngstown, OH', 'Williamson, WV'), ('Youngstown, OH', 'Wichita Falls, TX'), ('Youngstown, OH', 'Wichita, KS'), ('Youngstown, OH', 'Wheeling, WV'), ('Youngstown, OH', 'West Palm Beach, FL'), ('Youngstown, OH', 'Wenatchee, WA'), ('Youngstown, OH', 'Weed, CA'), ('Youngstown, OH', 'Waycross, GA'), ('Youngstown, OH', 'Wausau, WI'), ('Youngstown, OH', 'Waukegan, IL'), ('Youngstown, OH', 'Watertown, SD'), ('Youngstown, OH', 'Watertown, NY'), ('Youngstown, OH', 'Waterloo, IA'), ('Youngstown, OH', 'Waterbury, CT'), ('Youngstown, OH', 'Washington, DC'), ('Youngstown, OH', 'Warren, PA'), ('Youngstown, OH', 'Walla Walla, WA'), ('Youngstown, OH', 'Waco, TX'), ('Youngstown, OH', 'Vincennes, IN'), ('Youngstown, OH', 'Victoria, TX'), ('Youngstown, OH', 'Vicksburg, MS'), ('Youngstown, OH', 'Vancouver, BC'), ('Youngstown, OH', 'Valley City, ND'), ('Youngstown, OH', 'Valdosta, GA'), ('Youngstown, OH', 'Utica, NY'), ('Youngstown, OH', 'Uniontown, PA'), ('Youngstown, OH', 'Tyler, TX'), ('Youngstown, OH', 'Twin Falls, ID'), ('Youngstown, OH', 'Tuscaloosa, AL'), ('Youngstown, OH', 'Tupelo, MS'), ('Youngstown, OH', 'Tulsa, OK'), ('Youngstown, OH', 'Tucson, AZ'), ('Youngstown, OH', 'Trinidad, CO'), ('Youngstown, OH', 'Trenton, NJ'), ('Youngstown, OH', 'Traverse City, MI'), ('Youngstown, OH', 'Toronto, ON'), ('Youngstown, OH', 'Topeka, KS'), ('Youngstown, OH', 'Toledo, OH'), ('Youngstown, OH', 'Texarkana, TX'), ('Youngstown, OH', 'Terre Haute, IN'), ('Youngstown, OH', 'Tampa, FL'), ('Youngstown, OH', 'Tallahassee, FL'), ('Youngstown, OH', 'Tacoma, WA'), ('Youngstown, OH', 'Syracuse, NY'), ('Youngstown, OH', 'Swainsboro, GA'), ('Youngstown, OH', 'Sumter, SC'), ('Youngstown, OH', 'Stroudsburg, PA'), ('Youngstown, OH', 'Stockton, CA'), ('Youngstown, OH', 'Stevens Point, WI'), ('Youngstown, OH', 'Steubenville, OH'), ('Youngstown, OH', 'Sterling, CO'), ('Youngstown, OH', 'Staunton, VA'), ('Youngstown, OH', 'Springfield, OH'), ('Youngstown, OH', 'Springfield, MO'), ('Youngstown, OH', 'Springfield, MA'), ('Youngstown, OH', 'Springfield, IL'), ('Youngstown, OH', 'Spokane, WA'), ('Youngstown, OH', 'South Bend, IN'), ('Youngstown, OH', 'Sioux Falls, SD'), ('Youngstown, OH', 'Sioux City, IA'), ('Youngstown, OH', 'Shreveport, LA'), ('Youngstown, OH', 'Sherman, TX'), ('Youngstown, OH', 'Sheridan, WY'), ('Youngstown, OH', 'Seminole, OK'), ('Youngstown, OH', 'Selma, AL'), ('Youngstown, OH', 'Sedalia, MO'), ('Youngstown, OH', 'Seattle, WA'), ('Youngstown, OH', 'Scranton, PA'), ('Youngstown, OH', 'Scottsbluff, NE'), ('Youngstown, OH', 'Schenectady, NY'), ('Youngstown, OH', 'Savannah, GA'), ('Youngstown, OH', 'Sault Sainte Marie, MI'), ('Youngstown, OH', 'Sarasota, FL'), ('Youngstown, OH', 'Santa Rosa, CA'), ('Youngstown, OH', 'Santa Fe, NM'), ('Youngstown, OH', 'Santa Barbara, CA'), ('Youngstown, OH', 'Santa Ana, CA'), ('Youngstown, OH', 'San Jose, CA'), ('Youngstown, OH', 'San Francisco, CA'), ('Youngstown, OH', 'Sandusky, OH'), ('Youngstown, OH', 'San Diego, CA'), ('Youngstown, OH', 'San Bernardino, CA'), ('Youngstown, OH', 'San Antonio, TX'), ('Youngstown, OH', 'San Angelo, TX'), ('Youngstown, OH', 'Salt Lake City, UT'), ('Youngstown, OH', 'Salisbury, MD'), ('Youngstown, OH', 'Salinas, CA'), ('Youngstown, OH', 'Salina, KS'), ('Youngstown, OH', 'Salida, CO'), ('Youngstown, OH', 'Salem, OR'), ('Youngstown, OH', 'Saint Paul, MN'), ('Youngstown, OH', 'Saint Louis, MO'), ('Youngstown, OH', 'Saint Joseph, MO'), ('Youngstown, OH', 'Saint Joseph, MI'), ('Youngstown, OH', 'Saint Johnsbury, VT'), ('Youngstown, OH', 'Saint Cloud, MN'),","date":"2023-09-16","objectID":"/20230916/:12:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"纽约到里士满的交通距离 G.edges[('Rochester, NY', 'Richmond, VA')] {'weight': 486}\r","date":"2023-09-16","objectID":"/20230916/:13:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"筛选出距离小于指定阈值的城市 H = nx.Graph() for v in G: H.add_node(v) for (u, v, d) in G.edges(data=True): if d[\"weight\"] \u003c 800: H.add_edge(u, v) ","date":"2023-09-16","objectID":"/20230916/:14:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"可视化 # 节点颜色-节点度 node_color = [float(H.degree(v)) for v in H] # 节点尺寸-节点人口 node_size = [G.population[v] for v in H] fig = plt.figure(figsize=(12, 10)) nx.draw( H, G.position, node_size=node_size, node_color=node_color, with_labels=False, ) plt.show() 有向图可视化模板 ","date":"2023-09-16","objectID":"/20230916/:15:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"导入工具包 # 图数据挖掘 import networkx as nx import numpy as np # 数据可视化 import matplotlib.pyplot as plt %matplotlib inline # plt.rcParams['font.sans-serif']=['SimHei'] # 用来正常显示中文标签 plt.rcParams['axes.unicode_minus']=False # 用来正常显示负号 import matplotlib as mpl ","date":"2023-09-16","objectID":"/20230916/:16:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"创建有向图 seed = 13648 G = nx.random_k_out_graph(10, 3, 0.5, seed=seed) pos = nx.spring_layout(G, seed=seed) ","date":"2023-09-16","objectID":"/20230916/:17:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"初步可视化 nx.draw(G, pos, with_labels=True) ","date":"2023-09-16","objectID":"/20230916/:18:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"高级可视化设置 # 节点大小 node_sizes = [12 + 10 * i for i in range(len(G))] node_sizes [12, 22, 32, 42, 52, 62, 72, 82, 92, 102]\r# 节点颜色 M = G.number_of_edges() edge_colors = range(2, M + 2) edge_colors range(2, 32)\r# 节点透明度 edge_alphas = [(5 + i) / (M + 4) for i in range(M)] edge_alphas [0.14705882352941177,\r0.17647058823529413,\r0.20588235294117646,\r0.23529411764705882,\r0.2647058823529412,\r0.29411764705882354,\r0.3235294117647059,\r0.35294117647058826,\r0.38235294117647056,\r0.4117647058823529,\r0.4411764705882353,\r0.47058823529411764,\r0.5,\r0.5294117647058824,\r0.5588235294117647,\r0.5882352941176471,\r0.6176470588235294,\r0.6470588235294118,\r0.6764705882352942,\r0.7058823529411765,\r0.7352941176470589,\r0.7647058823529411,\r0.7941176470588235,\r0.8235294117647058,\r0.8529411764705882,\r0.8823529411764706,\r0.9117647058823529,\r0.9411764705882353,\r0.9705882352941176,\r1.0]\r# 配色方案 cmap = plt.cm.plasma # cmap = plt.cm.Blues plt.figure(figsize=(10,8)) # 绘制节点 nodes = nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color=\"indigo\") # 绘制连接 edges = nx.draw_networkx_edges( G, pos, node_size=node_sizes, # 节点尺寸 arrowstyle=\"-\u003e\", # 箭头样式 arrowsize=20, # 箭头尺寸 edge_color=edge_colors, # 连接颜色 edge_cmap=cmap, # 连接配色方案 width=4 # 连接线宽 ) # 设置每个连接的透明度 for i in range(M): edges[i].set_alpha(edge_alphas[i]) # 调色图例 pc = mpl.collections.PatchCollection(edges, cmap=cmap) pc.set_array(edge_colors) plt.colorbar(pc) ax = plt.gca() ax.set_axis_off() plt.show() 国际象棋对局MultiDiGraph多路图可视化 ","date":"2023-09-16","objectID":"/20230916/:19:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"导入工具包 # 图数据挖掘 import networkx as nx # 数据可视化 import matplotlib.pyplot as plt %matplotlib inline # plt.rcParams['font.sans-serif']=['SimHei'] # 用来正常显示中文标签 plt.rcParams['axes.unicode_minus']=False # 用来正常显示负号 ","date":"2023-09-16","objectID":"/20230916/:20:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"导入数据，构建MultiDiGraph import pandas as pd df = pd.read_csv('WCC.csv') df Date\rEventDate\rEvent\rSite\rECO\rWhite\rBlack\rRound\rResult\r0\r1886.01.11\r1886.01.11\rWorld Championship 1st\rUSA\rD11\rZukertort, Johannes H\rSteinitz, Wilhelm\r1\r0-1\r1\r1886.01.13\r1886.01.11\rWorld Championship 1st\rUSA\rC47\rSteinitz, Wilhelm\rZukertort, Johannes H\r2\r0-1\r2\r1886.01.15\r1886.01.11\rWorld Championship 1st\rUSA\rD10\rZukertort, Johannes H\rSteinitz, Wilhelm\r3\r1-0\r3\r1886.01.18\r1886.01.11\rWorld Championship 1st\rUSA\rC67\rSteinitz, Wilhelm\rZukertort, Johannes H\r4\r0-1\r4\r1886.01.20\r1886.01.11\rWorld Championship 1st\rUSA\rD10\rZukertort, Johannes H\rSteinitz, Wilhelm\r5\r1-0\r...\r...\r...\r...\r...\r...\r...\r...\r...\r...\r680\r1985.01.21\r1984.09.10\rWorld Championship 31th\rMoscow RUS\rC92\rKasparov, Gary\rKarpov, Anatoly\r44\r1/2-1/2\r681\r1985.01.23\r1984.09.10\rWorld Championship 31th\rMoscow RUS\rB85\rKarpov, Anatoly\rKasparov, Gary\r45\r1/2-1/2\r682\r1985.01.28\r1984.09.10\rWorld Championship 31th\rMoscow RUS\rC92\rKasparov, Gary\rKarpov, Anatoly\r46\r1/2-1/2\r683\r1985.01.30\r1984.09.10\rWorld Championship 31th\rMoscow RUS\rD52\rKarpov, Anatoly\rKasparov, Gary\r47\r0-1\r684\r1985.02.08\r1984.09.10\rWorld Championship 31th\rMoscow RUS\rC42\rKasparov, Gary\rKarpov, Anatoly\r48\r1-0\r685 rows × 9 columns ","date":"2023-09-16","objectID":"/20230916/:21:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"从连接表创建MultiDiGraph多路有向图 G = nx.from_pandas_edgelist(df, 'White', 'Black', edge_attr=True, create_using=nx.MultiDiGraph()) ","date":"2023-09-16","objectID":"/20230916/:22:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"初步探索 print('棋手（节点）个数', G.number_of_nodes()) print('棋局（连接）个数', G.number_of_edges()) 棋手（节点）个数 25\r棋局（连接）个数 685\r# 所有节点 G.nodes NodeView(('Zukertort, Johannes H', 'Steinitz, Wilhelm', 'Chigorin, Mikhail I', 'Gunsberg, Isidor A', 'Lasker, Emanuel', 'Marshall, Frank J', 'Tarrasch, Siegbert', 'Janowski, Dawid M', 'Schlechter, Carl', 'Capablanca, Jose Raul', 'Alekhine, Alexander A', 'Bogoljubow, Efim D', 'Euwe, Max', 'Keres, Paul', 'Smyslov, Vassily V', 'Reshevsky, Samuel H', 'Botvinnik, Mikhail M', 'Bronstein, David I', 'Tal, Mikhail N', 'Petrosian, Tigran V', 'Spassky, Boris V', 'Fischer, Robert J', 'Korchnoi, Viktor L', 'Karpov, Anatoly', 'Kasparov, Gary'))\r# 所有连接（带特征） # G.edges(data=True) # 两个棋手的所有棋局 G.get_edge_data('Zukertort, Johannes H', 'Steinitz, Wilhelm') {0: {'Date': '1886.01.11',\r'EventDate': '1886.01.11',\r'Event': 'World Championship 1st',\r'Site': 'USA',\r'ECO': 'D11',\r'Round': 1,\r'Result': '0-1'},\r1: {'Date': '1886.01.15',\r'EventDate': '1886.01.11',\r'Event': 'World Championship 1st',\r'Site': 'USA',\r'ECO': 'D10',\r'Round': 3,\r'Result': '1-0'},\r2: {'Date': '1886.01.20',\r'EventDate': '1886.01.11',\r'Event': 'World Championship 1st',\r'Site': 'USA',\r'ECO': 'D10',\r'Round': 5,\r'Result': '1-0'},\r3: {'Date': '1886.02.05',\r'EventDate': '1886.01.11',\r'Event': 'World Championship 1st',\r'Site': 'USA',\r'ECO': 'D40',\r'Round': 7,\r'Result': '0-1'},\r4: {'Date': '1886.02.10',\r'EventDate': '1886.01.11',\r'Event': 'World Championship 1st',\r'Site': 'USA',\r'ECO': 'D26',\r'Round': 9,\r'Result': '0-1'},\r5: {'Date': '1886.03.01',\r'EventDate': '1886.01.11',\r'Event': 'World Championship 1st',\r'Site': 'USA',\r'ECO': 'C49',\r'Round': 11,\r'Result': '0-1'},\r6: {'Date': '1886.03.05',\r'EventDate': '1886.01.11',\r'Event': 'World Championship 1st',\r'Site': 'USA',\r'ECO': 'D26',\r'Round': 13,\r'Result': '1-0'},\r7: {'Date': '1886.03.15',\r'EventDate': '1886.01.11',\r'Event': 'World Championship 1st',\r'Site': 'USA',\r'ECO': 'D50',\r'Round': 15,\r'Result': '1/2-1/2'},\r8: {'Date': '1886.03.19',\r'EventDate': '1886.01.11',\r'Event': 'World Championship 1st',\r'Site': 'USA',\r'ECO': 'D60',\r'Round': 17,\r'Result': '1/2-1/2'},\r9: {'Date': '1886.03.24',\r'EventDate': '1886.01.11',\r'Event': 'World Championship 1st',\r'Site': 'USA',\r'ECO': 'D53',\r'Round': 19,\r'Result': '0-1'}}\r","date":"2023-09-16","objectID":"/20230916/:23:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"初步可视化 pos = nx.spring_layout(G, seed=10) nx.draw(G, pos) ","date":"2023-09-16","objectID":"/20230916/:24:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"连通域分析 # 将G转为无向图，分析连通域 H = G.to_undirected() for each in nx.connected_components(H): print('连通域') print(H.subgraph(each)) print('包含节点') print(each) print('\\n') 连通域\rMultiGraph with 22 nodes and 304 edges\r包含节点\r{'Zukertort, Johannes H', 'Steinitz, Wilhelm', 'Tal, Mikhail N', 'Janowski, Dawid M', 'Alekhine, Alexander A', 'Euwe, Max', 'Botvinnik, Mikhail M', 'Lasker, Emanuel', 'Petrosian, Tigran V', 'Tarrasch, Siegbert', 'Schlechter, Carl', 'Bogoljubow, Efim D', 'Fischer, Robert J', 'Chigorin, Mikhail I', 'Bronstein, David I', 'Keres, Paul', 'Capablanca, Jose Raul', 'Smyslov, Vassily V', 'Marshall, Frank J', 'Gunsberg, Isidor A', 'Spassky, Boris V', 'Reshevsky, Samuel H'}\r连通域\rMultiGraph with 3 nodes and 49 edges\r包含节点\r{'Kasparov, Gary', 'Korchnoi, Viktor L', 'Karpov, Anatoly'}\r","date":"2023-09-16","objectID":"/20230916/:25:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"高级可视化 # 将G转为无向-单连接图 H = nx.Graph(G) H.edges() EdgeView([('Zukertort, Johannes H', 'Steinitz, Wilhelm'), ('Steinitz, Wilhelm', 'Chigorin, Mikhail I'), ('Steinitz, Wilhelm', 'Gunsberg, Isidor A'), ('Steinitz, Wilhelm', 'Lasker, Emanuel'), ('Lasker, Emanuel', 'Marshall, Frank J'), ('Lasker, Emanuel', 'Tarrasch, Siegbert'), ('Lasker, Emanuel', 'Janowski, Dawid M'), ('Lasker, Emanuel', 'Schlechter, Carl'), ('Lasker, Emanuel', 'Capablanca, Jose Raul'), ('Capablanca, Jose Raul', 'Alekhine, Alexander A'), ('Alekhine, Alexander A', 'Bogoljubow, Efim D'), ('Alekhine, Alexander A', 'Euwe, Max'), ('Euwe, Max', 'Keres, Paul'), ('Euwe, Max', 'Smyslov, Vassily V'), ('Euwe, Max', 'Botvinnik, Mikhail M'), ('Euwe, Max', 'Reshevsky, Samuel H'), ('Keres, Paul', 'Smyslov, Vassily V'), ('Keres, Paul', 'Botvinnik, Mikhail M'), ('Keres, Paul', 'Reshevsky, Samuel H'), ('Smyslov, Vassily V', 'Reshevsky, Samuel H'), ('Smyslov, Vassily V', 'Botvinnik, Mikhail M'), ('Reshevsky, Samuel H', 'Botvinnik, Mikhail M'), ('Botvinnik, Mikhail M', 'Bronstein, David I'), ('Botvinnik, Mikhail M', 'Tal, Mikhail N'), ('Botvinnik, Mikhail M', 'Petrosian, Tigran V'), ('Petrosian, Tigran V', 'Spassky, Boris V'), ('Spassky, Boris V', 'Fischer, Robert J'), ('Korchnoi, Viktor L', 'Karpov, Anatoly'), ('Karpov, Anatoly', 'Kasparov, Gary')])\r# 两个棋手的所有棋局 len(G.get_edge_data('Zukertort, Johannes H', 'Steinitz, Wilhelm')) 10\r# 两个棋手节点之间的 连接宽度 与 棋局个数 成正比 edgewidth = [len(G.get_edge_data(u, v)) for u, v in H.edges()] edgewidth [10,\r19,\r10,\r9,\r7,\r8,\r11,\r5,\r7,\r17,\r26,\r27,\r3,\r3,\r2,\r2,\r3,\r3,\r2,\r3,\r37,\r2,\r12,\r21,\r11,\r23,\r11,\r25,\r24]\r# 棋手节点的大小 与 赢棋次数 成正比 wins = dict.fromkeys(G.nodes(), 0) # 生成每个棋手作为key的dict for (u, v, d) in G.edges(data=True): r = d[\"Result\"].split(\"-\") if r[0] == \"1\": wins[u] += 1.0 elif r[0] == \"1/2\": wins[u] += 0.5 wins[v] += 0.5 else: wins[v] += 1.0 nodesize = [wins[v] * 50 for v in H] wins {'Zukertort, Johannes H': 7.5,\r'Steinitz, Wilhelm': 53.0,\r'Chigorin, Mikhail I': 17.0,\r'Gunsberg, Isidor A': 8.5,\r'Lasker, Emanuel': 61.5,\r'Marshall, Frank J': 3.5,\r'Tarrasch, Siegbert': 5.5,\r'Janowski, Dawid M': 3.5,\r'Schlechter, Carl': 5.0,\r'Capablanca, Jose Raul': 24.5,\r'Alekhine, Alexander A': 79.5,\r'Bogoljubow, Efim D': 20.0,\r'Euwe, Max': 29.0,\r'Keres, Paul': 10.5,\r'Smyslov, Vassily V': 46.0,\r'Reshevsky, Samuel H': 10.5,\r'Botvinnik, Mikhail M': 89.0,\r'Bronstein, David I': 12.0,\r'Tal, Mikhail N': 20.5,\r'Petrosian, Tigran V': 35.5,\r'Spassky, Boris V': 32.5,\r'Fischer, Robert J': 12.5,\r'Korchnoi, Viktor L': 23.0,\r'Karpov, Anatoly': 52.0,\r'Kasparov, Gary': 23.0}\rnodesize [375.0,\r2650.0,\r850.0,\r425.0,\r3075.0,\r175.0,\r275.0,\r175.0,\r250.0,\r1225.0,\r3975.0,\r1000.0,\r1450.0,\r525.0,\r2300.0,\r525.0,\r4450.0,\r600.0,\r1025.0,\r1775.0,\r1625.0,\r625.0,\r1150.0,\r2600.0,\r1150.0]\r# 布局 pos = nx.kamada_kawai_layout(H) # 手动微调节点的横坐标（越大越靠右）、纵坐标（越大越靠下） pos[\"Reshevsky, Samuel H\"] += (0.05, -0.10) pos[\"Botvinnik, Mikhail M\"] += (0.03, -0.06) pos[\"Smyslov, Vassily V\"] += (0.05, -0.03) fig, ax = plt.subplots(figsize=(12, 12)) # 可视化连接 nx.draw_networkx_edges(H, pos, alpha=0.3, width=edgewidth, edge_color=\"m\") # 可视化节点 nx.draw_networkx_nodes(H, pos, node_size=nodesize, node_color=\"#210070\", alpha=0.9) # 节点名称文字说明 label_options = {\"ec\": \"k\", \"fc\": \"white\", \"alpha\": 0.7} nx.draw_networkx_labels(H, pos, font_size=14, bbox=label_options) # 标题和图例 font = {\"fontname\": \"Helvetica\", \"color\": \"k\", \"fontweight\": \"bold\", \"fontsize\": 16} ax.set_title(\"World Chess Championship Games: 1886 - 1985\", font) # 图例字体颜色 font[\"color\"] = \"r\" # 文字说明 ax.text( 0.80, 0.10, \"edge width = # games played\", horizontalalignment=\"center\", transform=ax.transAxes, fontdict=font, ) ax.text( 0.80, 0.06, \"node size = # games won\", horizontalalignment=\"center\", transform=ax.transAxes, fontdict=font, ) # 调整图的大小，提高可读性 ax.margins(0.1, 0.05) fig.tight_layout() plt.axis(\"off\") plt.show() 自定义节点图标 ","date":"2023-09-16","objectID":"/20230916/:26:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"导入工具包 # 图数据挖掘 import networkx as nx # 数据可视化 import matplotlib.pyplot as plt %matplotlib inline # plt.rcParams['font.sans-serif']=['SimHei'] # 用来正常显示中文标签 plt.rcParams['axes.unicode_minus']=False # 用来正常显示负号 import PIL ","date":"2023-09-16","objectID":"/20230916/:27:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"自定义图标 # 图标下载网站 # www.materialui.co # https://www.flaticon.com/ # 服务器：https://www.flaticon.com/free-icon/database-storage_2906274?term=server\u0026page=1\u0026position=8\u0026page=1\u0026position=8\u0026related_id=2906274\u0026origin=search # 笔记本电脑：https://www.flaticon.com/premium-icon/laptop_3020826?term=laptop\u0026page=1\u0026position=13\u0026page=1\u0026position=13\u0026related_id=3020826\u0026origin=search # 路由器：https://www.flaticon.com/premium-icon/wifi_1183657?term=router\u0026page=1\u0026position=3\u0026page=1\u0026position=3\u0026related_id=1183657\u0026origin=search icons = { 'router': 'database-storage.png', 'switch': 'wifi.png', 'PC': 'laptop.png', } # 载入图像 images = {k: PIL.Image.open(fname) for k, fname in icons.items()} images {'router': \u003cPIL.PngImagePlugin.PngImageFile image mode=RGBA size=512x512 at 0x7FE3A59DA5D0\u003e,\r'switch': \u003cPIL.PngImagePlugin.PngImageFile image mode=RGBA size=512x512 at 0x7FE3A5927E10\u003e,\r'PC': \u003cPIL.PngImagePlugin.PngImageFile image mode=RGBA size=512x512 at 0x7FE3A58B2690\u003e}\r","date":"2023-09-16","objectID":"/20230916/:28:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"创建图 # 创建空图 G = nx.Graph() # 创建节点 G.add_node(\"router\", image=images[\"router\"]) for i in range(1, 4): G.add_node(f\"switch_{i}\", image=images[\"switch\"]) for j in range(1, 4): G.add_node(\"PC_\" + str(i) + \"_\" + str(j), image=images[\"PC\"]) # 创建连接 G.add_edge(\"router\", \"switch_1\") G.add_edge(\"router\", \"switch_2\") G.add_edge(\"router\", \"switch_3\") for u in range(1, 4): for v in range(1, 4): G.add_edge(\"switch_\" + str(u), \"PC_\" + str(u) + \"_\" + str(v)) nx.draw(G, with_labels=True) fig, ax = plt.subplots() # 图片尺寸（相对于 X 轴） icon_size = (ax.get_xlim()[1] - ax.get_xlim()[0]) * 0.04 icon_center = icon_size / 2.0 ","date":"2023-09-16","objectID":"/20230916/:29:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"可视化自定义节点图标（如果第一次节点图标尺寸偏小，可再次运行本代码块） pos = nx.spring_layout(G, seed=1) fig, ax = plt.subplots(figsize=(14,10)) # 绘制连接 # min_source_margin 和 min_target_margin 调节连接端点到节点的距离 nx.draw_networkx_edges( G, pos=pos, ax=ax, arrows=True, arrowstyle=\"-\", min_source_margin=30, min_target_margin=30, ) # 给每个节点添加各自的图片 for n in G.nodes: xf, yf = ax.transData.transform(pos[n]) # data坐标 转 display坐标 xa, ya = fig.transFigure.inverted().transform((xf, yf)) # display坐标 转 figure坐标 a = plt.axes([xa - icon_center, ya - icon_center, icon_size, icon_size]) a.imshow(G.nodes[n][\"image\"]) a.axis(\"off\") plt.show() 自我中心图（Ego图） ","date":"2023-09-16","objectID":"/20230916/:30:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"导入工具包 # 图数据挖掘 import networkx as nx import numpy as np # 数据可视化 import matplotlib.pyplot as plt %matplotlib inline plt.rcParams['font.sans-serif']=['SimHei'] # 用来正常显示中文标签 plt.rcParams['axes.unicode_minus']=False # 用来正常显示负号 from operator import itemgetter ","date":"2023-09-16","objectID":"/20230916/:31:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"创建Barabási-Albert无标度网络 论文：A. L. Barabási and R. Albert “Emergence of scaling in random networks”, Science 286, pp 509-512, 1999. n个节点逐渐生长，新节点与degree高的旧节点产生m条连接。 n = 1000 m = 2 seed = 20532 G = nx.barabasi_albert_graph(n, m, seed=seed) pos = nx.spring_layout(G, seed=seed) nx.draw(G, pos) ","date":"2023-09-16","objectID":"/20230916/:32:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"找到degree最大的主节点 largest_hub, degree = sorted(G.degree(), key=itemgetter(1))[-1] largest_hub 4\rdegree 88\r","date":"2023-09-16","objectID":"/20230916/:33:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"找到以主节点为中心的邻域子图（Ego Graph） nx.ego_graph? hub_ego = nx.ego_graph(G, largest_hub, radius=1) pos = nx.spring_layout(hub_ego, seed=seed) nx.draw(hub_ego, pos, node_color=\"b\", node_size=50, with_labels=False) # 大红显示主节点 options = {\"node_size\": 300, \"node_color\": \"r\"} nx.draw_networkx_nodes(hub_ego, pos, nodelist=[largest_hub], **options) plt.show() ","date":"2023-09-16","objectID":"/20230916/:34:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX可视化","uri":"/20230916/"},{"categories":["机器学习","Python"],"content":"前言 当然，还是习惯 linux + jupyterlab 的组合，当然还是基于 https://www.spiritlhl.net/case/case1.html#%E4%B8%80%E9%94%AE%E5%AE%89%E8%A3%85jupyter%E7%8E%AF%E5%A2%83 构建基础环境 安装 由于是非国内服务器，无需清华镜像 !pip3 install numpy pandas matplotlib tqdm networkx # -i https://pypi.tuna.tsinghua.edu.cn/simple 验证是否安装成功 import networkx as nx nx.__version__ 设置matplotlib中文字体 import matplotlib.pyplot as plt %matplotlib inline plt.rcParams['font.sans-serif'] = ['SimHei'] plt.rcParams['axes.unicode_minus'] = False 如果本身不存在对应字体，需要执行 import os import shutil import urllib.request import matplotlib # 设置字体文件的URL和目标文件路径 font_url = \"https://github.com/StellarCN/scp_zh/raw/master/fonts/SimHei.ttf\" target_font_path = os.path.join(matplotlib.get_data_path(), \"fonts/ttf/SimHei.ttf\") # 下载字体文件 urllib.request.urlretrieve(font_url, target_font_path) # 找到matplotlibrc文件的路径 matplotlibrc_path = matplotlib.matplotlib_fname() # 获取matplotlibrc文件所在的文件夹路径 matplotlibrc_dir = os.path.dirname(matplotlibrc_path) # 找到fonts/ttf目录的路径 fonts_dir = os.path.join(matplotlib.get_data_path(), \"fonts/ttf\") # 删除缓存文件夹中的内容 cache_dir = matplotlib.get_cachedir() shutil.rmtree(cache_dir, ignore_errors=True) print(\"字体文件已下载到:\", target_font_path) print(\"matplotlibrc文件所在目录:\", matplotlibrc_dir) print(\"删除缓存文件夹:\", cache_dir) 进行字体下载和配置，然后需要重启Python内核，此处需要在KERNELS中删除已经存在的活动内核，重新运行ipynb文件(运行后会要求你选择使用什么内核，使用默认的就行了)。 如果要查询某个函数的用法和源代码，在jupyterlab中只需要在后面加上一个英文?号就能查看用法，两个英文?号就是查询函数源代码，在命令前面加上英文!号就相当于在命令行执行命令而不是使用python解释器去解释执行。 参考文档 NetworkX主页：https://networkx.org networkx创建图：https://networkx.org/documentation/stable/reference/generators.html 正式使用 ","date":"2023-09-15","objectID":"/20230915/:0:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"导入工具包 import networkx as nx # 数据可视化 import matplotlib.pyplot as plt %matplotlib inline plt.rcParams['font.sans-serif']=['SimHei'] # 用来正常显示中文标签 plt.rcParams['axes.unicode_minus']=False # 用来正常显示负号 ","date":"2023-09-15","objectID":"/20230915/:1:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"经典图结构 ","date":"2023-09-15","objectID":"/20230915/:2:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"全连接无向图 G = nx.complete_graph(7) nx.draw(G) # 全图连接数 G.size() 21\r","date":"2023-09-15","objectID":"/20230915/:2:1","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"全连接有向图 G = nx.complete_graph(7, nx.DiGraph()) nx.draw(G) G.is_directed() True\r","date":"2023-09-15","objectID":"/20230915/:2:2","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"环状图 G = nx.cycle_graph(5) nx.draw(G) ","date":"2023-09-15","objectID":"/20230915/:2:3","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"梯状图 G = nx.ladder_graph(5) nx.draw(G) ","date":"2023-09-15","objectID":"/20230915/:2:4","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"线性串珠图 G = nx.path_graph(15) nx.draw(G) ","date":"2023-09-15","objectID":"/20230915/:2:5","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"星状图 G = nx.star_graph(7) nx.draw(G) ","date":"2023-09-15","objectID":"/20230915/:2:6","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"轮辐图 G = nx.wheel_graph(8) nx.draw(G) ","date":"2023-09-15","objectID":"/20230915/:2:7","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"二项树 G = nx.binomial_tree(5) nx.draw(G) ","date":"2023-09-15","objectID":"/20230915/:2:8","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"栅格图 ","date":"2023-09-15","objectID":"/20230915/:3:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"二维矩形网格图 G = nx.grid_2d_graph(3,5) nx.draw(G) ","date":"2023-09-15","objectID":"/20230915/:3:1","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"多维矩形网格图 G = nx.grid_graph(dim=(2, 3, 4)) nx.draw(G) ","date":"2023-09-15","objectID":"/20230915/:3:2","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"二维三角形网格图 G = nx.triangular_lattice_graph(2,5) nx.draw(G) ","date":"2023-09-15","objectID":"/20230915/:3:3","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"二维六边形蜂窝图 G = nx.hexagonal_lattice_graph(2,3) nx.draw(G) ","date":"2023-09-15","objectID":"/20230915/:3:4","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"n维超立方体图 G = nx.hypercube_graph(4) nx.draw(G) ","date":"2023-09-15","objectID":"/20230915/:3:5","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"NetworkX内置图 G = nx.diamond_graph() nx.draw(G) G = nx.bull_graph() nx.draw(G) G = nx.frucht_graph() nx.draw(G) G = nx.house_graph() nx.draw(G) G = nx.house_x_graph() nx.draw(G) G = nx.petersen_graph() nx.draw(G) G = nx.krackhardt_kite_graph() nx.draw(G) ","date":"2023-09-15","objectID":"/20230915/:4:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"随机图 G = nx.erdos_renyi_graph(10, 0.5) nx.draw(G) ","date":"2023-09-15","objectID":"/20230915/:5:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"有向图 ","date":"2023-09-15","objectID":"/20230915/:6:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"无标度有向图 G = nx.scale_free_graph(100) nx.draw(G) ","date":"2023-09-15","objectID":"/20230915/:6:1","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"社交网络 # 空手道俱乐部数据集 G = nx.karate_club_graph() nx.draw(G, with_labels=True) G.nodes[5][\"club\"] 'Mr. Hi'\rG.nodes[9][\"club\"] 'Officer'\r# 雨果《悲惨世界》人物关系 G = nx.les_miserables_graph() plt.figure(figsize=(12,10)) pos = nx.spring_layout(G, seed=10) nx.draw(G, pos, with_labels=True) # Florentine families graph G = nx.florentine_families_graph() nx.draw(G, with_labels=True) ","date":"2023-09-15","objectID":"/20230915/:7:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"社群聚类图 G = nx.caveman_graph(4, 3) nx.draw(G, with_labels=True) ","date":"2023-09-15","objectID":"/20230915/:8:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"树 tree = nx.random_tree(n=10, seed=0) print(nx.forest_str(tree, sources=[0])) ╙── 0\r├── 3\r└── 4\r├── 6\r│ ├── 1\r│ ├── 2\r│ └── 7\r│ └── 8\r│ └── 5\r└── 9\r连接表和邻接表创建图 ","date":"2023-09-15","objectID":"/20230915/:9:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"导入三元组连接表 数据来源：OpenKG-四大名著人物关系知识图谱和OWL本体：http://www.openkg.cn/dataset/ch4masterpieces # 导入 csv 文件定义的三元组连接表，构建有向图 df = pd.read_csv('triples.csv') df head\rtail\rrelation\rlabel\r0\r关羽\r刘备\ryounger_sworn_brother\r义弟\r1\r张飞\r刘备\ryounger_sworn_brother\r义弟\r2\r关羽\r张飞\relder_sworn_brother\r义兄\r3\r张苞\r张飞\rson\r儿子\r4\r关兴\r关羽\rson\r儿子\r...\r...\r...\r...\r...\r148\r曹植\r曹丕\ryounger_brother\r弟弟\r149\r马谡\r诸葛亮\rcolleague\r同事\r150\r马谡\r刘备\rminister\r臣\r151\r孙坚\r孙权\rfather\r父亲\r152\r吴国太\r孙权\rmother\r母亲\r153 rows × 4 columns ","date":"2023-09-15","objectID":"/20230915/:10:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"通过连接表Edge List创建图 G = nx.DiGraph() edges = [edge for edge in zip(df['head'], df['tail'])] G.add_edges_from(edges) G.edges('关羽') OutEdgeDataView([('关羽', '刘备'), ('关羽', '张飞')])\r","date":"2023-09-15","objectID":"/20230915/:11:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"可视化 # 节点排版布局-默认弹簧布局 pos = nx.spring_layout(G, seed=123) plt.figure(figsize=(15,15)) nx.draw(G, pos=pos, with_labels=True) ","date":"2023-09-15","objectID":"/20230915/:12:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"查看全图参数 print(G) DiGraph with 123 nodes and 144 edges\rlen(G) 123\rG.size() 144\rG.nodes NodeView(('关羽', '刘备', '张飞', '张苞', '关兴', '关平', '卢植', '公孙瓒', '甘氏', '刘禅', '诸葛瞻', '诸葛亮', '姜维', '黄月英', '黄承彦', '诸葛瑾', '公孙越', '马超', '马腾', '韩遂', '徐庶', '曹操', '刘胜', '刘启', '刘辩', '孙权', '孙尚香', '糜氏', '糜芳', '糜竺', '魏延', '赵云', '黄忠', '庞统', '法正', '蒋琬', '马良', '孟获', '沙摩柯', '庞德公', '马谡', '祝融', '孙韶', '孙策', '孙氏', '陆逊', '刘协', '董卓', '王允', '貂蝉', '吕布', '丁原', '高顺', '陈宫', '张辽', '刘表', '蔡氏', '蔡瑁', '蒯越', '黄祖', '文聘', '张宝', '张角', '张梁', '袁绍', '袁术', '袁谭', '袁熙', '袁尚', '吴国太', '孙坚', '大乔', '小乔', '周瑜', '丁奉', '徐盛', '鲁肃', '张昭', '蒋钦', '太史慈', '周泰', '凌统', '吕蒙', '甘宁', '黄盖', '韩当', '程普', '曹嵩', '吕伯奢', '邹氏', '张绣', '清河公主', '夏侯楙', '夏侯渊', '夏侯淳', '曹真', '曹爽', '郭嘉', '徐晃', '乐进', '张郃', '许褚', '典韦', '荀彧', '荀攸', '贾诩', '司马懿', '程昱', '于禁', '邓艾', '钟会', '庞德', '司马师', '司马昭', '司马炎', '曹仁', '曹纯', '曹昂', '刘氏', '超昂', '卞氏', '曹丕', '曹植'))\r","date":"2023-09-15","objectID":"/20230915/:13:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"保存并载入邻接表 Adjacency List for line in nx.generate_adjlist(G): print(line) 关羽 刘备 张飞\r刘备 诸葛亮 马超 徐庶 姜维 糜芳 糜竺 魏延 赵云 黄忠 庞统 法正 蒋琬 马良 孟获 沙摩柯\r张飞 刘备\r张苞 张飞\r关兴 关羽\r关平 张苞 关羽\r卢植 刘备\r公孙瓒 刘备\r甘氏 刘备\r刘禅 甘氏\r诸葛瞻 刘禅 诸葛亮\r诸葛亮 姜维\r姜维 诸葛亮\r黄月英 诸葛亮\r黄承彦 黄月英\r诸葛瑾 诸葛亮\r公孙越 公孙瓒\r马超\r马腾 马超\r韩遂 马腾\r徐庶\r曹操 徐庶 张辽 蒯越 蔡瑁 张绣 夏侯淳 夏侯渊 曹真 郭嘉 徐晃 乐进 张郃 许褚 典韦 荀彧 荀攸 贾诩 司马懿 程昱 于禁 邓艾 钟会 庞德\r刘胜 刘启\r刘启\r刘辩 刘启\r孙权 诸葛瑾 孙策 周瑜 陆逊 丁奉 徐盛 鲁肃 张昭 蒋钦 太史慈 周泰 凌统 吕蒙 甘宁 黄盖 韩当 程普\r孙尚香 刘备 吴国太\r糜氏 刘备\r糜芳 糜氏\r糜竺 糜芳\r魏延\r赵云\r黄忠\r庞统\r法正\r蒋琬\r马良\r孟获\r沙摩柯\r庞德公 庞统\r马谡 马良 诸葛亮 刘备\r祝融 孟获\r孙韶 孙策\r孙策 孙坚\r孙氏 陆逊 孙策\r陆逊\r刘协 刘辩\r董卓 刘协 吕布\r王允 刘协\r貂蝉 王允 吕布\r吕布 高顺 陈宫 张辽\r丁原 吕布\r高顺\r陈宫\r张辽\r刘表 刘协 黄祖 文聘\r蔡氏 刘表\r蔡瑁 蔡氏\r蒯越 蔡瑁\r黄祖\r文聘\r张宝 张角\r张角\r张梁 张宝\r袁绍 刘协\r袁术 袁绍\r袁谭 袁绍\r袁熙 袁谭\r袁尚 袁熙\r吴国太 孙坚 孙权\r孙坚 孙权\r大乔 孙策 陆逊\r小乔 大乔\r周瑜 小乔\r丁奉\r徐盛\r鲁肃\r张昭\r蒋钦\r太史慈\r周泰\r凌统\r吕蒙\r甘宁\r黄盖\r韩当\r程普\r曹嵩 曹操\r吕伯奢 曹嵩\r邹氏 曹操 张绣\r张绣\r清河公主 曹操\r夏侯楙 清河公主\r夏侯渊 夏侯楙 夏侯淳\r夏侯淳\r曹真\r曹爽 曹真\r郭嘉\r徐晃\r乐进\r张郃\r许褚\r典韦\r荀彧 荀攸\r荀攸\r贾诩\r司马懿\r程昱\r于禁\r邓艾\r钟会\r庞德\r司马师 司马懿\r司马昭 司马师 司马懿\r司马炎 司马昭\r曹仁 曹操\r曹纯 曹仁\r曹昂 曹操\r刘氏 曹操\r超昂 刘氏\r卞氏 曹操\r曹丕 卞氏\r曹植 曹丕\r# 将邻接表导出为本地文件 grid.edgelist nx.write_edgelist(G, path=\"grid.edgelist\", delimiter=\":\") # 从本地文件 grid.edgelist 读取邻接表 H = nx.read_edgelist(path=\"grid.edgelist\", delimiter=\":\") # 可视化 plt.figure(figsize=(15,14)) pos = nx.spring_layout(H, iterations=3, seed=5) nx.draw(H, pos, with_labels=True) plt.show() 创建节点 ","date":"2023-09-15","objectID":"/20230915/:14:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"创建无节点、无连接的空图 G = nx.Graph() G \u003cnetworkx.classes.graph.Graph at 0x7cea48aeb310\u003e\rG.nodes NodeView(())\r# 可视化 nx.draw(G) ","date":"2023-09-15","objectID":"/20230915/:15:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"添加单个节点 G.add_node('刘备') G.nodes NodeView(('刘备',))\rG.add_node('Tommy') G.nodes NodeView(('刘备', 'Tommy'))\rG.add_node(1) G.nodes NodeView(('刘备', 'Tommy', 1))\r","date":"2023-09-15","objectID":"/20230915/:16:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"添加多个节点 G.add_nodes_from(['诸葛亮', '曹操']) G.nodes NodeView(('刘备', 'Tommy', 1, '诸葛亮', '曹操'))\rG.add_nodes_from(range(100, 105)) G.nodes NodeView(('刘备', 'Tommy', 1, '诸葛亮', '曹操', 100, 101, 102, 103, 104))\r","date":"2023-09-15","objectID":"/20230915/:17:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"添加带属性特征的节点 G.add_nodes_from([ ('关羽',{'武器': '青龙偃月刀','武力值':90,'智力值':80}), ('张飞',{'武器': '丈八蛇矛','武力值':85,'智力值':75}), ('吕布',{'武器':'方天画戟','武力值':100,'智力值':70}) ]) G.nodes NodeView(('刘备', 'Tommy', 1, '诸葛亮', '曹操', 100, 101, 102, 103, 104, '关羽', '张飞', '吕布'))\r# 可视化 nx.draw(G) ","date":"2023-09-15","objectID":"/20230915/:18:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"创建另一个首尾相连成串的Path Graph H = nx.path_graph(10) # 可视化 nx.draw(H) H.nodes NodeView((0, 1, 2, 3, 4, 5, 6, 7, 8, 9))\r","date":"2023-09-15","objectID":"/20230915/:19:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"将H的节点添加到G中 G.add_nodes_from(H) G.nodes NodeView(('刘备', 'Tommy', 1, '诸葛亮', '曹操', 100, 101, 102, 103, 104, '关羽', '张飞', '吕布', 0, 2, 3, 4, 5, 6, 7, 8, 9))\rlen(G) 22\rnx.draw(G) ","date":"2023-09-15","objectID":"/20230915/:20:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"将H本身作为一个节点添加到G中 G.add_node(H) G.nodes NodeView(('刘备', 'Tommy', 1, '诸葛亮', '曹操', 100, 101, 102, 103, 104, '关羽', '张飞', '吕布', 0, 2, 3, 4, 5, 6, 7, 8, 9, \u003cnetworkx.classes.graph.Graph object at 0x7f5ad7283910\u003e))\rlen(G) 23\rnx.draw(G) ","date":"2023-09-15","objectID":"/20230915/:21:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"小贴士 节点可以为任意可哈希的对象，比如字符串、图像、XML对象，甚至另一个Graph、自定义的节点对象。 通过这种方式，你可以根据你的应用，自由灵活地构建：图为节点、文件为节点、函数为节点，等灵活的图形式。 创建图 NetworkX支持有向图（directed graph）、无向图（undirected graph）、带权重的图(weighte graph)、多路图（multigraph）。 文档：https://networkx.org/documentation/stable/reference/classes/index.html # 创建无向图 G = nx.Graph() print(G.is_directed()) False\r# 给整张图添加特征属性 G.graph['Name'] = 'HelloWorld' print(G.graph) {'Name': 'HelloWorld'}\r# 创建有向图 H = nx.DiGraph() print(H.is_directed()) True\r","date":"2023-09-15","objectID":"/20230915/:22:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"创建单个节点 特征属性的名字可以随便起 # 创建0号节点，并添加特征属性 G.add_node(0, feature=5, label=0, suibianqide=2) G.nodes[0] {'feature': 5, 'label': 0, 'suibianqide': 2}\r","date":"2023-09-15","objectID":"/20230915/:23:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"创建多个节点 G.add_nodes_from([ (1, {'feature': 1, 'label': 1, 'suibianqide':3}), (2, {'feature': 2, 'label': 2, 'suibianqide':4}) ]) ","date":"2023-09-15","objectID":"/20230915/:24:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"全图节点信息 G.number_of_nodes() 3\rG.nodes NodeView((0, 1, 2))\rG.nodes(data=True) NodeDataView({0: {'feature': 5, 'label': 0, 'suibianqide': 2}, 1: {'feature': 1, 'label': 1, 'suibianqide': 3}, 2: {'feature': 2, 'label': 2, 'suibianqide': 4}})\r# 遍历所有节点，data=True 表示输出节点特征属性信息 for node in G.nodes(data=True): print(node) (0, {'feature': 5, 'label': 0, 'suibianqide': 2})\r(1, {'feature': 1, 'label': 1, 'suibianqide': 3})\r(2, {'feature': 2, 'label': 2, 'suibianqide': 4})\r","date":"2023-09-15","objectID":"/20230915/:25:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"创建单个连接，设置属性特征 特征属性的名字可以随便起 G.add_edge(0, 1, weight=0.5, like=3) ","date":"2023-09-15","objectID":"/20230915/:26:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"创建多个连接 G.add_edges_from([ (1, 2, {'weight': 0.3, 'like':5}), (2, 0, {'weight': 0.1, 'like':8}) ]) G.edges[(0, 1)] {'weight': 0.5, 'like': 3}\r","date":"2023-09-15","objectID":"/20230915/:27:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"可视化 nx.draw(G, with_labels = True) ","date":"2023-09-15","objectID":"/20230915/:28:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"全图连接信息 G.number_of_edges() 3\rG.size() 3\rG.edges() EdgeView([(0, 1), (0, 2), (1, 2)])\rG.edges(data=True) EdgeDataView([(0, 1, {'weight': 0.5, 'like': 3}), (0, 2, {'weight': 0.1, 'like': 8}), (1, 2, {'weight': 0.3, 'like': 5})])\r# 遍历所有连接，data=True 表示输出连接特征属性信息 for edge in G.edges(data=True): print(edge) (0, 1, {'weight': 0.5, 'like': 3})\r(0, 2, {'weight': 0.1, 'like': 8})\r(1, 2, {'weight': 0.3, 'like': 5})\r","date":"2023-09-15","objectID":"/20230915/:29:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"节点的连接数（Node Degree） # 指定节点 node_id = 1 G.degree[node_id] 2\r# 指定节点的所有相邻节点 for neighbor in G.neighbors(node_id): print(\"Node {} has neighbor {}\".format(node_id, neighbor)) Node 1 has neighbor 0\rNode 1 has neighbor 2\r后言 如果实在找不到机器跑，用现成的也行，如 https://featurize.cn?s=ddfded217b7546b8b6f985a96fc1f7d7 各种认证加起来应该能免费用好一会了(还是不推荐远程付费这种，最好本地跑) ","date":"2023-09-15","objectID":"/20230915/:30:0","tags":["机器学习","深度学习","特征工程","图神经网络","networkx","CS244W"],"title":"NetworkX基本操作","uri":"/20230915/"},{"categories":["机器学习","Python"],"content":"前言 需要提取特征反映全图结构特定 依然是在数数字 ","date":"2023-09-14","objectID":"/20230914/:1:0","tags":["机器学习","深度学习","特征工程","图神经网络","核方法","Bow","gklearn","CS244W"],"title":"传统图机器学习和图特征工程(全图层面的特征工程)","uri":"/20230914/"},{"categories":["机器学习","Python"],"content":"Bag-of-Words - (BoW) 数节点是否存在，存在为0，不存在为1： 数节点度数为xx的节点有几个： 拓展数的东西，这里可以拓展到数任何图的特征，比如图的自定义子图模式： 全图层面和节点层面的graphlet的不同之处： graphlet 向量矩阵的构建方法： graphlet 向量的构建： 两图的相似度/匹配度(graphlet kernel)(两图大小不同需要归一化)： 缺陷： 需要枚举匹配子图模式，计算的量太大了，计算复杂度高 ","date":"2023-09-14","objectID":"/20230914/:2:0","tags":["机器学习","深度学习","特征工程","图神经网络","核方法","Bow","gklearn","CS244W"],"title":"传统图机器学习和图特征工程(全图层面的特征工程)","uri":"/20230914/"},{"categories":["机器学习","Python"],"content":"Weisfeiler-Lehman Graph Kernel - 威斯费勒-莱曼核 颜色微调法： 具体操作方法： 初始化大家都为1(同色) 求本节点的邻居数值列表 求和作为本节点的数值(注意，这里求和的时候涵盖自身节点的数值，也涵盖邻居数值) 再次求本节点的邻居数值列表(哈希表由两图共同构成) 抽象为向量的写法： 算 威斯费勒-莱曼核(Weisfeiler-Lehman Kernel) 的值： (W-L Kernel)总结： 构建哈希表，数哈希表编号在对应图中的个数 进行了K步 = 捕捉了图中K跳的连接 步数越多捕捉的跳数越多，范围就越广 该方法与连接的个数线性相关，与节点个数线性相关，算法复杂度为线性。 如果要计算对应每个节点的向量，需要使用gklearn库计算 ","date":"2023-09-14","objectID":"/20230914/:3:0","tags":["机器学习","深度学习","特征工程","图神经网络","核方法","Bow","gklearn","CS244W"],"title":"传统图机器学习和图特征工程(全图层面的特征工程)","uri":"/20230914/"},{"categories":["机器学习","Python"],"content":"后言 总结： W-L Kernal 方法和 GNN 图神经网络有微妙的联系。 两张图的向量做数量积做点乘得到一个实数的标量，这种方法叫做核方法(Kernel Method)。 这种方法在传统图机器学习中用的特别多(两张图的标量代表图结构，而不是分开用两个向量去代表图结构了)。 ","date":"2023-09-14","objectID":"/20230914/:4:0","tags":["机器学习","深度学习","特征工程","图神经网络","核方法","Bow","gklearn","CS244W"],"title":"传统图机器学习和图特征工程(全图层面的特征工程)","uri":"/20230914/"},{"categories":["机器学习"],"content":"前言 通过已知连接补全未知连接 ","date":"2023-09-13","objectID":"/20230913/:1:0","tags":["机器学习","深度学习","特征工程","图神经网络","CS244W"],"title":"传统图机器学习和图特征工程(连接层面的特征工程)","uri":"/20230913/"},{"categories":["机器学习"],"content":"连接预测 ","date":"2023-09-13","objectID":"/20230913/:2:0","tags":["机器学习","深度学习","特征工程","图神经网络","CS244W"],"title":"传统图机器学习和图特征工程(连接层面的特征工程)","uri":"/20230913/"},{"categories":["机器学习"],"content":"连接的特征 两节点的距离特征 两节点的最短路径长度： 两节点之间的最短路径长度可能一样，但经过的节点不一样，那么可能有用的信息就不同了，所以只用最短路径长度是不够的。 两节点的局部连接信息特征 可能两节点之间没有共同好友，那么上述的节点局部连接信息就没有意义了。 两节点的全图连接信息特征 邻接矩阵的n次幂表示路径长度为n的路径(假设每条路径长度均为1) 以上三图为Katz index卡兹系数的直观推导过程，下面是数学推导过程： ","date":"2023-09-13","objectID":"/20230913/:3:0","tags":["机器学习","深度学习","特征工程","图神经网络","CS244W"],"title":"传统图机器学习和图特征工程(连接层面的特征工程)","uri":"/20230913/"},{"categories":["机器学习"],"content":"后言 总结： ","date":"2023-09-13","objectID":"/20230913/:4:0","tags":["机器学习","深度学习","特征工程","图神经网络","CS244W"],"title":"传统图机器学习和图特征工程(连接层面的特征工程)","uri":"/20230913/"},{"categories":["机器学习"],"content":"前言 这里就是解决之前生成D维向量的问题，使用人工设置特征，后续会使用GNN也就是图神经网络自动学习特征而不再需要人工设置特征了，这块等同于是被替代掉的工作，但由于后续的自动特征提取还是起源于这里的，所以还是需要了解一下。 ","date":"2023-09-12","objectID":"/20230912/:1:0","tags":["机器学习","深度学习","特征工程","图神经网络","CS244W"],"title":"传统图机器学习和图特征工程(节点层面的特征工程)","uri":"/20230912/"},{"categories":["机器学习"],"content":"设计特征 节点特征、连接特征、子图/全图特征 都需要转换为向量形式输入后续的神经网络训练，这些向量组成了各种矩阵。 特征分为两种： ①节点自己的有的特征，称为属性特征，很多时候这些特征都是多模态的，属性本身就有很多类别 ②连接特征，节点在图中与其他节点的连接关系，也就是所谓的结构信息 ","date":"2023-09-12","objectID":"/20230912/:2:0","tags":["机器学习","深度学习","特征工程","图神经网络","CS244W"],"title":"传统图机器学习和图特征工程(节点层面的特征工程)","uri":"/20230912/"},{"categories":["机器学习"],"content":"训练通道 人工选取模型可能更容易学习的特征，构造人工特征，就叫做特征工程。 构造的人工特征可能有用可能没用，需要后面的机器学习自己筛选，重要的特征机器学习会选出重要的特征给出更大的权重。 ","date":"2023-09-12","objectID":"/20230912/:3:0","tags":["机器学习","深度学习","特征工程","图神经网络","CS244W"],"title":"传统图机器学习和图特征工程(节点层面的特征工程)","uri":"/20230912/"},{"categories":["机器学习"],"content":"节点层面的特征工程 需要构建D维向量，且质量需要足够高，后续的机器学习才能学习到好的特征。 后续以节点分类场景为例(以下为半监督节点分类问题) 结构特征(连接特征)分为以下几类： 节点的度 节点的重要程度 节点的聚集系数 节点的子图模式(从小波变换中得来，分解复杂的图为简单图的合集) 节点的度 - 度中心度 - degree centrality 以下是节点的重要程度的示例：(某些节点的度一样，但实际的重要程度可能不一样) 以下是按行求和，得到节点的连接数做特征：(某些节点的度可以当作节点的重要程度) 连接数就是无向图的度，度也是可以做重要度的。 节点的特征值/特征向量 - 特征值中心度 - eigenvalue centrality 节点的重要程度 = 邻居们的重要程度求和的平均 = 求邻接矩阵的特征向量 = 此时总会存在一个唯一的且为正的最大特征值(求邻接矩阵的特征值) 这里和PageRank的算法有点像，但PageRank是需要根据连接来等分重要度的，这里的重要度却是不等分的，比如一个节点有重要度1，连接数是3，那么PageRank是分给每个连接分到1/3，这里却是每个连接分到1。 以下是度的中心度和特征值中心度的区别： 很明显，特征值中心度更好的体现了节点的重要程度，因为哪怕某个节点连接数很多，也不一定重要。 节点间的最短路径 - 最短距离路线经过的数量 - betweenness centrality 这里只有分子需要计算且有不同，因为分母在同一个图的话值都一样。 节点的最短距离 - closeness centrality 节点到别的节点最短的距离之和的倒数。 这个值哪个节点的大，这个节点去哪都近。 集群系数 - clustering coefficient 衡量一个节点周围的节点有多抱团 分母是周围(和该节点相连)节点有几对(两两一对)，分子是这些对中实际也相连的对数。 这种网络又叫自我中心网络，也就是数三角形个数。 这里预定义的子图是三角形，实际也可以换成别的图形做子图。 子图模式 - graphlets 类似同分异构体查找，然后统计每种模式的频率，构成频率向量。 实际都是在数数，数的是不同东西的数量罢了。 ","date":"2023-09-12","objectID":"/20230912/:4:0","tags":["机器学习","深度学习","特征工程","图神经网络","CS244W"],"title":"传统图机器学习和图特征工程(节点层面的特征工程)","uri":"/20230912/"},{"categories":["机器学习"],"content":"后言 图的人工特征总结如下 重要度特征 \u0026 结构特征 ","date":"2023-09-12","objectID":"/20230912/:5:0","tags":["机器学习","深度学习","特征工程","图神经网络","CS244W"],"title":"传统图机器学习和图特征工程(节点层面的特征工程)","uri":"/20230912/"},{"categories":["机器学习"],"content":"图基础 本体图是导入图之前就应该设计好的，本体图和具体图的关系类同类和实例的关系。如何设计本体图取决于将来的图的用途，比如图的用途是分析，那么本体图的设计应该包含所有图的属性，比如节点和边的属性，以及节点和边的类型，比如节点是用户还是物品，边是用户对物品感兴趣还是用户对用户感兴趣。 ","date":"2023-09-11","objectID":"/20230911/:1:0","tags":["机器学习","深度学习","图神经网络","CS244W"],"title":"图的基本表示","uri":"/20230911/"},{"categories":["机器学习"],"content":"图分类 有向图 \u0026 无向图 异质图 如果异质图中节点只分为两类，则称为二部图(二分图) 二部图可分别展开为图 ","date":"2023-09-11","objectID":"/20230911/:2:0","tags":["机器学习","深度学习","图神经网络","CS244W"],"title":"图的基本表示","uri":"/20230911/"},{"categories":["机器学习"],"content":"图的属性 图节点的度 无向图 - 度 有向图 - 入度 \u0026 出度 节点的度一定程度上表现了图中节点的重要性 ","date":"2023-09-11","objectID":"/20230911/:3:0","tags":["机器学习","深度学习","图神经网络","CS244W"],"title":"图的基本表示","uri":"/20230911/"},{"categories":["机器学习"],"content":"图的表示形式 邻接矩阵 无向图不分起点终点，是对称矩阵 有向图中行是起点，列是终点，一般不是对称矩阵 无向图求度，求某个点的度按行或按列求和即可，总度数求整体度看上/下对角阵即可 有向图求度，求某个点的出度按行求和，入度按列求和，总度数求整体和即可 实际矩阵会是稀疏矩阵，不能直接用邻接矩阵表示 连接列表 邻接列表 带权重的图 自环图和多通路图 ","date":"2023-09-11","objectID":"/20230911/:4:0","tags":["机器学习","深度学习","图神经网络","CS244W"],"title":"图的基本表示","uri":"/20230911/"},{"categories":["机器学习"],"content":"图的连通性 强连通图和弱连通图 强连通域(SCC) ","date":"2023-09-11","objectID":"/20230911/:5:0","tags":["机器学习","深度学习","图神经网络","CS244W"],"title":"图的基本表示","uri":"/20230911/"},{"categories":["机器学习","Python"],"content":"传统机器学习 默认二者独立同分布，只需要拟合决策边界分类或拟合回归的曲线即可。 ","date":"2023-09-10","objectID":"/20230910/:1:0","tags":["机器学习","深度学习","图神经网络","Python","CS244W"],"title":"图神经网络基础","uri":"/20230910/"},{"categories":["机器学习","Python"],"content":"现代神经网络 斯坦福CS的相关课程： 网络类型 数据类型 课程 全连接神经网络 表格 无 卷积神经网络 图像 CS231N 循环神经网络、Transformer 文本语音带序列 CS224N 图神经网络 图数据 CS244W ","date":"2023-09-10","objectID":"/20230910/:2:0","tags":["机器学习","深度学习","图神经网络","Python","CS244W"],"title":"图神经网络基础","uri":"/20230910/"},{"categories":["机器学习","Python"],"content":"复杂的图结构 任意尺寸输入 没有固定的节点顺序和参考锚点 动态变化，多模态特征 ","date":"2023-09-10","objectID":"/20230910/:3:0","tags":["机器学习","深度学习","图神经网络","Python","CS244W"],"title":"图神经网络基础","uri":"/20230910/"},{"categories":["机器学习","Python"],"content":"表示学习 - 图嵌入 - node embedding 把一个复杂的图节点表示为一个d维向量，能充分表示原始数据的语义。 做这件事的实际就是图神经网络干的事情。 图神经网络无需专门的特征提取设计，可以直接端到端的表示学习出特征。(自动学习特征)(类似CNN) ","date":"2023-09-10","objectID":"/20230910/:4:0","tags":["机器学习","深度学习","图神经网络","Python","CS244W"],"title":"图神经网络基础","uri":"/20230910/"},{"categories":["机器学习","Python"],"content":"CS224W的概述 传统图机器学习方法 图(节点)嵌入(node embeddings)：DeepWalk、node2vec (这里还没开始用图神经网络) 图神经网络：GCN(图卷积)、GraphSAGE、GAT(图注意力网络)、GNN 知识图谱和推理：TransE、BetaE 生成一个新图：GraphRNN 图数据挖掘 ","date":"2023-09-10","objectID":"/20230910/:5:0","tags":["机器学习","深度学习","图神经网络","Python","CS244W"],"title":"图神经网络基础","uri":"/20230910/"},{"categories":["机器学习","Python"],"content":"推荐的图工具库 pyg 类同 pytorch 但有高级封装可以直接调用 graphgym networkx dgl 复现了很多顶会论文的源码，学术推荐 echarts 可视化必备 graphxr 做知识图谱渲染好用 ","date":"2023-09-10","objectID":"/20230910/:6:0","tags":["机器学习","深度学习","图神经网络","Python","CS244W"],"title":"图神经网络基础","uri":"/20230910/"},{"categories":["机器学习","Python"],"content":"图数据的排名 https://db-engines.com/en/ranking/graph+dbms ","date":"2023-09-10","objectID":"/20230910/:7:0","tags":["机器学习","深度学习","图神经网络","Python","CS244W"],"title":"图神经网络基础","uri":"/20230910/"},{"categories":["机器学习","Python"],"content":"图神经网络任务层级 节点层面 node-level 连接层面(边层) edg-level 子图层面 subgraph-level 全图层面 graph-level ","date":"2023-09-10","objectID":"/20230910/:8:0","tags":["机器学习","深度学习","图神经网络","Python","CS244W"],"title":"图神经网络基础","uri":"/20230910/"},{"categories":["机器学习","Python"],"content":"后言 好玩的网站 https://open-leaderboard.x-lab.info/ https://crx.hypertrons.io/ ","date":"2023-09-10","objectID":"/20230910/:9:0","tags":["机器学习","深度学习","图神经网络","Python","CS244W"],"title":"图神经网络基础","uri":"/20230910/"},{"categories":["机器学习","Python"],"content":"前言 所有资源均免费，遇到付费推荐勿要付费 方向是 图神经网络 和 强化学习 的学习路径 ","date":"2023-09-09","objectID":"/20230909/:1:0","tags":["机器学习","深度学习","强化学习","图神经网络","Python","CS244W"],"title":"Python相关的深度学习的学习路径","uri":"/20230909/"},{"categories":["机器学习","Python"],"content":"基础知识 白月黑羽的网站： https://www.byhy.net/ 适合学习Python基础知识，有对应的B站讲解视频 他的自动化方面课程讲的也很好，爬虫中的selenium，以及Python的自动化测试，都算是他很好的课程了。(属于题外话了，这些东西在深度学习中用不到，没时间的别浪费时间看) ","date":"2023-09-09","objectID":"/20230909/:2:0","tags":["机器学习","深度学习","强化学习","图神经网络","Python","CS244W"],"title":"Python相关的深度学习的学习路径","uri":"/20230909/"},{"categories":["机器学习","Python"],"content":"机器学习入门(实践非理论) 菜菜子的课程： https://space.bilibili.com/630710622 对应资料可留言她的QQ领取，都是免费的 适合学习Python的初学者马上实践上手，主要看她的sklearn系列视频 ","date":"2023-09-09","objectID":"/20230909/:3:0","tags":["机器学习","深度学习","强化学习","图神经网络","Python","CS244W"],"title":"Python相关的深度学习的学习路径","uri":"/20230909/"},{"categories":["机器学习","Python"],"content":"深度学习入门 理论看吴恩达老师的课程，B站搜吴恩达机器学习Deeplearning.ai课程，一般都有上一年的搬运，看上一年的就行了。 实践看李沐的教程，他的网站： https://zh.d2l.ai/ 有对应的B站讲解视频，但推荐看到不懂的部分就转下一个推荐的视频补充知识后再继续过后面的内容，结合着看。 ","date":"2023-09-09","objectID":"/20230909/:4:0","tags":["机器学习","深度学习","强化学习","图神经网络","Python","CS244W"],"title":"Python相关的深度学习的学习路径","uri":"/20230909/"},{"categories":["机器学习","Python"],"content":"图神经网络入门 推荐看 CS224W 的课程，B站搜也有，资料是英文的，有空找个翻译版本看看不错。 https://jingboyang.github.io/stanford-cs224w-graph-ml/stanford_cs224w_graph_ml.pdf https://snap-stanford.github.io/cs224w-notes/ 主讲人是俄罗斯人，口音有点重，务必结合字幕看懂。 CSDN上有别人整理的相关中文讲义，但老实说水平一般般，但可以作为参考。 更推荐以下的国人精讲 https://www.bilibili.com/video/BV1pR4y1S7GA https://github.com/TommyZihao/zihao_course/tree/main/CS224W 这个中文翻译讲解视频，比原版本的更能理解一些，原版的默认你都看过对应论文再进行的讲解的感觉，很多逻辑和名词默认你已经知道，所以看起来有点吃力。 但这个作者讲到GAT部分后就不用看了，后面的内容仅中文翻译，没什么亮点。(精讲论文也还行吧，个人更推荐集智学院的论文讲解或李沐老师的论文精讲，我更能听得进去) (但这个中文讲解实际上课件啥的需要购买，实际无需购买，GitHub都能搜得到对应的课件和代码，不推荐购买他的任何东西，当然你觉得只是知识付费/捐赠原作者，那无可厚非) ","date":"2023-09-09","objectID":"/20230909/:5:0","tags":["机器学习","深度学习","强化学习","图神经网络","Python","CS244W"],"title":"Python相关的深度学习的学习路径","uri":"/20230909/"},{"categories":["机器学习","Python"],"content":"强化学习入门 Youtube搜 王树森 找他的强化学习基础，应该是强化学习方面讲的最容易懂的入门视频了。 B站搜 李宏毅 的课程也讲的不错，但公式推导欠缺了点，倒是可以给你强化学习中的直观感受理解。 实践方面推荐以下仓库： https://github.com/wangshusen/DeepLearning ","date":"2023-09-09","objectID":"/20230909/:6:0","tags":["机器学习","深度学习","强化学习","图神经网络","Python","CS244W"],"title":"Python相关的深度学习的学习路径","uri":"/20230909/"},{"categories":["机器学习","Python"],"content":"后言 由于本方向很新很少有中文教程，所以有必要还得上 Pytorch 的论坛问问，很多实践的BUG找不到解决方案太折磨了。 ","date":"2023-09-09","objectID":"/20230909/:7:0","tags":["机器学习","深度学习","强化学习","图神经网络","Python","CS244W"],"title":"Python相关的深度学习的学习路径","uri":"/20230909/"},{"categories":["机器学习","Python"],"content":"前言 Actor-Critic Methods 结合了价值学习和策略学习，同时训练了两个神经网络。 Actor 网络用于产生策略，Critic 网络用于评估策略。 ","date":"2023-09-08","objectID":"/20230908/:1:0","tags":["机器学习","深度学习","强化学习","Python"],"title":"Actor-Critic Methods","uri":"/20230908/"},{"categories":["机器学习","Python"],"content":"目标 ① 更新策略网络Π的参数，是为了增大状态价值V的值，要用价值网络q进行打分来训练。 ② 更新价值网络q的参数，是为了让评价网络更精准的评价动作，从而更精准的预测累计奖励。 ","date":"2023-09-08","objectID":"/20230908/:2:0","tags":["机器学习","深度学习","强化学习","Python"],"title":"Actor-Critic Methods","uri":"/20230908/"},{"categories":["机器学习","Python"],"content":"具体的可视化流程 每个回合只执行一次动作，但预测两次动作，只更新一次参数。 ","date":"2023-09-08","objectID":"/20230908/:3:0","tags":["机器学习","深度学习","强化学习","Python"],"title":"Actor-Critic Methods","uri":"/20230908/"},{"categories":["机器学习","Python"],"content":"流程总结 这里不用qt用deta t是使用了 Baseline 而不是原始的方法，不影响期望，但可以让方差降低减少误差。 实际任何qt附近的数都可以作为 Baseline 但它不能是动作 at 的函数。 ","date":"2023-09-08","objectID":"/20230908/:4:0","tags":["机器学习","深度学习","强化学习","Python"],"title":"Actor-Critic Methods","uri":"/20230908/"},{"categories":["机器学习","Python"],"content":"用策略函数指导动作 使用策略函数随机抽样得到动作。 ","date":"2023-09-07","objectID":"/20230907/:1:0","tags":["机器学习","深度学习","强化学习","Python"],"title":"Policy-Based learning","uri":"/20230907/"},{"categories":["机器学习","Python"],"content":"近似策略函数 由于实际的策略函数无法得到，需要用各种方式去近似策略函数，所以这里可以使用神经网络去近似实际的策略函数，记作policy network。 最后在全连接层后使用softmax函数，得到概率分布(也即所有概率之和为1)。 ","date":"2023-09-07","objectID":"/20230907/:2:0","tags":["机器学习","深度学习","强化学习","Python"],"title":"Policy-Based learning","uri":"/20230907/"},{"categories":["机器学习","Python"],"content":"近似状态价值函数 VΠ 近似状态价值函数时，内积中的策略函数被近似为策略神经网络，因而学习V中的神经网络参数，使其V的期望最大化。(算的是随机梯度上升) 这里要算的策略梯度，很多时候也不是直接用解析解，用的是数值解，用蒙特卡洛近似求解。 可推导出以上策略梯度的两个近似，第一个是离散形式的动作，第二个是连续形式的动作。 连续动作一般使用蒙特卡洛近似，大致思想是随机抽样得到一个或多个样本，用样本来近似期望(无偏估计)。 即便蒙特卡洛算法得到的结果是低精度的，但也足够用了，随机梯度下降实际也是使用该方法得到的近似解。 ","date":"2023-09-07","objectID":"/20230907/:3:0","tags":["机器学习","深度学习","强化学习","Python"],"title":"Policy-Based learning","uri":"/20230907/"},{"categories":["机器学习","Python"],"content":"算法步骤 ","date":"2023-09-07","objectID":"/20230907/:4:0","tags":["机器学习","深度学习","强化学习","Python"],"title":"Policy-Based learning","uri":"/20230907/"},{"categories":["机器学习","Python"],"content":"近似动作价值函数 方法1需要跑到任务结束才能更新策略网络。 方法2用另一个神经网络做函数近似，原本已用神经网络近似了函数Π，要用新的神经网络去近似QΠ。 ","date":"2023-09-07","objectID":"/20230907/:5:0","tags":["机器学习","深度学习","强化学习","Python"],"title":"Policy-Based learning","uri":"/20230907/"},{"categories":["机器学习","Python"],"content":"方法总结 ","date":"2023-09-07","objectID":"/20230907/:6:0","tags":["机器学习","深度学习","强化学习","Python"],"title":"Policy-Based learning","uri":"/20230907/"},{"categories":["机器学习","Python"],"content":"寻找最佳的Q值函数 实际并不知道最佳的Q值函数，需要使用神经网络 Q(s,a;w) 来近似最佳的Q值函数。 实际流程大致为当前状态转换为矩阵后，通过卷积层提取特征向量，再通过全连接层得到Q值向量，此时的Q值向量每一个元素代表某一个动作的得分。 ","date":"2023-09-06","objectID":"/20230906/:1:0","tags":["机器学习","深度学习","强化学习","Python","DQN"],"title":"Deep Q-Network (DQN) (Value-Based learning)","uri":"/20230906/"},{"categories":["机器学习","Python"],"content":"TD算法训练DQN 实际就是在总任务中，预测任务的一部分，然后实际运行这部分任务，看看二者之间的TD误差，然后通过梯度下降不断调整参数，使得TD误差最小(最好的当然是0，但实际大都不可能达到)，然后继续执行这部分任务后续部分，循环往复。 任务执行前： 任务执行后： 完整流程： 在环境输出预测的Q值时，会使用贪心策略，即选择Q值最大的动作，实际在实际运行时，会使用epsilon-greedy策略，即有一定概率随机选择动作，以一定的概率选择Q值最大的动作。 每次得到reward和state时，都会去进行梯度下降计算，更新参数。 ","date":"2023-09-06","objectID":"/20230906/:2:0","tags":["机器学习","深度学习","强化学习","Python","DQN"],"title":"Deep Q-Network (DQN) (Value-Based learning)","uri":"/20230906/"},{"categories":["机器学习","Python"],"content":"State 状态，即状态空间，表示环境中的当前状态。 ","date":"2023-09-05","objectID":"/20230905/:1:0","tags":["机器学习","深度学习","强化学习","Python","gym"],"title":"强化学习术语翻译","uri":"/20230905/"},{"categories":["机器学习","Python"],"content":"Action \u0026\u0026 Agent 动作，即动作空间，表示在当前状态下，执行的动作。 动作由谁做的就是Agent，即智能体。 ","date":"2023-09-05","objectID":"/20230905/:2:0","tags":["机器学习","深度学习","强化学习","Python","gym"],"title":"强化学习术语翻译","uri":"/20230905/"},{"categories":["机器学习","Python"],"content":"Policy Π 策略，即策略空间，表示在当前状态下，智能体可以采取的动作。 数学上表示为概率密度函数Π，即执行动作a在当前状态s下概率为p(a|s)。 强化学习实际就是学习这个函数，执行的动作最好是随机抽样得到的，要有随机性，如果策略固定那么动作也就固定了。 ","date":"2023-09-05","objectID":"/20230905/:3:0","tags":["机器学习","深度学习","强化学习","Python","gym"],"title":"强化学习术语翻译","uri":"/20230905/"},{"categories":["机器学习","Python"],"content":"Reward R 奖励，即奖励函数，表示在当前状态下执行动作a后，环境给智能体的奖励。 这个函数是需要自己定义的，智能体通过学习策略，来最大化奖励。 ","date":"2023-09-05","objectID":"/20230905/:4:0","tags":["机器学习","深度学习","强化学习","Python","gym"],"title":"强化学习术语翻译","uri":"/20230905/"},{"categories":["机器学习","Python"],"content":"state transition 状态转移，即状态转移函数，表示在当前状态下执行动作a后，环境转移到下一个状态s的概率，是一个条件概率密度函数。 状态转移可以是确定或者随机的，一般是随机的。 ","date":"2023-09-05","objectID":"/20230905/:5:0","tags":["机器学习","深度学习","强化学习","Python","gym"],"title":"强化学习术语翻译","uri":"/20230905/"},{"categories":["机器学习","Python"],"content":"随机性来源 ① 动作带来的随机性，policy对输入状态s给予随机的动作。 ② 状态转移带来的随机性，环境对输入的状态s和动作a，输出下一个状态s’，这个s’是随机的。 以上都基于随机抽样得到的随机性。 ","date":"2023-09-05","objectID":"/20230905/:6:0","tags":["机器学习","深度学习","强化学习","Python","gym"],"title":"强化学习术语翻译","uri":"/20230905/"},{"categories":["机器学习","Python"],"content":"trajectory 轨迹 (状态、动作、奖励) 的序列，即轨迹。 ","date":"2023-09-05","objectID":"/20230905/:7:0","tags":["机器学习","深度学习","强化学习","Python","gym"],"title":"强化学习术语翻译","uri":"/20230905/"},{"categories":["机器学习","Python"],"content":"Return 回报 从开始到结束的累计奖励，即回报。 Ut = Rt + Rt+1 + Rt+2 + … + Rt+n 未来的奖励应当比当前的奖励低，所以 Rt+1 应当小于当前的 Rt。 因此 Discounted return 折扣回报 应运而生 γ 是折扣率，介于0到1之间，属于超参数需要调。 Ut = Rt + γRt+1 + γ^2Rt+2 + … + γ^n*Rt+n 由于当前的回报U取决于奖励R，所以未结束时Ut是未知的，只有当结束时，Ut才确定，因而Ut也是随机的。 当前时刻的Rt取决于当前时刻的状态st和动作at，所以Rt是随机的。 ","date":"2023-09-05","objectID":"/20230905/:8:0","tags":["机器学习","深度学习","强化学习","Python","gym"],"title":"强化学习术语翻译","uri":"/20230905/"},{"categories":["机器学习","Python"],"content":"Action-Value Function Q(s, a) 动作价值函数Q 在策略Π下，在状态s执行动作a的期望回报，即 QΠ(st, at) = E(Ut|St=st, At=at) 这里是对非当前时刻t下的状态s和a积分(通过策略Π)，由于当前时刻的状态s和动作t给定是数值，所以是一个数值。 直观意义下，就是使用策略 Π 在状态 s 下执行动作 a 是好还是坏，评估动作的分数(当前状态下所有可能的动作的得分)。 由于用不同的策略 Π 会有不同的Q函数，所以如果对QΠ求最大化，得到的就是最优策略Π下的Q函数。 ","date":"2023-09-05","objectID":"/20230905/:9:0","tags":["机器学习","深度学习","强化学习","Python","gym"],"title":"强化学习术语翻译","uri":"/20230905/"},{"categories":["机器学习","Python"],"content":"State-Value Function V(s) 状态价值函数S 离散动作求和，连续动作积分。 VΠ可以告诉我们当前的局势好不好，具体而言 ① 使用策略 Π ，VΠ 可以告诉我们状态 S 下当前局势的好坏。 ② 评价策略 Π 的好坏，不同的策略 Π 会有不同的 VΠ 值，策略 Π 越好，VΠ 的平均值越大。 ","date":"2023-09-05","objectID":"/20230905/:10:0","tags":["机器学习","深度学习","强化学习","Python","gym"],"title":"强化学习术语翻译","uri":"/20230905/"},{"categories":["机器学习","Python"],"content":"如何训练智能体 agent Policy-Based learning 和 Value-Based learning 也即是 策略学习 和 价值学习，前者不言自明就是学习Π函数，后者是学习最优动作价值函数，强化学习只需要学习其中之一即可。 ","date":"2023-09-05","objectID":"/20230905/:11:0","tags":["机器学习","深度学习","强化学习","Python","gym"],"title":"强化学习术语翻译","uri":"/20230905/"},{"categories":["机器学习","Python"],"content":"常用的测试集 (gym) 内含各种常见的测试强化学习算法的问题。 ","date":"2023-09-05","objectID":"/20230905/:12:0","tags":["机器学习","深度学习","强化学习","Python","gym"],"title":"强化学习术语翻译","uri":"/20230905/"},{"categories":["电脑技巧"],"content":"前言 观望了全网的Docker启用IPV6的方法，要么是Docker版本更替法子不通了，要么是没说明一些前置条件的细节，导致方法也用不了，所以这里记录一下我走通的方法，一个兼容高低版本Docker和不同网络环境的方法 ","date":"2023-08-29","objectID":"/20230829/:1:0","tags":["linux","docker","nat","radvd","ndppd","ndpresponder","ifupdown","shell","debian","ipv6"],"title":"为Docker配置启用IPV6网络并配置给容器自动分配IPV6地址(2023最新)","uri":"/20230829/"},{"categories":["电脑技巧"],"content":"环境 常见的方法是给Docker增加/etc/docker/daemon.json配置项，如 { \"ipv6\": true, \"fixed-cidr-v6\": \"这里填IPV6的Gateway地址/子网掩码\" } 但这种方法是有问题的，并不是所有宿主机都支持这么配置然后IPV6附加上去就通了的 宿主机的Gateway可能是公网地址和私网地址都有的，或者是要么只有公网，要么只有私网 对于只有私网的ipv6的Gateway当然可以如上配置，但只有公网的ipv6的Gateway就不能这么配置了，理论上需要iptables进行映射，都有的情况又得另外写一篇了 以上方法都很麻烦，因为即便配置好了网络，实际你仍旧需要手动一一附加IPV6地址给容器，这就很麻烦，下面介绍一下我的方法 ","date":"2023-08-29","objectID":"/20230829/:2:0","tags":["linux","docker","nat","radvd","ndppd","ndpresponder","ifupdown","shell","debian","ipv6"],"title":"为Docker配置启用IPV6网络并配置给容器自动分配IPV6地址(2023最新)","uri":"/20230829/"},{"categories":["电脑技巧"],"content":"使用 ndpresponder + radvd + 新建bridge 实现自动分配地址 如果嫌弃手动方法麻烦，可以移步 https://virt.spiritlhl.net/guide/docker_precheck.html 有写好自动化设置的方法，以下是手动设置的方法，仅作记录 以下示例已假设你物理网卡是eth0，是别的自行替换名字 ","date":"2023-08-29","objectID":"/20230829/:3:0","tags":["linux","docker","nat","radvd","ndppd","ndpresponder","ifupdown","shell","debian","ipv6"],"title":"为Docker配置启用IPV6网络并配置给容器自动分配IPV6地址(2023最新)","uri":"/20230829/"},{"categories":["电脑技巧"],"content":"前期准备 前期中的前期是先查看本机使用什么管理网络，执行 systemctl is-active systemd-networkd 和 systemctl is-active networking 看看属于哪种情况，如果是前者active，你需要切换本机使用ifupdown或者ifupdown2管理网络，如果是后者，则不需要切换网络管理程序，直接进行后续操作即可。 首先是确认一下IPV6的子网大小，宿主机需要至少/64大小的子网，因为后面需要划分出/80大小的子网使其自动附加到容器上，当然这不是绝对的，你可以划分更大的子网或者宿主机的子网更小也没问题，唯一的原则就是后续划分的子网中，不能包含宿主机的IPV6地址和IPV6的Gateway，这个是重点。 然后就是判断宿主机的IPV6的Gateway究竟是公网还是私网，亦或者是两者都有，执行以下命令查询 ip -6 route show | awk '/default via/{print $3}' 如果只有一行fe80开头的就是只有私网gateway 如果是没有fe80开头的行但有别的开头的ipv6地址，就是只有公网gateway 如果有两行甚至多行，fe80开头的行也有，非fe80开头的行也有，那就是公私网的gateway都有 如果你是只有公网的gateway，先执行 ip -6 addr show dev eth0 | awk '/inet6 fe80/ {print $2}' 查询fe80的地址，然后需要你手动修改/etc/network/interfaces文件新增一行在末尾 up ip addr del 这里填你查询到的地址 dev eth0 如果你是公私网gateway都有，那么/etc/network/interfaces文件的ipv6的gateway最好用公网的v6地址，然后也如同只有公网的gateway那样新增一行上面的内容 修改过文件后最好使用chattr命令锁死文件只读然后重启系统，以加载网络修改 如果是只有私网的gateway，那么/etc/network/interfaces文件无需修改，也无需重启系统 ","date":"2023-08-29","objectID":"/20230829/:3:1","tags":["linux","docker","nat","radvd","ndppd","ndpresponder","ifupdown","shell","debian","ipv6"],"title":"为Docker配置启用IPV6网络并配置给容器自动分配IPV6地址(2023最新)","uri":"/20230829/"},{"categories":["电脑技巧"],"content":"安装radvd和ndpresponder并新建bridge radvd正常只需要通过对应系统的包管理器下载就行了 如apt的直接apt install radvd -y，yum的直接yum install radvd -y，别的类同 然后修改配置文件/etc/radvd.conf，覆写如下 interface eth0 { AdvSendAdvert on; MinRtrAdvInterval 3; MaxRtrAdvInterval 10; prefix 这里写你IPV6的地址除去最后一个冒号后的内容但保留冒号/这里写你IPV6的子网掩码大小 { AdvOnLink on; AdvAutonomous on; AdvRouterAddr on; }; }; 然后就是创建一个新bridge命名为ipv6_net docker network create --ipv6 --subnet=172.26.0.0/16 --subnet=这里填你之前划分的/80子网带子网掩码的地址 ipv6_net 然后是ndpresponder的安装，ndpresponder是用来处理IPV6的NDP协议的，是ndppd的修改版本，所以安装方式不同，无法通过官方的包管理器安装。 这里我有编译好对应每个架构的docker镜像，自取docker镜像安装 x86的如下 docker run -d \\ --restart always --cpus 0.02 --memory 64M \\ -v /var/run/docker.sock:/var/run/docker.sock:ro \\ --cap-drop=ALL --cap-add=NET_RAW --cap-add=NET_ADMIN \\ --network host --name ndpresponder \\ spiritlhl/ndpresponder_x86 -i eth0 -N ipv6_net arm的如下 docker run -d \\ --restart always --cpus 0.02 --memory 64M \\ -v /var/run/docker.sock:/var/run/docker.sock:ro \\ --cap-drop=ALL --cap-add=NET_RAW --cap-add=NET_ADMIN \\ --network host --name ndpresponder \\ spiritlhl/ndpresponder_aarch64 -i eth0 -N ipv6_net 然后你可以使用以下命令开设容器看看是否IPV6镜像已经通畅了 docker run --network=ipv6_net --rm -it busybox ping -6 -c4 ipv6.ip.sb ","date":"2023-08-29","objectID":"/20230829/:3:2","tags":["linux","docker","nat","radvd","ndppd","ndpresponder","ifupdown","shell","debian","ipv6"],"title":"为Docker配置启用IPV6网络并配置给容器自动分配IPV6地址(2023最新)","uri":"/20230829/"},{"categories":["电脑技巧"],"content":"总结 以上方式简单易懂，适配所有可能的IPV6的gateway配置情况，当然如果你嫌弃手动修改麻烦，还是推荐使用 https://virt.spiritlhl.net/guide/docker_precheck.html 有写好自动化设置的方法，自动分辨对应情况进行修改，自己看对应说明使用即可 相关仓库 https://github.com/spiritLHLS/docker ","date":"2023-08-29","objectID":"/20230829/:4:0","tags":["linux","docker","nat","radvd","ndppd","ndpresponder","ifupdown","shell","debian","ipv6"],"title":"为Docker配置启用IPV6网络并配置给容器自动分配IPV6地址(2023最新)","uri":"/20230829/"},{"categories":["机器学习","Python"],"content":"前言 老板下指示复现两篇文章，这是其中一篇 https://arxiv.org/pdf/2205.14105v1.pdf 文章的原理什么的已经大部分明白了但仍然有部分懂，故而做下记录，以备后续复现或深入了解 ","date":"2023-08-23","objectID":"/20230823/:1:0","tags":["机器学习","深度学习","jupyter","pytorch","conda","Python","GCN","RNN"],"title":"高效探索学习解决组合图分区问题(基于强化学习的优化算法)","uri":"/20230823/"},{"categories":["机器学习","Python"],"content":"原始数据 ","date":"2023-08-23","objectID":"/20230823/:2:0","tags":["机器学习","深度学习","jupyter","pytorch","conda","Python","GCN","RNN"],"title":"高效探索学习解决组合图分区问题(基于强化学习的优化算法)","uri":"/20230823/"},{"categories":["机器学习","Python"],"content":"ER40/BA40到ER500/BA500 https://ojs.aaai.org/index.php/AAAI/article/download/5723/5579 https://journals.aps.org/rmp/abstract/10.1103/RevModPhys.74.47 分别命名为ER和BA数据集 ","date":"2023-08-23","objectID":"/20230823/:2:1","tags":["机器学习","深度学习","jupyter","pytorch","conda","Python","GCN","RNN"],"title":"高效探索学习解决组合图分区问题(基于强化学习的优化算法)","uri":"/20230823/"},{"categories":["机器学习","Python"],"content":"ER800到ER10000 https://www.sciencedirect.com/science/article/abs/pii/S0952197612002175 ","date":"2023-08-23","objectID":"/20230823/:2:2","tags":["机器学习","深度学习","jupyter","pytorch","conda","Python","GCN","RNN"],"title":"高效探索学习解决组合图分区问题(基于强化学习的优化算法)","uri":"/20230823/"},{"categories":["机器学习","Python"],"content":"相关Github仓库 https://github.com/tomdbar/ecord 这是作者的原始仓库，非常感谢作者提供了Dockerfile和对应的数据集，使得环境依赖强制约束的非常好，开源了这么久了还能跑，依赖无需大更新 我修复了一下numpy依赖的版本(pytorch要求更高了)，然后总结了一下一步安装的脚本和步奏如下 https://github.com/spiritysdx/ecord#edited 进入容器后可以非常容易的一键训练出网络和使用各测试集测试，再次感谢原作者对这方面的支持 ","date":"2023-08-23","objectID":"/20230823/:3:0","tags":["机器学习","深度学习","jupyter","pytorch","conda","Python","GCN","RNN"],"title":"高效探索学习解决组合图分区问题(基于强化学习的优化算法)","uri":"/20230823/"},{"categories":["机器学习","Python"],"content":"实验的问题 最大割（Max-Cut）问题的目标是将一个给定的无向图中的节点分成两个不相交的集合，使得割（即连接两个集合的边）的数量尽可能多。换句话说，要找到一个划分，使得划分的边的数目最大化。 形式化地说，给定一个无向图 G = (V, E)，其中 V 表示节点的集合，E 表示边的集合，Max-Cut问题的目标是找到一个节点划分 (A, B)，其中 A 和 B 是不相交的子集，使得划分的边的数量尽可能多。数学上，目标可以表示为最大化以下函数： maximize E(A, B) = {(u, v) ∈ E : u ∈ A 且 v ∈ B} 的大小。 ","date":"2023-08-23","objectID":"/20230823/:4:0","tags":["机器学习","深度学习","jupyter","pytorch","conda","Python","GCN","RNN"],"title":"高效探索学习解决组合图分区问题(基于强化学习的优化算法)","uri":"/20230823/"},{"categories":["机器学习","Python"],"content":"优化思路 构建了一个新的算法 ECORD（具有递归解码的探索性组合优化），它将单个GNN预处理步骤与快速行动解码相结合，从而用简单的顶点观察和对正在进行的优化轨迹的学习表示来替代进一步的几何推理。 这里的翻转实际就是属于哪个子集，对于每个顶点，都提供以下信息：(i) 当前标签，(ii) 如果翻转该顶点会导致的切割值的立即变化（被称为“预览”）和 (iii) 自上次翻转节点以来的步数。 目标观察是当前状态和最佳观察状态之间切割值的（归一化）差异，以及当前状态中任何顶点的最大预览值。 ","date":"2023-08-23","objectID":"/20230823/:5:0","tags":["机器学习","深度学习","jupyter","pytorch","conda","Python","GCN","RNN"],"title":"高效探索学习解决组合图分区问题(基于强化学习的优化算法)","uri":"/20230823/"},{"categories":["机器学习","Python"],"content":"ECORD的伪代码 对于每一批次的 episodes 做如下循环： 从分布 D 中随机采样一批 BG 图 G(V, E)。 使用图神经网络计算每个顶点的嵌入向量。 对于每个 episode 中的时间步 t 做如下循环： 计算用于反向传播的时间步数 k0。 对于批次中的每个图 Gj 做如下循环： 根据策略选择动作 a(t)： - 以概率 ε 随机选择动作 a(t)。 - 以概率 1 - ε 使用 softmax(Qθ(s(t),·) / τ) 方法选择动作 a(t)。 更新解决方案集合 S(t+1)： - 如果 a(t) 不在 S(t) 中，则将其加入到 S(t) 中。 - 如果 a(t) 在 S(t) 中，则将其从 S(t) 中移除。 将元组 m(t) = (s(t-k0), ..., s(t+1), a(t-k0), ..., a(t), r(t), d) 添加到经验回放内存 M 中。 # 这个元组包含了状态、动作、奖励等信息，用于训练模型。 如果 t 模除 fupd 等于 0，则进行如下操作： 从经验回放内存 M 中随机采样一批经验 M(t)。 使用 BPTT 方法从时间步 t 到 t - k0 进行反向传播，更新模型参数 θ。 更新目标网络的参数 θ： θ ← θτupd + θ(1 - τupd) 结束 结束 结束 结束 ","date":"2023-08-23","objectID":"/20230823/:6:0","tags":["机器学习","深度学习","jupyter","pytorch","conda","Python","GCN","RNN"],"title":"高效探索学习解决组合图分区问题(基于强化学习的优化算法)","uri":"/20230823/"},{"categories":["机器学习","Python"],"content":"优化点 ECO-DQN在每个决策步骤都使用了昂贵的GNN，再加上推理过程中的探索轨迹，导致其扩展性甚至不如S2V-DQN，并且仅用了一些手工特征来表示先前的搜索轨迹。 ECORD通过使用初始GNN嵌入，然后使用循环单元来平衡图网络提供的信息与基于学习的轨迹表示之间的关系，弥补了这一缺点。 ","date":"2023-08-23","objectID":"/20230823/:7:0","tags":["机器学习","深度学习","jupyter","pytorch","conda","Python","GCN","RNN"],"title":"高效探索学习解决组合图分区问题(基于强化学习的优化算法)","uri":"/20230823/"},{"categories":["机器学习","Python"],"content":"相关知识点 ","date":"2023-08-23","objectID":"/20230823/:8:0","tags":["机器学习","深度学习","jupyter","pytorch","conda","Python","GCN","RNN"],"title":"高效探索学习解决组合图分区问题(基于强化学习的优化算法)","uri":"/20230823/"},{"categories":["机器学习","Python"],"content":"RNN 基于MLP多塞了一项时间t，多了一个时间轴，当前的预测值实际就是当前的观察值的预测，但当前预测值只用到了当前的隐变量ht，ht和前一个时刻的ht-1有关，ht也和前一个时间t-1中的观察值xt-1有关。(当前时间t中，输出和输入的信息不互通，但理论上预测成功的话二者是一样的) ","date":"2023-08-23","objectID":"/20230823/:8:1","tags":["机器学习","深度学习","jupyter","pytorch","conda","Python","GCN","RNN"],"title":"高效探索学习解决组合图分区问题(基于强化学习的优化算法)","uri":"/20230823/"},{"categories":["机器学习","Python"],"content":"GRU 门控循环单元与普通的循环神经网络(RNN)之间的关键区别在于： 前者支持隐状态的门控。 这意味着模型有专门的机制来确定应该何时更新隐状态， 以及应该何时重置隐状态。 重置门有助于捕获序列中的短期依赖关系；更新门有助于捕获序列中的长期依赖关系。重置和更新门都具有可学习的参数， 因此可以对模型进行训练。 ","date":"2023-08-23","objectID":"/20230823/:8:2","tags":["机器学习","深度学习","jupyter","pytorch","conda","Python","GCN","RNN"],"title":"高效探索学习解决组合图分区问题(基于强化学习的优化算法)","uri":"/20230823/"},{"categories":["机器学习","Python"],"content":"BPTT 通过时间反向传播，要求将循环神经网络的计算图一次展开一个时间步， 以获得模型变量和参数之间的依赖关系。然后，基于链式法则，应用反向传播来计算和存储梯度。 由于通过时间反向传播是反向传播在循环神经网络中的应用方式， 所以训练循环神经网络交替使用前向传播和通过时间反向传播。 通过时间反向传播依次计算并存储上述梯度。 具体而言，存储的中间值会被重复使用，以避免重复计算。 ","date":"2023-08-23","objectID":"/20230823/:8:3","tags":["机器学习","深度学习","jupyter","pytorch","conda","Python","GCN","RNN"],"title":"高效探索学习解决组合图分区问题(基于强化学习的优化算法)","uri":"/20230823/"},{"categories":["机器学习","Python"],"content":"前言 两篇文章的主体解析没有涉及作者进行模型比较的部分，这里主要解决一下该部分 由于两篇文章都涉及该方法的比较，所以重头戏是DQN以及其衍生的一些变体，还有部分别的模型，是需要提前了解的。 大致的模型解决思路图 ","date":"2023-08-16","objectID":"/20230816/:1:0","tags":["机器学习","深度学习","jupyter","DQN","RL-GNN","SOTA"],"title":"图优化问题经常拿来比较的一些模型","uri":"/20230816/"},{"categories":["机器学习","Python"],"content":"RL-GNN ","date":"2023-08-16","objectID":"/20230816/:2:0","tags":["机器学习","深度学习","jupyter","DQN","RL-GNN","SOTA"],"title":"图优化问题经常拿来比较的一些模型","uri":"/20230816/"},{"categories":["机器学习","Python"],"content":"DQN Human-level control through deep reinforcement learning https://www.nature.com/articles/nature14236 使用CNN提取状态特征，状态表示的预处理 使用神经网络作为函数逼近器学习价值网络，得到高维空间下的近似Q值函数 使用off-policy框架，并把过去的经验transition保存下来重用 ","date":"2023-08-16","objectID":"/20230816/:2:1","tags":["机器学习","深度学习","jupyter","DQN","RL-GNN","SOTA"],"title":"图优化问题经常拿来比较的一些模型","uri":"/20230816/"},{"categories":["机器学习","Python"],"content":"S2V-DQN Learning Combinatorial Optimization Algorithms over Graphs https://proceedings.neurips.cc/paper_files/paper/2017/file/d9896106ca98d3d05b8cbdf4fd8b13a1-Paper.pdf S2V-DQN是DQN的一个变体。 该方法利用元算法（贪心算法），逐步构建问题的解决方案。 在每个贪心步骤中，利用图嵌入技术（structure2vec，即S2V）来将图中的节点编码为向量表示，这种编码方式在每一步中都会得到更新，以反映当前状态下的局部信息。这种图嵌入方法有助于捕捉图中节点的特征。 在每个贪心步骤中，通过结合部分解来更新图嵌入，以将新的收益信息反映到最终的目标值中。为了实现这种延迟回报的学习，采用强化学习中的n-step Q-learning方法，以调整图嵌入网络的参数。 ","date":"2023-08-16","objectID":"/20230816/:2:2","tags":["机器学习","深度学习","jupyter","DQN","RL-GNN","SOTA"],"title":"图优化问题经常拿来比较的一些模型","uri":"/20230816/"},{"categories":["机器学习","Python"],"content":"ECO-DQN Exploratory combinatorial optimization with reinforcement learning https://ojs.aaai.org/index.php/AAAI/article/download/5723/5579 基于DQN，修改action改为可以移除某一个点， reward改为normalized incremental reward，具体来说，在一个episode中，每次找到更低的局部最小值，就会获得一个小的reward。 允许agent在测试时通过探索解空间来不断改进解决方案，可以在解决方案子集中添加或删除顶点，并在测试时寻找不断改进的解决方案。 ","date":"2023-08-16","objectID":"/20230816/:2:3","tags":["机器学习","深度学习","jupyter","DQN","RL-GNN","SOTA"],"title":"图优化问题经常拿来比较的一些模型","uri":"/20230816/"},{"categories":["机器学习","Python"],"content":"M-DQN Munchausen Reinforcement Learning https://proceedings.neurips.cc//paper/2020/file/2c6a0bae0f071cbbf0bb3d5b11d90a82-Paper.pdf 利用当前策略去引导bootstrapping，因为当前策略能够影响下一步做的决策。 其实质就是在任何时间差异算法中(文章列举了DQN和IQN的修改)，将缩放的对数策略添加到即时奖励中。 ","date":"2023-08-16","objectID":"/20230816/:2:4","tags":["机器学习","深度学习","jupyter","DQN","RL-GNN","SOTA"],"title":"图优化问题经常拿来比较的一些模型","uri":"/20230816/"},{"categories":["机器学习","Python"],"content":"ReduMIS Finding Near-Optimal Independent Sets at Scale https://www.researchgate.net/publication/281487239_Finding_Near-Optimal_Independent_Sets_at_Scale 使用约简规则来提高进化算法的性能，并选择可能在大型独立集中的顶点以实现进一步的约简。 这个过程递归地重复进行，从而发现大型独立集。 该算法属于进化算法，结合核化技术，在巨大稀疏网络中计算大规模独立集。通过递归选择可能属于大规模独立集的顶点，并进一步核化图形，比现有的局部搜索算法更快，并且能够在比以前文献报道的更大实例上计算高质量的独立集。 ","date":"2023-08-16","objectID":"/20230816/:3:0","tags":["机器学习","深度学习","jupyter","DQN","RL-GNN","SOTA"],"title":"图优化问题经常拿来比较的一些模型","uri":"/20230816/"},{"categories":["机器学习","Python"],"content":"Classic Combinatorial Optimization: Algorithms and Complexity https://www.researchgate.net/publication/220695898_Combinatorial_Optimization_Algorithms_and_Complexity 经典强化学习方法包括动态规划、蒙特卡洛方法和时序差分学习等，但目前好像没看到直接用来解决问题的，大多数是嵌入到某些模型中，优化某一个步奏。 ","date":"2023-08-16","objectID":"/20230816/:4:0","tags":["机器学习","深度学习","jupyter","DQN","RL-GNN","SOTA"],"title":"图优化问题经常拿来比较的一些模型","uri":"/20230816/"},{"categories":["机器学习","Python"],"content":"原地操作 使用 a = 1 b = 1 a += b print(a) # 结果是2 而不是使用 a = a + b 好处是内存不会复制扩展，只使用a和b的内存运算 import numpy as np X = np.arange(12).reshape(3, 4) Y = np.array([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]]) np.concatenate([X, Y], axis=0), np.concatenate([X, Y], axis=1) 检测内存是否一致，在下面的例子中，用Python的id()函数演示了这一点， 它提供了内存中引用对象的确切地址。 运行Y = Y + X后，会发现id(Y)指向另一个位置。 这是因为Python首先计算Y + X，为结果分配新的内存，然后使Y指向内存中的这个新位置。 before = id(Y) Y = Y + X id(Y) == before 幸运的是，执行原地操作非常简单。 可以使用切片表示法将操作的结果分配给先前分配的数组，例如Y[:] = \u003cexpression\u003e。 为了说明这一点，首先创建一个新的矩阵Z，其形状与另一个Y相同， 使用zeros_like来分配一个全的块。 Z = np.zeros_like(Y) print('id(Z):', id(Z)) Z[:] = X + Y print('id(Z):', id(Z)) 如果在后续计算中没有重复使用X， 可以使用X[:] = X + Y或X += Y来减少操作的内存开销。 before = id(X) X += Y id(X) == before ","date":"2023-08-12","objectID":"/20230812/:1:0","tags":["机器学习","深度学习","jupyter","Python"],"title":"Python加速科学运算的一些小技巧","uri":"/20230812/"},{"categories":["机器学习","Python"],"content":"重复使用数据使其在缓存中，按序读写数据使其可预读取 矩阵按行存储比按列存储读取更快，预读取是按行读取的 ","date":"2023-08-12","objectID":"/20230812/:2:0","tags":["机器学习","深度学习","jupyter","Python"],"title":"Python加速科学运算的一些小技巧","uri":"/20230812/"},{"categories":["机器学习","Python"],"content":"CPU多核优势可用对应并行数优化速度 注意是使用物理核心数而不是逻辑核心数，这里的逻辑核心可能是物理核心的翻倍，需要仔细查看 由于Python的多线程只是在一个核心上跑，多进程才是在多核上跑，所以优化代码时最好使用多进程优化 多进程通信最好使用队列维护，可用兼容异步并行和同步逻辑，最好只使用尽量少的队列，尽量在一步逻辑内使用同队列一次，否则更新队列会很麻烦，逻辑考虑不周全可能会有漏洞(进程锁可解决，但太麻烦了，尽量多进程内的逻辑简单) 但进程逻辑也不能太简单，否则开销比多线程还要大，任务过于简单不如使用单核多线程了 ","date":"2023-08-12","objectID":"/20230812/:3:0","tags":["机器学习","深度学习","jupyter","Python"],"title":"Python加速科学运算的一些小技巧","uri":"/20230812/"},{"categories":["机器学习","Python"],"content":"GPU上少用控制语句 GPU的同步开销过大，支持很有限，GPU跑通用计算强但控制流不强 ","date":"2023-08-12","objectID":"/20230812/:4:0","tags":["机器学习","深度学习","jupyter","Python"],"title":"Python加速科学运算的一些小技巧","uri":"/20230812/"},{"categories":["机器学习","Python"],"content":"GPU上尽量保持内存本地性 GPU的三级缓存很小 ","date":"2023-08-12","objectID":"/20230812/:5:0","tags":["机器学习","深度学习","jupyter","Python"],"title":"Python加速科学运算的一些小技巧","uri":"/20230812/"},{"categories":["机器学习","Python"],"content":"GPU上尽量使用并行 使用数千个线程(类同CPU) ","date":"2023-08-12","objectID":"/20230812/:6:0","tags":["机器学习","深度学习","jupyter","Python"],"title":"Python加速科学运算的一些小技巧","uri":"/20230812/"},{"categories":["机器学习","Python"],"content":"GPU和CPU不要频繁互传数据 带宽限制，同步开销，都不好频繁传数据 ","date":"2023-08-12","objectID":"/20230812/:7:0","tags":["机器学习","深度学习","jupyter","Python"],"title":"Python加速科学运算的一些小技巧","uri":"/20230812/"},{"categories":["机器学习","Python"],"content":"前言 老板下指示复现两篇文章，这是其中一篇 https://arxiv.org/pdf/1810.10659.pdf 文章的原理什么的已经大致明白了但仍然有小部分不懂，故而做下记录，以备后续复现或深入了解 ","date":"2023-08-08","objectID":"/20230808/:1:0","tags":["机器学习","深度学习","jupyter","dgl","pytorch","conda","Python","GCN","Gurobi","CNF","GR","LS"],"title":"通过GCN生成概率图引导树搜索解决图的组合优化问题","uri":"/20230808/"},{"categories":["机器学习","Python"],"content":"原始数据 ","date":"2023-08-08","objectID":"/20230808/:2:0","tags":["机器学习","深度学习","jupyter","dgl","pytorch","conda","Python","GCN","Gurobi","CNF","GR","LS"],"title":"通过GCN生成概率图引导树搜索解决图的组合优化问题","uri":"/20230808/"},{"categories":["机器学习","Python"],"content":"Training Data https://www.cs.ubc.ca/~hoos/SATLIB/benchm.html ","date":"2023-08-08","objectID":"/20230808/:2:1","tags":["机器学习","深度学习","jupyter","dgl","pytorch","conda","Python","GCN","Gurobi","CNF","GR","LS"],"title":"通过GCN生成概率图引导树搜索解决图的组合优化问题","uri":"/20230808/"},{"categories":["机器学习","Python"],"content":"Testing Data SAT Competition 2017 https://helda.helsinki.fi/bitstream/handle/10138/224324/sc2017-proceedings.pdf BUAA-MC https://www.sciencedirect.com/science/article/pii/S0004370207000653 SNAP Social Networks http://snap.stanford.edu/data/#socnets Citation networks https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/2157 ","date":"2023-08-08","objectID":"/20230808/:2:2","tags":["机器学习","深度学习","jupyter","dgl","pytorch","conda","Python","GCN","Gurobi","CNF","GR","LS"],"title":"通过GCN生成概率图引导树搜索解决图的组合优化问题","uri":"/20230808/"},{"categories":["机器学习","Python"],"content":"相关Github仓库 原作者仓库的脚本年久失修且数据需要自己生成，但作者又没给生成方式，只给了一个mat文件，仓库issues有不少对此的疑问 https://github.com/isl-org/NPHard 另一位瑞士博士将原作者的代码修复后，又使用了dgl库进行优化，不用自己写基础代码构建了，同时还给出了原始数据如何标记的代码和生成的一些随机图实例，可以说是拿到就能跑了，这些在第二个仓库中都有 https://github.com/MaxiBoether/mis-benchmark-framework 但暂时由于第二个仓库作者的数据集的链接失效无法跑通，已发issue询问，已经和他联系上了，待他有空补一下数据集就能跑通了 ","date":"2023-08-08","objectID":"/20230808/:3:0","tags":["机器学习","深度学习","jupyter","dgl","pytorch","conda","Python","GCN","Gurobi","CNF","GR","LS"],"title":"通过GCN生成概率图引导树搜索解决图的组合优化问题","uri":"/20230808/"},{"categories":["机器学习","Python"],"content":"大体思路 分了几步走，我精简的总结一下 ","date":"2023-08-08","objectID":"/20230808/:4:0","tags":["机器学习","深度学习","jupyter","dgl","pytorch","conda","Python","GCN","Gurobi","CNF","GR","LS"],"title":"通过GCN生成概率图引导树搜索解决图的组合优化问题","uri":"/20230808/"},{"categories":["机器学习","Python"],"content":"一、根据最基础的GCN结构，做了以下的改进 输入层不变，激活函数是ReLU 在隐藏层加入drop out在激活函数前，激活函数是ReLU 输出层不变，激活函数是sigmod 二元交叉熵损失函数输出值不舍入为0或1，保持为[0, 1]上的值 层数作者实验过了，最好的层数是20层，输入层大小32，隐藏层大小都是32，输出层大小也是32 由于数据集 SATLIB 包含合成的 SAT 实例，知道其真实的指派情况。通过切换子句中的自由变量的开启和关闭，可以生成相应图的多个标记。 (上面这句话就看不懂了，生成标记卡住我了，原始的数据是一堆.cnf文件，第二个仓库作者用的Gurobi生成的标记，准备按第二个仓库作者的思路来) 使用Adam进行单图小批量训练，并使用学习率 10−4，训练进行200个epochs。 ","date":"2023-08-08","objectID":"/20230808/:4:1","tags":["机器学习","深度学习","jupyter","dgl","pytorch","conda","Python","GCN","Gurobi","CNF","GR","LS"],"title":"通过GCN生成概率图引导树搜索解决图的组合优化问题","uri":"/20230808/"},{"categories":["机器学习","Python"],"content":"二、为了生成多个概率图但又保持准确性和多样性，做了以下改进 为了使网络能够区分不同的模式，扩展了函数 \\(f\\) 的结构以生成多个概率图。给定输入图 \\(G\\)，改进后的网络 \\(f\\) 生成 \\(M\\) 个概率图： \\[ f_1(G_i; \\theta), \\ldots, f_M(G_i; \\theta) \\] 为了训练 \\(f\\) 生成多样且高质量的概率图，采用了反思损失： \\[ L(D, \\theta) = \\sum_i \\min_m \\ell(l_i, f_m(G_i; \\theta)) \\] 其中，\\(\\ell(\\cdot, \\cdot)\\) 是在公式 (2) 中定义的二元交叉熵损失函数。 大白话就是对于每个样本，计算 M 个概率图中的每个图与实际标签之间的损失，然后选择其中最小的损失作为训练损失。这样设计促使网络在生成多个概率图时，更加青睐于与实际标签最为接近的概率图，从而提高了生成结果的质量和多样性。 ","date":"2023-08-08","objectID":"/20230808/:4:2","tags":["机器学习","深度学习","jupyter","dgl","pytorch","conda","Python","GCN","Gurobi","CNF","GR","LS"],"title":"通过GCN生成概率图引导树搜索解决图的组合优化问题","uri":"/20230808/"},{"categories":["机器学习","Python"],"content":"三、树搜索算法改进概率图的选择，尽可能快速的遍历到所有可能的解，做了以下操作 维护一个不完整解决方案的队列， 并在每一步中随机选择一个进行扩展。 当扩展一个不完整的解决方案时， 使用原有的M个概率图生成M个新的更完整的解决方案，并将它们加入到队列后面。 这有点类似于广度优先搜索(BSF)，而不是深度优先搜索(DSF)。因为如果以深度优先的方式扩展树，解决方案的多样性将会受到影响，因为它们的大多数原始的解决方案是相同的。通过以广度优先的方式扩展树，可以获得更高的多样性。 扩展后的树节点被保留在一个队列中，并且每次迭代中随机选择一个节点进行扩展。 ( 这块作者说是使用了多线程，个人感觉上还能再进一步使用 多进程+多线程，但感觉进程之间的通信可能会影响解决的速度，得有阻塞的选择最优解，很麻烦且开销大，可能这就是没使用该方法的原因吧 ) ","date":"2023-08-08","objectID":"/20230808/:4:3","tags":["机器学习","深度学习","jupyter","dgl","pytorch","conda","Python","GCN","Gurobi","CNF","GR","LS"],"title":"通过GCN生成概率图引导树搜索解决图的组合优化问题","uri":"/20230808/"},{"categories":["机器学习","Python"],"content":"四、用了局部搜索和图缩减技术进一步优化算法 老实说这一步我没看太懂，因为作者说的很简洁，有空我再补补对应的知识，暂时先就文章字面的描述总结和翻译一下。 局部搜索(LS) 通过简单地插入、删除和交换节点，在局部范围内修改解决方案，以使解决方案的质量只能提高。 使用这种方法来优化树搜索产生的候选解 https://pubsonline.informs.org/doi/abs/10.1287/opre.42.5.860 对于局部搜索，采用了一种2-改进局部搜索算法。 https://dl.acm.org/doi/10.1145/3447548.3467232 该算法遍历图中的所有顶点，并尝试将一个标记为1的顶点vi替换为两个标记为1的顶点vj和vk。在最大独立集（MIS）中，vj和vk必须是vi的邻居，并且1-紧密而且彼此不邻接。这里，如果一个顶点的邻居中只有一个被标记为1，我们称该顶点为1-紧密。换句话说，在图中vj和vk的唯一一个标记为1的邻居是vi。 通过使用一种数据结构，使得插入和删除节点的时间与它们的度成正比，这个局部搜索算法可以在O(E)的时间内找到一个有效的2-改进（如果存在）。该算法的一种更快的增量版本维护了一个包含参与2-改进的候选节点的列表。它确保只有当节点的邻居发生了某些变化时才会反复检查一个节点。 图缩减(GR) 还有一些图缩减技术可以快速将图缩减为一个更小的图，同时保持最优独立集的大小不变。 通过仅将f应用于图的「复杂」部分来加速计算。 https://arxiv.org/abs/1411.2680 https://arxiv.org/abs/1509.00764 ","date":"2023-08-08","objectID":"/20230808/:4:4","tags":["机器学习","深度学习","jupyter","dgl","pytorch","conda","Python","GCN","Gurobi","CNF","GR","LS"],"title":"通过GCN生成概率图引导树搜索解决图的组合优化问题","uri":"/20230808/"},{"categories":["机器学习","Python"],"content":"实验比较 最后测试了四个经典的NP-hard问题：可满足性（SAT）、最大独立集（MIS）、最小顶点覆盖（MVC）和最大团（MC）。 (其他三种问题都可转换为MIS问题解决) 结果表明，与基于强化学习的方法相比，该方法在SATLIB基准测试中解决了所有问题，而强化学习方法没有解决任何问题。 此外，该方法在性能上与基于传统启发式方法的高度优化的求解器相当或更好。 ","date":"2023-08-08","objectID":"/20230808/:5:0","tags":["机器学习","深度学习","jupyter","dgl","pytorch","conda","Python","GCN","Gurobi","CNF","GR","LS"],"title":"通过GCN生成概率图引导树搜索解决图的组合优化问题","uri":"/20230808/"},{"categories":["机器学习","Python"],"content":"后言 总体读下来感觉自己对离散数学的图论部分基础不够扎实，看后面的树优化吃力 关于GCN的部分还是很好理解的，图嵌入树部分也还行，但到后面树优化部分就开始抓瞎了 看了项目仓库是conda的env做环境的约束，但我想我以后做的项目最好还是打包成docker镜像比较好，环境以及依赖版本的约束更有效一些 conda的依赖导出的yml文件好多都是没版本号的，属实坑后来者复现，docker的话一般导出都有版本号约束，几乎不需要改什么依赖就能跑了 这里其实还缺少了两个模型评价部分互相比较的别的模型，这些东西由于两篇文章都有点关系，所以准备整合到一起总结，不单独每篇文章都拉出来说一遍了。 ","date":"2023-08-08","objectID":"/20230808/:6:0","tags":["机器学习","深度学习","jupyter","dgl","pytorch","conda","Python","GCN","Gurobi","CNF","GR","LS"],"title":"通过GCN生成概率图引导树搜索解决图的组合优化问题","uri":"/20230808/"},{"categories":["机器学习","Python"],"content":"由于之前有写过一键安装jupyter的shell脚本，所以这里只需要找一个服务器就够了 https://github.com/spiritLHLS/one-click-installation-script#%E4%B8%80%E9%94%AE%E5%AE%89%E8%A3%85jupyter%E7%8E%AF%E5%A2%83 curl -L https://raw.githubusercontent.com/spiritLHLS/one-click-installation-script/main/install_scripts/jupyter.sh -o jupyter.sh \u0026\u0026 chmod +x jupyter.sh \u0026\u0026 bash jupyter.sh 又由于之前玩Linux积攒了很多机器，找了一台腾讯云广州的4C3C80G和OVH法国的4C2C25G的机器测试了一下 发现d2l的安装包所需内存比较大，起步需要至少4G内存才保险，所以这里又分别给各机器开了4G(输入1后输入4096)的SWAP curl -L https://raw.githubusercontent.com/spiritLHLS/addswap/main/addswap.sh -o addswap.sh \u0026\u0026 chmod +x addswap.sh \u0026\u0026 bash addswap.sh 开完SWAP后一键安装完毕jupyter，需要配置相关环境(暂时我只使用CPU计算) 装pytorch的时候，可能solve environment这一步可能需要转圈圈跑大概15~20分钟，因为要处理依赖问题，装d2l也大概需要10分钟左右，至于安装过程很快的(网络带宽足够大的话) conda install -c conda-forge nodejs conda install -c conda-forge jupyterlab_rise conda install pytorch==1.12.0 torchvision==0.13.0 torchaudio==0.12.0 cpuonly -c pytorch conda install -c conda-forge d2l conda install matplotlib-inline 不用cpu的可在 https://pytorch.org/ 中查看对应平台的安装命令 比如对应 https://zh.d2l.ai/chapter_installation/index.html#d2l 的是 https://pytorch.org/get-started/previous-versions/#v1120 由于执行官方安装程序可能会缺失matplotlib-inline包，如 # 执行 %matplotlib inline import torch from torch.distributions import multinomial from d2l import torch as d2l # 报错说 # --------------------------------------------------------------------------- # ModuleNotFoundError Traceback (most recent call last) # \u003cipython-input-3-8a74a3716418\u003e in \u003cmodule\u003e # 2 import torch # 3 from torch.distributions import multinomial # ----\u003e 4 from d2l import torch as d2l # ~/miniconda3/envs/jupyter-env/lib/python3.8/site-packages/d2l/torch.py in \u003cmodule\u003e # 34 from IPython import display # 35 from matplotlib import pyplot as plt # ---\u003e 36 from matplotlib_inline import backend_inline # 37 # 38 d2l = sys.modules[__name__] # ModuleNotFoundError: No module named 'matplotlib_inline' 所以安装过程中需要执行conda install matplotlib-inline 如果运行过程中缺什么包的话查找 https://anaconda.org/ 可得安装命令 系统模板还得是ubuntu20用的顺手，因为腾讯云的debian11和ubuntu22老有网络问题，懒得去搞镜像或者CDN加速了，都是国情因素导致的，带宽又小又容易被阻断，因为法国的测试都是没问题的，带宽大下东西就是爽，所以懒得管啦，还是用国外服务器得了 mkdir d2l-zh \u0026\u0026 cd d2l-zh curl https://zh-v2.d2l.ai/d2l-zh-2.0.0.zip -o d2l-zh.zip unzip d2l-zh.zip \u0026\u0026 rm d2l-zh.zip cd pytorch 相关的jupyternotebook的文件压缩包如上，实测还得是下到本地才传得上腾讯云，当然OVH的直接用没问题，原因大概是国情因素导致的TLS阻断，源站属于Github的pages服务搭建的所以被阻断了，又加上国内带宽口子贼小，还是算了吧，最终用法国的服务器好点，口子大还没各种网络问题 ","date":"2023-07-27","objectID":"/20230727/:0:0","tags":["机器学习","深度学习","jupyter","jupyterlab","d2l","conda","Python"],"title":"深度学习环境安装(李沐老师相关)","uri":"/20230727/"},{"categories":["机器学习"],"content":"一、命题逻辑与真值函数 命题逻辑：（又称命题演算、布尔逻辑）是最简单的一种形式逻辑系统。 主要研究对象：命题（常用p,q,r…代表任意命题即命题变元）每个命题可能为真，也可能为假（通常用1/0或T/F或T/⊥表示）。 真值函数：在真假值集合上定义一些运算函数，一个n元真值函数是从{0,1}^n到{0,1}的映射。 连接符/词（connectives）：真值函数的名字 常见真值函数：“与”（合取，^），“或”（析取，V），“非”（否定，﹁），“蕴涵”（记为‘→’），“等价”（记为‘↔’），“异或”（记为‘⊕’） 注意，这些连接词描述的是命题之间的逻辑关系，而不是因果关系。它们通过对命题的真值进行组合来构建复合命题。因果关系通常涉及事件或因果链的因果联系，而在命题逻辑中，只关注命题的真值。 例如，在“蕴涵”（→）中，如果P蕴涵Q为真，这并不意味着P是Q的因果条件，而只表示在P为真的情况下，Q也为真。“等价”只表示二者具有相同的真值，不关心具体真值。“异或”表示了“排他性或互斥”的关系。当且仅当两个命题中有一个为真时，异或的结果为真；如果两个命题都为真或都为假，异或的结果为假。 当命题变元的个数n\u003e2时，使用真值表（truth table）进行运算处理；当命题变元的个数为n时，真值表一般有2^n行；真值表左边是变元的各种可能取值，右边是运算结果。 命题逻辑公式：命题变元和连接符在一定规则下形成命题逻辑公式。 命题变元是命题逻辑公式（原子公式） 若ȹ是公式，则﹁ȹ也是公式 若ȹ1和ȹ2是公式，则（ȹ1*ȹ2）也是公式 只由上面三条规则生成的表达式是命题逻辑公式 (此处‘*’是指任意二元连接符) 连接符的优先级问题：﹁ \u003e (^或V) \u003e (→或↔) ","date":"2023-07-18","objectID":"/20230714/:1:0","tags":["机器学习","深度学习","组合优化"],"title":"命题逻辑","uri":"/20230714/"},{"categories":["机器学习"],"content":"二、命题逻辑相关定义梳理总结 真值赋值（truth assignment）：从命题变元集合到真假值集合的函数叫真值赋值，简称赋值，又叫解释。如果这个函数没有完全定义，则其被称为部分赋值。 如果有一个赋值使公式ȹ的值为1，那么命题逻辑公式ȹ是可满足的.使它得到这个满足的赋值就是ȹ的一个模型(model)。 重言式（tautology）：如果对于任何赋值，公式ȹ的值都为1，又称为永真公式。 等值定义：如果对于任何赋值，公式ȹ1和ȹ2都具有相同的真假值，那么称这两个公式为等值，记为ȹ1=ȹ2. 运算定义：满足代数运算的交换律、结合律和分配律以及特殊的德摩根律 德摩根律： ﹁(P^Q)↔(﹁P)V(﹁Q) ﹁(PVQ)↔(﹁P)^(﹁Q) 6.完备性定义：连接符集合M是完备的，任何n元连接符都能由M中的连接符定义（n为正整数）。 常见完备集：{﹁,V},{﹁,^},{﹁,→}和{﹁,V,^}。 7.称原子公式或其否定为文字（literal），原子公式本身为正文字，而原子公式的否定为负文字。若干个文字的析取构成子句（clause），其长度是所含文字的个数；只有一个文字的子句称为单子句（unit clause）,没有文字的子句称为空子句（empty clause）。 子句的可满足性：一般来说，文字越多，子句越易满足；极端情形而言，空子句不可满足。 8.互补的定义：原子公式p与其否定﹁p互补，又称p的补为﹁p。 9.合取范式与析取范式： 合取范式（conjunctive normal form,简写CNF）,其一般形式：F = c1∧c2∧...∧cm，这里的c是若干文字的析取。 析取范式（disjunctive normal form,简写DNF），其一般形式为：F = c1Vc2V...Vcm，这里的c是若干文字的合取。 定理：对任意公式，都有与之等值的合取范式和析取范式。 ","date":"2023-07-18","objectID":"/20230714/:2:0","tags":["机器学习","深度学习","组合优化"],"title":"命题逻辑","uri":"/20230714/"},{"categories":["机器学习"],"content":"可满足性问题（SAT） 可满足性(SAT)：考虑一个由布尔变量、括号和以下运算符构成的布尔表达式： AND（连接）、OR（析取）和 NOT（否定）。在这里，布尔表达式是分句的连接，分句是字面的析取。字面是布尔变量或其否定。问题是找到所有变量的布尔标签，使给定表达式为真，或者确定不存在这样的标签赋值。 也可以这么描述：对于一个确定的逻辑，是否存在一种输入使得输出为真。 可满足性（英语：Satisfiability）是用来解决给定的真值方程式，是否存在一组变量赋值，使问题为可满足。布尔可满足性问题（Boolean satisfiability problem；SAT ）属于决定性问题，也是第一个被证明属于NP完全的问题。 ","date":"2023-07-18","objectID":"/20230714/:3:0","tags":["机器学习","深度学习","组合优化"],"title":"命题逻辑","uri":"/20230714/"},{"categories":["机器学习"],"content":"最大独立集问题（MIS） 最大独立集(MIS)：给定一个无向图，找出其中没有两条边相连的最大顶点子集。 独立集（英语：Independent set）是图论中的概念。一个独立集（也称为稳定集）是一个图中一些两两不相邻的顶点所形成的集合。 ","date":"2023-07-18","objectID":"/20230714/:4:0","tags":["机器学习","深度学习","组合优化"],"title":"命题逻辑","uri":"/20230714/"},{"categories":["机器学习"],"content":"最小顶点覆盖问题（MVC） 最小顶点覆盖(MVC)：给定一个无向图，找出最小的顶点子集，使得图中的每条边都至少与所选集合中的一个顶点相连。 ","date":"2023-07-18","objectID":"/20230714/:5:0","tags":["机器学习","深度学习","组合优化"],"title":"命题逻辑","uri":"/20230714/"},{"categories":["机器学习"],"content":"最大团问题（MC） 最大团(MC)：给定一个无向图，找出形成一个小群的最大顶点子集。 最大团、最大独立集和最小顶点覆盖这三个组合优化问题在理论上是等价的。 ","date":"2023-07-18","objectID":"/20230714/:6:0","tags":["机器学习","深度学习","组合优化"],"title":"命题逻辑","uri":"/20230714/"},{"categories":["机器学习"],"content":"特别的，MVC、MC 和 SAT 问题都可以表示为 MIS 问题的实例 MVC（最小顶点覆盖）和 MIS（最大独立集）互补关系： 给定一个图，MVC 是指在图中选择尽可能少的顶点，使得每条边都至少与其中一个选定的顶点相邻。而 MIS 是指在图中选择尽可能多的顶点，使得这些顶点之间没有直接相连的边。上述引用提到，MVC 和 MIS 是互补的，意味着一个图的最小顶点覆盖与其最大独立集的补集相等。换句话说，一个顶点集合是独立集，当且仅当它的补集是顶点覆盖。 MC（最大团）和 MIS（最大独立集）的关系： 最大团是图中的一个完全子图（即子图中的任意两个顶点都相邻），且无法再添加其他顶点使其依然保持完全子图的性质。与之对应的是最大独立集，它是图中顶点的一个集合，其中任意两个顶点都不相邻。引用中提到，最大团与其补图的最大独立集是一致的，也就是说一个图的最大团等于其补图的最大独立集。 SAT（布尔可满足性问题）和 MIS（最大独立集）的关系： SAT 是一个经典的计算机科学问题，它涉及布尔逻辑中的命题和变量，判断是否存在一组变量的赋值使得整个布尔表达式为真。引用中描述了如何将 SAT 实例转换为图的形式：每个子句中的文字（变量或其否定形式）在图中对应一个顶点，同一个子句中的文字相邻（有边相连），而在不同子句中的文字之间也有边相连（表示它们不能同时为真）。然后，如果能找到一个与子句数目相等的最大独立集，就意味着找到了使得整个 SAT 公式为真的变量赋值，这也就是 SAT 实例的解。这是因为在最大独立集中，图中的每个顶点都不相邻，而在 SAT 图中，不相邻的顶点对应于可以同时为真的文字。 总结：图论中的顶点覆盖、最大独立集、最大团可与 SAT（布尔可满足性问题）联系起来，它们在某些条件下可以互相转化。 ","date":"2023-07-18","objectID":"/20230714/:6:1","tags":["机器学习","深度学习","组合优化"],"title":"命题逻辑","uri":"/20230714/"},{"categories":["电脑技巧"],"content":"要通过WiFi共享D盘给其他电脑，可以使用以下方法： 1.创建共享文件夹：首先，需要在D盘上创建一个共享文件夹。右键单击D盘上的文件夹，选择\"属性\"，然后切换到\"共享\"选项卡。点击\"高级共享\"，勾选\"共享此文件夹\"选项，并为文件夹指定一个共享名称。(或者直接就右键D盘，打开属性) 2.配置共享权限：在共享选项卡中，可以设置共享文件夹的权限。点击\"权限\"按钮，然后添加允许访问该共享文件夹的用户或用户组。 3.确保电脑连接到同一个WiFi网络：要与其他电脑进行共享，需要确保所有电脑都连接到同一个WiFi网络。 4.访问共享文件夹：在其他电脑上，打开文件资源管理器，然后在地址栏输入\"\u003c共享计算机的名称\u003e\"，其中\"\u003c共享计算机的名称\u003e“是拥有D盘共享文件夹的计算机的名称。按回车键后，应该会显示共享文件夹。(或者在地址栏中输入”\u003c共享计算机的IP地址\u003e\"，其中\"\u003c共享计算机的IP地址\u003e“是拥有共享文件夹的计算机的IP地址。可以在拥有共享文件夹的计算机上打开命令提示符，然后输入\"ipconfig\"来查找IP地址。) 5.输入用户名和密码：如果您在共享设置中设置了访问权限，系统可能会提示您输入用户名和密码。请提供具有访问权限的用户名和密码，以便访问共享文件夹。(一般就是你电脑开机要用的那个密码，或者说你远程连接本地计算机要的那个密码，用户名则是登录本机的用户名，或者可在 控制面板 –\u003e 用户账户 –\u003e 凭据管理器 查看用户名) 6.一旦成功访问了共享文件夹，就可以在其他电脑上浏览和使用D盘上的文件了。 实际上可以使用网线，将两台电脑都接到同一个路由器上，这样会更快，无线的话可能会慢一点。 ","date":"2023-06-11","objectID":"/20230611/:0:0","tags":["windows"],"title":"共享D盘给同一局域网下的其他电脑(WiFi)","uri":"/20230611/"},{"categories":["电脑技巧"],"content":"PVE 感谢 Proxmox VE 的免费订阅支持 原始仓库：https://github.com/spiritLHLS/pve 说明文档 国内(China)： virt.spiritlhl.net 国际(Global)： www.spiritlhl.net 说明文档中 Proxmox VE 分区内容 https://github.com/oneclickvirt/kvm_images 为对应虚拟机镜像仓库 ","date":"2023-05-06","objectID":"/20230506/:0:0","tags":["linux","pve","vps","kvm","virtual","qemu","nat","iptables","shell","debian"],"title":"一键安装PVE并一键开设KVM虚拟化的NAT服务器-带内外网端口转发","uri":"/20230506/"},{"categories":["电脑技巧"],"content":"前言 国内服务器请使用国内命令，国际服务器请使用国际命令 请确保使用前机器可以重装系统，不保证本套脚本不造成任何BUG!!! 如果服务器是VPS而不是独服，可能会出现各种各样的BUG，请做好部署失败重装服务器的准备!!! 待开发内容: 文档以及脚本输出修改支持双语 创建带IPV6独立地址的VM虚拟机或CT容器 目录 系统要求与配置 各种要求 检测硬件环境 PVE基础安装说明 一键安装PVE 预配置环境 自动配置IPV4的NAT网关 一键生成KVM虚拟化的NAT服务器 单独生成KVM虚拟化的VM 单个生成的使用方法 示例 删除示例 相关qcow2镜像 批量开设NAT的KVM虚拟化的VM 使用方法 删除所有虚拟机 注意事项 一键生成单个CT也就是LXC虚拟化的NAT容器 如何使用 CT示例 删除所有CT 批量开设NAT的LXC虚拟化的CT容器 一键命令 致谢 ","date":"2023-05-06","objectID":"/20230506/:0:1","tags":["linux","pve","vps","kvm","virtual","qemu","nat","iptables","shell","debian"],"title":"一键安装PVE并一键开设KVM虚拟化的NAT服务器-带内外网端口转发","uri":"/20230506/"},{"categories":["电脑技巧"],"content":"系统要求与配置 各种要求 建议debian在使用前尽量使用最新的系统 非debian11可使用 debian一键升级 来升级系统 当然不使用最新的debian系统也没问题，只不过得不到官方支持。只适配Debian系统(非Debian无法通过APT源安装，官方只给了Debian的镜像，其他系统只能使用ISO安装) 系统要求：Debian 8+ 最低的硬件要求：2核2G内存x86_64架构服务器硬盘至少20G 可开KVM的硬件要求：VM-X或AMD-V支持-(部分VPS和全部独服支持) 如果硬件需求不满足，可使用LXD批量开LXC的跳转 遇到选项不会选的可无脑回车安装，所有脚本内置国内外IP自动判断，使用的是不同的安装源与配置文件，有使用CDN加速镜像下载 检测硬件环境 本仓库脚本执行前务必执行本脚本检测环境，如果不符合安装PVE的要求则无法使用后续的脚本 检测硬件配置是否满足最低要求 检测硬件环境是否可嵌套虚拟化KVM类型的服务器 检测系统环境是否可嵌套虚拟化KVM类型的服务器 不可嵌套虚拟化KVM类型的服务器也可以开LXC虚拟化的服务器 bash \u003c(wget -qO- --no-check-certificate https://raw.githubusercontent.com/spiritLHLS/pve/main/scripts/check_kernal.sh) 国内： bash \u003c(wget -qO- --no-check-certificate https://ghproxy.com/https://raw.githubusercontent.com/spiritLHLS/pve/main/scripts/check_kernal.sh) PVE基础安装说明 安装的是当下apt源最新的PVE 比如debian10则是pve6.4，debian11则是pve7.x /etc/hosts文件修改(修正商家hostname设置错误以及新增PVE所需的内容) 已设置/etc/hosts为只读模式，避免重启后文件被覆写，如需修改请使用chattr -i /etc/hosts取消只读锁定，修改完毕请执行chattr +i /etc/hosts只读锁定 检测是否为中国IP，如果为中国IP使用清华镜像源，否则使用官方源 安装PVE开虚拟机需要的必备工具包 替换apt源中的企业订阅为社区源 打印查询Linux系统内核和PVE内核是否已安装 查询网络配置是否为dhcp配置的V4网络，如果是则转换为静态地址避免重启后dhcp失效，已设置为只读模式，如需修改请使用chattr -i /etc/network/interfaces.d/50-cloud-init取消只读锁定，修改完毕请执行chattr +i /etc/network/interfaces.d/50-cloud-init只读锁定 检测/etc/resolv.conf是否为空，为空则设置检测8.8.8.8的开机自启添加DNS的systemd服务 新增PVE的APT源链接后，下载PVE并打印输出登陆信息 配置完毕需要重启系统加载新内核 一键安装PVE curl -L https://raw.githubusercontent.com/spiritLHLS/pve/main/scripts/install_pve.sh -o install_pve.sh \u0026\u0026 chmod +x install_pve.sh \u0026\u0026 bash install_pve.sh 国内： curl -L https://ghproxy.com/https://raw.githubusercontent.com/spiritLHLS/pve/main/scripts/install_pve.sh -o install_pve.sh \u0026\u0026 chmod +x install_pve.sh \u0026\u0026 bash install_pve.sh 安装过程中可能会退出安装，需要手动修复apt源，如下图所示修复完毕后再次执行本脚本 ","date":"2023-05-06","objectID":"/20230506/:0:2","tags":["linux","pve","vps","kvm","virtual","qemu","nat","iptables","shell","debian"],"title":"一键安装PVE并一键开设KVM虚拟化的NAT服务器-带内外网端口转发","uri":"/20230506/"},{"categories":["电脑技巧"],"content":"预配置环境 创建资源池mypool 移除订阅弹窗 尝试开启硬件直通 检测AppArmor模块并试图安装 bash \u003c(wget -qO- --no-check-certificate https://raw.githubusercontent.com/spiritLHLS/pve/main/scripts/build_backend.sh) 国内 bash \u003c(wget -qO- --no-check-certificate https://ghproxy.com/https://raw.githubusercontent.com/spiritLHLS/pve/main/scripts/build_backend.sh) ","date":"2023-05-06","objectID":"/20230506/:0:3","tags":["linux","pve","vps","kvm","virtual","qemu","nat","iptables","shell","debian"],"title":"一键安装PVE并一键开设KVM虚拟化的NAT服务器-带内外网端口转发","uri":"/20230506/"},{"categories":["电脑技巧"],"content":"自动配置IPV4的NAT网关 使用前请保证重启过服务器且此时PVE能正常使用WEB端再执行，重启机器后不要立即执行此命令，至少等几分钟待WEB端启动成功后再执行 这一步是最容易造成SSH断开的，原因是未等待PVE内核启动就修改网络会造成设置冲突，所以至少等几分钟待内核启动也就是WEB端启动成功后再执行 创建vmbr0，母鸡允许addr和gateway为内网IP或外网IP，已自动识别，测试腾讯云可用 创建vmbr1(NAT网关) 开NAT虚拟机时网关（IPV4）使用172.16.1.1，IPV4/CIDR使用172.16.1.x/24，这里的x不能是1，当然如果后续使用本套脚本无需关注这点细枝末节的东西 想查看完整设置可以执行cat /etc/network/interfaces查看 加载iptables并设置回源且允许NAT端口转发 bash \u003c(wget -qO- --no-check-certificate https://raw.githubusercontent.com/spiritLHLS/pve/main/scripts/build_nat_network.sh) 国内 bash \u003c(wget -qO- --no-check-certificate https://ghproxy.com/https://raw.githubusercontent.com/spiritLHLS/pve/main/scripts/build_nat_network.sh) ","date":"2023-05-06","objectID":"/20230506/:0:4","tags":["linux","pve","vps","kvm","virtual","qemu","nat","iptables","shell","debian"],"title":"一键安装PVE并一键开设KVM虚拟化的NAT服务器-带内外网端口转发","uri":"/20230506/"},{"categories":["电脑技巧"],"content":"一键生成KVM虚拟化的NAT服务器 使用前记得执行本仓库的第一个个命令，那个检测硬件环境的命令，展示如下 查询如上的只需使用下面的一键脚本自动创建虚拟机即可，无需手动再修改WEB端设置 查询如上的在使用后续脚本创建了虚拟机后，需要手动修改WEB端设置，需要关闭对应每个虚拟机的硬件嵌套虚拟化，如下图 先停止虚拟机再修改，修改完后再开机才能使用NOVNC，不关闭可能导致这个虚拟机有BUG无法使用，如果强行安装PVE开KVM，启动不了的也可以关闭这个虚拟化试试能不能启动虚拟机 ","date":"2023-05-06","objectID":"/20230506/:1:0","tags":["linux","pve","vps","kvm","virtual","qemu","nat","iptables","shell","debian"],"title":"一键安装PVE并一键开设KVM虚拟化的NAT服务器-带内外网端口转发","uri":"/20230506/"},{"categories":["电脑技巧"],"content":"单独生成KVM虚拟化的VM 自动开设NAT服务器，默认使用Debian10镜像，因为该镜像占用最小 可在命令中自定义需要使用的镜像，这里有给出配置好的镜像，镜像自带空间是2G硬盘，所以最少需要在命令中设置硬盘到3G 自定义内存大小推荐512MB内存，需要注意的是母鸡内存记得开点swap免得机器炸了开SWAP点我跳转 自动进行内外网端口映射，含22，80，443端口以及其他25个内外网端口号一样的端口 生成后需要等待一段时间虚拟机内部的cloudinit配置好网络以及登陆信息，大概需要5分钟 curl -L https://raw.githubusercontent.com/spiritLHLS/pve/main/scripts/buildvm.sh -o buildvm.sh \u0026\u0026 chmod +x buildvm.sh 国内 curl -L https://ghproxy.com/https://raw.githubusercontent.com/spiritLHLS/pve/main/scripts/buildvm.sh -o buildvm.sh \u0026\u0026 chmod +x buildvm.sh 单个生成的使用方法 系统支持：详见 跳转 中列出的系统，使用时只需写文件名字，不需要.qcow2尾缀 注意这里的用户名不能是纯数字，会造成cloudinit出问题，最好是纯英文或英文开头 ./buildvm.sh VMID 用户名 密码 CPU核数 内存 硬盘 SSH端口 80端口 443端口 外网端口起 外网端口止 系统 示例 测试开一个NAT服务器 以下示例开设VMID为102的虚拟机，用户名是test1，密码是1234567，CPU是1核，内存是512MB，硬盘是5G，SSH端口是40001，80端口是40002，443端口是40003 同时内外网映射端口一致的区间是50000到50025，系统使用的是ubuntu20 ./buildvm.sh 102 test1 1234567 1 512 5 40001 40002 40003 50000 50025 ubuntu20 开设完毕可执行 cat vm102 查看信息 删除示例 删除端口映射，删除测试的虚拟机和log文件 qm stop 102 qm destroy 102 iptables -t nat -F iptables -t filter -F service networking restart systemctl restart networking.service rm -rf vm102 相关qcow2镜像 已预安装开启cloudinit，开启SSH登陆，预设值SSH监听V4和V6的22端口，开启允许密码验证登陆，开启允许ROOT登陆 https://github.com/spiritLHLS/Images/releases/tag/v1.0 ","date":"2023-05-06","objectID":"/20230506/:1:1","tags":["linux","pve","vps","kvm","virtual","qemu","nat","iptables","shell","debian"],"title":"一键安装PVE并一键开设KVM虚拟化的NAT服务器-带内外网端口转发","uri":"/20230506/"},{"categories":["电脑技巧"],"content":"批量开设NAT的KVM虚拟化的VM 初次使用前需要保证当前PVE未有任何虚拟机未有进行任何端口映射，否则可能出现BUG 开设前请使用screen挂起执行，避免批量开设时间过长，SSH不稳定导致中间执行中断，推荐使用PVE自带的Shell操作母鸡 可多次运行批量生成VM，但需要注意的是母鸡内存记得开点swap免得机器炸了开SWAP点我跳转 自动开设NAT服务器，默认使用Debian10镜像，因为该镜像占用最小 自动进行内外网端口映射，含22，80，443端口以及其他25个内外网端口号一样的端口 生成后需要等待一段时间虚拟机内部的cloudinit配置好网络以及登陆信息，大概需要5分钟 默认批量开设的虚拟机网络配置为：22，80，443端口及一个25个端口区间的内外网映射 可自定义批量开设的核心数，内存大小，硬盘大小，记得自己计算好空闲资源开设 使用方法 curl -L https://raw.githubusercontent.com/spiritLHLS/pve/main/scripts/create_vm.sh -o create_vm.sh \u0026\u0026 chmod +x create_vm.sh \u0026\u0026 bash create_vm.sh 国内 curl -L https://ghproxy.com/https://raw.githubusercontent.com/spiritLHLS/pve/main/scripts/create_vm.sh -o create_vm.sh \u0026\u0026 chmod +x create_vm.sh \u0026\u0026 bash create_vm.sh 开设完毕可执行 cat vmlog 查看信息 删除所有虚拟机 删除所有nat的端口映射并重启网络，删除所有虚拟机和log文件 for vmid in $(qm list | awk '{if(NR\u003e1) print $1}'); do qm stop $vmid; qm destroy $vmid; rm -rf /var/lib/vz/images/$vmid*; done iptables -t nat -F iptables -t filter -F service networking restart systemctl restart networking.service rm -rf vmlog ","date":"2023-05-06","objectID":"/20230506/:1:2","tags":["linux","pve","vps","kvm","virtual","qemu","nat","iptables","shell","debian"],"title":"一键安装PVE并一键开设KVM虚拟化的NAT服务器-带内外网端口转发","uri":"/20230506/"},{"categories":["电脑技巧"],"content":"注意事项 PVE修改虚拟机配置前都得停机先，再修改配置，修改完再启动，免得出现配置重载错误 ","date":"2023-05-06","objectID":"/20230506/:1:3","tags":["linux","pve","vps","kvm","virtual","qemu","nat","iptables","shell","debian"],"title":"一键安装PVE并一键开设KVM虚拟化的NAT服务器-带内外网端口转发","uri":"/20230506/"},{"categories":["电脑技巧"],"content":"一键生成单个CT也就是LXC虚拟化的NAT容器 LXC虚拟化的容器-自带内外网映射 初次使用前需要保证当前PVE未有任何虚拟机未有进行任何端口映射，否则可能出现BUG 开设前请使用screen挂起执行，避免批量开设时间过长，SSH不稳定导致中间执行中断，推荐使用PVE自带的Shell操作母鸡 自动开设NAT服务器，默认使用Debian11镜像，也可自定义系统 自动进行内外网端口映射，含22，80，443端口以及其他25个内外网端口号一样的端口 生成后需要等待一段时间虚拟机内部配置好网络以及登陆信息，大概需要3分钟 默认开设的虚拟机网络配置为：22，80，443端口及一个25个端口区间的内外网映射 可自定义开设的核心数，内存大小，硬盘大小，记得自己计算好空闲资源开设 开设的CT默认已启用SSH且允许root登陆，且已设置支持使用docker的嵌套虚拟化 curl -L https://raw.githubusercontent.com/spiritLHLS/pve/main/scripts/buildct.sh -o buildct.sh \u0026\u0026 chmod +x buildct.sh 国内 curl -L https://ghproxy.com/https://raw.githubusercontent.com/spiritLHLS/pve/main/scripts/buildct.sh -o buildct.sh \u0026\u0026 chmod +x buildct.sh 如何使用 系统支持：debian10，debian11，ubuntu18，ubuntu20，ubuntu22 其他系统可能支持可能不支持，自行测试 默认用户名是root ./buildct.sh CTID 密码 CPU核数 内存 硬盘 SSH端口 80端口 443端口 外网端口起 外网端口止 系统 CT示例 测试开一个NAT的LXC虚拟化的容器 以下示例开设CTID为102的容器，用户名是root，密码是1234567，CPU是1核，内存是512MB，硬盘是5G，SSH端口是20001，80端口是20002，443端口是20003 同时内外网映射端口一致的区间是30000到30025，系统使用的是debian10 ./buildct.sh 102 1234567 1 512 5 20001 20002 20003 30000 30025 debian10 开设完毕可执行 cat ct102 查看信息 删除所有CT 以下命令将删除所有CT和所有的log文件，删除所有nat的端口映射并重启网络 pct list | awk 'NR\u003e1{print $1}' | xargs -I {} sh -c 'pct stop {}; pct destroy {}' rm -rf ct* iptables -t nat -F iptables -t filter -F service networking restart systemctl restart networking.service ","date":"2023-05-06","objectID":"/20230506/:2:0","tags":["linux","pve","vps","kvm","virtual","qemu","nat","iptables","shell","debian"],"title":"一键安装PVE并一键开设KVM虚拟化的NAT服务器-带内外网端口转发","uri":"/20230506/"},{"categories":["电脑技巧"],"content":"批量开设NAT的LXC虚拟化的CT容器 自带内外网映射 可重复运行继承配置 一键命令 初次使用前需要保证当前PVE未有任何CT容器未有进行任何端口映射，否则可能出现BUG 开设前请使用screen挂起执行，避免批量开设时间过长，SSH不稳定导致中间执行中断，推荐使用PVE自带的Shell操作母鸡 可多次运行批量生成CT容器，但需要注意的是母鸡内存记得开点swap免得机器炸了开SWAP点我跳转 可自定义批量开设的核心数，内存大小，硬盘大小，记得自己计算好空闲资源开设 开设的CT默认已启用SSH且允许root登陆，且已设置支持使用docker的嵌套虚拟化 curl -L https://raw.githubusercontent.com/spiritLHLS/pve/main/scripts/create_ct.sh -o create_ct.sh \u0026\u0026 chmod +x create_ct.sh \u0026\u0026 bash create_ct.sh 国内 curl -L https://ghproxy.com/https://raw.githubusercontent.com/spiritLHLS/pve/main/scripts/create_ct.sh -o create_ct.sh \u0026\u0026 chmod +x create_ct.sh \u0026\u0026 bash create_ct.sh 开设完毕可执行 cat ctlog 查看信息 ","date":"2023-05-06","objectID":"/20230506/:3:0","tags":["linux","pve","vps","kvm","virtual","qemu","nat","iptables","shell","debian"],"title":"一键安装PVE并一键开设KVM虚拟化的NAT服务器-带内外网端口转发","uri":"/20230506/"},{"categories":["电脑技巧"],"content":"致谢 https://blog.ilolicon.com/archives/615 https://github.com/Ella-Alinda/somescripts/blob/main/nat.sh https://pve.proxmox.com/pve-docs/qm.1.html https://down.idc.wiki/Image/realServer-Template/ https://mirrors.tuna.tsinghua.edu.cn/proxmox/ https://github.com/roacn/pve/blob/main/pve.sh https://github.com/spiritLHLS/lxc 感谢 @Ella-Alinda 提供的PVE指导 ","date":"2023-05-06","objectID":"/20230506/:4:0","tags":["linux","pve","vps","kvm","virtual","qemu","nat","iptables","shell","debian"],"title":"一键安装PVE并一键开设KVM虚拟化的NAT服务器-带内外网端口转发","uri":"/20230506/"},{"categories":["电脑技巧"],"content":"友链 VPS融合怪测评脚本 https://github.com/spiritLHLS/ecs ","date":"2023-05-06","objectID":"/20230506/:5:0","tags":["linux","pve","vps","kvm","virtual","qemu","nat","iptables","shell","debian"],"title":"一键安装PVE并一键开设KVM虚拟化的NAT服务器-带内外网端口转发","uri":"/20230506/"},{"categories":["python"],"content":"近期码代码的个人心得 尊重他人命运，放弃助人情节，帮得了一次往往意味着帮无数次 不要让不懂行的人改你的代码，改了最好别再接手代码，往往写的越来越屎，接手了意味着有锅的话你得背，很难辨清 接手什么项目一定要摸清楚自己的定位，是开发者还是维护者，维护发现有锅的推给开发，开发的一定要保证接手的项目没有什么地雷 保持良好心态，遇到不懂行的合作者，不急就晾着吧，免得引火烧身，一个人被当好几个人用 后言 本来不咋想写的，但属实忍不住说了，希望往后合作的人能带我飞而不是等我带他飞，唉。 ","date":"2023-04-22","objectID":"/20230422/:0:0","tags":["python"],"title":"近期码代码的个人心得","uri":"/20230422/"},{"categories":["电脑技巧"],"content":"前言 该方法的前提： 商家使用PVE虚拟化WIN服务器 WIN服务器可配置使用Network进行启动 启动时可使用NO VNC操控IPXE命令 已知符合条件的服务器：NETFRONT 配置：20Mbps Windows 不限流量 Unlimited Traffic (4C+4G+128G+1IP) 香港C区 ","date":"2023-02-22","objectID":"/20230222/:0:1","tags":["linux","pve","vps","kvm","virtual","qemu","ipxe","hongkong","dd"],"title":"将WIN系统DD为Linux系统","uri":"/20230222/"},{"categories":["电脑技巧"],"content":"步骤 1 更改Boot Order选项为如下形式 Device 1: Network Device 2: Disk Device 3: None 2 然后记录下IPV4地址和GATEWAY地址 打开no VNC 等待提示使用CTRL+B键打开IPXE命令窗口 输入以下命令 set net0/ip 你的IPV4地址 set net0/netmask 255.255.255.0 # 你的SUBNET MASK，一般不用改 set net0/gateway 你的gateway地址 set dns 8.8.8.8 ifopen net0 chain -a http://boot.netboot.xyz # 或 chain --autofree http://boot.netboot.xyz 这些命令的解释(不看也没问题)：https://netboot.xyz/docs/booting/ipxe/ 3 回车后等待一段时间 选择Linux Network Installs (64-bit) 4 然后选择需要的系统安装 我习惯debian的debian11中的Expert install 5 后续就是按照地域选择语言，选择使用美式英语键盘等，直到下图提示 不要使用DHCP自动配置网络，因为可能会出现配置失败，此时这个选择要选择NO进行手动配置 配置时需要依次填入 IPV4地址： SUBNET MASK(netmask)： GATEWAY： nameserver： 其中nameserver使用8.8.8.8即可，其他后续会自动补全，比如hostname什么的，如果不自动补全就是有问题的了，需要回退上一步重新设置network(重新设置nameserver) 6 installer components那块不要选择任何组件，直接按TAB跳到continue按键继续 7 后续基本就是全程回车默认即可，设置root密码和新用户以及新用户密码记得记一下，否则后续难改得重装系统了 后面disk分配的时候，默认回车到最后会选择是否要写入更改，此时需要选择yes写入，否则会一直停留在该界面 8 选择镜像时使用linux-image-cloud-amd64而不是linux-image-amd64以节省空间 9 选择镜像完毕后需要选择initrd，推荐选择第二个选项targted开头的选项，以减少空间占用 10 修改前的显示如下： 继续安装后面需要选择Software selection，选项列表中的第一第二个选项 Debian desktop environment GNOME 的选中需要取消掉，避免安装桌面环境(按空格移除选中)，修改后： 然后将SSH server选中，不然进去系统你还得自己装SSH，这里选了就不用再自己装了，然后按TAB跳到continue按键继续 11 最后在选择Install the GRUB boot loader的时候需要在选项列表选择第二个选项，不要默认，选择使用类如/dev/sda开头的选项，然后选择Yes 安装完毕后会默重启系统 12 不要使用重启后的系统，先更改这里 更改Boot Order选项为如下形式 Device 1: Disk Device 2: None Device 3: None 然后Shutdown再Boot 重启后会出现选项选择如何启动，默认回车GRUB启动就行 13 登陆后依次执行 apt update apt install vim -y 进去后由于未开启SSH使用远程root登陆，所以依然需要NO VNC进去后，修改/etc/ssh/sshd_config vim /etc/ssh/sshd_config 修改前： 修改后： 将#PermitRootLogin prohibit-password修改为PermitRootLogin yes，记得去除开头的#号 最后退出编辑保存的使用输入service sshd restart和service ssh restart重启SSH服务 ","date":"2023-02-22","objectID":"/20230222/:0:2","tags":["linux","pve","vps","kvm","virtual","qemu","ipxe","hongkong","dd"],"title":"将WIN系统DD为Linux系统","uri":"/20230222/"},{"categories":["电脑技巧"],"content":"后言 这样捣鼓之后系统就DD完毕且可以在外面使用SSH使用root登陆了 ","date":"2023-02-22","objectID":"/20230222/:0:3","tags":["linux","pve","vps","kvm","virtual","qemu","ipxe","hongkong","dd"],"title":"将WIN系统DD为Linux系统","uri":"/20230222/"},{"categories":["python","数学建模","机器学习"],"content":"只给出个人完成的代码部分与一些简单的结果和说明 from sklearn.decomposition import PCA from sklearn.ensemble import RandomForestClassifier as RFC from sklearn.neighbors import KNeighborsClassifier as KNN from sklearn.model_selection import cross_val_score from sklearn import datasets, decomposition,manifold import matplotlib.pyplot as plt import pandas as pd import numpy as np import time import warnings plt.rcParams['font.family'] = 'SimHei' ### # matplotlib其实是不支持显示中文的 显示中文需要一行代码设置字体 plt.rcParams['axes.unicode_minus'] = False warnings.filterwarnings ('ignore') ### 忽略版本警告 # # 读取并查看数据 # data = pd.read_csv(r\"digit recognizor.csv\") # X = data.iloc[:,1:] # y = data.iloc[:,0] # print(X.shape) #加载数据，显示数据 digits = datasets.load_digits() X = digits.data y = digits.target print (X.shape,y.shape) (1797, 64) (1797,)\r# 画累计方差贡献率曲线，找最佳降维后维度的范围 pca_line = PCA().fit(X) plt.figure(figsize=[20,5]) plt.plot(np.cumsum(pca_line.explained_variance_ratio_)) plt.xlabel(\"降维后的基组件数量\") plt.ylabel(\"累计方差贡献率\") plt.show() #降维后维度的学习曲线，继续缩小最佳维度的范围 time_start = time.time() score = [] for i in range(1,51): X_pca = PCA(i).fit_transform(X) once = cross_val_score(RFC(n_estimators=10,random_state=0),X_pca,y,cv=5).mean() score.append(once) plt.figure(figsize=[20,5]) plt.plot(range(1,51),score) plt.xlabel(\"降维后的基组件数量\") plt.ylabel(\"准确率\") plt.show() time_end = time.time() time_sum = time_end - time_start print(time_sum) 12.560771465301514\r#细化学习曲线，找出降维后的最佳维度 score = [] for i in range(10,20): X_pca = PCA(i).fit_transform(X) once = cross_val_score(RFC(n_estimators=10,random_state=0),X_pca,y,cv=5).mean() score.append(once) plt.figure(figsize=[20,5]) plt.xlabel(\"降维后的基组件数量\") plt.ylabel(\"准确率\") plt.plot(range(10,20),score) plt.show() #导入找出的最佳维度进行降维，查看模型效果 X_pca = PCA(16).fit_transform(X) # 64 列特征变为 16 列特征 print(cross_val_score(RFC(n_estimators=100,random_state=0),X_pca,y,cv=5).mean()) # 使用随机森林进行交叉验证 0.9282342927886104\r# 使用默认的KNN参数，看到在交叉验证环节使用KNN是否比随机森林好 print(cross_val_score(KNN(),X_pca,y,cv=5).mean()) # 结果是KNN好 0.9593980191891054\r# KNN的K值学习曲线 time_start = time.time() score = [] for i in range(10): X_dr = PCA(16).fit_transform(X) once = cross_val_score(KNN(i+1),X_pca,y,cv=5).mean() score.append(once) plt.figure(figsize=[20,5]) plt.xlabel(\"K值\") plt.ylabel(\"准确率\") plt.plot(range(1,11),score) plt.show() time_end = time.time() time_sum = time_end - time_start print(time_sum) 1.1747395992279053\r#K值优化后的交叉验证 print(cross_val_score(KNN(5),X_pca,y,cv=5).mean()) 0.9593980191891054\r################################################################################################################################## # 由之前的实验可知t-SNE在手写数据集上效果良好 # 默认参数下的t-SNE - n_components 小于4，维度不能超过4 tsne = manifold.TSNE(n_components=3, init='pca', random_state=0, perplexity=10) X_tsne = tsne.fit_transform(X) print (X_tsne.shape) print(cross_val_score(KNN(),X_tsne,y,cv=5).mean()) (1797, 3)\r0.972742185082018\r# KNN的K值学习曲线 time_start = time.time() score = [] for i in range(10): once = cross_val_score(KNN(i+1),X_tsne,y,cv=5).mean() score.append(once) plt.figure(figsize=[20,5]) plt.xlabel(\"K值\") plt.ylabel(\"准确率\") plt.plot(range(1,11),score) plt.show() time_end = time.time() time_sum = time_end - time_start print(time_sum) 0.5395219326019287\r#K值优化后的交叉验证 print(cross_val_score(KNN(3),X_tsne,y,cv=5).mean()) 0.9766419065304859\r############################################################################################################################# # 尝试LLE以下使用10作默认的邻居数 clf = manifold.LocallyLinearEmbedding(n_neighbors=10, n_components=2,method='standard') X_lle = clf.fit_transform(X) print(cross_val_score(KNN(),X_lle,y,cv=5).mean()) 0.9026385020117612\r# 画学习曲线，找出降维后的最佳维数和邻居数 # 单线程太慢，下面使用多线程加速 # best_list = [] #(维数，邻居数，交叉验证的准确率) # for i in range(2,64): # 维数 # score = [] # for j in range(3, 20): # 邻居数 # clf = manifold.LocallyLinearEmbedding(n_neighbors=j, n_components=i,method='standard') # X_lle = clf.fit_transform(X) # once = cross_val_score(KNN(),X_lle,y,cv=5).mean() # score.append(once) # best_list.append((i,score.index(max(score)),max(score))) # ","date":"2022-12-30","objectID":"/20221230/:0:0","tags":["python","PCA","LLE","T-SNE","机器学习","特征工程"],"title":"关于手写数字识别的特征工程","uri":"/20221230/"},{"categories":["python","爬虫"],"content":"解决上一篇文章的一些问题 解决方法： https://github.com/wkeeling/selenium-wire/issues/622 下载证书 https://github.com/wkeeling/selenium-wire/raw/master/seleniumwire/ca.crt 将该 ca.crt 添加到受信任的证书中 google浏览器打开chrome://settings/security 点击管理证书，选择受信任的的根证书颁发机构分区，选择导入 导入后再运行seleniumwire开启浏览器则不会出现Not Secure的问题了 ","date":"2022-12-10","objectID":"/20221212/:0:1","tags":["python","selenium","chromedriver","geckodriver","edgedriver","socks5","seleniumwire","selenium-wire","代理"],"title":"在seleniumwire中解决Not Secure问题","uri":"/20221212/"},{"categories":["python","爬虫"],"content":"前言 需要下载Chrome或Firefox的driver，Chrome内核81.440与Firefox内核74.0下载链接如下： Firefox Chrome 其他版本请在搜索引擎查找，本篇使用该版本，注意，driver下载后需要配置对应内核的游览器，电脑本身需要有该内核的游览器。 ","date":"2022-12-09","objectID":"/20200516/:1:0","tags":["python","爬虫"],"title":"Selenium的web自动化操作02(基本语法)","uri":"/20200516/"},{"categories":["python","爬虫"],"content":"正文 ","date":"2022-12-09","objectID":"/20200516/:2:0","tags":["python","爬虫"],"title":"Selenium的web自动化操作02(基本语法)","uri":"/20200516/"},{"categories":["python","爬虫"],"content":"radio框 radio框选择选项，直接用WebElement的click方法，模拟用户点击就可以了。 比如, 我们要在下面的html中： 先打印当前选中的 # 获取当前选中的元素 element = wd.find_element_by_css_selector( '#s_radio input[checked=checked]') print('当前选中的是: ' + element.get_attribute('value')) # 点选 wd.find_element_by_css_selector( '#s_radio input[value=\"小雷老师\"]').click() ","date":"2022-12-09","objectID":"/20200516/:2:1","tags":["python","爬虫"],"title":"Selenium的web自动化操作02(基本语法)","uri":"/20200516/"},{"categories":["python","爬虫"],"content":"checkbox框 对checkbox进行选择，也是直接用WebElement的click方法，模拟用户点击选择。 需要注意的是，要选中checkbox的一个选项，必须先获取当前该复选框的状态。 如果该选项已经勾选了，就不能再点击。 否则反而会取消选择。 先把已经选中的选项全部点击一下，确保都是未选状态再点击要选的 # 先把 已经选中的选项全部点击一下 elements = wd.find_elements_by_css_selector( '#s_checkbox input[checked=\"checked\"]') for element in elements: element.click() wd.find_element_by_css_selector( \"#s_checkbox input[value='要选']\").click() ","date":"2022-12-09","objectID":"/20200516/:2:2","tags":["python","爬虫"],"title":"Selenium的web自动化操作02(基本语法)","uri":"/20200516/"},{"categories":["python","爬虫"],"content":"select框 radio框及checkbox框都是input元素，只是里面的type不同而已。 select框 则是一个新的select标签，大家可以对照浏览器网页内容查看一下 对于Select 选择框， Selenium 专门提供了一个 Select类 进行操作。 Select类 提供了如下的方法 select_by_value 根据选项的 value属性值 ，选择元素。 比如，下面的HTML \u003coption value=\"xxl\"\u003ecool\u003c/option\u003e 就可以根据 xxl 这个值选择该选项 s.select_by_value('xxl') select_by_index 根据选项的 次序 （从0开始），选择元素 select_by_visible_text 根据选项的 可见文本 ，选择元素。 比如，下面的HTML： \u003coption value=\"xxl\"\u003ecool\u003c/option\u003e 就可以根据 cool 这个内容，选择该选项 s.select_by_visible_text('cool') deselect_by_value 根据选项的value属性值， 去除选中元素 deselect_by_index 根据选项的次序，去除选中元素 deselect_by_visible_text 根据选项的可见文本，去除选中元素 deselect_all 去除选中所有元素 ","date":"2022-12-09","objectID":"/20200516/:2:3","tags":["python","爬虫"],"title":"Selenium的web自动化操作02(基本语法)","uri":"/20200516/"},{"categories":["python","爬虫"],"content":"Select单选框 对于 select单选框，操作比较简单： 不管原来选的是什么，直接用Select方法选择即可。 例如，选择要选的，示例代码如下 # 导入Select类 from selenium.webdriver.support.ui import Select # 创建Select对象（实例化） select = Select(wd.find_element_by_id(\"要选id\")) # 通过 Select 对象选中 要选选项 select.select_by_visible_text(\"要选选项\") ","date":"2022-12-09","objectID":"/20200516/:2:4","tags":["python","爬虫"],"title":"Selenium的web自动化操作02(基本语法)","uri":"/20200516/"},{"categories":["python","爬虫"],"content":"Select多选框 对于select多选框，要选中某几个选项，要注意去掉原来已经选中的选项。 例如，我们选择示例多选框中的 x1 和 x2 可以用select类的deselect_all方法，清除所有 已经选中 的选项。 然后再通过select_by_visible_text方法选择 x1 和 x2。 示例代码如下： # 导入Select类 from selenium.webdriver.support.ui import Select # 创建Select对象 select = Select(wd.find_element_by_id(\"x\")) # 清除所有 已经选中 的选项 select.deselect_all() # 选择 x1 和 x2 select.select_by_visible_text(\"x1\") select.select_by_visible_text(\"x2\") ","date":"2022-12-09","objectID":"/20200516/:2:5","tags":["python","爬虫"],"title":"Selenium的web自动化操作02(基本语法)","uri":"/20200516/"},{"categories":["python","爬虫"],"content":"ActionChains类 鼠标右键点击、双击、移动鼠标到某个元素、鼠标拖拽等。 这些操作，可以通过Selenium提供的ActionChains类来实现。 ActionChains类里面提供了 一些特殊的动作的模拟，我们可以通过ActionChains类的代码查看到，如下所示 我们以移动鼠标到某个元素为例。 百度首页的右上角，有个选项 网址：https://www.baidu.com/ 如果我们把鼠标放在上边，就会弹出下面的各种图标。 使用ActionChains来模拟鼠标移动 操作的代码如下： (百度网站首页可能有变化，选择的类可能需要更改) from selenium import webdriver driver = webdriver.Chrome(r'f:\\chromedriver.exe') driver.implicitly_wait(5) driver.get('https://www.baidu.com/') from selenium.webdriver.common.action_chains import ActionChains ac = ActionChains(driver) # 鼠标移动到 元素上 ac.move_to_element( driver.find_element_by_css_selector('[name=\"tj_briicon\"]') ).perform() 直接执行javascript 我们可以直接让浏览器运行一段javascript代码，并且得到返回值，如下 # 直接执行 javascript，里面可以直接用return返回我们需要的数据 nextPageButtonDisabled = driver.execute_script( ''' ele = document.querySelector('.soupager \u003e button:last-of-type'); return ele.getAttribute('disabled') ''') # 返回的数据转化为Python中的数据对象进行后续处理 if nextPageButtonDisabled == 'disabled': # 是最后一页 return True else: # 不是最后一页 return False ","date":"2022-12-09","objectID":"/20200516/:2:6","tags":["python","爬虫"],"title":"Selenium的web自动化操作02(基本语法)","uri":"/20200516/"},{"categories":["python","爬虫"],"content":"冻结界面 有些网站上面的元素，我们鼠标放在上面，会动态弹出一些内容。 比如，百度首页的右上角，有个选项：https://www.baidu.com/ 如果我们把鼠标放在上边，就会弹出很多图标。 如果我们要用selenium自动化点击其中图标，就需要F12查看这个元素的特征。 但是当我们的鼠标从图标移开，这个栏目就整个消失了，就没法查看其对应的HTML。 怎么办？ 在开发者工具栏console里面执行如下js代码 setTimeout(function(){debugger}, 5000) 这句JavaScript代码什么意思呢？ 表示在 5000毫秒后，执行debugger命令 执行该命令会 浏览器会进入debug状态。debug状态有个特性，界面被冻住，不管我们怎么点击界面都不会触发事件。 所以，我们可以在输入上面代码并回车 执行后，立即鼠标放在界面右上角图标处。 这时候，就会弹出下面的各种图标。 然后，我们仔细等待5秒到了以后，界面就会因为执行了debugger命令而被冻住。 然后，我们就可以点击开发者工具栏的查看箭头，再去点击其中图标，查看其属性了。 ","date":"2022-12-09","objectID":"/20200516/:2:7","tags":["python","爬虫"],"title":"Selenium的web自动化操作02(基本语法)","uri":"/20200516/"},{"categories":["python","爬虫"],"content":"弹出对话框 有的时候，我们经常会在操作界面的时候，出现一些弹出的对话框。 弹出的对话框有三种类型，分别是 Alert（警告信息）、confirm（确认信息）和prompt（提示输入） ","date":"2022-12-09","objectID":"/20200516/:2:8","tags":["python","爬虫"],"title":"Selenium的web自动化操作02(基本语法)","uri":"/20200516/"},{"categories":["python","爬虫"],"content":"Alert Alert 弹出框，目的就是显示通知信息，只需用户看完信息后，点击 OK（确定） 就可以了。 那么，自动化的时候，代码怎么模拟用户点击 OK 按钮呢？ selenium提供如下方法进行操作 driver.switch_to.alert.accept() 注意：如果我们不去点击它，页面的其它元素是不能操作的。 如果程序要获取弹出对话框中的信息内容，可以通过如下代码 driver.switch_to.alert.text 示例代码如下 from selenium import webdriver driver = webdriver.Chrome() driver.implicitly_wait(5) driver.get('http://cdn1.python3.vip/files/selenium/test4.html') # --- alert --- driver.find_element_by_id('b1').click() # 打印 弹出框 提示信息 print(driver.switch_to.alert.text) # 点击 OK 按钮 driver.switch_to.alert.accept() ","date":"2022-12-09","objectID":"/20200516/:2:9","tags":["python","爬虫"],"title":"Selenium的web自动化操作02(基本语法)","uri":"/20200516/"},{"categories":["python","爬虫"],"content":"Confirm Confirm弹出框，主要是让用户确认是否要进行某个操作。 比如：当管理员在网站上选择删除某个账号时，就可能会弹出Confirm弹出框，要求确认是否确定要删除。 Confirm弹出框 有两个选择供用户选择，分别是OK和Cancel，分别代表确定和取消操作。 那么，自动化的时候，代码怎么模拟用户点击OK或者Cancel按钮呢？ selenium提供如下方法进行操作 如果我们想点击OK按钮，还是用刚才的accept方法，如下 driver.switch_to.alert.accept() 如果我们想点击 Cancel 按钮， 可以用 dismiss方法，如下 driver.switch_to.alert.dismiss() 示例代码如下 from selenium import webdriver driver = webdriver.Chrome() driver.implicitly_wait(5) driver.get('http://cdn1.python3.vip/files/selenium/test4.html') # --- confirm --- driver.find_element_by_id('b2').click() # 打印 弹出框 提示信息 print(driver.switch_to.alert.text) # 点击 OK 按钮 driver.switch_to.alert.accept() driver.find_element_by_id('b2').click() # 点击 取消 按钮 driver.switch_to.alert.dismiss() ","date":"2022-12-09","objectID":"/20200516/:3:0","tags":["python","爬虫"],"title":"Selenium的web自动化操作02(基本语法)","uri":"/20200516/"},{"categories":["python","爬虫"],"content":"Prompt 出现 Prompt 弹出框 是需要用户输入一些信息，提交上去。 比如：当管理员在网站上选择给某个账号延期时，就可能会弹出 Prompt 弹出框， 要求输入延期多长时间。 可以调用如下方法 driver.switch_to.alert.send_keys() 示例代码如下 from selenium import webdriver driver = webdriver.Chrome() driver.implicitly_wait(5) driver.get('http://cdn1.python3.vip/files/selenium/test4.html') # --- prompt --- driver.find_element_by_id('b3').click() # 获取 alert 对象 alert = driver.switch_to.alert # 打印 弹出框 提示信息 print(alert.text) # 输入信息，并且点击 OK 按钮 提交 alert.send_keys('web自动化 - selenium') alert.accept() # 点击 Cancel 按钮 取消 driver.find_element_by_id('b3').click() alert = driver.switch_to.alert alert.dismiss() 注意： 有些弹窗并非浏览器的alert 窗口，而是html元素，这种对话框，只需要通过之前介绍的选择器选中并进行相应的操作就可以了。 ","date":"2022-12-09","objectID":"/20200516/:3:1","tags":["python","爬虫"],"title":"Selenium的web自动化操作02(基本语法)","uri":"/20200516/"},{"categories":["python","爬虫"],"content":"其他技巧 下面是一些其他的 Selenium 自动化技巧 ","date":"2022-12-09","objectID":"/20200516/:4:0","tags":["python","爬虫"],"title":"Selenium的web自动化操作02(基本语法)","uri":"/20200516/"},{"categories":["python","爬虫"],"content":"窗口大小 有时间我们需要获取窗口的属性和相应的信息，并对窗口进行控制 获取窗口大小 driver.get_window_size() 改变窗口大小 driver.set_window_size(x, y) ","date":"2022-12-09","objectID":"/20200516/:4:1","tags":["python","爬虫"],"title":"Selenium的web自动化操作02(基本语法)","uri":"/20200516/"},{"categories":["python","爬虫"],"content":"获取当前窗口标题 浏览网页的时候，我们的窗口标题是不断变化的，可以使用WebDriver的title属性来获取当前窗口的标题栏字符串。 driver.title 获取当前窗口URL地址 driver.current_url 例如，访问网易，并获取当前窗口的标题和URL from selenium import webdriver driver = webdriver.Chrome() driver.implicitly_wait(5) # 打开网站 driver.get('https://www.163.com') # 获取网站标题栏文本 print(driver.title) # 获取网站地址栏文本 print(driver.current_url) ","date":"2022-12-09","objectID":"/20200516/:4:2","tags":["python","爬虫"],"title":"Selenium的web自动化操作02(基本语法)","uri":"/20200516/"},{"categories":["python","爬虫"],"content":"截屏 有的时候，我们需要把浏览器屏幕内容保存为图片文件。 比如，做自动化测试时，一个测试用例检查点发现错误，我们可以截屏为文件，以便测试结束时进行人工核查。 可以使用WebDriver的get_screenshot_as_file方法来截屏并保存为图片。 from selenium import webdriver driver = webdriver.Chrome() driver.implicitly_wait(5) # 打开网站 driver.get('https://www.baidu.com/') # 截屏保存为图片文件 driver.get_screenshot_as_file('1.png') ","date":"2022-12-09","objectID":"/20200516/:4:3","tags":["python","爬虫"],"title":"Selenium的web自动化操作02(基本语法)","uri":"/20200516/"},{"categories":["python","爬虫"],"content":"手机模式 我们可以通过 desired_capabilities 参数，指定以手机模式打开chrome浏览器 参考代码，如下 from selenium import webdriver mobile_emulation = { \"deviceName\": \"Nexus 5\" } chrome_options = webdriver.ChromeOptions() chrome_options.add_experimental_option(\"mobileEmulation\", mobile_emulation) driver = webdriver.Chrome( desired_capabilities = chrome_options.to_capabilities()) driver.get('http://www.baidu.com') input() driver.quit() ","date":"2022-12-09","objectID":"/20200516/:4:4","tags":["python","爬虫"],"title":"Selenium的web自动化操作02(基本语法)","uri":"/20200516/"},{"categories":["python","爬虫"],"content":"上传文件 有时候，网站操作需要上传文件。 比如，著名的在线图片压缩网站： https://tinypng.com/ 以及由网友Cristy分享的压缩网站：https://www.websiteplanet.com/webtools/imagecompressor/ 后者运行同时压缩jpeg和png文件，并且每幅图片的大小可以达到50MB 通常，网站页面上传文件的功能，是通过 type 属性 为 file 的 HTML input 元素实现的。 如下所示： \u003cinput type=\"file\" multiple=\"multiple\"\u003e 使用selenium自动化上传文件，我们只需要定位到该input元素，然后通过 send_keys 方法传入要上传的文件路径即可。 如下所示： # 先定位到上传文件的 input 元素 ele = wd.find_element_by_css_selector('input[type=file]') # 再调用 WebElement 对象的 send_keys 方法 ele.send_keys(r'h:\\g02.png') 如果需要上传多个文件，可以多次调用send_keys，如下 ele = wd.find_element_by_css_selector('input[type=file]') ele.send_keys(r'h:\\g01.png') ele.send_keys(r'h:\\g02.png') ","date":"2022-12-09","objectID":"/20200516/:4:5","tags":["python","爬虫"],"title":"Selenium的web自动化操作02(基本语法)","uri":"/20200516/"},{"categories":["python","爬虫"],"content":"自动化Edge浏览器 自动化基于Chromium内核的微软最新Edge浏览器，首先需要查看Edge的版本。 点击菜单 帮助和反馈 \u003e 关于Microsoft Edge ，在弹出界面中，查看到版本，比如 Microsoft Edge 是最新版本。 版本 81.0.416.72 (官方内部版本) (64 位) 然后点击这里，打开Edge浏览器驱动下载网页 ，并选择下载对应版本的驱动。 在自动化代码中，指定使用Edge Webdriver类，并且指定Edge驱动路径，如下所示 from selenium import webdriver driver = webdriver.Edge(r'd:\\tools\\webdrivers\\msedgedriver.exe') driver.get('http://www.51job.com') ","date":"2022-12-09","objectID":"/20200516/:4:6","tags":["python","爬虫"],"title":"Selenium的web自动化操作02(基本语法)","uri":"/20200516/"},{"categories":["python","爬虫"],"content":"自动化Electron程序 Electron程序都是基于基于Chromium技术开发的，所以基本也可以用Chromedriver驱动自动化。 要自动化，首先需要得到内置Chromium的版本号。 向开发人员查询打开 Dev Tools 窗口的快捷键（通常是ctrl + Shift + I），打开Dev Tools 窗口后， 在 Console tab中输入 如下语句，查看版本 navigator.appVersion.match(/.*Chrome/([0-9.]+)/)[1] “79.0.3945.130” 然后去 chromedriver下载网址 ，下载对应版本的驱动。 在自动化程序中需要指定打开的可执行程序为Electron程序，而不是 Chrome浏览器。 如下所示 from selenium import webdriver from selenium.webdriver.chrome.options import Options ops = Options() # 指定Electron程序路径 ops.binary_location = r\"C:\\electronAPP.exe\" driver = webdriver.Chrome(r\"e:\\chromedriver.exe\", options = ops) ","date":"2022-12-09","objectID":"/20200516/:4:7","tags":["python","爬虫"],"title":"Selenium的web自动化操作02(基本语法)","uri":"/20200516/"},{"categories":["python","爬虫"],"content":"黑科技 ","date":"2022-12-09","objectID":"/20200516/:5:0","tags":["python","爬虫"],"title":"Selenium的web自动化操作02(基本语法)","uri":"/20200516/"},{"categories":["python","爬虫"],"content":"使用代理 selenium 自动化谷歌浏览器可以这样使用代理 from selenium import webdriver from selenium.webdriver.common.proxy import Proxy, ProxyType prox = Proxy() prox.proxy_type = ProxyType.MANUAL prox.http_proxy = \"127.0.0.1:10800\" prox.ssl_proxy = \"127.0.0.1:10800\" # prox.socks_proxy = \"127.0.0.1:10800\" capabilities = webdriver.DesiredCapabilities.CHROME prox.add_to_capabilities(capabilities) driver = webdriver.Chrome(desired_capabilities=capabilities) driver.get('https://youtube.com') input() ","date":"2022-12-09","objectID":"/20200516/:5:1","tags":["python","爬虫"],"title":"Selenium的web自动化操作02(基本语法)","uri":"/20200516/"},{"categories":["python","爬虫"],"content":"使用缺省用户的profile运行浏览器 前面我们selenium打开浏览器，都是创建一个临时的新的用户，在新的用户环境中运行自动化。 如果我们想使用现有缺省用户的 profile运行浏览器自动化，可以这样 from selenium import webdriver from selenium.webdriver.chrome.options import Options options = Options() # 缺省使用的是该目录下面的 Default目录里面保存的用户profile options.add_argument(r'user-data-dir=c:\\Users\\baiyh\\AppData\\Local\\Google\\Chrome\\User Data') driver = webdriver.Chrome(options=options) ","date":"2022-12-09","objectID":"/20200516/:5:2","tags":["python","爬虫"],"title":"Selenium的web自动化操作02(基本语法)","uri":"/20200516/"},{"categories":["python","爬虫"],"content":"自动化手工打开的Chrome浏览器 Selenium自动化打开的浏览器，每次都是使用全新的profile，有的网站用Selenium自动化，会有奇怪的问题（可能是profile的原因），比如不能登录，打开首页是空白等等。 这时，我们可以 1.关闭所有的Chrome浏览器 2.找到chrome的安装目录，打开命令行窗口，cd进入该目录， 3.输入如下命令，手动启动Chrome浏览器，指定debug端口。 chrome.exe --remote-debugging-port=9222 因为没有 –user-data-dir 参数，使用的是缺省用户profile。就是我们手动直接启动Chrome使用的profile。 这一步，也可以不这么麻烦，参考这篇文章，修改chrome桌面快捷图标启动参数，修改后双击打开Chrome 然后 手动操作浏览器网页，比如登录，进入到可以自动化的状态， 然后，自动化程序中这样写 from selenium import webdriver from selenium.webdriver.chrome.options import Options options = Options() # 指定Chrome的debug地址 和前面命令行中启动参数一致 # 这样，就会直接自动化刚才启动的浏览器 options.add_experimental_option(\"debuggerAddress\", \"127.0.0.1:9222\") wd = webdriver.Chrome(options=options) wd.implicitly_wait(10) # 下面接着写自动化的代码 ","date":"2022-12-09","objectID":"/20200516/:5:3","tags":["python","爬虫"],"title":"Selenium的web自动化操作02(基本语法)","uri":"/20200516/"},{"categories":["python","爬虫"],"content":"无头模式 from selenium import webdriver from selenium.webdriver.chrome.options import Options options = Options() # 设置为无头模式参数 options.add_argument(\"--headless\") driver = webdriver.Chrome(options=options) driver.implicitly_wait(10) driver.get('http://www.ahtba.org.cn/Category/Detail?id=568') eles = driver.find_elements_by_css_selector('#night_7460 li a') for ele in eles: print(ele.text) ","date":"2022-12-09","objectID":"/20200516/:5:4","tags":["python","爬虫"],"title":"Selenium的web自动化操作02(基本语法)","uri":"/20200516/"},{"categories":["python","爬虫"],"content":"前言 爬虫过程中出现了cloudflare的高风险质询验证阻拦或者recaptcha的阻拦，想要破除验证要么使用干净的代理保证低风险爬虫，要么使用hcaptcha求解器求解，后者需要部署的东西过于复杂，为了提高效率，本文介绍第一种方法破除质询验证 cloudflare的风险得分查询(详见我项目的对应函数) https://github.com/spiritLHLS/ecs/blob/main/qzcheck.py#L32 Recaptcha的风险得分查询 https://antcpt.com/score_detector/ ","date":"2022-12-09","objectID":"/20221211/:1:0","tags":["python","selenium","hcaptcha","recaptcha","captcha","验证码","chromedriver","geckodriver","edgedriver","socks5","中间件","seleniumwire","selenium-wire","python-proxy","pproxy","goproxy","代理"],"title":"解决selenium爬虫加密代理问题(含socks5等一切代理)","uri":"/20221211/"},{"categories":["python","爬虫"],"content":"四种解决方法 仅以chromedriver做例子，至于geckodriver，edgedriver可以类比使用 ","date":"2022-12-09","objectID":"/20221211/:2:0","tags":["python","selenium","hcaptcha","recaptcha","captcha","验证码","chromedriver","geckodriver","edgedriver","socks5","中间件","seleniumwire","selenium-wire","python-proxy","pproxy","goproxy","代理"],"title":"解决selenium爬虫加密代理问题(含socks5等一切代理)","uri":"/20221211/"},{"categories":["python","爬虫"],"content":"原生支持解决 chromedriver的有头模式下，使用透明代理(无用户和密码) def input_dependence(): opt = ChromeOptions() opt.headless = False opt.add_argument('--proxy-server=socks5://ip:port') driver = Chrome(executable_path=r\"./chromedriver\", options=opt) return driver chromedriver的有头模式下，使用透明代理(有用户和密码，带身份验证) 自定义插件，加载插件 def create_proxy_auth_extension(proxy_host, proxy_port, proxy_username, proxy_password, scheme='http', plugin_path=None): if plugin_path is None: plugin_path = r'./{}.zip'.format(str(proxy_host).replace(\".\", \"\")) manifest_json = \"\"\" { \"version\": \"1.0.0\", \"manifest_version\": 2, \"name\": \"Chrome Proxy\", \"permissions\": [ \"proxy\", \"tabs\", \"unlimitedStorage\", \"storage\", \"\", \"webRequest\", \"webRequestBlocking\" ], \"background\": { \"scripts\": [\"background.js\"] }, \"minimum_chrome_version\":\"22.0.0\" } \"\"\" background_js = string.Template( \"\"\" var config = { mode: \"fixed_servers\", rules: { singleProxy: { scheme: \"${scheme}\", host: \"${host}\", port: parseInt(${port}) }, bypassList: [\"foobar.com\"] } }; chrome.proxy.settings.set({value: config, scope: \"regular\"}, function() {}); function callbackFn(details) { return { authCredentials: { username: \"${username}\", password: \"${password}\" } }; } chrome.webRequest.onAuthRequired.addListener( callbackFn, {urls: [\"\"]}, ['blocking'] ); \"\"\" ).substitute( host=proxy_host, port=proxy_port, username=proxy_username, password=proxy_password, scheme=scheme, ) with zipfile.ZipFile(plugin_path, 'w') as zp: zp.writestr(\"manifest.json\", manifest_json) zp.writestr(\"background.js\", background_js) return plugin_path # 传入的i为socks5://user:password@ip:port def input_dependence(i): global driver, proxy_auth_plugin_path, status_p # 启动浏览器内核 opt = ChromeOptions() opt.headless = False ipp = str(i) if \"@\" in ipp: ip = ipp.split(\"@\")[1].split(\":\")[0] port = ipp.split(\"@\")[1].split(\":\")[1] username = ipp.split(\"@\")[0].split(\":\")[0] passwd = ipp.split(\"@\")[0].split(\":\")[1] proxy_auth_plugin_path = create_proxy_auth_extension( proxy_host=ip, proxy_port=port, proxy_username=username, proxy_password=passwd) # 如报错 chrome-extensions #opt.add_argument(\"--disable-extensions\") opt.add_extension(proxy_auth_plugin_path) driver = Chrome(executable_path=r\"./chromedriver\", options=opt) 以上加载插件的方式是需要有头模式下运行，linux下使用xvfb模拟有头环境使用 xvfb-run python3 test.py ","date":"2022-12-09","objectID":"/20221211/:2:1","tags":["python","selenium","hcaptcha","recaptcha","captcha","验证码","chromedriver","geckodriver","edgedriver","socks5","中间件","seleniumwire","selenium-wire","python-proxy","pproxy","goproxy","代理"],"title":"解决selenium爬虫加密代理问题(含socks5等一切代理)","uri":"/20221211/"},{"categories":["python","爬虫"],"content":"使用中间件 本地架设通道转发有身份验证的代理为无身份验证的代理 推荐项目： https://github.com/qwj/python-proxy pip install pproxy https://github.com/snail007/goproxy 使用中间件在本地架设代理转发，需要注意本地使用127.0.0.1而服务器使用0.0.0.0，且保证本机的端口是开放的 另一个优点是代理不再局限于socks5一种代理方式，涵盖vmess，ss，trojan等等你只要找得到的对应中间件，那么代理都能使用 当然，这种代理也保证了有头与无头模式下皆可使用，无需使用xvfb之类的工具 转发代理至于本地:8080后，可使用 def input_dependence(): opt = ChromeOptions() opt.headless = False opt.add_argument('--proxy-server=socks5://127.0.0.1:8080') driver = Chrome(executable_path=r\"./chromedriver\", options=opt) return driver 简单的说代理的范围取决于使用了什么中间件，只要中间件支持协议，那么代理就能用 ","date":"2022-12-09","objectID":"/20221211/:2:2","tags":["python","selenium","hcaptcha","recaptcha","captcha","验证码","chromedriver","geckodriver","edgedriver","socks5","中间件","seleniumwire","selenium-wire","python-proxy","pproxy","goproxy","代理"],"title":"解决selenium爬虫加密代理问题(含socks5等一切代理)","uri":"/20221211/"},{"categories":["python","爬虫"],"content":"使用selenium的扩展模块 项目： https://github.com/wkeeling/selenium-wire pip install selenium-wire 使用这种方法可以在无头和有头模式下使用代理，且无需本地架设中间件程序，只需要替换原有的selenium为seleniumwire即可 缺点是只能使用socks5的有身份验证的代理，无法支持更多代理方式 from seleniumwire import webdriver options = { 'proxy': { 'http': 'socks5://user:password@ip:port', 'https': 'socks5://user:password@ip:port', 'no_proxy': 'localhost,127.0.0.1' } } driver = webdriver.Chrome(seleniumwire_options=options) 上述方法即可简单的使用含用户名和密码的s5代理了 值得注意的是seleniumwire只是修补了webdriver下的包，其他selenium包以及webdriver的子包仍然使用selenium导入 # Sub-packages of webdriver must still be imported from `selenium` itself from selenium.webdriver.support.ui import WebDriverWait from seleniumwire.webdriver import ActionChains 替换 from selenium.webdriver import ActionChains 区别就在这里 ","date":"2022-12-09","objectID":"/20221211/:2:3","tags":["python","selenium","hcaptcha","recaptcha","captcha","验证码","chromedriver","geckodriver","edgedriver","socks5","中间件","seleniumwire","selenium-wire","python-proxy","pproxy","goproxy","代理"],"title":"解决selenium爬虫加密代理问题(含socks5等一切代理)","uri":"/20221211/"},{"categories":["python","爬虫"],"content":"使用全局代理 非常方便的傻瓜式方法，缺点是需要保证代理使用过程中，python程序可以正常运行 ","date":"2022-12-09","objectID":"/20221211/:2:4","tags":["python","selenium","hcaptcha","recaptcha","captcha","验证码","chromedriver","geckodriver","edgedriver","socks5","中间件","seleniumwire","selenium-wire","python-proxy","pproxy","goproxy","代理"],"title":"解决selenium爬虫加密代理问题(含socks5等一切代理)","uri":"/20221211/"},{"categories":["python","爬虫"],"content":"后言 使用代理过程中可能会出现各种个月的bug以及爆错，还是建议多看看仓库说明仓库的issues，实在不行上google查询，一般都能解决 ","date":"2022-12-09","objectID":"/20221211/:3:0","tags":["python","selenium","hcaptcha","recaptcha","captcha","验证码","chromedriver","geckodriver","edgedriver","socks5","中间件","seleniumwire","selenium-wire","python-proxy","pproxy","goproxy","代理"],"title":"解决selenium爬虫加密代理问题(含socks5等一切代理)","uri":"/20221211/"},{"categories":["电脑技巧"],"content":"为openvz或kvm架构的linux服务器增加swap分区 addswap 更新时间：2022.12.05 为openvz或kvm架构的linux服务器增加swap分区，请确保在root权限下使用 sudo -i curl -L https://raw.githubusercontent.com/spiritLHLS/addswap/main/addswap.sh -o addswap.sh \u0026\u0026 chmod +x addswap.sh \u0026\u0026 bash addswap.sh 已增加openvz架构重启swap自动添加。 openvz这个添加=掩耳盗铃，实际受到虚拟化限制应该是无法添加的，只能由虚拟化主机控制，因此，该项目不再更新，除非另有需求 单位换算：输入 1024 产生 1G SWAP内存 致谢 kvm分区原版脚本源自 https://www.moerats.com/ curl -L https://www.moerats.com/usr/shell/swap.sh -o swap.sh \u0026\u0026 chmod +x swap.sh \u0026\u0026 bash swap.sh openVZ分区原版脚本源自 http://linux-problem-solver.blogspot.com/2013/08/create-fake-swap-in-openvz-vps-if-you-get-swapon-failed-operation-not-permitted-error.html 由 @fscarmen 指导修改优化 ","date":"2022-12-06","objectID":"/20221206/:0:1","tags":["linux","shell","server","vps","kvm","openvz","virtual","swap"],"title":"为openvz或kvm架构的linux服务器增加swap分区","uri":"/20221206/"},{"categories":["电脑技巧"],"content":"使用LXD对服务器进行LXC容器切分(下面简称母鸡开小鸡) Linux母鸡开小鸡，一键多开NAT小鸡，一键LXC虚拟化，一键多开服务器，多开容器，一键多开NAT小鸡，一键多开NAT服务器 上述需求都得到了解决 ","date":"2022-12-05","objectID":"/20221205/:0:1","tags":["linux","lxd","lxc","shell","server","nat","vps","kvm","virtual","vnstat"],"title":"使用LXD对服务器进行LXC容器切分","uri":"/20221205/"},{"categories":["电脑技巧"],"content":"自写仓库链接 https://github.com/spiritLHLS/lxd ","date":"2022-12-05","objectID":"/20221205/:0:2","tags":["linux","lxd","lxc","shell","server","nat","vps","kvm","virtual","vnstat"],"title":"使用LXD对服务器进行LXC容器切分","uri":"/20221205/"},{"categories":["电脑技巧"],"content":"实验性一键脚本 环境要求：必须为Ubuntu系统 一键安装lxd环境 curl -L https://raw.githubusercontent.com/spiritLHLS/lxd/main/lxdinstall.sh -o lxdinstall.sh \u0026\u0026 chmod +x lxdinstall.sh 设置母鸡内存虚拟化大小以及资源池硬盘大小 ./lxdinstall.sh 内存大小以MB计算 硬盘大小以GB计算 一键安装开lxd母鸡所需要的带vnstat环境的常用预配置环境 (实际主体功能是一键安装vnstat工具) curl -L https://raw.githubusercontent.com/spiritLHLS/lxd/main/backend.sh -o backend.sh \u0026\u0026 chmod +x backend.sh \u0026\u0026 bash backend.sh ","date":"2022-12-05","objectID":"/20221205/:0:3","tags":["linux","lxd","lxc","shell","server","nat","vps","kvm","virtual","vnstat"],"title":"使用LXD对服务器进行LXC容器切分","uri":"/20221205/"},{"categories":["电脑技巧"],"content":"如果上述一键安装出现问题，建议使用手动+自动结合的方式，如下 同时进行TCP和UDP转发，除了SSH端口其他的映射内网外网端口一致，且只适用于Ubuntu或Debian，推荐Ubuntu20或Ubuntu更低版本，debian系列多半有问题 一定要在 /root 的路径下运行本脚本！ 普通版本(带1个SSH端口，25个外网端口) 开出的小鸡配置：1核256MB内存1GB硬盘限速250MB 自动关闭防火墙 apt update apt install curl wget sudo dos2unix ufw -y ufw disable 内存看你开多少小鸡，这里如果要开8个，换算需要2G内存，实际内存如果是512MB内存，还需要开1.5G，保守点开2G虚拟内存即可 执行下面命令，输入1，再输入2048，代表开2G虚拟内存 curl -L https://raw.githubusercontent.com/spiritLHLS/lxd/main/swap.sh -o swap.sh \u0026\u0026 chmod +x swap.sh \u0026\u0026 bash swap.sh 实际swap开的虚拟内存应该是实际内存的2倍，也就是开1G是合理的，上面我描述的情况属于超开了 apt install snapd -y snap install lxd /snap/bin/lxd init 如果上面的命令中出现下面的错误 (snap “lxd” assumes unsupported features: snapd2.39 (try to update snapd and refresh the core snap)) 使用命令修补后再进行lxd的安装 snap install core 如果无异常，上面三行命令执行结果如下 一般的选项回车默认即可 选择配置物理盘大小(提示默认最小1GB那个选项)，一般我填空闲磁盘大小减去内存大小后乘以0.95并向下取整 提示带auto的更新image的选项记得选no，避免更新占用 软连接lxc命令 ! lxc -h \u003e/dev/null 2\u003e\u00261 \u0026\u0026 echo 'alias lxc=\"/snap/bin/lxc\"' \u003e\u003e /root/.bashrc \u0026\u0026 source /root/.bashrc export PATH=$PATH:/snap/bin 测试lxc有没有软连接上 lxc -h lxc命令无问题，执行初始化开小鸡，这一步最好放screen中后台挂起执行，开小鸡时长与你开几个和母鸡配置相关 执行下面命令加载开机脚本 # 初始化 rm -rf init.sh wget https://github.com/spiritLHLS/lxd/raw/main/init.sh chmod 777 init.sh apt install dos2unix -y dos2unix init.sh 下面命令为开小鸡名字前缀为tj的10个小鸡 ./init.sh tj 10 有时候init.sh的运行路径有问题，此时建议前面加上sudo强制根目录执行 纯探针版本(只有一个SSH端口) 开出的小鸡配置：1核128MB内存300MB硬盘限速200MB 自动关闭防火墙 apt update apt install curl wget sudo dos2unix ufw -y ufw disable 内存看你开多少小鸡，这里如果要开10个，换算需要1G内存，实际内存如果是512MB内存，还需要开0.5G，保守点开1G虚拟内存即可 执行下面命令，输入1，再输入1024，代表开1G虚拟内存 curl -L https://raw.githubusercontent.com/spiritLHLS/lxd/main/swap.sh -o swap.sh \u0026\u0026 chmod +x swap.sh \u0026\u0026 bash swap.sh 实际swap开的虚拟内存应该是实际内存的2倍，也就是开1G是合理的，再多就超开了 apt install snapd -y snap install lxd /snap/bin/lxd init 如果上面的命令中出现下面的错误 (snap “lxd” assumes unsupported features: snapd2.39 (try to update snapd and refresh the core snap)) 使用命令修补后再进行lxd的安装 snap install core 如果无异常，上面三行命令执行结果如下 一般的选项回车默认即可 选择配置物理盘大小(提示默认最小1GB那行)，一般我填空闲磁盘大小减去内存大小后乘以0.95并向下取整 提示带auto的更新image的选项记得选no，避免更新占用 软连接lxc命令 ! lxc -h \u003e/dev/null 2\u003e\u00261 \u0026\u0026 echo 'alias lxc=\"/snap/bin/lxc\"' \u003e\u003e /root/.bashrc \u0026\u0026 source /root/.bashrc export PATH=$PATH:/snap/bin 测试lxc有没有软连接上 lxc -h lxc命令无问题，执行初始化开小鸡，这一步最好放screen中后台挂起执行，开小鸡时长与你开几个和母鸡配置相关 加载开机脚本 # 初始化 rm -rf least.sh wget https://github.com/spiritLHLS/lxd/raw/main/least.sh chmod 777 least.sh apt install dos2unix -y dos2unix least.sh 下列命令最后一行为开小鸡名字前缀为tj的10个小鸡 ./least.sh tj 10 有时候least.sh的运行路径有问题，此时建议前面加上sudo强制根目录执行 ","date":"2022-12-05","objectID":"/20221205/:0:4","tags":["linux","lxd","lxc","shell","server","nat","vps","kvm","virtual","vnstat"],"title":"使用LXD对服务器进行LXC容器切分","uri":"/20221205/"},{"categories":["电脑技巧"],"content":"开完多个容器后，具体信息会生成在当前目录下的log文件中，格式如下 1号服务器名称 密码 ssh端口 外网端口起始 外网端口终止 2号服务器名称 密码 ssh端口 外网端口起始 外网端口终止 ","date":"2022-12-05","objectID":"/20221205/:0:5","tags":["linux","lxd","lxc","shell","server","nat","vps","kvm","virtual","vnstat"],"title":"使用LXD对服务器进行LXC容器切分","uri":"/20221205/"},{"categories":["电脑技巧"],"content":"只开一个容器 预装环境如上面的那些一样 加载开机脚本 # 初始化 rm -rf buildone.sh wget https://github.com/spiritLHLS/lxd/raw/main/buildone.sh chmod 777 buildone.sh apt install dos2unix -y dos2unix buildone.sh 开鸡 内存大小以MB计算，硬盘大小以GB计算 ./buildone.sh 小鸡名称 内存大小 硬盘大小 SSH端口 外网起端口 外网止端口 ","date":"2022-12-05","objectID":"/20221205/:0:6","tags":["linux","lxd","lxc","shell","server","nat","vps","kvm","virtual","vnstat"],"title":"使用LXD对服务器进行LXC容器切分","uri":"/20221205/"},{"categories":["电脑技巧"],"content":"常用LXC命令 查看所有 lxc list 查看个例 lxc info 服务器名字 启动个例 lxc start 服务器名字 停止个例 lxc stop 服务器名字 删除个例 lxc rm -f 服务器名字 ","date":"2022-12-05","objectID":"/20221205/:0:7","tags":["linux","lxd","lxc","shell","server","nat","vps","kvm","virtual","vnstat"],"title":"使用LXD对服务器进行LXC容器切分","uri":"/20221205/"},{"categories":["电脑技巧"],"content":"更多更新以及使用方式以仓库说明为准 ","date":"2022-12-05","objectID":"/20221205/:1:0","tags":["linux","lxd","lxc","shell","server","nat","vps","kvm","virtual","vnstat"],"title":"使用LXD对服务器进行LXC容器切分","uri":"/20221205/"},{"categories":["电脑技巧"],"content":"备份仓库： https://gitlab.com/spiritysdx/lxc ","date":"2022-12-05","objectID":"/20221205/:2:0","tags":["linux","lxd","lxc","shell","server","nat","vps","kvm","virtual","vnstat"],"title":"使用LXD对服务器进行LXC容器切分","uri":"/20221205/"},{"categories":["python","爬虫"],"content":"前言 前面有破解谷歌验证码，现在来破解相对简单的图片验证码。(数字以及中英混合) ","date":"2022-11-03","objectID":"/20221103/:0:0","tags":["python","selenium","recaptcha","captcha","验证码"],"title":"免费破解图片验证码(数字或中英混合)(附代码)(2022)","uri":"/20221103/"},{"categories":["python","爬虫"],"content":"插件过验证码 需要加载谷歌插件AutoVerify 这种识别是为了过简单的文字+数字的验证图片用的方法。 这个插件能实现点击输入框后自动查找图片自动填入验证码的功能，不需要浏览器级别的操作(右键菜单栏之类的浏览器级别操作)，所以是过普通验证码的不二选择。 当然这个过于依赖插件了，实际可以去使用一些公开的库进行验证码识别，这样速度更快。 比如说以下这些 https://github.com/sml2h3/ddddocr https://github.com/madmaze/pytesseract 这个识别正确率因人而异。 直接上代码，展示如何加载插件。 # 插件需要放在和py文件的同一目录下 def input_dependence(): # 加载谷歌插件并初始化环境 global driver, shadow # 启动浏览器内核 opt = ChromeOptions() opt.headless = False path_e = os.getcwd() + r\"\\AutoVerify.crx\" opt.add_extension(path_e) opt.add_argument(\"window-size=1920,1080\") # opt.add_experimental_option('prefs', prefs) # 关掉浏览器左上角的通知提示 # opt.add_argument(\"disable-infobars\") # 关闭'chrome正受到自动测试软件的控制'提示 opt.add_argument('--no-sandbox') # 设置开发者模式启动，该模式下webdriver属性为正常值 opt.add_experimental_option('excludeSwitches', ['enable-automation']) # opt.add_argument({\"extensions.ui.developer_mode\": True}) # opt.add_experimental_option('useAutomationExtension', False) # opt.set_preference(\"extensions.firebug.allPagesActivation\", \"on\") opt.add_experimental_option('excludeSwitches', ['enable-logging']) ser = Service(\"chromedriver\") driver = Chrome(service=ser, options=opt) driver.set_page_load_timeout(300) ","date":"2022-11-03","objectID":"/20221103/:1:0","tags":["python","selenium","recaptcha","captcha","验证码"],"title":"免费破解图片验证码(数字或中英混合)(附代码)(2022)","uri":"/20221103/"},{"categories":["python","爬虫"],"content":"免费API实现打码过验证码 列举一些常用的免费API资源 ","date":"2022-11-03","objectID":"/20221103/:2:0","tags":["python","selenium","recaptcha","captcha","验证码"],"title":"免费破解图片验证码(数字或中英混合)(附代码)(2022)","uri":"/20221103/"},{"categories":["python","爬虫"],"content":"国外TrueCaptcha 每日100次，每月合记3000次，需要gmail邮箱注册。每月免费额度最高，适合国外环境以及每日使用。识别成功率较高。 1.truecaptha 注册地址： https://apitruecaptcha.org/ 查找对应用户的信息(userid和apikey)： https://apitruecaptcha.org/api 使用图像文件形式的图片(png或者jpg) import requests import base64 import json def solve(f): # f是png文件名字，你需要保存验证码为本地图片再进行此操作，如何保存详见下面腾讯云的main函数 with open(f, \"rb\") as image_file: encoded_string = base64.b64encode(image_file.read()) #print(encoded_string) url = 'https://api.apitruecaptcha.org/one/gettext' data = { 'userid':'userid的对应值填这里', 'apikey':'apikey的对应值填这里', 'data':str(encoded_string)[2:-1]} r = requests.post(url = url, json = data) j = json.loads(r.text) return(j) 或者使用链接形式的图片(base64码)(推荐上面的用selenium直观点，下面的直接通过BeautifulSoup解析了，需要对网页源码研究透彻) TRUECAPTCHA_USERID = os.environ.get(\"TRUECAPTCHA_USERID\", \"userid的对应值填这里\") TRUECAPTCHA_APIKEY = os.environ.get(\"TRUECAPTCHA_APIKEY\", \"apikey的对应值填这里\") def captcha_solver(captcha_image_url: str, session: requests.session) -\u003e dict: \"\"\" TrueCaptcha API doc: https://apitruecaptcha.org/api Free to use 100 requests per day. \"\"\" response = session.get(captcha_image_url) encoded_string = base64.b64encode(response.content) url = \"https://api.apitruecaptcha.org/one/gettext\" data = { \"userid\": TRUECAPTCHA_USERID, \"apikey\": TRUECAPTCHA_APIKEY, # case sensitivity of text (upper | lower| mixed) \"case\": \"lower\", # use human or AI (human | default) \"mode\": \"default\", \"data\": str(encoded_string)[2:-1], } r = requests.post(url=url, json=data) j = json.loads(r.text) return j def handle_captcha_solved_result(solved: dict) -\u003e str: \"\"\"Since CAPTCHA sometimes appears as a very simple binary arithmetic expression. But since recognition sometimes doesn't show the result of the calculation directly, that's what this function is for. \"\"\" if \"result\" in solved: solved_text = solved[\"result\"] if \"RESULT IS\" in solved_text: log(\"[Captcha Solver] You are using the demo apikey.\") print(\"There is no guarantee that demo apikey will work in the future!\") # because using demo apikey text = re.findall(r\"RESULT IS . (.*) .\", solved_text)[0] else: # using your own apikey log(\"[Captcha Solver] You are using your own apikey.\") text = solved_text operators = [\"X\", \"x\", \"+\", \"-\"] if any(x in text for x in operators): for operator in operators: operator_pos = text.find(operator) if operator == \"x\" or operator == \"X\": operator = \"*\" if operator_pos != -1: left_part = text[:operator_pos] right_part = text[operator_pos + 1 :] if left_part.isdigit() and right_part.isdigit(): return eval( \"{left} {operator} {right}\".format( left=left_part, operator=operator, right=right_part ) ) else: # Because these symbols(\"X\", \"x\", \"+\", \"-\") do not appear at the same time, # it just contains an arithmetic symbol. return text else: return text else: print(solved) raise KeyError(\"Failed to find parsed results.\") def get_captcha_solver_usage() -\u003e dict: url = \"https://api.apitruecaptcha.org/one/getusage\" params = { \"username\": TRUECAPTCHA_USERID, \"apikey\": TRUECAPTCHA_APIKEY, } r = requests.get(url=url, params=params) j = json.loads(r.text) return j ","date":"2022-11-03","objectID":"/20221103/:2:1","tags":["python","selenium","recaptcha","captcha","验证码"],"title":"免费破解图片验证码(数字或中英混合)(附代码)(2022)","uri":"/20221103/"},{"categories":["python","爬虫"],"content":"国内腾讯云，账户需要有实名认证即可 免费的文字识别服务，每个接口每个月1000次免费额度，破解一般用通用印刷体或通用印刷体(高精度)的接口，合计2000次每个月免费次数。每月免费额度一般，泛用性最强，专用性也不差，识别成功率一般。 你需要准备挺多东西的，我一一说一下前期工作。 腾讯云账号一个—\u003e链接 右上角点击注册或登陆(不需要钱，白嫖的服务，有账号就行了) 腾讯云账号对应的访问密钥一对—-\u003ehttps://console.cloud.tencent.com/cam/capi 新建密钥后把密钥的SecretId和SecretKey记住备用。 腾讯云账号对应开启文字识别服务—-\u003ehttps://console.cloud.tencent.com/ocr/ 开通后记得领取免费额度。 本地python环境安装腾讯云的python的sdk： pip install tencentcloud-sdk-python 好了，准备工作做完了，直接上代码！ from selenium.webdriver import ChromeOptions, Chrome from selenium.webdriver.chrome.service import Service from selenium.common.exceptions import TimeoutException from selenium.webdriver.support.ui import WebDriverWait from selenium.webdriver.common.by import By from selenium.webdriver.support import expected_conditions as EC from selenium.webdriver import ActionChains from selenium.webdriver.common.keys import Keys from tencentcloud.common import credential from tencentcloud.common.profile.client_profile import ClientProfile from tencentcloud.common.profile.http_profile import HttpProfile from tencentcloud.common.exception.tencent_cloud_sdk_exception import TencentCloudSDKException import base64 def pass_ocr(src): from tencentcloud.ocr.v20181119 import ocr_client, models try: cred = credential.Credential(SecretId, SecretKey) httpProfile = HttpProfile() httpProfile.endpoint = \"ocr.tencentcloudapi.com\" clientProfile = ClientProfile() clientProfile.httpProfile = httpProfile client = ocr_client.OcrClient(cred, \"na-toronto\", clientProfile) req = models.GeneralAccurateOCRRequest() params = { \"ImageBase64\": src, \"IsPdf\": False } req.from_json_string(json.dumps(params)) resp = client.GeneralAccurateOCR(req) # print(resp.to_json_string()) # return resp.to_json_string() result = resp.to_json_string() # 处理验证结果 temp = [] for i in json.loads(result)[\"TextDetections\"]: y = i[\"DetectedText\"].split(\" \") try: for j in y: temp.append(j) except: temp.append(i[\"DetectedText\"]) print(temp) cct = \"\" # 验证后的字符为cct for i in temp: cct = cct + i return cct except TencentCloudSDKException as err: print(err) def main(): driver.switch_to.default_content() # 确保默认在全局中 WebDriverWait(driver, 20, 0.5).until( EC.visibility_of_element_located((By.CSS_SELECTOR, 'css选择器中选中验证码图片位置'))) element = driver.find_element(By.CSS_SELECTOR, 'css选择器中选中验证码图片位置)') try: os.remove(\"origin.png\") # 确保删除原有图片 except Exception as e: print(e) element.screenshot(\"origin.png\") # 截取验证码图片元素位置并保存为origin.png f = open(os.getcwd() + \"\\\\\" + \"origin.png\", 'rb') # 读取保存的图片 code_data = base64.b64encode(f.read()).decode('utf-8') # 转码为API能读取的base64格式 f.close() result = pass_ocr(code_data) # 验证 time.sleep(random.uniform(1, 3)) WebDriverWait(driver, 20, 0.5).until( EC.visibility_of_element_located((By.CSS_SELECTOR, 'css选择器选中的验证码填空框'))) driver.find_element(By.CSS_SELECTOR, 'css选择器选中的验证码填空框').send_keys(result) print(\"successfully verify captha PNG to str:\\n{}\".format(result)) ","date":"2022-11-03","objectID":"/20221103/:2:2","tags":["python","selenium","recaptcha","captcha","验证码"],"title":"免费破解图片验证码(数字或中英混合)(附代码)(2022)","uri":"/20221103/"},{"categories":["python","爬虫"],"content":"国内百度智能云，账户需要有实名认证即可 一般使用数字打码，或其他对应验证码的API，每个API每个月免费额度为1000次，专用性强，泛用性一般，免费额度一般。识别成功率一般。 开通链接：(事先记得注册和实名认证百度智能云的账号) https://cloud.baidu.com/product/ocr_general 开通后记得领取免费额度。 import urllib.request import re import base64 import requests # 这里嫖的别人的代码，自行替换自己的访问密钥谢谢 # 原始仓库: https://github.com/zqtz/verifycode/blob/master/%E5%9B%BE%E5%83%8F%E9%AA%8C%E8%AF%81%E7%A0%81/baidu_api.py host = \"https://aip.baidubce.com/oauth/2.0/token?grant_type=client_credentials\u0026client_id=oa6VVGS7ldI5GG1e3fHrgvB6\u0026client_secret=xdaZFWKnqt2Hsxvnpd2GDo2QNpfGrHLQ\u0026\" response = requests.get(host) if response: access_token = re.findall(r'\"access_token\":\"(.*?)\"', response.text)[0] ''' 通用文字识别（高精度版） ''' request_url = \"https://aip.baidubce.com/rest/2.0/ocr/v1/accurate_basic\" # 二进制方式打开图片文件 fetch.jpg f = open('fetch.jpg', 'rb') # 这里怎么截取验证码图片可以参照上面腾讯云的我咋写的 img = base64.b64encode(f.read()) params = {\"image\": img} access_token = access_token request_url = request_url + \"?access_token=\" + access_token headers = {'content-type': 'application/x-www-form-urlencoded'} response = requests.post(request_url, data=params, headers=headers) if response: print(response.json()['words_result'][0]['words']) ","date":"2022-11-03","objectID":"/20221103/:2:3","tags":["python","selenium","recaptcha","captcha","验证码"],"title":"免费破解图片验证码(数字或中英混合)(附代码)(2022)","uri":"/20221103/"},{"categories":["python","爬虫"],"content":"自建打码，成功率随缘。 项目地址：(没试过，闲的没事干的可以自行测试) https://github.com/smxiazi/NEW_xp_CAPTCHA 后言 个人推荐国外环境用TrueCaptcha，国内用腾讯云或百度智能云。 我目前只使用了TrueCaptcha和腾讯云做这方面的打码服务。 付费的话有超级鹰之类的，穷人一个，没那钱买付费服务。 ","date":"2022-11-03","objectID":"/20221103/:2:4","tags":["python","selenium","recaptcha","captcha","验证码"],"title":"免费破解图片验证码(数字或中英混合)(附代码)(2022)","uri":"/20221103/"},{"categories":["python","爬虫"],"content":"前言 破解谷歌验证码，其实并不需要用高深的法子，只需要借助一些免费资源，免费插件，就能达到很好的效果。 网上现在流传的几乎都说Google验证码ReCaptchav3得用深度学习，或者第三方收费打码网站，又或者抓住某些验证漏洞才能过，实际上，并不需要。这里我先从普通的验证码开始，介绍我破解Google验证码的思路以及个人成功案例。(全网独家，目前我各大搜索引擎找遍了都没有的，如需转发请注明本文来源) ","date":"2022-11-02","objectID":"/20221102/:0:0","tags":["python","selenium","shadow-root","reCAPTCHA-V3","验证码"],"title":"Python破解Google验证码ReCaptchav3的成功案例(附代码)(免费)(2022)","uri":"/20221102/"},{"categories":["python","爬虫"],"content":"验证码识别(数字字符混合图片) 1.需要加载谷歌插件AutoVerify 这种识别是为了过简单的文字+数字的验证图片用的方法。 这个插件能实现点击输入框后自动查找图片自动填入验证码的功能，不需要浏览器级别的操作(右键菜单栏之类的浏览器级别操作)，所以是过普通验证码的不二选择。 当然这个过于依赖插件了，实际可以去使用一些公开的库进行验证码识别，这样速度更快。 比如说以下这些 https://github.com/sml2h3/ddddocr https://github.com/madmaze/pytesseract 这个识别正确率因人而异。 2.使用公开的API进行验证码识别，需要各种平台账户，这部分将在我的另一篇博客中总结。 (具体使用方法跟我过谷歌验证的reCAPTCHA的第二路线有异曲同工之妙) ","date":"2022-11-02","objectID":"/20221102/:0:1","tags":["python","selenium","shadow-root","reCAPTCHA-V3","验证码"],"title":"Python破解Google验证码ReCaptchav3的成功案例(附代码)(免费)(2022)","uri":"/20221102/"},{"categories":["python","爬虫"],"content":"过谷歌验证(V3)reCAPTCHA(V3)的路线 两个路线，跟上面的想法也是类似的。 1.直接通过插件过验证，但需要你点击某个特定按钮显示特定内容才能过。优点是只需要点点点，配置简单，速度极快，缺点是通过率80%左右(国内环境)，点的过程中需要点击shadow-root(closed)里的按钮，而且可能触发谷歌的人机识别，导致IP短暂进入黑名单不给后续验证。 2.通过第三方接口。优点是不需要插件，通过率几乎100%，不易触发谷歌的人机识别，缺点是配置比较麻烦，而且你的第三方接口账号有一定的风险(几乎忽略不计，只要你不泄露密钥)。 ","date":"2022-11-02","objectID":"/20221102/:0:2","tags":["python","selenium","shadow-root","reCAPTCHA-V3","验证码"],"title":"Python破解Google验证码ReCaptchav3的成功案例(附代码)(免费)(2022)","uri":"/20221102/"},{"categories":["python","爬虫"],"content":"代码 1.先说插件版本的路线，直接上代码，具体内容看注释 插件地址buster.crx # by spiritlhl import random import time import os from selenium.webdriver import ChromeOptions, Chrome from selenium.webdriver.chrome.service import Service from selenium.webdriver.common.by import By from selenium.common.exceptions import TimeoutException from selenium.webdriver.support.ui import WebDriverWait from selenium.webdriver.support import expected_conditions as EC from selenium.webdriver import ActionChains from selenium.webdriver.common.keys import Keys from selenium.webdriver.support.ui import WebDriverWait as wait from selenium.webdriver import DesiredCapabilities from pyshadow.main import Shadow # 加载依赖 def input_dependence(): global driver, shadow # 启动浏览器内核 opt = ChromeOptions() opt.headless = False # 有头模式才能加载插件，无头模式无法加载插件 path_e = os.getcwd() + r\"\\buster.crx\" # 插件放同一文件夹下，加载 opt.add_extension(path_e) # 通过配置参数加载 # 为了提高成功率，需要随机浏览器指纹，当然也可以不随机，此时建议同IP或地域运行，避免不同IP或不同地域同浏览器指纹的奇怪情况 # path_e = os.getcwd() + r\"\\random-user-agent.crx\" # opt.add_extension(path_e) # path_e = os.getcwd() + r\"\\canvas-fingerprint-blocker.crx\" # opt.add_extension(path_e) opt.add_argument(\"--start-maximized\") # 最大化浏览器窗口，避免谷歌验证检测出默认大小判定机器 # 设置开发者模式启动，该模式下webdriver属性为正常值 opt.add_argument('--no-sandbox') # 这一串在linux下有用，win下没啥大用 # 下面几个参数开启开启插件的功能避免导入后无法显示使用 opt.add_experimental_option('excludeSwitches', ['enable-automation']) opt.add_experimental_option('excludeSwitches', ['enable-logging']) opt.add_argument('--disable-blink-features=AutomationControlled') # 配置谷歌浏览器的chromedriver，我的在同一目录下，直接写名字即可 ser = Service(\"chromedriver\") driver = Chrome(service=ser, options=opt) # 加载阴影模块，有需要GitHub搜一下pyshadow库，在shadow-root为open的状态下好用 shadow = Shadow(driver) # 设置加载页面超时时长 driver.set_page_load_timeout(300) return driver # 在谷歌浏览器配置界面修改插件默认配置(很重要，不然你插件加载了但不在所有网站启用，照样白加载了) def change_seeting(): global driver, shadow element = shadow.find_element(\"#devMode\") # pyshadow库真是个好东西，点谷歌配置shadow-root(open)按钮的不二之选 element.click() time.sleep(3) element = shadow.find_element('#detailsButton') time.sleep(3) element.click() time.sleep(10) element = shadow.find_element('#host-access') element.click() all_options = element.find_elements(By.TAG_NAME, \"option\") for option in all_options: # 第三个选项适配所有网站 try: print(translator.trans(\"选项显示的文本 \"), translator.trans(option.text)) print(translator.trans(\"选项值为 \"), translator.trans(option.get_attribute(\"value\"))) except: print(translator.trans(\"选项显示的文本 \"), option.text) print(translator.trans(\"选项值为 \"), option.get_attribute(\"value\")) time.sleep(2) option.click() element = shadow.find_element('#centeredContent') time.sleep(2) element.click() time.sleep(2) element = shadow.find_element('#closeButton')# 一定要点返回，不然白改选项了，不返回不保存，你直接跳转别的页面也没保存的！！！ time.sleep(2) element.click() time.sleep(2) def pass_recaptha(): global driver # 点击验证 # 这一句是跳转验证框内，不然在iframe外无法对iframe内元素进行操作 driver.switch_to.frame(driver.find_element(By.XPATH, '/html/body/main/div/div/div[2]/div/div/div/div/div/form/div[3]/div/div/div/iframe')) # 等待那个勾选框加载，当可点击时再点击 WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"span#recaptcha-anchor\"))).click() # 返回默认的界面，跳出iframe，此时需要加载进入另一个iframe driver.switch_to.default_content() time.sleep(1) # 加载进入另一个iframe element = driver.switch_to.frame(driver.find_element(By.XPATH, '/html/body/div[10]/div[4]/iframe')) time.sleep(random.uniform(3, 5)) # 选中buster插件需要使用的第三个黄色无障碍按钮 driver.find_element(By.CSS_SELECTOR, '#rc-imageselect \u003e div.rc-footer \u003e div.rc-controls \u003e div.primary-controls \u003e div.rc-buttons \u003e div.button-holder.help-button-holder') # 下面的操作是使用tab键盘事件选中按钮，enter键盘事件点击，因为该按钮不在open的shadow-root中，在shadow-root(closed)中，必须使用这种操作点击，否则其他任何方法都无法奏效，pyshadow也不能 Ac = ActionChains(driver) Ac.send_keys(Keys.TAB).perform() Ac.send_keys(Keys.ENTER).perform() print(translator.trans(\"点击了\")) # 点击完毕后，页面跳转到无障碍页面，此时有可能需要再次点击无障碍按钮使得插件运作(我尝试多次，有可能需要有可能不需要，自己判别) time.sleep(3) driver.find_element(By.CSS_SELECTOR, 'body \u003e div \u003e div \u003e div.rc-footer \u003e div.rc-controls \u003e div.primary-controls \u003e div.rc-buttons \u003e div.bu","date":"2022-11-02","objectID":"/20221102/:0:3","tags":["python","selenium","shadow-root","reCAPTCHA-V3","验证码"],"title":"Python破解Google验证码ReCaptchav3的成功案例(附代码)(免费)(2022)","uri":"/20221102/"},{"categories":["python","数学建模"],"content":"前言 美赛论文对应主体代码部分，吐槽一句美赛居然不收代码也是离谱。 论文配套的代码均为本人编写，运行无问题。 感谢组员组长的配合论文撰写。 正文 import numpy as np import pandas as pd import re,math import matplotlib.pyplot as plt from scipy.optimize import linprog np.set_printoptions(suppress=True) data1 = pd.read_csv(r'BCHAIN-MKPRU.csv') # B data2 = pd.read_csv(r'LBMA-GOLD.csv') # G r_hex = '#dc2624' # red, RGB = 220,38,36 dt_hex = '#2b4750' # dark teal, RGB = 43,71,80 tl_hex = '#45a0a2' # teal, RGB = 69,160,162 r1_hex = '#e87a59' # red, RGB = 232,122,89 tl1_hex = '#7dcaa9' # teal, RGB = 125,202,169 g_hex = '#649E7D' # green, RGB = 100,158,125 o_hex = '#dc8018' # orange, RGB = 220,128,24 tn_hex = '#C89F91' # tan, RGB = 200,159,145 g50_hex = '#6c6d6c' # grey-50, RGB = 108,109,108 bg_hex = '#4f6268' # blue grey, RGB = 79,98,104 g25_hex = '#c7cccf' # grey-25, RGB = 199,204,207 data1 Date\rValue\r0\r9/11/16\r621.65\r1\r9/12/16\r609.67\r2\r9/13/16\r610.92\r3\r9/14/16\r608.82\r4\r9/15/16\r610.38\r...\r...\r...\r1821\r9/6/21\r51769.06\r1822\r9/7/21\r52677.40\r1823\r9/8/21\r46809.17\r1824\r9/9/21\r46078.38\r1825\r9/10/21\r46368.69\r1826 rows × 2 columns data1.isnull().any() Date False\rValue False\rdtype: bool\rdata2 Date\rUSD (PM)\r0\r9/12/16\r1324.60\r1\r9/13/16\r1323.65\r2\r9/14/16\r1321.75\r3\r9/15/16\r1310.80\r4\r9/16/16\r1308.35\r...\r...\r...\r1260\r9/6/21\r1821.60\r1261\r9/7/21\r1802.15\r1262\r9/8/21\r1786.00\r1263\r9/9/21\r1788.25\r1264\r9/10/21\r1794.60\r1265 rows × 2 columns # 线性插值填充 data2.interpolate(method='linear', limit_direction='backward', axis=0, inplace = True) def amplitude(list_1): # 涨幅跌幅计算函数 x1 = list_1.copy()[1:] x2 = list_1.copy()[:-1] y = (x1 - x2)/x2 return y # 比特币日涨幅 day_b_amp = amplitude(np.array(data1[\"Value\"])) pd.DataFrame(day_b_amp).T.to_csv(\"比特币日涨幅.csv\") day_b_amp_b = pd.concat([pd.DataFrame(np.array(data1[\"Date\"])[1:],columns=[\"Date\"]), pd.DataFrame(day_b_amp)],axis=1) day_b_amp array([-0.01927129, 0.00205029, -0.00343744, ..., -0.11139939,\r-0.01561211, 0.00630035])\r# 黄金日涨幅 day_amp = amplitude(np.array(data2[\"USD (PM)\"])) pd.DataFrame(day_amp).T.to_csv(\"黄金日涨幅.csv\") day_g_amp_g = pd.concat([pd.DataFrame(np.array(data2[\"Date\"])[1:],columns=[\"Date\"]), pd.DataFrame(day_amp)],axis=1) day_amp array([-0.0007172 , -0.00143542, -0.00828447, ..., -0.00896152,\r0.0012598 , 0.00355096])\rpd.DataFrame(np.array(data2[\"Date\"][1:]),columns=[\"Date\"]) Date\r0\r9/13/16\r1\r9/14/16\r2\r9/15/16\r3\r9/16/16\r4\r9/19/16\r...\r...\r1259\r9/6/21\r1260\r9/7/21\r1261\r9/8/21\r1262\r9/9/21\r1263\r9/10/21\r1264 rows × 1 columns pd.DataFrame(day_amp) 0\r0\r-0.000717\r1\r-0.001435\r2\r-0.008284\r3\r-0.001869\r4\r0.004968\r...\r...\r1259\r-0.001152\r1260\r-0.010677\r1261\r-0.008962\r1262\r0.001260\r1263\r0.003551\r1264 rows × 1 columns # 黄金全投夏普比率 SRg = [] SRb = [] cct = pd.concat([pd.DataFrame(np.array(data2[\"Date\"][1:]),columns=[\"Date\"]), pd.DataFrame(day_amp)],axis=1).set_index([\"Date\"]) y1 = cct[0:77] y2 = cct[77:329] y3 = cct[329:582] y4 = cct[582:835] y5 = cct[835:1089] y6 = cct[1089:] y = [y1,y2,y3,y4,y5,y6] # ym_l = [] # yd_l = [] for i in y: ym = np.array(i).mean() yd = np.std(np.array(i),ddof = 1) SRg.append(ym/yd) # ym_l.append(ym) # yd_l.append(yd) # fig = plt.figure( figsize=(16,4), dpi=100) # ax = fig.add_subplot(1,1,1) # x = np.array([i+1 for i in range(6)]) # plot = ax.plot( x, ym_l, color=g_hex, linewidth=2, linestyle='-',label='mean' ) # plot = ax.plot( x, yd_l, color=o_hex, linewidth=2, linestyle='-',label='std' ) # ax.set_xticks( range(0,len(x),100)) # plt.xlabel('x',fontsize=20) # plt.ylabel('y',fontsize=20) # plt.title('title',fontsize=25) # ax.legend( loc=0, frameon=True ) # # plt.savefig('黄金交易图.png',dpi=600) # plt.show() # pd.DataFrame([ym_l,yd_l],columns=[i+1 for i in range(6)],index=[\"mean\", \"std\"]) # 比特币全投夏普比率 cct = pd.concat([pd.DataFrame(np.array(data1[\"Date\"][1:]),columns=[\"Date\"]), pd.DataFrame(day_b_amp)],axis=1).set_index([\"Date\"]) y1 = cct[0:111] y2 = cct[111:476] y3 = cct[476:841] y4 = cct[841:1206] y5 = cct[1206:1572] y6 = cct[1572:] y = [y1,y2,y3,y4,y5,y6] # ym_l = [] # yd_l = [] for i in y: ym = np.array(i).mean() yd = np.std(np.array(i),ddof = 1) SRb.append(ym/yd) # ym_l.append(ym) ","date":"2022-02-24","objectID":"/20220224/:0:0","tags":["python"],"title":"(MCM/ICM)比特币和黄金组合投资策略的主体代码部分","uri":"/20220224/"},{"categories":["python","数学建模"],"content":"感谢组员组长的配合论文撰写。 1 Introduction Background and restatement of the problem 在如今金融迅猛发展的大背景下，交易员可以对众多的金融投资产品进行选择，并对其投资的波动性资产进行交易，以收获期望的回报。其中黄金和比特币为本文所选取的金融资产。比特币每天都进行交易而黄金只在开市日进行交易，且在交易中交易员需要支付对应比例的佣金。 假设一场时间从2016年9月11日至2021年9月10日，起始资金为1000美元的投资活动。并且通过对该时间内交易员持有的以黄金，比特币，美元为投资组合的资产进行交易或持有处置，以达到最终总收益最大化，即在交易截止日前的资产达到最大值的目的。为了实现该目标，我们需要做如下的工作： • 建立该情景的投资模型，仅根据截至当天的价格数据提供对应的策略。并预估在2021年9月10日（投资截止日）时的资产价值。 • 证明以上建立的模型中给出的策略具有最优性。 • 得到策略对交易成本的敏感程度和交易成本又是怎样影响策略和最终结果的。 2.2 Our works 2. Assumptions 考虑到模型的可解性与简化原则，我们有如下假设： **Assumption 1:**所有原始数据的采集均合理和客观，能够反映真实情况。 **Assumption 2:**假设交易时间具有较好的连续性，即一旦决定交易，则它可以在瞬间完成，不会中断或拖延。 **Assumption 3:**个人或机构对交易市场的影响有限。 3. Abbreviation and definition 符号 含义 资产日收益率（i=1为黄金，i=2为比特币，下同） 资产i的购入价格 出售资产i的价格 对i类资产的投入 i类资产的佣金比例 持有资金 黄金和比特币的组合总收益 黄金和比特币的组合风险 SR 夏普比率 ** 4 Data processing 在对原始数据进行预处理的过程中，我们发现黄金的部分数据存在缺失的情况。缺失的日期分布呈离散化且数量很少，故我们采用拉格朗日插值方法对缺失的数据进行补齐。计算式如下： \u0026Ln(x)=k=0nlk(x)f(xk)\u0026lk(x)=(x-x0)…(x-xk-1)(x-xk+1)…(x-xn)(xk-x0)…(xk-xk-1)(xk-xk+1)…(xk-xn) （1） 其中lk(x)为插值基函数，f(xk)是日期xk时对应的黄金价格。我们发现缺失数据周围的数据很饱满，所以只选取金价缺失日前后两日的数据进行插值，得到低次的插值多项式（龙格现象对低次插值多项式影响很微弱）。最后补全缺失值即可。 五、投资比例——含交易费用的在线组合交易规划模型 在每次交易前，我们需要确定两者交易份额的比例，以达到收益最大化以及风险最小化的目的。由于市场风险的存在以及风险的动态波动性，损失可能达到交易员无法承受的情况，故我们设定交易员的最大损失承受比例为10%。一旦损失可能超过这个比例时，就应该采取措施尽可能减少损失。 对于用于交易的黄金和比特币而言，其日收益率为： ri=P1i-P0ip0i （i=1代表黄金，i=2代表比特币） （） 其中P0i为购入资产i时的价格，P1i为出售资产i时的价格。可以看到，由于市场的不确定性，ri为随机变量。 5.1、模型介绍 组合交易是通过选择不同的资本进行交易，来提高组合中不同风险资产的多样性，减小非系统性的交易风险。类似于不把鸡蛋放在同一个篮子里。（需要加一些动态规划，体现在线）马科维茨指出，交易者的交易倾向由其对风险交易的态度，项目的期望收益和交易风险决定，即关于交易组合的期望收益和标准差的函数。i类资本的期望收益率和风险为： Ri=E(ri) （） σii=E(ri-Ri)2 （） 5.2、模型建立 设xi为交易员投资i类资产的投资比例（i=1代表黄金，i=2代表比特币，下面的定义与此处相同），Ci为i类资产的交易佣金比例。为保证不受长期趋势对短期判断的错误影响，对风险与收益设定观察周期为60天，则黄金和比特币的组合交易的60天收益率为： \u0026Ri(xi)=0iRixi-CixiCixi ( i\u003c60)\u0026Ri(xi)=i-60iRixi-CixiCixi(i≥60) （） 它们的60天内交易风险为： \u0026σ(Ri)=0i(ri-r)2i-1(i\u003c60)\u0026σ(Ri)=i-60i(ri-r)259(i≥60) （） 我们设定在交易中，交易员不能够被卖空，即交易额非负： xi≥0,i=1,2 当然的，交易员在黄金，比特币上的投注费用，应该不超过其自身的美元持有量，即： i=1nxi+i=1nCixi≤1 （i=1,2） （2） 式中，D0是当前交易员的美元持有量。那么，我们就初步建立了下面的考虑佣金的组合交易模型： maxRp(x1,x2)=i=12(Ri-Ci)xi minσp2(x1,x2)=i=12j=12σijxixj s.t.\u0026i=12xi+i=12Cixi≤D0\u0026xi≥0,i=1,2 （） 为表示方便，我们令X=(x1,x2)T为交易中黄金和比特币的投入资金组合；C=(C1,C2)T表示佣金组合；R=(R1,R2)表示收益率组合；V=(σij)n×n，表示交易组合的协方差矩阵，显然矩阵正定；最后定义I=(1,1)T。那么，以上模型可以写成如下的形式： maxRp(X)=RTX-CTX minσp2(X)=XTVX s.t.\u0026ITX+CTX≤D0\u0026X≥0 5.3、含交易费用的在线组合交易规划模型的求解： 前文说过，价格市场的波动其实是交易者过去，现在，未来的意志体现，这导致了收益和风险通常情况下呈现正比趋势。故想要同时实现收益最大和风险最小较为困难。为了充分考虑交易员对市场风险的评估和收益的综合判断的情况，我们采用权重系数转换法，引入风险偏好系数 λ，衡量交易员对收益和风险的综合考虑情况。目标加权后的目标函数如下： minU(X)=λσij2(X)-(1-λ)Rp(X) （） 约束条件不变。将其展开后，得到如下式子： minU(X)=λXTVX-(1-λ)(RTX-CTX) （） 多目标规划模型就转化为了单目标规划模型。显然，这时的规划中，存在二次项，所以是二次规划模型。目标函数是严格凸函数（计算其海森矩阵正定便可判断），可行域（限制条件范围）为凸集（根据凸集的定义即可判断）。所以该目标的求解属于凸规划问题，我们采用单纯法对其求解，便可以得到当X=(x1,x2)T时，目标函数达到最优。（x1,x2分别为此时求得的用于购买黄金和比特币的资金投入。） 6基于道氏理论的交易策略 6.1、模型介绍 理查德•杜兰特（建议加引用）等人的研究已经证明了道氏理论的实用性。道氏理论是一种基于过去价格趋向，对未来价格走势进行预估的趋势性理论。即通过判断当前资本在市场交易中价格大幅度的趋势性走向来实现获利。根据其参考周期的长度可将其分为长期趋势，中期趋势，短期趋势。长期趋势为主要趋势，持续数月乃至数年，用于判断整体发展走势，适用于指导长期投资；中期趋势持续数周到数月，属于修正趋势；短期趋势波动剧烈，难以捉摸，受人为操纵或其他不可控因素的影响较大。 道氏理论涨跌趋势判断标准：若在交易价格走势中，每一段涨幅都能推动价格突破之前的高点，但在这两个高点之间的呈现下降走势的最低点，仍旧比前一个低点更高，即高点和低点都比之前的更高，这种价格走势被称为上升趋势。类似的，高点和低点都比之前更低的价格走势称为下降趋势。 在道氏理论中，交易价格的趋势可以认为其已经对参与交易的每个人的综合情况作出了充足的反映，也就是市场具有客观性。市场走势就是对过去，现在和将来市场交易情况的最好解释。由于趋势的连续性，趋势的逆转可能发生在更小时间长度的趋势上。但从长期趋势看，由于其韧性强，难以被影响。若交易员只根据短期的趋势做出决策，其大概率与长期趋势做逆向交易，亏损的风险也就更大。道氏理论的核心便是交易员应该在中期趋势和长期趋势出现一致，也就是局部小势和总体大式同趋向的时候再进行交易，此时或者可观收益的机会更大。其它时刻交易员应该多耐心等待，寻找合适的交易时机 由于黄金和比特币的资本属性不同（比特币属于虚拟货币，是区块链和数字加密货币的源头），其交易趋向，价格峰值及收益模式可能不尽相同。但道氏理论的实质是根据客观的市场价格趋势作出未来相应的走势判断后，再进行交易，而不是单纯的猜测短期内的价格高点和低点进行的局部化交易。无论是黄金还是比特币，其价值并不是由其客观物体本身决定的，更多的是来源于市场中的交易人对其价值的心里认可。例如比特币并不是自然界中存在的客观物质，但其仍然具有一定的价值。从这点来看，无论市场怎么发展，交易物的存在形态如何变迁，它们终究是存在于市场中的具有一定价值的交易物，其价格走向仍然受到交易人交易倾向的影响。那么，黄金和比特币价格走向趋势，均符合道氏理论。 道氏理论也存在着一些缺点，比如它需要首先对长期趋势作出判断，但交易者对于这种趋势的把握是存在困难的，这就可能就会导致交易的迷茫。其次，道氏理论是根据已经发布的市场价格信息来判断现在的市场形势的，所以可能存在形势已经变化，但判断刚刚作出的情况，这时就错过了部分的市场交易。 由于道氏理论得出的结论落后与市场价格的变化，即理论发出的信号具有滞后性。仅仅根据道氏理论选择进出场，会缩小许多的利润以及交易空间，这可能造成交易时机的流失。而判断区间缩短以及通过多个标准共同判断进出场时机，这一问题将得到了很大程度的解决。 6.2、模型建立： 6.2.1、（道氏理论改进策略）：“双时间周期确认”原则 为了解决道氏理论迟滞性的特点，增大投资获利区间，我们针对道氏理","date":"2022-02-23","objectID":"/20220226/:0:0","tags":["python"],"title":"(MCM/ICM)比特币和黄金组合投资策略","uri":"/20220226/"},{"categories":["python","数学建模"],"content":"前言 美赛论文对应策略代码部分，吐槽一句美赛居然不收代码也是离谱。 论文配套的代码均为本人编写，运行无碍。 感谢组员组长的配合论文撰写。 正文 import numpy as np import pandas as pd import re,math import matplotlib.pyplot as plt np.set_printoptions(suppress=True) B = pd.read_csv(r'B.csv') # B H = pd.read_csv(r'H.csv') # H Times = pd.read_csv(r'022.csv') # Time B = B.set_index(\"Unnamed: 0\") H = H.set_index(\"Unnamed: 0\") Times = Times.set_index(\"Unnamed: 0\") # 先向前取值填充，再先后取值填充 BH = pd.merge(H.iloc[:,0:2], B.iloc[:,0:2], how='outer',on='0').sort_values('0',ascending=True) BH = pd.merge(BH, H.iloc[:,0:3:2], how=\"left\", on=[\"0\"]) BH = pd.merge(BH, B.iloc[:,0:3:2], how=\"left\", on=[\"0\"]).fillna(0) H 0\r1\r2\rUnnamed: 0\r0\r76\r-1\r1145.90\r1\r154\r1\r1281.85\r2\r171\r-1\r1257.40\r3\r233\r1\r1282.30\r4\r247\r-1\r1333.10\r5\r308\r1\r1291.85\r6\r324\r-1\r1264.55\r7\r532\r1\r1223.00\r8\r551\r-1\r1203.25\r9\r608\r1\r1312.40\r10\r628\r-1\r1285.85\r11\r685\r1\r1280.95\r12\r703\r-1\r1431.40\r13\r760\r1\r1503.10\r14\r781\r-1\r1490.60\r15\r839\r1\r1567.85\r16\r856\r-1\r1578.25\r17\r912\r1\r1682.05\r18\r931\r-1\r1737.95\r19\r988\r1\r2031.15\r20\r1008\r-1\r1928.45\rm = 10000 h = 0 b = 0 p = 0 q = 0 control_list = [] for i in range(len(Times)): x1 = 0 x2 = 0 j = 0 t = 0 if i \u003c= 9: control_list.append([i,0,m,h,j,b,t,x1,x2]) continue else: if i not in list(np.array(BH['0'])): control_list.append([i,0,m,h,j,b,t,x1,x2]) continue if np.array(BH[BH['0'].isin([str(i)])]['1_x'])[0] != 0: # H # if np.array(BH[BH['0'].isin([str(i)])]['2_y'])[0] == 0: # B if np.array(BH[BH['0'].isin([str(i)])]['1_x'])[0] \u003c 0: # 买 j = np.array(H[H['0'].isin([i])]['2'])[0] print(j) x1 = np.array(Times.iloc[[i]]['0'])[0] x2 = np.array(Times.iloc[[i]]['1'])[0] p = m*x1#(x1/(x1+x2)) q = m*x2#(x2/(x1+x2)) h = (p-0.01*p)/j p = 0 m = p + q control_list.append([i,11,m,h,j,b,0,x1,x2]) # print(m) if np.array(BH[BH['0'].isin([str(i)])]['1_x'])[0] \u003e 0: # 卖 j = np.array(H[H['0'].isin([i])]['2'])[0] x1 = np.array(Times.iloc[[i]]['0'])[0] x2 = np.array(Times.iloc[[i]]['1'])[0] p = m*x1 q = m*x2 m = h*j-h*j*0.01+p+q h = 0 control_list.append([i,-11,m,h,j,b,0,x1,x2]) # print(m) # if np.array(BH[BH['0'].isin([str(i)])]['2_x'])[0] == 0: # H if np.array(BH[BH['0'].isin([str(i)])]['1_y'])[0] != 0: # B if np.array(BH[BH['0'].isin([str(i)])]['1_y'])[0] \u003c 0: # 买 t = np.array(B[B['0'].isin([i])]['2'])[0] x1 = np.array(Times.iloc[[i]]['0'])[0] x2 = np.array(Times.iloc[[i]]['1'])[0] p = m*x1#(x1/(x1+x2)) q = m*x2#(x2/(x1+x2)) b = (q-0.02*q)/t q = 0 m = p + q control_list.append([i,22,m,h,0,b,t,x1,x2]) # print(m) elif np.array(BH[BH['0'].isin([str(i)])]['1_y'])[0] \u003e 0: # 卖 t = np.array(B[B['0'].isin([i])]['2'])[0] x1 = np.array(Times.iloc[[i]]['0'])[0] x2 = np.array(Times.iloc[[i]]['1'])[0] p = m*x1 q = m*x2 m = b*t-b*t*0.02+p+q b = 0 control_list.append([i,-22,m,h,0,b,t,x1,x2]) # print(m) m 1145.9\r1257.4\r1333.1\r1264.55\r1203.25\r1285.85\r1431.4\r1490.6\r1578.25\r1737.95\r1928.45\r2.935705996261112e-06\rm = 10000 h = 0 b = 0 p = 0 q = 0 control_list = [] for i in range(len(Times)): x1 = 0 x2 = 0 j = 0 t = 0 if i \u003c= 9: control_list.append([i,0,m,h,j,b,t,x1,x2]) continue else: if i not in list(np.array(BH['0'])): control_list.append([i,0,m,h,j,b,t,x1,x2]) continue if np.array(BH[BH['0'].isin([str(i)])]['1_x'])[0] != 0: # H # if np.array(BH[BH['0'].isin([str(i)])]['2_y'])[0] == 0: # B if np.array(BH[BH['0'].isin([str(i)])]['1_x'])[0] \u003c 0: # 买 j = np.array(H[H['0'].isin([i])]['2'])[0] x1 = np.array(Times.iloc[[i]]['0'])[0] x2 = np.array(Times.iloc[[i]]['1'])[0] p = m*x1#(x1/(x1+x2)) q = m*x2#(x2/(x1+x2)) h = (p-0.01*p)/j p = 0 m = p + q control_list.append([i,11,m,h,j,b,t,x1,x2]) # print(m) if np.array(BH[BH['0'].isin([str(i)])]['1_x'])[0] \u003e 0: # 卖 j = np.array(H[H['0'].isin([i])]['2'])[0] x1 = np.array(Times.iloc[[i]]['0'])[0] x2 = np.array(Times.iloc[[i]]['1'])[0] p = m*x1 q = m*x2 m = h*j-h*j*0.01+p+q h = 0 control_list.append([i,-11,m,h,j,b,t,x1,x2]) # print(m) # if np.array(BH[BH['0'].isin([str(i)])]['2_x'])[0] == 0: # H if np.array(BH[BH['0'].isin([str(i)])]['1_y'])[0] != 0: # B if np.array(BH[BH['0'].isin([str(i)])]['1_y'])[0] \u003c 0: # 买 t = np.array(B[B['0'].isin([i","date":"2022-02-23","objectID":"/20220225/:0:0","tags":["python"],"title":"(MCM/ICM)比特币和黄金组合投资策略的策略代码部分","uri":"/20220225/"},{"categories":["python","数学建模"],"content":"前言 美赛论文，由于不能在md中方便的插入图片与数学公式，所以我选择删掉对应的地方。 英文译制版本。 论文配套的代码均为本人编写，感谢组员组长的配合论文撰写。 完整材料详见博客相关资源 正文 2022 MCM/ICM The Best Investment Strategies For Gold And Bitcoin ","date":"2022-02-22","objectID":"/20220222/:0:0","tags":["python"],"title":"(MCM/ICM)The Best Investment Strategies For Gold And Bitcoin","uri":"/20220222/"},{"categories":["python","数学建模"],"content":"Summary With the rapid development of the economy, financial investment has become more and more common. But how to accurately grasp the market trend so as to make reasonable trading choices is a difficult problem. Our team uses historical price data to formulate a portfolio investment strategy of gold and bitcoin to help traders invest safely and make long-term profits. For question 1, to formulate the best investment strategy, it is necessary to determine the best investment ratio and trading timing. For this reason, we establish an online portfolio trading model with commissions. Based on historical price data, risk assessment and expected returns, and introducing risk preference coefficients , a multi-objective planning model is constructed to obtain the best investment ratio of the day too. We use the “Double Time Period Confirmation Principle” to improve the \" Dow Theory “, and through the monitoring of historical prices, we use the Dow model to analyze the trend of asset prices to determine the long-term and medium-term trends of asset prices. Finally, take the breakout point of the medium-term trend as a suitable date and invest with the best investment ratio. We choose a risk preference coefficient of 0.6. Taking the commission ratio required by the question into the model calculation, we get the result that by the end of the transaction in 2021, the total income will reach $72,087.61, and the investment rate of return will be 7108.7%. For question 2, through the comparative analysis of the profitability , risk , Sharpe coeffi- cient and capital liquidity of the investment , we obtained the conclusion that the model has higher returns, better liquidity, the best performance of risk control and Sharpe coefficient. After comprehensive analysis , it shows that the strategy provided by this model is the best investment strategy. For question 3, we conducted a sensitivity analysis on transaction costs,then came to the con- clusion that transaction costs have a greater impact on gold investment, less on Bitcoin investment, and mainly affect the number of transactions and investment ratio. After analysis,transaction fees have a direct impact on transaction frequency, transaction selection and transaction amount, and it affects the benefits and risks in actual transactions by changing the coefficients of the objective function and constraints in the model. Finally, we analyze the shortcomings of the model and the direction of optimization, and attach a memo. Keywords : Dow Theory; Online Portfolio Investment; risk preference coefficient; Sharpe ratio ","date":"2022-02-22","objectID":"/20220222/:0:1","tags":["python"],"title":"(MCM/ICM)The Best Investment Strategies For Gold And Bitcoin","uri":"/20220222/"},{"categories":["python","数学建模"],"content":"Contents 1 Introduction 1.1 Background and restatement of the problem 1.2 Our works 2 Model preparation 2.1 Assumptions 2.2 Abbreviation and definition 2.3 Data processing 3 Online portfolio trading model with commission 3.1 Model introduction 3.2 Establishment of the portfolio trading model 3.3 The solution of portfolio transaction planning model 4 Trading strategies based on Dow Theory 4.1 Overview of theoretical principles 4.2 Formation of trading strategy 4.3 Analysis of the effect and rationality of the strategy 5 Overall trading plan 5.1 Division of trading periods 5.2 Confirmation of the transaction plan 5.3 Analysis of transaction results 6 Analysis of model advantages 6.1 Profitability perspective 6.2 Risk perspective 6.3 Risk-return composite indicator - Sharpe ratio 6.4 Liquidity perspective 7 Sensitivity of the strategy to transaction costs 8 Model advantages and disadvantages and optimization solutions 9 Memorandum ","date":"2022-02-22","objectID":"/20220222/:1:0","tags":["python"],"title":"(MCM/ICM)The Best Investment Strategies For Gold And Bitcoin","uri":"/20220222/"},{"categories":["python","数学建模"],"content":"1 Introduction ","date":"2022-02-22","objectID":"/20220222/:2:0","tags":["python"],"title":"(MCM/ICM)The Best Investment Strategies For Gold And Bitcoin","uri":"/20220222/"},{"categories":["python","数学建模"],"content":"1.1 Background and restatement of the problem In the context of today’s rapid financial development, traders can choose from numerous financial investment products and trade the volatile assets they invest in to reap the desired returns. Among them, gold and bitcoin are the financial assets selected in this paper. Bitcoin is traded every day while gold is traded only on the open day, and traders need to pay a proportional commission during the trade. Assume an investment activity with a starting capital of $1,000 from September 11, 2016 to September 10, 2021. And by trading or holding the assets in the portfolio of gold, bitcoin, and U.S. dollars owned by the trader during this time, ultimately to maximize the final total return. To achieve this goal, we need to do the following: Build an investment model for this scenario, providing strategies based only on price data up to that day. And estimate the asset value on September 10, 2021 (investment deadline). Prove that the strategy given in the model established above is optimal. Find out how sensitive the strategy is to transaction costs and how transaction costs affect the strategy and final outcome. ","date":"2022-02-22","objectID":"/20220222/:2:1","tags":["python"],"title":"(MCM/ICM)The Best Investment Strategies For Gold And Bitcoin","uri":"/20220222/"},{"categories":["python","数学建模"],"content":"1.2 Our works Analyze the historical price data of the two assets, and design a calculation model for the transaction ratio of the two assets. According to the Dow theory and previous data, determine the price trend and transaction timing. By judging the investment ratio and transaction date, formulate the best trading strategy to achieve higher returns and lower risks Evaluate the investment strategy formulated in terms of profitability, risk, and liquidity , to prove that the model is the best model Analyze the impact of commission on the model, and explore changes in investment strategies and returns under different commission rates. ","date":"2022-02-22","objectID":"/20220222/:2:2","tags":["python"],"title":"(MCM/ICM)The Best Investment Strategies For Gold And Bitcoin","uri":"/20220222/"},{"categories":["python","数学建模"],"content":"2 Model preparation ","date":"2022-02-22","objectID":"/20220222/:3:0","tags":["python"],"title":"(MCM/ICM)The Best Investment Strategies For Gold And Bitcoin","uri":"/20220222/"},{"categories":["python","数学建模"],"content":"2.1 Assumptions Considering the solvability and simplification principle of the model, we have the following assumptions: Assumption 1 : All raw data collections are reasonable and objective, and can reflect the real situation. Assumption 2 : It is assumed that the transaction time has a good continuity, that is, once a transaction is decided, it can be completed in an instant without interruption or delay. Assumption 3: Individuals or institutions have limited influence on the trading market. Assumption 4 : There is no negative equity, that is, no loans. ","date":"2022-02-22","objectID":"/20220222/:3:1","tags":["python"],"title":"(MCM/ICM)The Best Investment Strategies For Gold And Bitcoin","uri":"/20220222/"},{"categories":["python","数学建模"],"content":"2.2 Abbreviation and definition ","date":"2022-02-22","objectID":"/20220222/:3:2","tags":["python"],"title":"(MCM/ICM)The Best Investment Strategies For Gold And Bitcoin","uri":"/20220222/"},{"categories":["python","数学建模"],"content":"2.3 Data processing In the process of preprocessing the original data, we found that some data on the opening day of the gold market were missing. The missing date distribution is discretized and the number is small, so we use the Lagrangian interpolation method to fill in the missing data. The calculation formula is as follows: Wherelk(x)is the interpolation basis function, andf(xk)is the corresponding gold price on date xk. ","date":"2022-02-22","objectID":"/20220222/:3:3","tags":["python"],"title":"(MCM/ICM)The Best Investment Strategies For Gold And Bitcoin","uri":"/20220222/"},{"categories":["python","数学建模"],"content":"3 Online portfolio trading model with commission Figure 1 is the schematic diagram of portfolio transaction. Before each transaction, we need to determine the ratio of the two transaction shares. Due to the existence of market risks and the dynamic volatility of risks, losses may reach unbearable conditions for traders, so we set the maximum loss tolerance ratio of traders to 10%. Once the loss may exceed this ratio, measures should be taken to minimize the loss as much as possible. WhereP 0 iis the price when asset i is purchased, andP 1 iis the price when asset i is sold. It can be seen thatriis a random variable due to market uncertainty. ","date":"2022-02-22","objectID":"/20220222/:4:0","tags":["python"],"title":"(MCM/ICM)The Best Investment Strategies For Gold And Bitcoin","uri":"/20220222/"},{"categories":["python","数学建模"],"content":"3.1 Model introduction The online portfolio trading model of commissions, selects different capitals for trading, and maximizes the expected return of the investment portfolio through online portfolio investment and reduces unsystematic trading risks. Based on real-time price information, investors dynamically adjust the proportion of the investment portfolio according to the selected investment strategy, while taking into account the commission expenses. This investment method utilizes computer programs for dynamic position investment adjustment, which simplifies the difficulty of strategy implementation. Markowitz pointed out that a trader’s propensity to trade is determined by his attitude towards risky trades, the average return of the project and the risk of the trade, that is, a function of the average return and standard deviation of the trade portfolio. The average rate of return and risk for class i capital is: Ri=E(ri) (3) σi=E(ri−Ri)^2 (4) ","date":"2022-02-22","objectID":"/20220222/:4:1","tags":["python"],"title":"(MCM/ICM)The Best Investment Strategies For Gold And Bitcoin","uri":"/20220222/"},{"categories":["python","数学建模"],"content":"3.2 Establishment of the portfolio trading model Letxibe the investment ratio of traders investing in assets of type i (i=1 represents gold, i=2 represents Bitcoin, the following definitions are the same as here), andCiis the transaction commission ratio of assets of type i. We set the observation period of risk and return as 60 days, then the 60-day return on the combined trading of gold and Bitcoin is: Their 60-day trading risks are: Of course, traders’ betting fees on gold and bitcoin should not exceed their own dollar holdings, namely: whereD 0 is the current trader’s dollar holdings. Then, we initially established the following combined trading model considering commissions: In order to fit the reality and simplify the calculation and solution, we introduce the risk preference coefficient m to unify the benefits and risks, and use the weight distribution method to convert the multi-objective planning into a single-objective planning. Then, the above model can be optimized into the following form: ","date":"2022-02-22","objectID":"/20220222/:4:2","tags":["python"],"title":"(MCM/ICM)The Best Investment Strategies For Gold And Bitcoin","uri":"/20220222/"},{"categories":["python","数学建模"],"content":"3.3 The solution of portfolio transaction planning model As mentioned above, the volatility of the price market is actually a reflection of the traders’ past, present, and future will, which leads to a positive trend between returns and risks. Therefore, it is difficult to achieve the maximum benefit and the minimum risk at the same time. In order to fully consider the situation of traders’ assessment of market risks and comprehensive judgment of returns, we adopt the weight coefficient conversion method and introduce the risk preference coefficient m to measure traders’ comprehensive consideration of returns and risks. The weighted objective function is as follows: The multi-objective programming model is transformed into a single-objective programming model. Obviously, there are quadratic terms in the planning at this time, so it is a quadratic programming model. The objective function is a strictly convex function (it can be judged by calculating its Hessian matrix positive definite), and the feasible region (the range of constraints) is a convex set (it can be judged according to the definition of a convex set). Therefore, the solution of the objective belongs to the convex programming problem, and we use the simplex method to solve it, so that the objective function can be solved optimally in the corresponding time. (respectively, the capital investment for the purchase of gold and Bitcoin obtained at this time) ","date":"2022-02-22","objectID":"/20220222/:4:3","tags":["python"],"title":"(MCM/ICM)The Best Investment Strategies For Gold And Bitcoin","uri":"/20220222/"},{"categories":["python","数学建模"],"content":"4 Trading strategies based on Dow Theory ","date":"2022-02-22","objectID":"/20220222/:5:0","tags":["python"],"title":"(MCM/ICM)The Best Investment Strategies For Gold And Bitcoin","uri":"/20220222/"},{"categories":["python","数学建模"],"content":"4.1 Overview of theoretical principles Dow Theory is a trend theory that predicts future price movements based on past price trends. The length of the reference period can be divided into long-term, medium-term and short-term trends. If in the trend of the trading price, each period of increase can push the price to break through the previous high, but the lowest point of the downward trend between these two highs is still higher than the previous low, that is, the high and lows are higher than the previous ones, a movement known as an uptrend. Similarly, a price action in which both the high and the low are lower than the previous one is called a downtrend. Due to the continuity of trends, trend reversals may occur on trends of smaller time lengths, and Dow Theory does not deny that a mid-term trend change may signal a longer-term trend change. However, if traders only make decisions based on short-term trends, it is easy to fall into the predicament of contrarian trading, and the risk of loss is even greater. The core of Dow Theory is that traders should trade when the medium-term trend and the long-term trend are consistent, that is, when they are in the same trend. At other times, they should wait more patiently and look for opportunities. Because the conclusions drawn by Dow Theory lag behind changes in market prices, the signals sent by the theory have a lag. Only choosing to enter and exit the market according to Dow Theory will reduce a lot of profits and trading space, which may cause the loss of trading opportunities. If the judgment interval is shortened and the timing of entry and exit is judged through multiple criteria, this problem will be solved to a great extent. ","date":"2022-02-22","objectID":"/20220222/:5:1","tags":["python"],"title":"(MCM/ICM)The Best Investment Strategies For Gold And Bitcoin","uri":"/20220222/"},{"categories":["python","数学建模"],"content":"4.2 Formation of trading strategy 4.2.1 Principle of “Dual Time Period Confirmation” In order to deal with the shortcomings of the hysteresis of Dow Theory and increase the invest- ment profit range, we have improved the Dow Theory. Adopt the “Dual Time Period Confirmation Principle” to judge the long-term and mid-cycle price trends by analyzing the previous prices. Take the long-term trend as the macro judgment direction and the medium-term trend as the trading basis. When the long-term trend is the same as the medium-term trend, grasp the best time to buy and sell. Due to the existence of commissions, the transactions of gold and bitcoin should not be too frequent. The change of gold transaction price is relatively stable, which is suitable for long-term investment. The price of bitcoin changes drastically, which is suitable for short- and medium-term investment. In view of the differences in capital attributes, trading trends, and price peaks of gold and bitcoin, we select different observation periods for gold and bitcoin to judge the price trend, so as to choose the best trading period. 4.2.2 Trend judgment Selection of observation period For gold, we use 20 days as the long-term trend observation period and 5 days as the medium- term trend observation period. For Bitcoin, we use 10 days as the long-term trend observation period and 4 days as the medium-term trend observation period. The method of judging the trend Taking the long-term trend judgment of gold trading as an example, the observation period of the long-term trend is 20 days, and the period of medium-term trend observation is 5 days. Take historical transaction price data for analysis, and take 5 days as a small set. Take the 5-day average transaction price as the price reference data, and draw a line chart. Every 4 points is a large set, and the highest and lowest points are taken to form Dow highs and Dow lows, and rising highs and lows are determined as long-term uptrends, and falling highs and lows are to determine that the long-term period is a downward trend. The trend diagram is shown in Figure 2. If the highs and lows change irregularly, the price changes drastically during this period, the risk is high, and it is not suitable to invest. The judgment of the mid-cycle trend disk is similar to that of the long-term cycle. 4.2.3 Selection of transaction time After consolidating and evaluating the current phase of the mid- to long-term trend, all a trader has to do is time the trade. We refer to buying gold or bitcoin as entering the market and the opposite as leaving the market. First of all, for the entry into the market, it is required that both the long-term trend and the medium-term trend are downtrends, at which time the price continues to move lower. In a medium-term trend, the first reversal point from a downtrend to an uptrend is the time to enter the market. For example, we assume that the long-term trend at this time is declining, and the medium-term trend is also declining. The Dow high point of the previous mid-term trend is a, then when the price exceeds a, it means that the situation has reversed, and it is suitable to buy the asset at this time. For the case of leaving the market, it is also judged by the reversal point in the medium-term trend. For example, we assume that the mid-term trend and the long-term trend are both uptrends at this time, the Dow high of the mid-term trend gradually rises, and then the most recent Dow high is broken, indicating that the situation has reversed, and the asset is sold at this time. For cases where gold is not bought and sold on Saturdays and Sundays but Bitcoin can be bought and sold on Saturdays and Sundays, we choose to round up the gold transaction price on those days to the price of the previous trading day. In the actual calculation, we use the uncompleted raw data of gold to calculate the medium and long period, monitor the price trend of the long period and the medium period, and avoid trading o","date":"2022-02-22","objectID":"/20220222/:5:2","tags":["python"],"title":"(MCM/ICM)The Best Investment Strategies For Gold And Bitcoin","uri":"/20220222/"},{"categories":["python","数学建模"],"content":"4.3 Analysis of the effect and rationality of the strategy The judgment result of the trend: The Figure 4 and Figure 5 show the long-term and medium- term trends of gold and Bitcoin (1 means up, -1 means down, 0 means irregular price changes) Taking the trend chart of gold as an example, in the two long cycles of A and B, the price trend of gold is rising. Therefore, we judge that the long-term C is also an upward trend. The D interval corresponds to the long period C, and it can be seen that the trend in the D interval is a continuous rise. Next, we take the gold price in the long period C and draw the Figure 6 as follows: Some of the Dow highs and Dow lows in this period are marked in the figure, and it is not difficult to see that the trend in this long period is upward. Therefore, our prediction Table 3: Algorithm Principle of Dow Theory Algorithm: Dow Theory Algorithm Input : The ups and downs of the last mid-cycle, yesterday’s ups and downs, whether the last trade was entry or exit Output : Whether or not to operate today and what to do If: the ups and downs of the last medium cycle are down And yesterday’s ups and downs were up and the last transaction was an entry Buy, no more trading in this mid-cycle Elif: the ups and downs of the last medium cycle are up And yesterday’s ups and downs were down and the last transaction was an exit Sell today, no more trading in this mid-cycle Else: : No operation today of the trend is reasonable. Of course, there will be instances of misjudgment, which are normal, as no prediction theory is 100% perfect. Even if the judgment is biased, losses may occur in the short term, but long-term investment has a great probability of achieving better profits. rationality Analysis Judging from the price trends of gold and bitcoin, whether from a long-term or short-term perspective, the distribution of gold is relatively uniform, while the distribution of bitcoin is very dense, basically showing a cluster distribution. This shows that the price volatility of gold is more stable than that of Bitcoin. Therefore, gold is more suitable for long-term trading, and bitcoin is more suitable for medium-term trading. Table 4 lists some trading time judgment tables. According to the data in the table, it can be seen that according to this investment strategy, it is generally a good trading plan to buy at low points and sell at high points. Even on non-trading days for gold (gold is not open on the day corresponding to #), the combination trade is proceeding normally. ","date":"2022-02-22","objectID":"/20220222/:5:3","tags":["python"],"title":"(MCM/ICM)The Best Investment Strategies For Gold And Bitcoin","uri":"/20220222/"},{"categories":["python","数学建模"],"content":"5 Overall trading plan ","date":"2022-02-22","objectID":"/20220222/:6:0","tags":["python"],"title":"(MCM/ICM)The Best Investment Strategies For Gold And Bitcoin","uri":"/20220222/"},{"categories":["python","数学建模"],"content":"5.1 Division of trading periods A schematic diagram of the transaction date division is shown in Figure 7. Observation period - accumulating data At the beginning of the transaction, the lack of historical price data, the long-term trend and the medium-term trend cannot be judged. In order to avoid the blindness of transactions, we choose not to conduct transactions for the time being and see the direction of market transactions. The observation time is 20 days, so the market transaction prices of the previous 20 days are accumulated as data. Enture capital period - test the market After data accumulation, we can already predict the medium-term trend based on the obtained data. Only relying on the mid-cycle trend to guide the investment is risky, and it is easy to miss the best trading time. Although it will not achieve the maximum profit, it has a high probability of making a profit. At this point, we start investing (belonging to testing the market), predicting the mid-cycle Dow trend, monitoring the daily market prices of Bitcoin and gold, and using the Dow theory trading strategy to capture the right time to buy and sell. At the same time, monitor the long-term cycle. When the long-term market trend can be judged, the investment plan will gradually mature and enter the investment income period. Investment income period - the model guides the investment and realizes the income With the further deepening of investment, historical transaction data gradually increased, and the grasp and judgment of long-term trends became more accurate. ","date":"2022-02-22","objectID":"/20220222/:6:1","tags":["python"],"title":"(MCM/ICM)The Best Investment Strategies For Gold And Bitcoin","uri":"/20220222/"},{"categories":["python","数学建模"],"content":"5.2 Confirmation of the transaction plan The investment strategy process is shown in Figure 8.The details are as follows: According to the degree of personal risk preference, select the risk preference coefficient 0-1. Here, we take the risk preference degree of 0.6 as an example. The larger the value of the risk preference coefficient, the greater the investment risk value. Monitor prices in real time, make a judgment every day based on the improved Dow in- vestment strategy, and make a decision whether it is suitable to buy or sell gold or Bitcoin When a suitable transaction date is found, it will be based on the online portfolio investment strategy with transaction fees. then calculate the investment ratio, and get the optimal investment ratio (x 1 ,x 2 ). Invest according to the investment ratio, assuming that it is suitable to buy gold today. At this time, the dollar amount is D, then buy D*x1 gold, The next amount is used to prepare for investing in Bitcoin and risk control. Today’s trading ends, enter the next day’s observation. ","date":"2022-02-22","objectID":"/20220222/:6:2","tags":["python"],"title":"(MCM/ICM)The Best Investment Strategies For Gold And Bitcoin","uri":"/20220222/"},{"categories":["python","数学建模"],"content":"5.3 Analysis of transaction results According to this investment strategy, an investment plan for the five-year trading period from September 11, 2016 to September 10, 2021 is formulated.Figure 9 and Figure 10 is its schematic diagram .(Gold is bought in troy ounces ,the unit of bitcoin buying is bitcoin, and the selling proceeds are all converted into US dollars) In the portfolio investment strategy, observe Figure 10 and compare the purchase and sale records of gold and Bitcoin. It can be seen that before 2018 , there were many transactions in gold, with gold as the main investment object. After 2018 , for the increase in bitcoin transactions, bitcoin has become the main investment object. As can be seen from Figure 10, before 2018 , by investing in gold, the price difference between gold purchases and sales was small, and stable income was obtained. After 2018, The price difference between when Bitcoin is bought in 2020 and when it is sold in 2021 is huge. Assets will soar at the intersection of 2020 and 2021. The portfolio investment strategy has seized the moment of the Bitcoin price surge while constantly trading gold to ensure investment stability, achieving huge gains at a small cost. ","date":"2022-02-22","objectID":"/20220222/:6:3","tags":["python"],"title":"(MCM/ICM)The Best Investment Strategies For Gold And Bitcoin","uri":"/20220222/"},{"categories":["python","数学建模"],"content":"6 Analysis of model advantages In trading of the financial markets, there may be a variety of situations that need to be taken into account. We comprehensively expound its rationality and superiority from the perspective of model solving process and results of profitability, risk, Sharpe ratio and liquidity. ","date":"2022-02-22","objectID":"/20220222/:7:0","tags":["python"],"title":"(MCM/ICM)The Best Investment Strategies For Gold And Bitcoin","uri":"/20220222/"},{"categories":["python","数学建模"],"content":"6.1 Profitability perspective We get the trading strategy and income of only trading gold are Figure 12: (buy at the red dot, sell at the blue dot) The Figure 13 shows that only buying Bitcoin has the highest return, only gold has the lowest return, and the case of combination trading is in the middle. Therefore, purely from the perspective of profitability, the portfolio trading model is only better. However, the combination trading model ensures the stability of the transaction. In the early stage of Bitcoin trading, there is a large decline in the early stage, and there is also a large decline in the later stage of the transaction. At this time, the price of gold rose steadily. It is a good time to enter gold, and the combination trading model has seized this opportunity to ensure the controllable risks while maintaining high returns. ","date":"2022-02-22","objectID":"/20220222/:7:1","tags":["python"],"title":"(MCM/ICM)The Best Investment Strategies For Gold And Bitcoin","uri":"/20220222/"},{"categories":["python","数学建模"],"content":"6.2 Risk perspective 6.2.1 Control of the maximum loss amount In the process of formulating the trading strategy, the maximum loss limit is introduced, and we set the maximum loss ratio that investors can bear for a single investment to be 10%. In each day’s price monitoring, the price of the day is compared with the purchase price of the asset. When the decline exceeds 10%, in order to avoid the abnormal collapse of the asset system, the asset will be sold immediately and the loss will be stopped in time.The Figure 14 shows the change curve of return with risk appetite coefficient. 6.2.2 Free risk control By comparison, when m\u003c0.4, the investment is relatively conservative and the benefit is small; when 0.4\u003cm\u003c0.6, the risk is moderate and the benefit is the largest; when m\u003e0.6, the risk increases, the probability of investment loss increases, and the benefit decreases. Due to the continuous soaring price of Bitcoin in recent years, risk lovers are more inclined to invest in Bitcoin in order to obtain greater returns. ","date":"2022-02-22","objectID":"/20220222/:7:2","tags":["python"],"title":"(MCM/ICM)The Best Investment Strategies For Gold And Bitcoin","uri":"/20220222/"},{"categories":["python","数学建模"],"content":"6.3 Risk-return composite indicator - Sharpe ratio The Sharpe ratio is a classic indicator that takes both return and risk into account. It means that investors can get a little bit of excess return for every extra risk they take; if it is positive, it means that the underlying return is higher than the risk of volatility; if it is negative value, which means that the underlying operational risk is higher than the rate of return. It represents the ratio of investment return to risk taking, the higher the ratio, the better the portfolio. In the formula,rpis the expected annualized rate of return of the portfolio,rfis the annualized return of risk-free assets (there is no risk-free asset in this paper), andσqisthe standard deviation of the annualized rate of return of the investment portfolio. In our investment selection, risk-free investment is not included, that is,rf= 0. By calculating the annual Sharpe coefficients of the four investment strategies of only investing in gold, only investing in Bitcoin, gold and Bitcoin with a constant proportion of investment, and online portfolio trading investment, the advantages and disadvantages of the four trading strategies are compared and analyzed. The Table 5 is the Sharpe coefficients of the four portfolios: According to the table below, among the four investment strategies, online portfolio investment has the best performance in terms of Sharpe coefficients, all of which are positive, and its Sharpe coefficient values are higher than those of the other three.This kind of investment strategy is relatively large. In the case of considering both the return and the risk, the online portfolio investment strategy can effectively control the risk and improve the return. The table below shows the calculated Sharpe coefficients: ","date":"2022-02-22","objectID":"/20220222/:7:3","tags":["python"],"title":"(MCM/ICM)The Best Investment Strategies For Gold And Bitcoin","uri":"/20220222/"},{"categories":["python","数学建模"],"content":"6.4 Liquidity perspective According to the Table 6, the number of transactions of portfolio investment is 5 less than that of only investing in gold, but the income is 9 times that of only investing in gold. Although the return of portfolio investment is no better than that of only investing in gold, the number of transactions is less than 10 times, which effectively avoids some risks in the process of Bitcoin investment, so that the return has been in a relatively stable upward state. By analyzing the investment results under the guidance of the online portfolio investment model, this investment strategy has high profitability, and the risk preference coefficient is selected as 0.6, which is a risk preference investment type. At the same time, the maximum loss amount can be effectively controlled, the Sharpe coefficient has the best performance, and the capital liquidity is relatively high. The above investment indicators are considered in a comprehensive comparison, and the investment model is the optimal model. ","date":"2022-02-22","objectID":"/20220222/:7:4","tags":["python"],"title":"(MCM/ICM)The Best Investment Strategies For Gold And Bitcoin","uri":"/20220222/"},{"categories":["python","数学建模"],"content":"7 Sensitivity of the strategy to transaction costs Sensitivity of the strategy to transaction costs In a transaction, whether it is a profit or a loss, a corresponding proportion of the commission needs to be paid. Therefore, the commission value is a data that affects the transaction for a long time, and the higher the commission is, the profit of the trader will definitely decrease. However, due to the differences in the price fluctuations of gold and bitcoin markets, different commission ratios have different effects on them. In the title, the commissions for gold and bitcoin are 1% and 2% of the transaction amount, respectively. In order to analyze the influence of commission on the model, we take the commission ratio of gold to be approximately 0, 1%, 5%, 10%, and the commission ratio of Bitcoin to be approximately 0, 1%, 5%, 10%. According to the model established above, we solve these different commission ratios respectively, and obtain the corresponding final income values under the combination of these commission ratios, as shown in the Table 6 (the horizontal axis represents the change of gold commission, and the vertical axis represents the bit Coin commission changes): According to the analysis in 7, when the commission ratio of Bitcoin remains unchanged and the commission ratio of gold increases, the final income will drop rapidly; but when the commission ratio of gold remains unchanged and the commission ratio of Bitcoin increases, the final income changes are not as drastic as in the previous case. This makes perfect sense, since Bitcoin sometimes trades at extremely high prices and the market price fluctuates so much that commissions affect it less than gold. When the commissions of both are close to 0, the final profit price is nearly five thousand dollars higher than the scenario set, and when the commissions of both are close to 10%, the final profit will become very small, which also conforms to the general law that the income changes with the commission ratio. In conclusion, the commission ratio has a far greater impact on gold trading than on Bitcoin, and has a huge impact on the returns of the portfolio investment model. The impact of transaction costs on the model Figure 15 is a schematic diagram of the impact of transaction costs on investment strategies.In the model we established, transaction cost mainly affects the investment ratio and the actual amount of investment. In the determination of the investment ratio, an online portfolio investment model with transaction costs is used to construct a multi-objective programming algorithm. The transaction costs affect the constraints and the coefficients of the objective function. When the transaction cost changes, the rate of return changes. In order to achieve the maximum return and the minimum risk, the investment ratio is adjusted to find a new optimal solution. As transaction fees increase, the amount actually used to purchase investment products will decrease, and the return on a single investment will also decrease. When transaction costs increase, the number of transactions will decrease accordingly. The decrease in the number of transactions will have an uncertain impact on profitability, and investment risks will also increase. ","date":"2022-02-22","objectID":"/20220222/:8:0","tags":["python"],"title":"(MCM/ICM)The Best Investment Strategies For Gold And Bitcoin","uri":"/20220222/"},{"categories":["python","数学建模"],"content":"8 Model advantages and disadvantages and optimization solutions ","date":"2022-02-22","objectID":"/20220222/:9:0","tags":["python"],"title":"(MCM/ICM)The Best Investment Strategies For Gold And Bitcoin","uri":"/20220222/"},{"categories":["python","数学建模"],"content":"tions Model Advantages The model makes full use of historical transaction data. First, the investor chooses the risk preference coefficient ( 0 \u003c m \u003c 1 ), and obtains the optimal solution of the investment ratio (x 1 ,x 2 ) through the online portfolio investment strategy including transaction costs. Combined with the classic Dow Theory in ,the investment market, this paper analyzes the shortcomings and deficiencies of the Dow Theory, and adopts the principle of “Dual Time Period Confirmation” to improve the Dow Theory. Successfully seized the best time to buy or sell an asset. Disadvantages of the model The early investment judgment of the model is only based on the medium-term trend, and the Dow theory is used to monitor the timing of buying or selling assets. There is a certain lag in the grasp of the transaction date, resulting in less profit from the early investment. Only when the time exceeds 60 days, the long-term trend is gradually clear, and the investment enters the investment income period, it will have good returns. Model optimization direction Select a more suitable observation period. The difference of observation period has certain influence on the selection of transaction date. The shorter the observation period, the more sensitive it is to market price changes, the more transactions are recommended, and the greater the risk. The longer the observation period, the more likely it is to miss many suitable trading dates, resulting in reduced returns. Therefore, according to different assets, exploring an observation period that conforms to the law of market changes will allow you to have a better grasp of the timing of transactions and achieve greater profits and less risk. Selection of risk preference coefficient. The risk preference coefficient directly deter- mines the choice of investment ratio. Risk-loving people are keen to invest in Bitcoin, and risk-averse people are keen to invest in gold. Therefore, the choice of risk ap- petite coefficient plays a key role in investment decisions. In different trading periods, there may be different optimal risk factors. Therefore, the dynamic selection of risk coefficients according to market laws will help to achieve stable returns. Optimization algorithm structure. By optimizing the algorithm structure, conducting more index analysis on asset transaction prices, conducting joint analysis of different assets, and exploring their internal correlations, we will be able to grasp the market trend better, make more accurate investments, and obtain greater returns. ","date":"2022-02-22","objectID":"/20220222/:10:0","tags":["python"],"title":"(MCM/ICM)The Best Investment Strategies For Gold And Bitcoin","uri":"/20220222/"},{"categories":["python","数学建模"],"content":"9 Memorandum The formulation of our investment strategy is mainly the selection of the best investment ratio and the grasp of the best trading date. The investment ratio and transaction date are based on the analysis of historical transaction data. With the passage of time, the model is in a dynamic change and has strong universality. The models used in our investment strategies are mainly: online portfolio investment models with transaction fees and trading strategies based on Dow Theory. The online portfolio investment model is used to find the best investment ratio allocation in real time. By analyzing the income and risk of the transaction data of the first 60 days, the multi- objective planning model is used to pursue the maximum return and the minimum risk, and the risk preference coefficient is introduced to integrate the risk and return according to the unification of weights. It is transformed into a single-objective programming problem, and the simplex method is used to find the optimal solution of the investment ratio. Trading strategies based on Dow Theory are used to capture the best trading opportunities. Through the detection and trend analysis of historical transaction data, as well as the monitoring of the long-term and medium-term trends of Bitcoin and gold, the Dow highs, Dow lows and trend trends can be judged, and combined with “dual time cycle confirmation” principles to determine the best date to buy or sell. The investment strategy is: using the transaction model based on Dow Theory, if a suitable purchase opportunity is found, the online portfolio transaction model with transaction fees is used to calculate the optimal investment allocation ratio at this time, and purchase the corresponding assets proportionally. If it is judged that it is suitable to buy gold on that day, the investment ratio is calculated as , and the dollar holdings are D. So D* is used to purchase gold, and the remaining amount will not be invested for the time being to prepare for Bitcoin investment and risk control. Using our investment model to guide traders to invest, traders only need to choose their preferred risk preference coefficient ( 0 \u003c m \u003c1)). The larger the risk preference coefficient, the greater the risk. We choose the risk preference degree as 0.6 to guided investments. After that, traders only need to input the price data of gold and bitcoin in the past, and the model will output whether it is recommended to trade today, the trading behavior, the type of trading assets, and the best trading ratio. Traders make buy, hold, and sell operations based on model recommendations. On Saturdays and Sundays, the price of gold can be regarded as unchanged and without profit. Based on our Dow Theory model, we will not choose a day without profit for trading, but continue to monitor the price trend of Bitcoin to determine whether it is suitable for trading. It effectively solves the problem that the gold market does not open on Saturdays and Sundays, and Bitcoin can be traded every day. Using our investment model to guide traders to invest, traders only need to choose their preferred risk preference coefficient ( 0 \u003c m \u003c1)). The larger the risk preference coefficient, the greater the risk. We choose the risk preference degree as 0.6 to guided investments. After that, traders only need to input the price data of gold and bitcoin in the past, and the model will output whether it is recommended to trade today, the trading behavior, the type of trading assets, and the best trading ratio. Traders make buy, hold, and sell operations based on model recommendations. Guided by our model, the asset increased from $1,000 on September 11, 2016 to $72,087.61 on September 10, 2021. The investment rate of return is 7108.7%, the total number of transactions is 16, the maximum loss ratio of a single investment does not exceed 10%, the average Sharpe coefficient is 0.152, and the Sharpe coefficient is positive every year. The investment has good","date":"2022-02-22","objectID":"/20220222/:11:0","tags":["python"],"title":"(MCM/ICM)The Best Investment Strategies For Gold And Bitcoin","uri":"/20220222/"},{"categories":["python","数学建模"],"content":"References [1] Li Shuli.Research on Markowitz Portfolio Models of Mean and Variance ChangesEconomic [J].Outlook of the Bohai Rim,2020(2),185-186 [2] TM. Universal Portfolios[J]. Mathmatical Finance, 1991,1(1):1-29 [3] Arpe W F. The Sharpe ratio Journalof Portfolio Management,1994,21(1) : 49-58 [4] Liu Bing, Zheng Chengli. Review and application of several online portfolio investment strategies [J]. Journal of Shandong Agricultural Engineering Institute, 2020, 37(03): 63-69. DOI: 10.15948/j.cnki.37-1500/ s.2020.03.011. [5] Li Chulin. Research on portfolio investment considering transaction costs [J]. Forecast, 1998, [6] Zhang Dingyuan. The establishment, evaluation and improvement of spot gold trading strategy [D]. Xinjiang University of Finance and Economics, 2015. [7] Fu Zhong. Defects of Dow Theory and Coping Methods [J]. Economic Research Guide, 2013(26):18-19. [8] Chen Huayou, Xu Yisheng. Multi-objective planning model of portfolio investment with transaction costs [J]. Operations Research and Management, 1999(03):57-60. [9] Liu Shancun, Qiu Wanhua, Wang Shouyang. Pan-portfolio investment strategy with transac- tion costs [J]. System Engineering Theory and Practice, 2003(01):22-25 [10] Lin Hongmei, Du Jinyan, Zhang Shaodong. Sharpe Ratio: Estimation Method, Ap- plicability and Empirical Analysis [J]. Journal of Statistics, 2021, 2(06): 73-88. DOI: 10.19820/j.cnki.issn2096-7411.2021. 06.006. [11] Deng Hongwu, Xing Kai, Wang Zhiyong, et al. An optimization method for model general- ization ability based on time-invariant stability and Sharpe ratio [J]. Small Microcomputer System, 2021: 1-12 [12] Song Hongyu. The application of Sharpe ratio in investment management [J]. Statistics and Decision, 2006 (24): 107-109 [13] Operations Research Writing Group. Operations Research [M]. Beijing: Tsinghua University Press, 1990, 2nd edition ","date":"2022-02-22","objectID":"/20220222/:12:0","tags":["python"],"title":"(MCM/ICM)The Best Investment Strategies For Gold And Bitcoin","uri":"/20220222/"},{"categories":["python","数学建模"],"content":"背景： 市场交易者频繁买卖波动性资产，目标是最大化其总回报。每次买卖通常都会有佣金。 两种这样的资产是黄金和比特币。 图 1：黄金每日价格，每金衡盎司美元。 资料来源：伦敦金银市场协​​会，2021 年 9 月 11 日 图 2：比特币每日价格，每比特币美元。 资料来源：纳斯达克，2021 年 9 月 11 日 要求： 一位交易员要求您开发一个模型，该模型仅使用迄今为止的每日价格流来确定交易员每天是否应该购买、持有或出售其投资组合中的资产。 2016 年 9 月 11 日，您将从 1000 美元开始。 您将使用从 2016 年 9 月 11 日到 2021 年 9 月 10 日的五年交易期。 在每个交易日，交易者将拥有一个由现金、黄金和比特币 [C, G, B] 分别以美元、金衡盎司和比特币组成的投资组合。 初始状态为 [1000, 0, 0]。 每笔交易（购买或销售）的佣金成本为交易金额的 α%。假设= 1% 和 = 2%。 持有资产没有成本。 请注意，比特币可以每天交易，但黄金仅在开市日交易，定价数据文件 LBMA-GOLD.csv 和 BCHAIN-MKPRU.csv 反映了这一点。 你的模型应该考虑到这个交易时间表。 要开发您的模型，您只能使用提供的两个电子表格中的数据：LBMA-GOLD.csv 和 BCHAIN-MKPRU.csv。 • 开发一个模型，该模型仅根据截至当天的价格数据提供最佳每日交易策略。 使用您的模型和策略，在 2021 年 9 月 10 日，最初的 1000 美元投资价值多少？ • 提供证据证明您的模型提供了最佳策略。 • 确定策略对交易成本的敏感程度。 交易成本如何影响策略和结果？ • 在最多两页的备忘录中向交易者传达您的策略、模型和结果。 总页数不超过 25 页的 PDF 解决方案应包括： • 一页摘要表。 • 目录。 • 您的完整解决方案。 • 一到两页的备忘录。 • 参考文献列表。 注意：MCM 有 25 页的限制。 您提交的所有方面都计入 25 页的限制（摘要表、目录、参考列表和任何附录）。 您必须引用您的想法、图像和报告中使用的任何其他材料的来源 附件 提供的两个数据文件包含您应该用于此问题的唯一数据 数据说明 \\1. LBMA-GOLD.csv - 日期：mm-dd-yyyy（月-日-年）格式的日期。 - USD (PM)：一金衡盎司黄金在指定日期的美元收盘价。 2. BCHAIN-MKPRU.csv - 日期：mm-dd-yyyy（月-日-年）格式的日期。 - 价值：指定日期单个比特币的美元价格 ","date":"2022-02-21","objectID":"/20220221/:0:0","tags":["python"],"title":"(MCM/ICM)2022C题比特币与黄金投资问题汉译题目","uri":"/20220221/"},{"categories":["python","数学建模"],"content":"前言 很水的比赛，官方求着收论文，说是保底有钱。。。。 英文译制版本。 感谢组员组长的配合论文撰写。 正文 Suzhou Carbon Neutral Circular Development Creative Plan Problem Analysis 1.1 Background brief 1.1.1 Problem introduction In recent years, Suzhou has faced various new problems and challenges, such as economic transformation, low coordination between low-carbon development and social progress, and increased uncertainty in economic development, which has brought impacts and challenges to the realization of the carbon neutrality goal. However, due to the influence of many factors, such as excessive reliance on foreign transfer of primary energy, insufficient resource endowment, energy consumption mainly based on traditional fossil fuels such as coal, weak development of new energy and small market share, the overall impact of Suzhou has been directly or indirectly caused the higher carbon emissions. The following mainly deals with the processing and analysis of Suzhou’s carbon emissions and other economic and environmental data in recent years, and gives a reasonable assessment of Suzhou’s carbon neutrality prospects. Provide opinions and plans on resource utilization, green economy, policy system and etc, to promote environmental protection and governance in Suzhou and the Yangtze River Delta region, respond to the dual-carbon strategy, and facilitate the green and low-carbon development of the region. 1.1.2 The scientific connotation of carbon neutralization ** Carbon peaking refers to the process in which the total amount of emissions reaches the maximum value within a specific time interval, and then enters a stable decline stage, including three key elements: the peak-to-peak path, the peak-to-peak time, and the peak level. The carbon peak is the historical inflection point of the total emissions from increasing to decreasing. There is also a situation where carbon dioxide emissions enter a plateau period and fluctuate within a certain range. Therefore, the realization of the carbon peak often depends on the economy to further confirm the trend of carbon emissions and make a statement. Suzhou and even my country are facing policy-driven carbon peaking, because China and other late-developing countries have advanced their climate goals such as carbon peaking and carbon neutrality, and they are facing more time and intensity than industrialized countries. To meet the emission reduction requirements, the strong intervention of the central government and the active innovation of local governments are needed to drive the realization of the carbon peaking goal with policies. Carbon neutrality, also known as net-zero emissions, refers to the amount of global human-induced emissions equal to the anthropogenic removal over a given period of time. Carbon neutrality is a concept of net value, which is not equivalent to zero emissions. The main body is not limited to countries and regions, but also includes industries, enterprises, communities and even individuals. The core is that the net emissions in the entire life cycle of economic activities and within the scope of influence are zero. Among them, factors such as population, economic development level, industrialization, urbanization level, and energy structure significantly affect the carbon emission level. The KAYA identity establishes the relationship between human activities and population size, technological level, energy structure, and environmental regulation through mathematical analysis methods. The KAYA identity states that the level of emissions depends on the size of the population, per capita GDP, energy consumption per unit of GDP, and carbon emissions per unit of energy consumption. Various factors are affected by technological level, environmental regulations, etc. And also act on production and consumption activities to directly or indirectly affect the emission level. 1.1.3 The theoretical basis of research 1.1.3.1 Carbon Emission Estimation The Intergovernmental Panel on Climate Change of the United Nations ha","date":"2022-02-13","objectID":"/20220213/:0:0","tags":["python"],"title":"Suzhou Carbon Neutral-Circular Development Creative Plan","uri":"/20220213/"},{"categories":["python","数学建模"],"content":"前言 很水的比赛，官方求着收论文，说是保底有钱。。。。 感谢组员组长的配合论文撰写。 正文 问题分析 背景简述 问题引入 近年来，苏州由于面临经济的转型、低碳发展与社会进步协调性降低、经济发展面临的不确定性增加等各种新问题、新挑战，给碳中和目标的实现带来的冲击与挑战。而一次能源过度依赖外地调入、资源禀赋不足、能源消费多以煤炭等传统化石燃料为主、新能源发展乏力且占市场份额较小等诸多因素的影响，直接或间接的造成了苏州整体的碳排放量较高的情况。 下文主要针对苏州近年来的碳排放以及其它的经济、环境数据进行处理分析，对苏州的碳中和前景给出一定的合理性评估，并以构建苏州的绿色低碳循环发展体系为导向，从资源利用、绿色经济、政策体系等方面给出意见方案，助推苏州及长三角地区的环境保护和治理，响应双碳战略，助力地区的绿色低碳发展。 碳达峰碳中和的科学内涵 碳达峰指特定时间区间内排放总量达到最大值，随后进入平稳下降阶段的过程，包括达峰路径、达峰时间以及峰值水平三个关键要素。碳达峰是排放总量由增转降的历史拐点，也存在排放进入平台期并在一定范围内波动的情况。因此，碳达峰的实现与否往往有赖于经济体进一步确认碳排放量变化趋势并作出声明。苏州乃至我国面对的是碳达峰中的政策驱动型碳达峰，因为中国等后发国家超前提出碳达峰碳中和等气候目标后，面对比工业化国家时间更紧张、强度更大的减排要求，需要中央政府的强介入和地方政府的主动创新，以政策驱动碳达峰目标的实现。 碳中和，也称为净零排放，指特定时期内全球人类活动导致的排放量与人为消除量相等。碳中和是一个净值的概念，并不等同于零排放，主体不仅限于国家和地区，也包括行业、企业、社区乃至个人，核心是经济活动全生命周期和影响范围内的净排放量为零。其中人口、经济发展水平、工业化、城镇化水平，能源结构等因素显著影响碳排放水平。KAYA恒等式通过数学分析方法，建立起人类活动产生的与人口规模、技术水平、能源结构、环境规制等的联系。KAYA恒等式指出，排放水平取决于人口规模、人均国内生产总值、单位GDP能耗以及单位能耗碳排放水平。各因素受到技术水平、环境规制等的影响，又作用于生产和消费活动对排放水平产生直接或间接影响。 研究理论基础 1.1.3.1碳排放估算 联合国政府间气候变化专门委员会已制定了通用碳排放估算方法，我们采用的碳排放计算表达式如下： （1） 其中，CE为碳排放总量，为影响因子，为相应源头。 通过数据调查，苏州市近年来碳排放量逐年增加。通过对苏州市近年来碳排放数据走势分析，并结合苏州市关于碳排放的政策措施，预估苏州市将于2025年碳达峰。我国整体计划于2030年实现碳达峰，于2050年实现碳中和，苏州市政府近年来越来越重视节能减排以及环境保护，预计可以于2025年实现碳达峰。 通过对表中数据进行分析，苏州市近年来谈判碳排放在逐年增加，2019年开始有所下降。结合实际，由于受疫情影响，2019年之后我国经济发展缓慢甚至进入停滞状态，但苏州市经过飞跃式发展期后，经济发展已逐渐平稳，GDP增速以及碳排放增速逐渐稳定。其增速约在4%左右，预计在2025年实现碳达峰，碳排放总量估计在2.45亿吨。 年份 碳排放总量（亿吨） 碳排放增速（％） ＧＤＰ（万亿元） ＧＤＰ增速（％） 单位地区生产总值二氧化碳排放量 2015 1.6 缺失 1.45 缺失 1.1034 2016 1.7 6.25 1.55 6.9 1.0968 2017 1.7 11.8 1.73 11.61 1.0983 2018 2.06 8.42 1.85 6.94 1.1135 2019 2.07 0.49 1.92 3.78 1.0781 2020 2.02 2.42 2.02 5.2 1 表（1）2015 2020年苏州地区生产总值（GDP）和碳排放情况表 1.1.3.2碳排放强度 碳排放强度是指每单位生产总值（GDP）增长所引起的碳排放总量（CE），表达式为： （2） 式中，CI为碳排放强度；CE为碳排放量；GDP为该地区的GDP值。 根据历年相关 GDP、碳排放计算得出的碳排放强度，趋势如图1所示。由于近几年苏州地区人口变化波动小，因此在计算碳排放强度时未考虑人口因素。可以发现，单位GDP碳排放强度2015～2018年里出现一定波动。据悉，2018～2019 年碳排放强度超额完成4.73%的年度下降目标，增速暂缓，于 2019年后明显降低。 图（1）单位 GDP 碳排放强度 1.1.3.3生态系统固碳能力 对环境中起到明显吸收作用的途径主要分为农田固碳、林地与园地固碳和以荒草地、苇地等地类为代表的其他地类固碳。下面是分别对于以上三类固碳途径的具体研究。 农田固碳的研究 各类农作物对于碳的吸收量，等于其光合作用产生并储存的有机质，既农作物的总第一生产力,并且对于该部分的估算，还应该包括农作物凋落物和秸秆腐化还田所产生的碳量。碳吸收的部分采用从经济产量推算得到生物产量，进而再估算碳吸收量的方法。因为是根据经济产量进行的计算，因此在实际考虑中，扣除了作物生长过程中呼吸作用释放的碳，并以此作为农田生态系统的碳吸收。 考虑到苏州的菜地面积较小，所以我们对其不予考虑，重点关注耕地的碳吸收量。以下主要参考李克让的估算方法，既用不同种类作物经济系数和碳吸收率来估算农作物的生长期内的碳吸收量，具体步骤如下： 若已知经济产量（作物被采集的含碳化合物的量）Y，生物产量（总干物质）D和经济系数H的关系如下： （3） 则作物的全生长周期的碳吸收量为： （4） 林地与园地固碳的研究 森林生态系统的固碳效应取决于碳素输入和碳素输出这两个对立的过程。碳素输入过程主要靠森林植物的净光合作用实现，碳素输出过程主要指森岭土壤和动物异养呼吸过程以及凋落物的矿质化过程由对中国森林植被的生物量和净生产量的研究表明，不同植被干物质生产量的差别较大，其范围在0.11-0.14之间。下表为苏州市1997-2005年的各类生态系统的固碳量： 表（2）苏州市1997-2005年的各类生态系统的固碳量 单位： 地类 1997 1998 1999 2000 2001 2002 2003 2004 2005 耕地 309.37 253.93 251.82 220.78 180.39 161.39 125.99 131.96 124.79 林地 4.79 4.82 4.81 4.81 4.8 4.93 4.92 5.08 5.08 园地 9.98 9.96 9.83 9.78 9.71 9.38 9.29 10.21 10.84 城市绿地 1.26 1.29 1.42 1.61 1.73 1.94 2.24 2.52 2.81 其他地类 28.51 28.45 28.30 28.28 28.17 30.44 30.10 30.62 30.67 总计 353.91 298.45 296.18 265.26 224.80 208.08 172.54 180.39 174.19 差额 - -55.46 -57.73 -88.65 -129.11 -145.83 -181.37 -173.52 -179.72 在地类划分中，林地划分为林地、灌木林地、疏林地、未成林造林地、苗圃迹地。其中迹地为由于森林采伐或火烧后5年内未更新的土地类型，计算时不予考虑。根据相关学者的研究表明，江苏省内林地的年初级净生产量为9.84t/h,疏林地和灌木林地的年初级净生产量为10.95t/h。未成林造林地是指造林成活率大于或等于合理造林的41%的新造林地，其年净初级生产量按林地的41%计算，为4.49t/h。苗圃的年净初级生产量按灌木林地计算，为10.95t/h。 考虑到苏州园地主要为果园、桑园与茶园，在计算时将其固碳能力视为与林地的相同； 城市绿地包括公共绿地、防护和生产绿地，具有重要的生态价值。依照1997年至2005年的相关研究，我们取每公顷绿地每年的碳吸收量为5.99t。 其他地类固碳的研究 这类具有固碳功能的地类有苇地、滩涂、荒草地、沼泽地以及长有水生植物的湖泊、河流等水系统。通过对以上各种地类表层生态情况的研究和朱青海等人的研究，我们取荒草地的年净初级生产量按灌木林地的10%算，既1.10t/h；湖泊、河流等水系统的固碳速率均取5-72g/；苏州地区苇地的密度大致为1.57106株/h，单株的净生长量为6.37g/（株a）,故苇地的年生长量，既固碳量为10.00t/h；根据Aselmann等人的研究表明，我们取苏州市的沼泽、滩涂地植被的年净初级生产量为15.00t/h。 1.1.3.4 碳排放量的计算研究 标准煤亦称煤当量，其具有统一的热值标准。我国规定每千克标准煤的热值为7000千卡（既29307.6千焦）。能源的种类有很多，其所含的热量也各不相同，为了便于相互对比和在总量上进行研究，我们经常将各种能源折合成标准煤来表示。下表为苏州市常用能源及大部外调一次能源的折算标准煤参考系数： 表（3）苏州市常用能源及大部外调一次能源的折算标准煤参考系数表 能源序号 能源名称 平均低位发热量（kJ/kg） 折算标准煤系数 1 原煤 20934 0.7143 2 洗精煤 26377 0.9000 3 洗煤煤泥 8374 0.2857 4 焦炭 28470 0.9714 5 原油 41868 1.4286 6 燃料油 41868 1.4286 7 汽油 43124 1.4714 8 煤油 43124 1.4714 9 柴油 42705 1.4571 10 液化石油气 47472 1.6198 11 天然气 35588 1.2143 12 焦炉煤气 16746 0.5714 ","date":"2022-02-12","objectID":"/20220212/:0:0","tags":["python"],"title":"苏州市碳中和-循环发展创意方案书","uri":"/20220212/"},{"categories":["python","爬虫"],"content":"直接使用原始图片做验证码识别正确率较低，使用增强技术后能大大提高识别率 黑底填充白底 from PIL import Image import os def Convert(filename): \"\"\" 将图像中白色像素转变为黑色像素 \"\"\" img = Image.open(os.getcwd()+ \"\\\\\"+ filename) img = img.convert(\"RGBA\") pixdata = img.load() for y in range(img.size[1]): for x in range(img.size[0]): if all(pixdata[x, y][i] \u003e 220 for i in range(4)): pixdata[x, y] = 0, 0, 0 try: os.remove(\"result.png\") except Exception as e: print(e) # result.png 黑色填充白底彩色图 img.save(\"result.png\") print(\"Successfully: \" + filename) if __name__ == \"__main__\": # origin.png 彩色验证码图片 Convert(r\"origin.png\") 彩色变黑白二值化增强 from PIL import Image from PIL import ImageEnhance ##增强图形识别率的处理 # origin.png 彩色验证码图片 i2=Image.open(r\"origin.png\") imgry = i2.convert('L') #图像加强，二值化，PIL中有九种不同模式。分别为1，L，P，RGB，RGBA，CMYK，YCbCr，I，F。L为灰度图像 sharpness =ImageEnhance.Contrast(imgry)#对比度增强 i3 = sharpness.enhance(3.0) #3.0为图像的饱和度 try: os.remove(\"result.png\") except Exception as e: print(e) # result.png 黑白灰度图 i3.save(\"result.png\") ","date":"2022-02-06","objectID":"/20220206/:0:1","tags":["python","recaptcha","captcha","验证码"],"title":"图片验证码增强技术(提高识别正确率)","uri":"/20220206/"},{"categories":["电脑技巧"],"content":"2022.1.16 Euserv激活账号以及安装机子需要钱了，无法白嫖了。。。 但是有别的机子有类似机制能白嫖，详情请看 https://github.com/spiritLHL/Hang-up-items 原有已经嫖到的自动续期脚本还是有效的。 ","date":"2022-01-20","objectID":"/20220120/:1:0","tags":["linux"],"title":"白嫖永久的免费VPS云服务器(2022.1.16已报废)","uri":"/20220120/"},{"categories":["电脑技巧"],"content":"前言 2022.1.5更新图片链接以及部分说明 2021.11.26更新教程，解决11.6增加了邮件pin验证的问题 每个号限量一台，申请审核制，没耐心的不推荐嗷！ 如果想注册多账户，建议更换IP和浏览器嗷，环境得变一下，不然会被识别出已注册过，直接给你封号的！ 服务器仅支持装linux系统，没有需求建议别撸，把机会留给有需要的人。 都是个人经验，如果还是不会可以—\u003e点击联系我，有时间或许会帮助一下 ","date":"2022-01-20","objectID":"/20220120/:2:0","tags":["linux"],"title":"白嫖永久的免费VPS云服务器(2022.1.16已报废)","uri":"/20220120/"},{"categories":["电脑技巧"],"content":"前期准备 需要一个国际邮箱，什么QQ邮箱163邮箱是不能用的，推荐gmail或yandex邮箱 相关注册地址如下： gmail注册地址 yandex注册地址 个人推荐yandex邮箱，因为它可以国内直连，方便随时查看信息，gmail就有点麻烦，得拥有一个谷歌账户才行。 yandex注册需要手机号，手机号前加+86就能收到验证码了。 yandex邮箱国内直连就能上，很香。 需要随机的没有被使用过的个人英文信息和英文地址信息 这里比较重要，推荐使用符合自己登陆ip或离登陆ip非常接近的地区的随机生成的虚拟信息，尤其重要的是得是全英文的，不然必然过不了审核。 我自己使用香港IP注册的，所以使用的是随机生成的虚拟香港个人信息与地址。 随机虚拟香港个人信息： 虚拟香港个人信息 推荐随机香港信息，注意一定要按教程写，不然你的账户会被自动注销，得重新注册！！！ 需要一个支持IPV6的环境 自己测试一下，如果不支持IPV6的话你登不上SSH，此时建议使用手机流量开热点给电脑，手机流量一般是有IPV6环境的。 IPV6环境测试网站 测试成功后是这个样子的： 到这里基本的东西已经完事了，下面开始正式开撸！ ","date":"2022-01-20","objectID":"/20220120/:3:0","tags":["linux"],"title":"白嫖永久的免费VPS云服务器(2022.1.16已报废)","uri":"/20220120/"},{"categories":["电脑技巧"],"content":"注册账户 官网地址：http://www.euserv.de/ 界面如下： 点击后注册 输入你的国际邮箱，点击发送PIN码到你的邮箱进行验证 将PIN码输入后点击验证 (邮箱可能将该信息整到广告垃圾信息里了，得翻一下那块) 验证后需要你设置密码和用户信息啥的，自己设置吧，记得是英文，密码得包含数字，字母。 然后下面就是重中之重了，填写账户信息！能不能成功就看这个！ 点击下面这个链接登陆客户面板。 https://support.euserv.com/ 然后它会要求你填写详情信息，重点来了嗷！ 重点一，这个街道地址和街道号，我找的实际的香港街道地址和对应的街道号，这个一定得找真实的！ 查找香港英文地址链接： https://www.hongkongpost.hk/correct_addressing/index.jsp?lang=zh_TW 在里面查询关键词\"新界\"之类的，然后使用第二列的街道名称中的名字和街道号，对应第一个箭头的框，第一个框是街道名字，第二个框是街道号。 重点二，城市名称和邮政编码，这个照着虚拟信息填！ 随机虚拟香港个人信息： https://www.meiguodizhi.com/hk-address 对应第二个箭头，第一个框是邮政号，第二个框是城市名称。 重点三，个人手机号，这个照着上面生成的电话号填！ 生成的电话号是XXX-XXXXXXX的形式，对应第三个箭头的两个空格分别填前半部分和后半部分，+86是已经有的，不用改。 第四个箭头里的值不用改，默认就行。 注册完后就能正常使用用户面板了。 记得全英文！不能有汉字！一定得对应做！不然后面审核过不了号就废了！ ","date":"2022-01-20","objectID":"/20220120/:4:0","tags":["linux"],"title":"白嫖永久的免费VPS云服务器(2022.1.16已报废)","uri":"/20220120/"},{"categories":["电脑技巧"],"content":"购买免费的VPS云服务器 申请地址：https://www.euserv.com/en/virtual-private-server/root-vserver/v2/vs2-free.php 也可以登录官网，找到“vServer VS2”会看到“VS2-free”点击申请即可。 需要等待几个小时审核，官方说24~48小时审核完成，我实际6小时不到就审核完毕了。 审核完后是这个样子 服务器有效期一个月，续期大概在你使用的第20天开始可以续期下一个月，下面有自动化脚本部署到腾讯云函数(免费)来实现自动续期。 ","date":"2022-01-20","objectID":"/20220120/:5:0","tags":["linux"],"title":"白嫖永久的免费VPS云服务器(2022.1.16已报废)","uri":"/20220120/"},{"categories":["电脑技巧"],"content":"自动续期的腾讯云函数(免费)脚本 仓库链接： (已反代理加速，直连点击即可，无法登陆账号) 老仓库，只有issues值得一看 2021.11.19更新日志：原仓库脚本↑已经失效，使用下方我改的脚本部署云函数，自测yandex邮箱注册的账号无问题↓（点开python栏）记得修改里面的信息 #! /usr/bin/env python3 # # SPDX-FileCopyrightText: (c) 2020-2021 CokeMine \u0026 Its repository contributors # SPDX-FileCopyrightText: (c) 2021 A beam of light # # SPDX-License-Identifier: GPL-3.0-or-later # \"\"\" euserv auto-renew script v2021.09.30 * Captcha automatic recognition using TrueCaptcha API * Email notification * Add login failure retry mechanism * reformat log info v2021.11.06 * Receive renew PIN(6-digits) using mailparser parsed data download url workflow: auto-forward your EUserv PIN email to your mailparser inbox -\u003e parsing PIN via mailparser -\u003e get PIN from mailparser * Update kc2_security_password_get_token request \"\"\" import os import re import json import time import base64 from email.mime.application import MIMEApplication from email.mime.multipart import MIMEMultipart from email.mime.text import MIMEText from smtplib import SMTP_SSL, SMTPDataError import requests from bs4 import BeautifulSoup # 多个账户请使用空格隔开 USERNAME = \"\" # 用户名或邮箱 PASSWORD = \"\" # 密码 # default value is TrueCaptcha demo credential, # you can use your own credential via set environment variables: # TRUECAPTCHA_USERID and TRUECAPTCHA_APIKEY # demo: https://apitruecaptcha.org/demo # demo2: https://apitruecaptcha.org/demo2 # demo apikey also has a limit of 100 times per day # { # 'error': '101.0 above free usage limit 100 per day and no balance', # 'requestId': '7690c065-70e0-4757-839b-5fd8381e65c7' # } TRUECAPTCHA_USERID = os.environ.get(\"TRUECAPTCHA_USERID\", \"arun56\") TRUECAPTCHA_APIKEY = os.environ.get(\"TRUECAPTCHA_APIKEY\", \"wMjXmBIcHcdYqO2RrsVN\") # Extract key data from your emails, automatically. https://mailparser.io # 30 Emails/Month, 10 inboxes and unlimited downloads for free. # 多个mailparser下载链接id请使用空格隔开, 顺序与 EUserv 账号/邮箱一一对应 MAILPARSER_DOWNLOAD_URL_ID = \"这里填写我下方加粗链接中的仓库里获取到的mailparser的json文件链接ID\" # mailparser.io parsed data download base url MAILPARSER_DOWNLOAD_BASE_URL = \"https://files.mailparser.io/d/\" # Telegram Bot Push https://core.telegram.org/bots/api#authorizing-your-bot TG_BOT_TOKEN = \"TG的机器人TOKEN\" # 通过 @BotFather 申请获得，示例：1077xxx4424:AAFjv0FcqxxxxxxgEMGfi22B4yh15R5uw TG_USER_ID = \"你的TGID\" # 用户、群组或频道 ID，示例：129xxx206 TG_API_HOST = \"https://api.telegram.org\" # 自建 API 反代地址，供网络环境无法访问时使用，网络正常则保持默认 # Email notification RECEIVER_EMAIL = os.environ.get(\"RECEIVER_EMAIL\", \"\") YD_EMAIL = os.environ.get(\"YD_EMAIL\", \"\") YD_APP_PWD = os.environ.get(\"YD_APP_PWD\", \"\") # yandex mail 使用第三方 APP 授权码 # Magic internet access PROXIES = {\"http\": \"http://127.0.0.1:10808\", \"https\": \"http://127.0.0.1:10808\"} # Maximum number of login retry LOGIN_MAX_RETRY_COUNT = 5 # Waiting time of receiving PIN, units are seconds. WAITING_TIME_OF_PIN = 15 # options: True or False CHECK_CAPTCHA_SOLVER_USAGE = True user_agent = ( \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) \" \"Chrome/97.0.4692.71 Safari/537.36\" ) desp = \"\" # 空值 def log(info: str): print(info) global desp desp = desp + info + \"\\n\\n\" def login_retry(*args, **kwargs): def wrapper(func): def inner(username, password): ret, ret_session = func(username, password) max_retry = kwargs.get(\"max_retry\") # default retry 3 times if not max_retry: max_retry = 3 number = 0 if ret == \"-1\": while number \u003c max_retry: number += 1 if number \u003e 1: log(\"[EUserv] Login tried the {}th time\".format(number)) sess_id, session = func(username, password) if sess_id != \"-1\": return sess_id, session else: if number == max_retry: return sess_id, session else: return ret, ret_session return inner return wrapper def captcha_solver(captcha_image_url: str, session: requests.session) -\u003e dict: \"\"\" TrueCaptcha API doc: https://apitruecaptcha.org/api Free to use 100 requests per day. \"\"\" response = session.get(captcha_image_url) encoded_string = base64.b64encode(response.content) url = \"https://api.apitruecaptcha.org/one/gettext\" data = { \"userid\": TRUECAPTCHA_USERID, \"api","date":"2022-01-20","objectID":"/20220120/:6:0","tags":["linux"],"title":"白嫖永久的免费VPS云服务器(2022.1.16已报废)","uri":"/20220120/"},{"categories":["电脑技巧"],"content":"SSH连接 审核完毕后就能通过SSH连接了，如果没有通过，你的邮箱会出现这个样子的邮件 这就说明号废了，你现在登号可能登不上去了了，但可以试试。 审核成功会出现这样子的邮件 审核成功后查看IPV6地址 控制面板地址：https://support.euserv.com/index.iphp 点select选择系统，个人推荐centos7，其他系统比较难装东西 安装系统大概需要10~20分钟，安装成功后再点select可查看下面信息 在左侧的serverdata中找IPV6信息 上图中一个箭头是ipv6转的一个免费域名 第二个箭头是你的管理员密码，如果你和我一样都是选centos7系统，那么系统用户名一样是root 第三个箭头指的是实际的IPV6地址+/128，去掉/128前面那串就是实际的IPV6地址。 到这里已经可以使用SSH客户端连接服务器进行操作了，但本地必须要有IPV6环境才能连，记得前期准备要做好。 SSH客户端下载：点击下载远程SSH工具,下载解压即可使用 提取码： QLHL 打开软件，直接点击左上角会话，选择SSH类型，远程主机框填写自带转的免费域名某某莫de或者填入IPV6地址，然后点击好的创建会话窗口，然后等待连接成功后会出现 填入管理员账号名字(我的是root，我是centos7系统，别的系统不一样的) 然后按回车，它会叫你输入密码 显示如下 root@XXXXXXXXX.DDDDDDDDD.XXXXXX.de's password:这里填密码，输入的时候看不见输入了什么的，输入完毕后按回车就登陆了 登陆失败按r键重试，多次还是失败估计你前面某一步错了。 登陆成功后，什么都别做，先输入下面这串代码按回车执行，不然你装什么都装不上，开启IPV4的出口，使用荷兰出口下载东西 echo -e \"nameserver 2001:67c:2b0::4\\nnameserver 2001:67c:2b0::6\" \u003e /etc/resolv.conf 然后后面就能和正常的云服务器一样装东西了。 ps:只有IPV6地址，装什么面板前缀都是IPV6地址，只能在IPV6环境下访问。 pps：没有IPV4地址，可以使用nginx反代或者cloudflare或者别的方式，使得面板在只有IPV4环境中展示并使用。 ppps：这机子可以搭那啥，你懂的嘿嘿嘿 ","date":"2022-01-20","objectID":"/20220120/:7:0","tags":["linux"],"title":"白嫖永久的免费VPS云服务器(2022.1.16已报废)","uri":"/20220120/"},{"categories":["电脑技巧"],"content":"后言 相关资源收集站点：Github原始仓库链接 上面仓库会及时分享资源信息，有想收取续期脚本更新提示的，建议去仓库右上角watch一下notification一下，邮件获取更新信息。 上述都是个人经验，如果还是不会可以—\u003e点击联系我，有时间或许会帮助一下 欢迎请站长喝一杯！ ","date":"2022-01-20","objectID":"/20220120/:8:0","tags":["linux"],"title":"白嫖永久的免费VPS云服务器(2022.1.16已报废)","uri":"/20220120/"},{"categories":["电脑技巧"],"content":"前言 因为青龙拉取部分作者仓库通过https://ghproxy.com/代理拉取频繁，导致了请求量比较大的仓库被该代理加速作者封禁。所以可以自建代理的链接替换默认的https://github.com/，自己用自己的反代不会封禁，自建代理实现ql repo或ql raw拉取实时的GitHub仓库或文件。 步骤 ","date":"2022-01-19","objectID":"/20220119/:0:0","tags":["linux"],"title":"自建青龙代理拉取Github仓库或文件","uri":"/20220119/"},{"categories":["电脑技巧"],"content":"1.注册cloudflare账号一枚 注册链接：https://dash.cloudflare.com/sign-up 注册不需要特殊条件，只是访问缓慢，当然魔法后更快打开页面就是了。 邮箱也没有要求，我是163邮箱注册。 注册完密码后点击对应邮箱的信件验证账号。 ","date":"2022-01-19","objectID":"/20220119/:0:1","tags":["linux"],"title":"自建青龙代理拉取Github仓库或文件","uri":"/20220119/"},{"categories":["电脑技巧"],"content":"2.创建worker 第四个选项是Workers 点击创建 改动默认前缀，方便自己记住 记住改后的网址，这个打码部分记住备用 创建后需要更改内容，点击更改 记得删除原有的更改 你需要粘贴的代码如下，将该代码复制粘贴覆盖原有的代码 'use strict' /** * static files (404.html, sw.js, conf.js) */ const ASSET_URL = 'https://github.com' const JS_VER = 10 const MAX_RETRY = 1 /** @type {RequestInit} */ const PREFLIGHT_INIT = { status: 204, headers: new Headers({ 'access-control-allow-origin': '*', 'access-control-allow-methods': 'GET,POST,PUT,PATCH,TRACE,DELETE,HEAD,OPTIONS', 'access-control-max-age': '1728000', }), } /** * @param {any} body * @param {number} status * @param {Object\u003cstring, string\u003e} headers */ function makeRes(body, status = 200, headers = {}) { headers['--ver'] = JS_VER headers['access-control-allow-origin'] = '*' return new Response(body, {status, headers}) } /** * @param {string} urlStr */ function newUrl(urlStr) { try { return new URL(urlStr) } catch (err) { return null } } addEventListener('fetch', e =\u003e { const ret = fetchHandler(e) .catch(err =\u003e makeRes('cfworker error:\\n' + err.stack, 502)) e.respondWith(ret) }) /** * @param {FetchEvent} e */ async function fetchHandler(e) { const req = e.request const urlStr = req.url const urlObj = new URL(urlStr) const path = urlObj.href.substr(urlObj.origin.length) if (urlObj.protocol === 'http:') { urlObj.protocol = 'https:' return makeRes('', 301, { 'strict-transport-security': 'max-age=99999999; includeSubDomains; preload', 'location': urlObj.href, }) } if (path.startsWith('/http/')) { return httpHandler(req, path.substr(6)) } switch (path) { case '/http': return makeRes('请更新 cfworker 到最新版本!') case '/ws': return makeRes('not support', 400) case '/works': return makeRes('it works') default: // static files return fetch(ASSET_URL + path) } } /** * @param {Request} req * @param {string} pathname */ function httpHandler(req, pathname) { const reqHdrRaw = req.headers if (reqHdrRaw.has('x-jsproxy')) { return Response.error() } // preflight if (req.method === 'OPTIONS' \u0026\u0026 reqHdrRaw.has('access-control-request-headers') ) { return new Response(null, PREFLIGHT_INIT) } let acehOld = false let rawSvr = '' let rawLen = '' let rawEtag = '' const reqHdrNew = new Headers(reqHdrRaw) reqHdrNew.set('x-jsproxy', '1') // 此处逻辑和 http-dec-req-hdr.lua 大致相同 // https://github.com/EtherDream/jsproxy/blob/master/lua/http-dec-req-hdr.lua const refer = reqHdrNew.get('referer') const query = refer.substr(refer.indexOf('?') + 1) if (!query) { return makeRes('missing params', 403) } const param = new URLSearchParams(query) for (const [k, v] of Object.entries(param)) { if (k.substr(0, 2) === '--') { // 系统信息 switch (k.substr(2)) { case 'aceh': acehOld = true break case 'raw-info': [rawSvr, rawLen, rawEtag] = v.split('|') break } } else { // 还原 HTTP 请求头 if (v) { reqHdrNew.set(k, v) } else { reqHdrNew.delete(k) } } } if (!param.has('referer')) { reqHdrNew.delete('referer') } // cfworker 会把路径中的 `//` 合并成 `/` const urlStr = pathname.replace(/^(https?):\\/+/, '$1://') const urlObj = newUrl(urlStr) if (!urlObj) { return makeRes('invalid proxy url: ' + urlStr, 403) } /** @type {RequestInit} */ const reqInit = { method: req.method, headers: reqHdrNew, redirect: 'manual', } if (req.method === 'POST') { reqInit.body = req.body } return proxy(urlObj, reqInit, acehOld, rawLen, 0) } /** * * @param {URL} urlObj * @param {RequestInit} reqInit * @param {number} retryTimes */ async function proxy(urlObj, reqInit, acehOld, rawLen, retryTimes) { const res = await fetch(urlObj.href, reqInit) const resHdrOld = res.headers const resHdrNew = new Headers(resHdrOld) let expose = '*' for (const [k, v] of resHdrOld.entries()) { if (k === 'access-control-allow-origin' || k === 'access-control-expose-headers' || k === 'location' || k === 'set-cookie' ) { const x = '--' + k resHdrNew.set(x, v) if (acehOld) { expose = expose + ',' + x } resHdrNew.delete(k) } else if (acehOld \u0026\u0026 k !== 'cache-control' \u0026\u0026 k !== 'content-language' \u0026\u0026 k !== 'content-type' \u0026\u0026 k !== 'expires' \u0026\u0026 k !== 'last-modified' \u0026\u0026 k !== 'pragma' ) { expose = expose + ',' + k } } if (ace","date":"2022-01-19","objectID":"/20220119/:0:2","tags":["linux"],"title":"自建青龙代理拉取Github仓库或文件","uri":"/20220119/"},{"categories":["电脑技巧"],"content":"使用方法 很简单 刚刚你记住的网址相当于github.com，只需要替换掉即可。 如果拉取失败，不考虑别的，打开你刚刚记住的网址，在浏览器中打开，查找作者仓库，找作者仓库的raw链接或仓库文件下载链接，如图。 这个是单文件的链接，你右键选则复制链接即可。↓↓↓ 这个是仓库的拉取链接，反代的可能打开缓慢加载，可以先去Github找这个链接，再替换其中的github.com即可。 也是右键右键选则复制链接即可，再替换。↓↓↓ 优点是相当于反代直连，仓库有任何改动你拉取的都不是缓存的内容，更新及时。 每天100,000(10万)次免费请求额度，根本用不完。 实际上你已经搭了一个反代github网站，你点击那个网址打开的网站就是github，除了不能登陆以外，其他所有操作和你魔法后访问GitHub一样，又快又好。 我写几个范例你们就明白了 ","date":"2022-01-19","objectID":"/20220119/:1:0","tags":["linux"],"title":"自建青龙代理拉取Github仓库或文件","uri":"/20220119/"},{"categories":["电脑技巧"],"content":"范例 假设你刚刚记住的链接是这个： “github.yourname.workers.dev” 那么拉取仓库从 ql repo https://github.com/spiritLHL/qinglong_auto_tools.git \"scripts_\" 或 ql repo https://ghproxy.com/https://github.com/spiritLHL/qinglong_auto_tools.git \"scripts_\" 变为 ql repo https://github.yourname.workers.dev/spiritLHL/qinglong_auto_tools.git \"scripts_\" 拉取单文件不大一样，不能直接替换raw.githubusercontent.com，还需要在作者名字后加上/raw/，小白建议打开你那个github.yourname.workers.dev搜索查找脚本，点击raw按钮找到反代raw的链接 拉取单文件从 ql raw https://raw.githubusercontent.com/spiritLHL/qinglong_auto_tools/master/scripts_restore_env.py 或 ql raw https://ghproxy.com/https://raw.githubusercontent.com/spiritLHL/qinglong_auto_tools/master/scripts_restore_env.py 变为 ql raw https://github.yourname.workers.dev/spiritLHL/qinglong_auto_tools/raw/master/scripts_rearblack.py ps:实际就是替换后在仓库名字后面加上/raw/，不打开查找直接替换后加上也行。 pps:有些作者单文件拉取链接里有/blob/，得改成/raw/。 后言 仓库:https://github.com/spiritLHL/qinglong_auto_tools 频道：https://t.me/qinglong_auto_tools 群组：https://t.me/qinglong_auto_tools_chat ","date":"2022-01-19","objectID":"/20220119/:1:1","tags":["linux"],"title":"自建青龙代理拉取Github仓库或文件","uri":"/20220119/"},{"categories":["电脑技巧"],"content":"前言 事先声明，本文为个人内网穿透经验，可能不具备复刻性质，自行查验。 ","date":"2022-01-17","objectID":"/20220117/:0:0","tags":["linux"],"title":"本地ARM机子+云服务vps指定端口内穿+开机自启=外网访问本地机子","uri":"/20220117/"},{"categories":["电脑技巧"],"content":"前期配置 A 腾讯云的VPS一台(配置带宽决定你的上限) — 我的是Ubuntu，内核amd64 B 你需要内穿的本地arm机子一台 — 我的是centos，内核arm32 A购买渠道(1核1G最低端的机子也够用了)： 点我进入优惠渠道 其他系统具体操作步骤一样的只不过用的命令前缀(下载器)不一样而已。 ","date":"2022-01-17","objectID":"/20220117/:1:0","tags":["linux"],"title":"本地ARM机子+云服务vps指定端口内穿+开机自启=外网访问本地机子","uri":"/20220117/"},{"categories":["电脑技巧"],"content":"下载两个安装包(一个arm的一个amd64的) 下载地址：https://github.com/snail007/goproxy/releases amd64： arm： ","date":"2022-01-17","objectID":"/20220117/:2:0","tags":["linux"],"title":"本地ARM机子+云服务vps指定端口内穿+开机自启=外网访问本地机子","uri":"/20220117/"},{"categories":["电脑技巧"],"content":"对应每个机子上传对应压缩包 宝塔使用宝塔面板的上传即可，如果没有宝塔，自行使用wget下载到服务器中。 分别上传对应内核的压缩包后，分别解压，如果宝塔内的使用宝塔面板点击解压，如果没有宝塔，自行使用unzip解压。 解压完毕后，只有A也就是你的服务端需要手动安装。 手动安装脚本： A中执行(对应那个amd64文件解压的路径下)(root权限) wget https://mirrors.host900.com/https://raw.githubusercontent.com/snail007/goproxy/master/install.sh chmod +x install.sh ./install.sh ","date":"2022-01-17","objectID":"/20220117/:3:0","tags":["linux"],"title":"本地ARM机子+云服务vps指定端口内穿+开机自启=外网访问本地机子","uri":"/20220117/"},{"categories":["电脑技巧"],"content":"设置服务器凭证 命令会在本地生成两个文件proxy.crt proxy.key, 相当于账号和密码，用于服务连接的验证。 A中执行(对应那个amd64文件解压的路径下)(root权限) sudo proxy keygen -C proxy ","date":"2022-01-17","objectID":"/20220117/:4:0","tags":["linux"],"title":"本地ARM机子+云服务vps指定端口内穿+开机自启=外网访问本地机子","uri":"/20220117/"},{"categories":["电脑技巧"],"content":"启动服务端 在云服务器也就是A中启动goproxy的server端 这里设定goproxy服务端与客户端的通信端口为8802。8801属于服务器访问端口，之后我们访问云服务器IP:8801就可以正常访问本地arm机子的5700界面。5700属于本地你需要内穿的端口，如修改这里需要填上自己的。 A中执行(对应那个amd64文件解压的路径下)(root权限) sudo proxy bridge -p \":8802\" -C proxy.crt -K proxy.key --daemon sudo proxy server -r \":8801@:5700\" -P \"127.0.0.1:8802\" -C proxy.crt -K proxy.key --daemon ","date":"2022-01-17","objectID":"/20220117/:5:0","tags":["linux"],"title":"本地ARM机子+云服务vps指定端口内穿+开机自启=外网访问本地机子","uri":"/20220117/"},{"categories":["电脑技巧"],"content":"arm机子部署goproxy客户端 arm机子不需要安装，直接使用解压后的文件。 但要注意，需要上传之前生成的服务器凭证。 上传到与解压文件的同一文件夹下 B中执行(对应那个armV6文件解压的路径下)(root权限) sudo ./proxy client -P 云服务器ip:8802 -C proxy.crt -K proxy.key 到此如没有报错访问云服务器IP:8801就可以访问到本地arm机子内网的5700端口了。 但这个启动是需要一直运行的，所以最好安装screen窗口长期挂起，或者直接nohup挂起。 使用ctrl+Z键停止B中的服务。 ","date":"2022-01-17","objectID":"/20220117/:6:0","tags":["linux"],"title":"本地ARM机子+云服务vps指定端口内穿+开机自启=外网访问本地机子","uri":"/20220117/"},{"categories":["电脑技巧"],"content":"A(服务器端)设置开机自启 A机子中，因为执行过一遍就会稳定执行了，不需要自己再挂起任务，所以可以不一定得设置开机自启，你只需要记得每次重启服务器执行一下这行命令即可。 A执行：(这里内容和你上面的命令一样的，参照一下) sudo proxy server -r \":8801@:5700\" -P \"127.0.0.1:8802\" -C proxy.crt -K proxy.key --daemon 如果上述命令你记得执行，那就不需要看下面的了，跳转下一步骤。 A中创建一个新文件autostart.sh(随便路径，但最好和你安装goproxy的路径一样，方便记忆) 内容：(这里第二行内容和你上面第一次部署的命令一样的，参照一下) cd /Date-iterms/frp sudo proxy server -r \":8801@:5700\" -P \"127.0.0.1:8802\" -C proxy.crt -K proxy.key --daemon 记住这个文件的路径，保存后打开新路径/etc/init.d 创建新文件ghproxy(注意没有后缀，就是ghproxy) 写入内容：(修改路径为autostart.sh所在路径，这里我的是/Date-iterms/frp，你的不一样自己改) #!/bin/sh ### BEGIN INIT INFO # Provides: XXX # Required-Start: $remote_fs $syslog # Required-Stop: $remote_fs $syslog # Default-Start: 2 3 4 5 # Default-Stop: 0 1 6 # Short-Description: start XXX # Description: start XXX ### END INIT INFO goproxy_path=/Date-iterms/frp #你的那个autostart.sh文件所在路径 case \"$1\" in start) echo \"start goproxy service..\" sh ${goproxy_path}/autostart.sh ;; *) exit 1 ;; esac 保存 A中执行(当前路径下)(root权限) sudo chmod 755 /etc/init.d/ghproxy cd /etc/init.d sudo update-rc.d ghproxy defaults 若显示未安装update-rc.d，参照 https://blog.csdn.net/willingtolove/article/details/107494719 安装 测试服务是否能启动成功，shell命令如下： sudo service ngrok start 检查自启动的服务，shell命令如下： sudo sysv-rc-conf ","date":"2022-01-17","objectID":"/20220117/:7:0","tags":["linux"],"title":"本地ARM机子+云服务vps指定端口内穿+开机自启=外网访问本地机子","uri":"/20220117/"},{"categories":["电脑技巧"],"content":"B(客户端)设置开机自启 编写脚本，脚本内容如下(创建路径必须为/etc/rc.d/init.d) 这里我的armv6文件解压在/root/proxy中，所以写/root/proxy，不一样的自行更改。 (这里最后一行内容和你上面第一次部署的命令一样的，参照一下) #!/bin/bash #chkconfig:2345 80 90 cd /root/proxy sudo ./proxy client -P 服务器IP:8802 -C proxy.crt -K proxy.key B中执行(执行路径/etc/rc.d/init.d)(root权限) 这里第三行有的会执行报错，不用理会 chmod +x /etc/rc.d/init.d/autostart.sh cd /etc/rc.d/init.d chkconfig --add autostart.sh chkconfig autostart.sh on ","date":"2022-01-17","objectID":"/20220117/:8:0","tags":["linux"],"title":"本地ARM机子+云服务vps指定端口内穿+开机自启=外网访问本地机子","uri":"/20220117/"},{"categories":["电脑技巧"],"content":"此时完成开机自启的所有步骤。 可以重启B试一下是否开机自启了。 后言 我的机子是arm32，用的armV6，如果你的机子是别的arm，需要使用的是armV7或armV8。 内穿速度取决于你的服务器速度，带宽啥的。 如果你内穿多个端口，那么只需要在B中链接过A，A中多次执行类似下面这行命令就行了(aaaa是A中端口，bbbb是B中端口) sudo proxy server -r \":aaaa@:bbbb\" -P \"127.0.0.1:8802\" -C proxy.crt -K proxy.key --daemon 推一波项目合集：(仓库说明就是合集) https://github.com/spiritLHL/Hang-up-items ","date":"2022-01-17","objectID":"/20220117/:8:1","tags":["linux"],"title":"本地ARM机子+云服务vps指定端口内穿+开机自启=外网访问本地机子","uri":"/20220117/"},{"categories":["python","数学建模"],"content":"前言 论文配套的代码均为本人编写，第三四问存在部分代码问题，需要改动细节部分才能运行成功，后面两问的代码时间成本很高，长则数小时，短则十几二十分钟，自己跑酌情修改迭代次数，转换赛题要求的填表格式得通过最后部分的代码才能转换。 完整材料详见博客相关资源 ","date":"2021-10-03","objectID":"/20211003/:1:0","tags":["python"],"title":"2021年全国大学生数学建模竞赛C题省一等奖代码部分","uri":"/20211003/"},{"categories":["python","数学建模"],"content":"代码 import numpy as np import pandas as pd import matplotlib.pyplot as plt import matplotlib.gridspec as gridspec import time,random plt.rcParams['font.sans-serif'] = ['SimHei'] # 用来正常显示中文标签 plt.rcParams['axes.unicode_minus'] = False # 用来正常显示负号 # 第一问 #原始数据 data1 = pd.read_excel(r'附件1 近5年402家供应商的相关数据.xlsx',sheet_name='企业的订货量（m³）') data2 = pd.read_excel(r'附件1 近5年402家供应商的相关数据.xlsx',sheet_name='供应商的供货量（m³）') #企业订货量 temp1 = data1.set_index('供应商ID').drop(['材料分类'],axis=1) #供应商供货量 temp2 = data2.set_index('供应商ID').drop(['材料分类'],axis=1) #订货量与供货量的差值 temp3 = temp2 - temp1 #材料分类系数 Dtype = list(data1['材料分类']) Ddata = [0.95,0.86,0.79] D = [] for i in Dtype: if i == 'A': D.append(Ddata[0]) elif i == 'B': D.append(Ddata[1]) elif i == 'C': D.append(Ddata[2]) else: continue #构造趋势函数 def f(x): if x \u003c 0: return 4-4*(0.8)**x elif x \u003e= 0: return (0.5)**x else: pass #画趋势图 plt.figure() x=list(np.linspace(-1,1)) y = [f(i) for i in x] plt.plot(x,y) plt.xlabel('t') plt.ylabel('y') plt.savefig('qushi.jpg') plt.show() #供货量与订货量的差值比企业订货量 temp4=temp3/temp1 temp4 = temp4.fillna(0) #计算供货商每周得分 roworder = 0 ttp = [] for row in temp3.itertuples(): lineorder = 0 rowlist = [] for i in list(row)[1:]: #计算供应商每周对应综合得分 tp = f(np.array(temp4)[roworder][lineorder])*abs(np.array(temp2)[roworder][lineorder])*D[roworder] rowlist.append(tp) lineorder +=1 roworder +=1 ttp.append(rowlist) #计算供货商总得分 d1 = [] for i in ttp: d1.append(sum(i)) #构造供货商总得分表 df1 = pd.DataFrame(d1) #构造问题一供货商综合得分表 ttpp = ttp.copy() count = 0 for i in ttpp: ct = 0 i.append(Dtype[count]) i.append(d1[count]) count +=1 index = temp1.index.values columns = data1.columns.values[2:] index = list(index) columns = list(columns) columns.append('材料分类') columns.append('得分') w1_defen = pd.DataFrame(ttpp,index=index,columns=columns) #w1_defen.to_csv('问题一供货商得分表.csv') #供货商综合得分表排序后得到最优的50个供货商 df1_data = df1.sort_values(by=[0],ascending=False).head(50) #最优的50家供货商得到的订购量 tptp = [] for i in list(df1_data.index): tptp.append(pd.DataFrame(list(data1.iloc[i])).T) dff1 = pd.concat(tptp) #dff1.to_csv('dff1.csv') #最优的50家供货商提供的供货量 tptp = [] for i in list(df1_data.index): tptp.append(pd.DataFrame(list(data2.iloc[i])).T) dff1 = pd.concat(tptp) #dff1.to_csv('df1.csv') #第二问 #第二问 #50家供应商的一周总平均提供 temp5 = dff1.set_index(0).drop([1],axis=1) tp = temp5.std(axis=1)#具体方差表 tmp = temp5.median(axis=1)#具体中位数 index = list(tp.index) fc_values = list(tp) zvs_values = list(tmp) #方差中位数图 plt.figure(figsize=(25, 10), dpi=60) x = np.linspace(1,len(index)) y1 = fc_values#方差 y2 = zvs_values#中位数 plt.plot(x,y1,x,y2) plt.show() #突变稳定初筛选 tubian_list = [] wending_list = [] for i in fc_values: if i \u003e= 300:#方差大于300 addres = fc_values.index(i) if zvs_values[addres] \u003c= 100:#中位数小于100 tubian_list.append(index[addres]) else: wending_list.append(index[addres]) else: addres = fc_values.index(i) wending_list.append(index[addres]) #处理类型成本 Dtype50 = [] for i in np.array(dff1): Dtype50.append(i[1]) Ddata50 = [0.6,0.66,0.72] D50 = [] for i in Dtype50: if i == 'A': D50.append(Ddata50[0]) elif i == 'B': D50.append(Ddata50[1]) elif i == 'C': D50.append(Ddata50[2]) else: continue #已订购的平均值 you0 = list((temp5 == 0).astype(int).sum(axis=1)) sum_temp5 = list(temp5.sum(axis=1).values) fei0 = [240 - i for i in you0] mean_temp5 = np.array(sum_temp5)/np.array(fei0) #按顺序提取最低限度的供应商 index = list(dff1[0]) pj_values = list(mean_temp5) sum_cn = 0 ct = 0 count = 0 pjcn = [] ljcn = [] for i in mean_temp5: sum_cn = sum_cn + (i/D50[ct]) ljcn.append(sum_cn) pjcn.append((i/D50[ct])) if sum_cn \u003c 28200: count+=1 ct+=1 continue else: break gys = list(dff1[0].values)[0:count+1] cpt = Dtype50[0:count+1] gys23 = pd.DataFrame([gys,cpt,pjcn,ljcn],index=['供应商ID','材料分类','供应商平均产能','累计产能']).T.set_index('供应商ID') #gys23.to_excel('选择的23个供应商.xlsx') #看看原始23家的供货商供货量图 #for i in gys: #if i in tubian_list tpw = [] for i in gys: tpw.append(np.array(temp5.T[i])) biao23 = pd.DataFrame(tpw) count = 0 for j in tpw: y = tpw[count] x = biao23.columns.values plt.figure() plt.plot(x,y) plt.xlabel(gys[count]) plt.show() time.sleep(2)","date":"2021-10-03","objectID":"/20211003/:2:0","tags":["python"],"title":"2021年全国大学生数学建模竞赛C题省一等奖代码部分","uri":"/20211003/"},{"categories":["python","数学建模"],"content":"前言 博客展示的是机器转义的markdown格式的，部分内容无法正常展示，完整内容详见博客相关资源。 论文配套的代码均为本人编写，第三四问存在部分代码问题，需要改动细节部分才能运行成功，后面两问的代码时间成本很高，长则数小时，短则十几二十分钟，自己跑酌情修改迭代次数，转换赛题要求的填表格式得通过最后部分的代码才能转换。 省一等奖。。。还是有点小遗憾啊 感谢组员的论文编写和组长和我的解题思路探讨 ","date":"2021-10-02","objectID":"/20211002/:1:0","tags":["python"],"title":"2021年全国大学生数学建模竞赛C题省一等奖论文部分","uri":"/20211002/"},{"categories":["python","数学建模"],"content":"正文 生产企业原材料的订购与运输策略 摘要 本文研究生产企业原材料订购与运输策略，根据原材料供应商和转运商往年数据，结合产能、成本要求，制定采购以及运输策略，根据不同要求，规划制定企业未来24周最优的原材料订购和转运方案。 针对问题一：利用402家供应商过去250周的订货和供货数据，提取供货商评价特征，综合考虑了供货能力、供货稳定性、供货类别三项指标，建立供货稳定性评价函数为 ，对A、B、C原材料进行加权，利用Borda-排序法建立供应商综合评分体系S，并对得分前50的供应商进行特征分析，分为稳定型供应商和突变型供应商，。 针对问题二：按得分排序，以累积转化产能2.82万为阈值，选取前23家供应商满足企业生产。先制定最经济采购方案，再制定最优转运方案，为两个单目标规划问题。对23家供应商订货量进行规划，稳定供应商过去250周供货量符合正态分布，采用蒙特卡洛算法，突变供应商采用遗传算法预测，突变概率为 目标函数原料成本，迭代循环求解最优值，制定最经济订购方案。周平均最经济订购费用为：20825。以转运历史数据非0平均值作为指标，对转运商进行排序，采用随机抽样法生成未来24周每家转运商转运商的损耗率。转运方案采用逆向选择，转运商按照排名，选择多家供应商进行转运。损耗量最小为目标，利用动态规划进行决策，生成的最优转运方案。 针对问题三：从供给侧调整原材料订购比例，优先选择A类材料供应商合作，重新选取了31家供货商保障生产。该问题为多目标规划，目标为采购成本、转运成本、损耗成本、原料A、C订购量差值，以产能和转运能力为约束，进行多目标规划模型求解，转运方案选择思路同第一问，使得损耗率小的转运商转运数量优先达到最大或接近最大。解得的最优采购以及转运方案，24周的原料和损耗总成本为533642。 针对问题四：依据得分和产品类别，以平均供货累积和48000为阈值，选取134家供货商保障生产。供应商均作为稳定型供应商以简化模型，采用蒙特卡洛算法生成订购表，一家转运商可选取多家供应商提供转运，平均损耗率小的转运商优先选择A类原料供应商，利用动态规划模型求解最佳转运计划，计算总成本S，迭代10000次寻找最优订购以及转运方案。计算周平均产能为7.4万立方米，可得出企业每周的产能可以提高 4.93万立方米。 关键词： Borda-排序 蒙特卡洛算法 动态规划 多目标规划 一、问题重述 ","date":"2021-10-02","objectID":"/20211002/:2:0","tags":["python"],"title":"2021年全国大学生数学建模竞赛C题省一等奖论文部分","uri":"/20211002/"},{"categories":["python","数学建模"],"content":"1.1 问题背景 某建筑和装饰板材的生产企业在生产中主要用到A、B、C三种不同类型的木质及其他的植物纤维材料。相关材料由订购的原材料供应商（也称\"供应商\"）进行提供，并由第三方的物流公司（也称\"转运商\"）进行运输，将货物运送到企业仓库进行储存和使用。该企业每年规划使用48周进行生产，考虑到需要保持生产活动的持续性，需要在生产活动的前24周制定各类原材料的订购和运输计划。 该企业每周的产能为2.82万立方米，每生产一立方米的产品需要消耗0.6立方米A类原材料、0.66立方米B类材料、0.72立方米C类原材料。由于原材料的特殊性，供货商可能存在不能完全按照企业提出的订货量需求进行供应的情况，既实际的供货量可能高出或者低于订货量。故在保证企业正常生产的前提下，该企业最好可以保持库存的原材料足够维持企业两周的生产所需，（三类原材料的储存和运输单价均相同）为此，企业通常对供货商提供的原材料全部收购。 在实际的运输过程中，原材料存在着一定的损耗（（损耗量/供货量） 的值称为\"损耗率\"），故企业仓库实际收到的由转运商所运输的货物数量称为\"接收量\"。每家转运商的货物转运能力均为6000立方米/周。在一般情况下，一家转运商一周只能运输一家供货商的货物。 原材料的采购成本将直接影响到企业的生产效益，且在实际中，A类与B类原材料的采购单价分别比C类原材料的高20%与10%。 ","date":"2021-10-02","objectID":"/20211002/:3:0","tags":["python"],"title":"2021年全国大学生数学建模竞赛C题省一等奖论文部分","uri":"/20211002/"},{"categories":["python","数学建模"],"content":"1.2 问题提出 根据以上的背景及附件数据，需要解决以下四个问题： 根据附件一，对文件中给出的402家供货商的供货特征进行量化分析，建立起基于保证企业正常生产重要性的数学模型，并在此基础上确定50家最重要的供货商，在论文中列表给出结果。 参考上一问的结果，求解该企业至少需要选定多少家供应商进行原材料供应方可满足生产需要。并针对这些供货商，为企业制定未来24周每周的最经济的原料订购方案，并由该方案制定运输损耗最小的转运方案，最后分析方案的实际实施效果。 该企业为了节省开支，压缩生产成本，现计划对A类原材料加大采购力度，同时对C类原材料的采购进行缩减，以此来减少运输及储存的成本，同时希望转运商在转运过程中对商品的损耗尽可能的减少。请制定新的订购方案及转运方案，最后分析方案的实际实施效果。 该企业在技术改造后具备了提高产能的潜力。请根据现有的原材料供应商和转运商的实际情况，确定该企业每周产能的提高量，最后给出未来24周的订购和转运方案。 二、问题假设 假设1：各供货商和转运商的运营情况稳定，短时间不会出现破产情况； 假设2：忽略转运过程中出现交通事故导致原材料大规模损失的情况； 假设3：企业仓库足够大，能够全部接收供货商的原材料； 假设4：假设订货与供货都在一周内完成； 假设5：题目所给数据真实可靠； 三、符号说明 详见原文文档 注：未列出符号及重复符号以出现处标注为准 四、问题分析 ","date":"2021-10-02","objectID":"/20211002/:4:0","tags":["python"],"title":"2021年全国大学生数学建模竞赛C题省一等奖论文部分","uri":"/20211002/"},{"categories":["python","数学建模"],"content":"4.1 问题一分析 为保障企业生产，对于供应链这一环最重要的就是保障原材料的供应。对于一家供应商来说，考量指标为供货能力和供货稳定性。原料供应能力表现为单次供应量的多少，供货稳定性表现为供应量与预定量的差值。当差值为负，即供应量小于预定量，企业就有由于原材料供应不足而导致产能不足的情况出现的可能性，故该种情况从根本上阻碍了企业生产，对企业影响较大。当差值为正，即供应量大于预定量，造成库存积压，增加成本，但不会影响企业的产能需求，且在本题中不考虑原料贮藏成本，所以此种情况对于企业生产影响较小。故建立函数 表征供应商的供货稳定性。将建立评价模型对供应商进行评价，由于企业制造产品所需原料量不同，产品类别也直接影响了企业生产，则针对不同原材料进行加权处理，权重为 故选取供货能力、供货稳定性和供货类别为供应商的供货特征，对供应商特征进行量化分析，建立组合评价模型。对每家供应商依据已有的订货量、供货量数据进行评分，得分为S。S与供货能力、供货稳定性和权重呈正相关。企业应该选取有着较强的供货能力、供货稳定性较好的供应商来保证企业稳定生产。 ","date":"2021-10-02","objectID":"/20211002/:5:0","tags":["python"],"title":"2021年全国大学生数学建模竞赛C题省一等奖论文部分","uri":"/20211002/"},{"categories":["python","数学建模"],"content":"4.2 问题二分析 问题二首先要求选择足够数量的供应商进行原材料供应，也就是各家供应商每周提供的原材料至少在理论上可以满足该企业每周的产能需求。在问题一建立的评价体系下，得到了排名前50的满足企业生产要求的供应商ID，那么这些\"优良\"供应商就是我们的重点考虑对象。 在对这些供应商五年来的供货曲线分析后，发现由这些供应商的供货特点可以将其分为三大类：第一是持续供货的稳定型供应商，第二是长时间不供货，但存在极大的供货峰值的突变型供应商（且其峰值的出现周期大约为12周一次），第三是既存在持续供货阶段，又具有较大供应能力的综合型供应商。在对供应商按照其提供的A、B、C类材料分类后，对每个供应商的供应量取周平均值（该供应商的总供货量/订货天数），并将供应量换算为对应的产能数据，按照产能从高到低的顺序相加，直至达到2.82万立方米的每周产能需求，便可求得供应商的最小数量。 题目还要求为该企业制定未来24周中每周的最经济原材料订购方案，则该方案的目标为最经济，既购买成本最小化，同时满足约束条件。故该问题转化为多层次单目标规划问题。其中，稳定型和综合型供应商的供货能力稳定，故作为长期供货目标进行选择。但由于原材料的特殊性导致的发货误差（该误差不可控，难以预测），存在导致库存量不足而影响生产的可能性，故突变型供应商作为产能不足预警出现时的补充，最后得到最经济的原材料订购方案。 在最优订购方案产生后，对附件二中各转运商的损耗率数据进行分析，得到转运商的优劣及其排名，则考虑让较优的转运企业优先选择订单，并尽可能的多运输原材料，以达到原材料损耗最小的目标。 ","date":"2021-10-02","objectID":"/20211002/:6:0","tags":["python"],"title":"2021年全国大学生数学建模竞赛C题省一等奖论文部分","uri":"/20211002/"},{"categories":["python","数学建模"],"content":"问题三分析 该问要求尽可能的减少采购C类原材料，多采购A类原材料，则通过分析生产单位产品需要的三类原材料的量以及对应的成本价与运输估计费用（只与原材料量的多少有关）得到三类原材料对于该企业生产单位产品的经济数据。 在确定最优订购方案之前，首先在各家供应商的周平均供货值对应的产能之和满足企业的周产能需求前提下，优先对提供经济数据好的原材料的供应商进行选择。 在供应商选择完毕后，该题需要在订购方案最优的情况下，同时满足转运消耗最少，既订购方案的选定与转运方案的选定同时进行，总目标为订购原材料的费用与转运损耗带来的经济损失的和最小，故将该问题转化为单目标动态规划问题。 ","date":"2021-10-02","objectID":"/20211002/:7:0","tags":["python"],"title":"2021年全国大学生数学建模竞赛C题省一等奖论文部分","uri":"/20211002/"},{"categories":["python","数学建模"],"content":"问题四分析 该企业具备提高产能的潜力，即产能不设上限，供货商为402家，通过计算，原料供给充足。则产能的提升取决于转运能力，那么让8家转运商均全力转运，以提升企业产能。产能与原料类别有关，由于原材料A、B、C生产单位产品所需的量依次降低。则应尽可能多的采购料A，其次为B和C。优先用转运损耗较小的转运商转运原料A，后调节原材料比例以及损耗量来提升产能。 五、问题一的模型建立与求解 ","date":"2021-10-02","objectID":"/20211002/:8:0","tags":["python"],"title":"2021年全国大学生数学建模竞赛C题省一等奖论文部分","uri":"/20211002/"},{"categories":["python","数学建模"],"content":"5.1 问题分析 供应商的原材料供应能力对保障企业的正常生产具有重要影响，根据题目对产能的要求进行分析，供应商的考量指标为供货能力和供货稳定性，供货稳定性表现为供应量与预定量的差值。当差值为负数时，可能导致企业产能不足，故该情况一定会妨碍企业生产；当差值为正数时，有可能造成产品积压导致库存量上升，但至少不会影响企业的产能需求，且该问不考虑储存费用的影响，则该种情况对企业产生的影响较小。 故建立函数 表征供应商的供货稳定性，建立评价模型对供应商进行评价。其次原材料类别也直接影响企业生产，则针对不同原材料进行加权处理。 选取供货能力、供货稳定性和供货类别为供应商的供货特征，对供应商特征进行量化分析，建立组合评价模型，得到供应商排名，企业择优进行选择。 图1问题一解决流程图 ","date":"2021-10-02","objectID":"/20211002/:9:0","tags":["python"],"title":"2021年全国大学生数学建模竞赛C题省一等奖论文部分","uri":"/20211002/"},{"categories":["python","数学建模"],"content":"5.2 模型建立 设供货稳定性评价函数为 其中： 依据 对于供应能力的影响，当差值为负，即供应量小于预定量，从根本 上阻碍了企业生产，有出现企业产能不足的风险；当差值为正，即供应量大于预定量，易造成库存积压，增加生产成本，由于本题中不考虑原料储存成本，则该情况对于企业生产影响较小。 根据此特点， 选用指数函数模型。当 时，采用指数段的突变部分，当 时，采用指数函数中缓慢变化的部分。 确定不同类别原料权重 由于企业对于生产每立方米产品需消耗 A 类原材料、B类原材料和C类原材料需求不同，则产品对于不同原材料的依赖性不同。制造每立方米产品需消耗原材料越少，则产品对于原材料的的依赖性越高，原材料对应权重越高；制造每立方米产品需消耗原材料越多，则产品对于原材料的的依赖性越高，原材料对应权重越低。（依赖性特指：缺少同样的量，对于产能的影响。）据此特点，三类原材料权重 建立供应商综合评价模型 设供应商综合得分为S，S与供货能力、供货稳定性和权重呈正相关；设 n代表企业对供应商订货量不为0的总周数； 指供应量，代表供应商供货能力； ","date":"2021-10-02","objectID":"/20211002/:10:0","tags":["python"],"title":"2021年全国大学生数学建模竞赛C题省一等奖论文部分","uri":"/20211002/"},{"categories":["python","数学建模"],"content":"5.3 模型求解 求解供货稳定性评价函数 代表供货稳定性，取范围为[-1,1] 。 当预定量=供货量时，即 时，t=0，供货稳定性最佳， 。 当有订货没有供货时，即 时，t=-1，供货稳定性最差，为 当预定量\u0026lt;供货量时，即 时，呈指数型缓慢变化曲线段； 当预定量\u0026gt;供货量时，即 时，呈指数型迅速变化曲线段。 根据以上特征，结合原料对于生产企业产能影响规律，解得: 图2 供货稳定性评价函数图 求解不同类别原料权重 代入数据得： 化简并归一化，取值为： 求解供应商综合评价模型： 代入 得出供应商评价模型。 对402家供应商进行综合评价，进行得分排名，选出50名最重要供应商。50名最重要供应商如下表： 表1 50名供应商ID S229 S131 S307 S040 S086 S361 S308 S143 S338 S210 S140 S330 S395 S364 S003 S108 S356 S247 S367 S114 S282 S268 S374 S055 S273 S151 S306 S284 S346 S189 S275 S348 S126 S080 S078 S329 S352 S037 S294 S292 S340 S201 S031 S218 S074 S139 S194 S365 S244 S291 其中，通过对所选择重要企业进行分析可得，绘制出50家供应商的供货量方差与中位数可得，对于保障企业生产比较重要的企业大致分为两类： 第一类：可以长期稳定对企业进行供货，供货稳定性高的供应商，这类供应商方差较小，中位数较高（以S361为代表） 第二类：供货能力极强，可以满足企业超大订货需求的供应商，这类供应商与企业不进行稳定合作，却可以对企业提供关键帮助，供应紧急订单，这类供应商供货数据方差极大，中位数极小。（以S140为代表） 图3 50家供应商方差与中位数数据图 图4两类供应商的发货历史数据图（左一右二） 六、问题二的模型建立与求解 ","date":"2021-10-02","objectID":"/20211002/:11:0","tags":["python"],"title":"2021年全国大学生数学建模竞赛C题省一等奖论文部分","uri":"/20211002/"},{"categories":["python","数学建模"],"content":"6.1 问题分析 题目要求求得最小的供应商数量，既在该数量的供应商进行供货的情况下，该企业的每周产能需求得以满足。又考虑到由于在订购方案欠佳的情况下，即使所选的供应商供货充足，也可能导致一些离散的产能不足的情况出现，故该问题求解时忽略订购方案不同带来的影响，只要所选各供应商的周平均供应量的总和达到企业的每日产能，则从理论上，这些供应商能够满足企业的生产需求，从而求得最小的供应商数量。 在对该企业未来24周的采购计划进行规划时，考虑到供应商的不同供应特点，我们将突变型供应商与稳定型、综合型供应商作为两大类考虑，对后者进行规划以保证供应总量的稳定性，突变型供应商作为产能储备不足预警情况出现时的补充，从而得到最优的订购方案。 在最优订购方案产生后，对转运商的相关数据进行分析，得到转运商的优劣，则最优的转运思路既为让较优的转运商优先进行转运选择，并尽可能饱和其转运能力，则该问题转化为损耗最小化的动态规划问题。 ","date":"2021-10-02","objectID":"/20211002/:12:0","tags":["python"],"title":"2021年全国大学生数学建模竞赛C题省一等奖论文部分","uri":"/20211002/"},{"categories":["python","数学建模"],"content":"6.2 模型建立 6.2.1 确定供应商的最小数量 在第一问中得到的50家最重要的供应商中，对每个供应商的供货量对应的产能求周平均值 （j为附件一中供应商ID），对其由大到小顺序排序，得到序列 （i为排序的序号），则该企业产能的周平均值为 ，当满足以下条件时： 的值为所求的供应商最小数量。 6.2.2 最优订购方案规划问题模型建立 目标函数的确立： 该问的目标是确立前24周最经济的原材料选购方案，由于A、B、C类原材料的订购价格不同，且企业对原材料的生产种类不做改变，则最优化目标可以确立为从不同供应商中订购的A、B、C类原材料的订购价格之和最小，目标函数如下： 约束条件： 每周的订购方案应该保证至少不会影响企业的正常产能，并且企业每周的最大原材料数量不得超过八家转运商的单周最大转运能力，约束条件如下： 为满足库存至少够两周的生产所需，我们考虑在第一周就订购两周生产所需的原材料，故： 第一周的产能约束为： 第一周的剩余产能： 第二周的产能约束为： （12）（13）联立得： ） 同理得第三周的产能约束为： 第n周的产能约束为： 6.2.3 最优转运方案模型的建立 转运商数据分析： 通过对附件二中各家转运商5年来的运输损耗率作图如下：（以转运商1、4为代表） 图5转运商1的运输损耗率图 图6转运商4的运输损耗率图 可以发现，以转运商1、4为代表的各家转运商5年来的运输损耗率并没有显著的统计学分布规律。但对于不同的转运商而言，其损耗率的大小存在明显差异。下图为转运商2的运输损耗率图： 图7转运商2的运输损耗率图 将转运商1与转运商2的运输损耗率图像对比，可以明显发现转运商2的损耗率峰值数量更少，且大部的运输损耗率均小于转运商1的，故转运商2的转运可靠性（与原材料的运输损耗成反比）大于转运商1的。 对于转运商3来说，其运输损耗率在五年的时间内均居于较低水平，只有一个损耗率峰值出现，说明该转运商的转运能力也较为出色。下图为转运商3的运输损耗率图： 图8转运商3的运输损耗率图像 综合以上分析，我们选取各转运商5年来的运输损耗率周平均值（计算公式为：5年内企业的运输损耗率总和/运输天数）来反映转运商转运水平的优劣。 目标函数的确定： 该问题要求在最佳订购方案已经确定的情况下，确定最佳的转运方案，每家转运商的周平均转运损耗率为： 各转运商的优劣排名与 值的大小成反比。由于题目要求的时间周期为24周，附件二中给出了5年的损耗率数据，故我们考虑，某转运商在未来24周内出现的损耗率数据与过去5年的数据具有一定的映射关系。我们通过对过去五年非0的转运损耗率随机抽样，作为转运商未来24周的转运损耗率。则转运损耗最小化的目标函数如下： 约束条件： 在最优订购方案已经确定的情况下，问题求解需要满足的约束条件为： 其次考虑到转运商的转运能力差异，应当尽可能饱和优秀转运商的转运能力，既 的值尽可能小。 ","date":"2021-10-02","objectID":"/20211002/:13:0","tags":["python"],"title":"2021年全国大学生数学建模竞赛C题省一等奖论文部分","uri":"/20211002/"},{"categories":["python","数学建模"],"content":"6.3 模型求解 6.3.1确定供应商的最小数量问题求解 将附件一数据依照要求带入上式计算，可得供应商的最小数量为23个，下面为得到的23家供应商的相关数据： 表2 求得的23家供应商数据表 供应商** ID ** ** 材料分类 ** ** 供应商平均产能 ** ** 累计产能** S229 A 2464.493 2464.493 — — — — S361 C 1898.611 4363.104 S140 B 2089.712 6452.816 S108 B 1521.149 7973.965 S282 A 1175.972 9149.938 S151 C 1125.567 10275.5 S275 A 1101.063 11376.57 S329 A 1086.931 12463.5 S340 B 1082.235 13545.73 S139 B 1036.459 14582.19 S131 B 868.1313 15450.32 S308 B 864.8864 16315.21 S330 B 862.702 17177.91 S356 C 754.0914 17932 S268 C 751.0764 18683.08 S306 C 729.7222 19412.8 S348 A 793.9948 20206.8 S352 A 618.2708 20825.07 S201 A 4880.298 25705.36 S194 C 586.603 26291.97 S307 A 762.1442 27054.11 S143 A 574.9097 27629.02 S395 A 1708.176 29337.2 图9 23家供应商的相关数据（图中最下的数据为供应商ID，均省略S） 6.3.2 最优订购方案规划问题模型求解 供应商按照其供货特点，分为两大类，第一类由稳定型与综合型供应商组成，第二类由突变型供应商组成。对附件一中供应商的历史供货数据进行分析后，将6.3.1中23家供应商依照供货类型进行分类，可得下表： 表3供应商的供应类型分类表 供应类型 供应商ID 稳定型 S229 S361 S282 S275 S329 S340 S131 S356 S268 S306 S352 S194 S143 S395 综合型 S108 S201 S348 S330 S308 S151 突变型 S140 S139 S307 将第一问得到的50家最重要公司5年来的供货量随时间变化的图像画出，可以清晰的得到三类供应商的供货特点如下: 图10稳定型供应商供货量数据图像 图11 综合型与突变型供应商供货量数据图像（左综右突） 转运商选择供应商供货，采用动态规划模型求解。将制定转运方案分为N次单个转运商匹配问题，转运商按照排名先后相对供应企业进行选择。 对于综合型供应商，可以发现，其在五年的时间内，出现供货量突变的次数极少，故在实际的订购过程中，这种微弱的突变性对订购方案的选择产生的影响极小，将该类型供应商其他时间的供货量的中位数代替其突变值，即可将综合型供应商视为稳定型供应商。 对于突变型供应商，采用遗传算法进行预估其订购量，从S108供应商供货量数据图像可以看到，其突变时间具有明显的周期性，集中体现出每12周一次的趋势，故定义突变型供应商产生突变，那么设定其既能够接收大额订单并及时供货的概率为 。对该类企业的供货突变值进行数据统计后，发现其大部突变值均超过了6000立方米/周（单个转运商的周转运最大值），则我们对选中的突变型原材料供应商的突变值均取2000-6000立方米/周，以便于在选择供货商时，避免出现向单家供应商发出超过单个转运商的周转运最大值的订单。且该类供应商只接收该突变值区间内的订单。 企业生产的第一周，由于没有储备，为保证接下来企业产能生产的稳定性，故企业在该周订购的原材料应该保证产能达到28200*2立方米，在2.3.1中得到的23家供应商中，S108供应商为综合型企业，其具备较强的短期大量供应能力，故第一周选取S108企业，并向其订购6000立方米的原材料，以保证订购量的总量规模。 对于稳定型供应商，每周供货量比较稳定，采用蒙特卡洛算法，随机生成订购量，每周该公司宜向其订购5年内区间为0到单周最大供货量之间的随机订单，订单随机数生成符合正态分布，以正态分布概率随机生成其订购量。并且突变型企业以 的突变概率参与订单的接收，在上文给出的约束条件下，产生第一次的最优订购方案，得到一个最小收购成本 的值，再以同样的方法进行二次，三次…n次运算，每次都会得到一个最新的最小收购成本，并对最小收购成本进行更新，直至迭代次数达到1000次，则停止迭代，取最新的值为该周的最小收购成本，得到最优订购方案，进而进入下一周的规划。 求解思路如下图所示： 图12最优订购方案规划问题求解思路图 在进行大量的实验寻优后，我们发现稳定型供应商的订单均在其5年内供应峰值的40%-90%之间，故将每个供货商的随机订单的订购区间修改为该供应商5年内供应峰值的40%-90%之间，可以发现，其迭代求解次数大大减少，求解效率提高。 6.3.3 最优转运方案模型的求解 转运商转运水平的求解： 将附件二中转运商的运输损耗率带入6.2.3的对应计算公式中，求得八家转运商的周平均运输损耗率如下图所示： 图13 转运商的周平均运输损耗率 可得转运商的优劣顺序为（由优到劣顺序排列）：3、6、2、8、4、1、7、5 转运方案的求解： Step1: 找到最优转运商，从6.3.2中找到该周的最优订购计划，对订购的原材料量按从大到小进行排序。 Step2： 首先将目前所剩的订单中原材料订购量最大的订单交给当前的最优转运商，判断转运商当前的剩余转运能力是否能够接收该订单，如果剩余转运能力足够，则接收该订单；若剩余转运能力不足以接收，则转向考虑仅次于该订单的订单，直至当周计划中原材料订购量最小的订单。 Step3： 若该周订单仍有剩余，则重复以上两步的步骤，直至该周的订单清零，则此时的转运方案既为该周最优的转运方案。 ","date":"2021-10-02","objectID":"/20211002/:14:0","tags":["python"],"title":"2021年全国大学生数学建模竞赛C题省一等奖论文部分","uri":"/20211002/"},{"categories":["python","数学建模"],"content":"6.4 订购方案和转运方案的实施效果分析 问题二为两次单目标规划，第一个目标是每周订购方案最经济，即满足产能的条件下，运材料购买费用最经济。通过模型建立与求解可以得出，原材料购买费用最少为21825。 当理想情况下，即每周原材料对应产能刚好满足产能要求，准备两周的原料储备粮，且损耗率不计的情况下，原材料购买费用应该为：21150~21326 。费用接近，在误差范围内，说明该方案为最经济的原材料订购方案。 第二个目标为损耗率最小，根据损耗率定义，不考虑原材料种类。通过转运方案规划得到最小损耗方案，订购材料实际对应每周平均产能为：29940立方米。订购材料得满足两周的原料储备量，所以订购材料实际对应每周平均产能大于2.82万立方米。 在供应商全部可以按时按量供应的情况下,可以满足产能要求，保障企业生产。由于三类原材料运输和储存的单位费用相同，在订购方案最优情况下，运输存储费用为常数。满足要求前提下，原材料费用最低，损耗率最小，分别达到最优，所以该订购方案和转运方案的实施效果良好。 七、问题三的模型建立与求解 ","date":"2021-10-02","objectID":"/20211002/:15:0","tags":["python"],"title":"2021年全国大学生数学建模竞赛C题省一等奖论文部分","uri":"/20211002/"},{"categories":["python","数学建模"],"content":"7.1 问题分析 在尽量多采购A类，少采购C类的要求下，分析三类原材料对于生产单位产品的经济数据，得到原则上企业选择原材料类型的倾向。以各供应商的周平均供货量对应的产能之和满足企业的周产能需求为前提，对原材料供给侧进行修改，既重新筛选符合要求的供应商。 由于题目要求在订购方案产生的同时，对转运方案进行规划，达到每周原材料订购费用与转运损耗造成的经济损失之和最小的目标，将问题转化为在该目标下的单目标动态规划问题。 ","date":"2021-10-02","objectID":"/20211002/:16:0","tags":["python"],"title":"2021年全国大学生数学建模竞赛C题省一等奖论文部分","uri":"/20211002/"},{"categories":["python","数学建模"],"content":"7.2 模型建立 7.2.1 原材料供应商的选择 由于生产单位产品对三类原材料的需求，以及原材料价格各不相同等因素的影响，企业应当在经济角度考虑优先选择哪类原材料进行生产。下表为生产单位产品之于三类原材料的相关数据：（此处定义M与N分别为单价与运输+储存价格的单位） 表4 生产单位产品之于三类原材料的相关数据表 原材料类别 所需原材料量 单价 生产单位产品的成本 运输价格+储存价格 A 0.6立方米 1.2M 0.72M 0.6N B 0.66立方米 1.1M 0.726M 0.66N C 0.72立方米 1M 0.72M 0.72N 分别将三类原材料的生产单位产品的成本与运输+储存价格相加，得到该原材料的对于产品生产的经济数据，该数据越大，说明订购该原材料进行生产的成本更高。从该表中可知，欲生产单位产品，选择A类原材料与C类原材料的生产成本相同，但A类原材料的运输+储存价格更低，故企业选择A类原材料进行生产优于选择C类材料，与题目要求吻合，故生产产品的原材料选择为：A类最优，B类次之，C类最差。 与问题二类似，进行订购规划的前提是所选择供应商的周平均供货量的产能可以满足企业的周产能需求。在问题一求得的50家供应商中，以供应商供应原材料类型的不同将其分为A类、B类、C类供应商，首先在A类供应商中按照周平均供货量由高到低进行选择，其次是B类、C类供应商，直至其供货量之和对应的产能达到企业的周产能需求，这时选择出的供应商即纳入本题最优订购方案规划时考虑的供应商群体中。 7.2.2 约束条件的确定 该问的约束条件与第二问中订购与转运方案的约束条件相同，均为所制定的订购计划中，各供应商的周原料供应量之和能够满足企业的周产能需求，且单个供应商周接收订单的原材料订购总量小于等于其最大周转运能力（6000立方米） 7.2.3 目标函数的确立： 考虑在某订购方案下的原材料花费最少和对应于该订购方案的最优转运方案损耗造成的损失最小同时满足，则将两部分的支出（运输损耗视为额外支出）相加，之和最小的规划方案即为所求的方案。故该动态规划问题的目标函数如下： 该目标函数的 为原材料订购的费用，为转运商在转运过程中因原材料损耗而产生的损失费用， 为所求支出最小的目标函数。 ","date":"2021-10-02","objectID":"/20211002/:17:0","tags":["python"],"title":"2021年全国大学生数学建模竞赛C题省一等奖论文部分","uri":"/20211002/"},{"categories":["python","数学建模"],"content":"7.3 模型求解 原材料供应商的确定： 在对问题一中筛选出的50家供应商按原材料供应类别进行分类后（且每类供应商内以周平均供应量由大到小顺序排列）根据7.2.1中依照A类、B类、C类供应商顺序进行选择的原则进行供应商筛选，直至选出的供应商的周平均供应量满足企业的周产能需求，共筛选出31家供应商进行原材料的供应。 总支出量最少（既目标函数最优解）的求解： Step1: 在筛选出的31家供应商中，随机生成24周的订购方案。 Step2: 判断生成的订购方案是否满足产能与转运能力的约束条件，若不满足，则返回Step1，若满足，则按照6.2.3中寻求最优转运方案的思路为生成的订购方案寻求转运方案。 Step3: j供应商在第i周的供应量可以由生成的订购方案确定，可以由匹配的最优转运方案找到j供应商在第i周的转运企业，从而得到 。既一旦订购方案与和其匹配的转运方案生成，就可以求得该方案下目标函数的最小值。并对该值进行动态更新。 Step4: 判断迭代次数是否大于1000次，若不够，则返回Step1;若够，则此时的订购方案与转运方案为所求最优方案。 ","date":"2021-10-02","objectID":"/20211002/:18:0","tags":["python"],"title":"2021年全国大学生数学建模竞赛C题省一等奖论文部分","uri":"/20211002/"},{"categories":["python","数学建模"],"content":"6.4 订购方案和转运方案的实施效果分析 1、问题二中每周采购不同类别原材料周平均数量如下： A类：8550立方米每周 B类：6757立方米每周 C类：4141立方米 问题三中每周采购不同类别原材料周平均数量如下： A类：10525立方米每周 B类：7037立方米每周 C类：1563立方米 通过数据对比可以得出：问题三中采购方案A远多于C，有效减少了转运以及仓储成本。 2、本题为最经济且损耗率最低，建立动态规划模型。按照成本费用核算公式： 成本费用=原材料费用+损耗费用+运输存储费用 在最优情况下得出24周原材料成本费用总和为：533672 当采用问题二中分布规划计算的出最小成本费用为：544786 注：记原料C的单价为1 通过对比，在同时考虑订购以及转运的情况下，调控A、B、C采购比例，建模求出最优采购和转运方案，更有利于提高工厂产能和较少损耗和转运费用。 八、问题四的模型建立与求解 ","date":"2021-10-02","objectID":"/20211002/:19:0","tags":["python"],"title":"2021年全国大学生数学建模竞赛C题省一等奖论文部分","uri":"/20211002/"},{"categories":["python","数学建模"],"content":"8.1 问题分析 在最大产能不设上限的情况下，对402家供货商供应的原材料产能计算了，以判断理论产能供应限制。 另外，产能的提升取决于转运能力，则8家转运商均全力转运，以提升企业产能。且由第三问对于三类原材料的分析可得，应尽可能多的采购料A，其次为B和C。优先选用转运损耗较小的转运商转运原料A，通过调节原材料比例以及损耗量来提升产能。 ","date":"2021-10-02","objectID":"/20211002/:20:0","tags":["python"],"title":"2021年全国大学生数学建模竞赛C题省一等奖论文部分","uri":"/20211002/"},{"categories":["python","数学建模"],"content":"8.2 模型建立 8.2.1数据处理 对供应商重新进行评价，选用第一问中综合评价模型，根据综合得分对全部供应商进行排序。通过对排名情况以及该供应商过去五年供货量进行数据分析可得，排名靠后的供应商平均供货量很小，对于企业产能影响极小。故优先选用排名靠前的供货商进行供应。 8.2.2重要供应商选择 首先计算所有供应商的平均供货量，作为供应商供应能力的评价值 ，接着按照排名顺序计算累加平均供应能力 。已知共有8家转运商，每家转运商均以最高转运能力运转，最大转运能力为： 当累加平均供应能力 时，以上部分供应商可以满足转运能力最大的要求，将以上供货商选择为企业的重要供货商。 根据原材料种类对于产能的影响，应尽可能多的采购料A，其次为B和C。对以上重要供货商进行二次排序，在综合得分排名基础上，按照A、B、C的顺序进行二次数据排序，此数据即为重要供应商以及排名。并依据过去250周供货数据，以供货方差为依据，将供应商划分为稳定型供应商和突变型供应商。 8.2.3模型简化 1、由于产能不受限制，则对于原料需求量激增，所有转运商的转运能力均用于制造产品，来达到长期稳定高效生产，则不考虑满足两周生产需求的原材料库存量要求。 2、由于供应商分为稳定型供应商和应急性供应商，根据应急性供应商的特点，无法长期供应，可以短期内供应大量值。由于产能不受限制，则应急型供应商需要长期进行原料补充。在此问题中，将应急型供应商供应数据进行平稳化处理，使其既满足供应商生产原材料规律，又有利于进行原材料补充，使得最大限度达到最大转运能力，以增加企业产能。 8.2.3 寻找最优订购以及转运方案 1、初始化重要供应商可能的订货量： 取随机值，由于产能不受限制，则对于稳定型企业的订货量应大于过去订货的平均值，以增加原料供给量。初始化采用随机数法给出，根据过去250周供货数据，供货商的供货最大值很可能偏离整体数据，为了避免极端数据的影响，则选择中位数作为衡量指标。随机数选择中位数和1.5倍中位数之间的随机整数，以此值作为该供应商初始化数据。按照此规则对第一周选择的所有重要供应商进行初始化。 2、寻找最优转运方案： 为了达到产能最大，采用逆向选择思维，将供应商选择转运商转变为转运商选择供应商。 首先计算8家转运商的平均损耗，用来衡量该转运商的转运能力，进行排序。平均损耗率最小的转运商优先进行选择，依照供应商排序表的顺序依次选择，直至最大限度的满足最大转运量。 算法思路如下： 图14最优转运商的选择思路流程图 当剩余转运能力为0或者对所有供货商进行遍历完成之后，该转运商转运方案制定，由下一家转运商对剩余供货商进行选择。 按照此算法，平均损耗量小的转运商将优先运送A产品，损耗量最小，产能可达到最大，寻找出最优转运方案 。 3、寻找全局最优解： 在所给范围内，对重要供应商可能的订货量重新预测，，每次预测都按照供应商选择算法寻找最优配送方案，计算并记录每一周产能，据此求出该企业周平均产能。 目标函数即为周平均产能： 指的是所选择的供应商一周内不同原材料供应量 为不同原材料的损耗量 为对应原材料的产品转化率 计算迭代10000次， 即可找出使得产能最大的订购方案及转运方案。可提升产能即为： ：为目前企业每周的产能，为常数2.82万立方米 ","date":"2021-10-02","objectID":"/20211002/:21:0","tags":["python"],"title":"2021年全国大学生数学建模竞赛C题省一等奖论文部分","uri":"/20211002/"},{"categories":["python","数学建模"],"content":"8.3 模型求解 8.3.1重要供货商选择 依照模型求解得到的转运商数据见支撑材料，下图为达到要求的截取部分： 图15 供应商相关数据图 由表可得，前134家供应商即可满足最大运力要求（在表中，供应商S017为第134家供应商），所以选择这134家供应商即可满足要求。 8.3.2** 最佳采购以及转运方案求解** 通过多次程序实验，当订购方案迭代10000次，就可以找到最佳的订购以及转运方案。 周数 平均产能 周数 平均产能 周数 平均产能 周数 平均产能 1 77482 7 77273 13 82157 19 76881 2 74899 8 79464 14 75774 20 79549 3 77772 9 77445 15 78266 21 77145 4 79811 10 75969 16 76471 22 76530 5 75126 11 76904 17 78666 23 75991 6 81203 12 77647 18 75658 24 74802 周7平均产能为：7.4万立方米 3、平均每周可提升产能：4.93万立方米 九、模型评价 ","date":"2021-10-02","objectID":"/20211002/:22:0","tags":["python"],"title":"2021年全国大学生数学建模竞赛C题省一等奖论文部分","uri":"/20211002/"},{"categories":["python","数学建模"],"content":"9.1 模型优点 1、数据特征分析充分，根据以往转运商订货供货数据特点，考虑到生产过程中实际情况，将供应商分为稳定型供应商和实际型供应商，选择保障企业生产的重要供应商时，同时选择了两种供应商，并制定不同的订货策略，可以有效应对突发情况，更符合实际生产过程。 2、损耗率采用随机抽样，在企业在选择转运商时，无法确定具体损耗率，只能通过以往数据进行评价，使得结果具有一定的随机性，更符合现实情况。 3、采用蒙特卡洛算法和遗传算法，分别针对两种供应商，使得订购方案更科学。 4、转运方案制定采用动态规划，兼顾效率与准确性。 ","date":"2021-10-02","objectID":"/20211002/:23:0","tags":["python"],"title":"2021年全国大学生数学建模竞赛C题省一等奖论文部分","uri":"/20211002/"},{"categories":["python","数学建模"],"content":"9.2 模型缺点 1、在处理突变型供应商的供货数据时，具有一定的主观性。 2、模型考虑的影响因素不够全，如仓储费用随时间的变化。 3、多目标规划过程中，寻优复杂度较高，模型运行效率较低。 ","date":"2021-10-02","objectID":"/20211002/:24:0","tags":["python"],"title":"2021年全国大学生数学建模竞赛C题省一等奖论文部分","uri":"/20211002/"},{"categories":["python","数学建模"],"content":"9.2 模型改进 1、算法合理调整参数，以提高运行效率 2、优化算法结构，提高寻优准确性。 十、参考文献 [1] 司守奎. 数学建模算法与应用[M]. 北京：国防工业出版社. 2016-2. [2] 葛显龙, 王伟鑫, 李顺勇. 智能算法及应用[M]. 陕西：西安交通大学出版社 2017-08. 附录 附录一：50家企业综合得分排名表 企业名称 综合得分 企业名称 综合得分 企业名称 综合得分 企业名称 综合得分 S229 316917.2435 S356 96052.94439 S037 35852.67231 S086 10582.73309 S361 225420.1526 S268 95603.50132 S031 34851.93137 S210 9818.638453 S140 224845.9604 S306 93901.01957 S365 31968.99077 S003 9038.902209 S108 195778.5333 S348 83542.05506 S040 30305.73908 S114 8490.263903 S282 156587.1989 S352 76396.70446 S338 23961.95622 S273 8350.85536 S151 145125.0488 S201 75193.20529 S364 21733.90959 S189 8208.411534 S275 140854.36 S194 74765.6373 S367 21661.38842 S078 7153.26208 S329 139104.1277 S307 73326.15308 S055 19579.47875 S292 6910.421161 S340 137802.0682 S143 69338.65548 S346 17308.15821 S074 6907.022773 S139 124401.6012 S395 67788.08345 S080 16284.18955 S291 6873.309978 S131 106515.8348 S247 41520.27762 S294 12436.92084 S131 104000.9205 S374 38473.73904 S218 12286.25891 S330 103851.5722 S284 36199.1097 S244 10623.68767 ","date":"2021-10-02","objectID":"/20211002/:25:0","tags":["python"],"title":"2021年全国大学生数学建模竞赛C题省一等奖论文部分","uri":"/20211002/"},{"categories":["python","数学建模","机器学习"],"content":"前言 逻辑回归的一个小案例，使用sklearn自带的一个数据 ","date":"2021-07-28","objectID":"/20210728/:1:0","tags":["python","神经网络","机器学习"],"title":"逻辑回归1-乳腺癌数据案例","uri":"/20210728/"},{"categories":["python","数学建模","机器学习"],"content":"代码 from sklearn.linear_model import LogisticRegression as LR #逻辑回归 from sklearn.datasets import load_breast_cancer #导入乳腺癌数据集 import numpy as np import matplotlib.pyplot as plt from sklearn.model_selection import train_test_split # 导入分测试与训练集 from sklearn.metrics import accuracy_score#精确性分数 data = load_breast_cancer()#乳腺癌数据集 data {'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\r1.189e-01],\r[2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\r8.902e-02],\r[1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\r8.758e-02],\r...,\r[1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\r7.820e-02],\r[2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\r1.240e-01],\r[7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\r7.039e-02]]),\r'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\r0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\r0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\r1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\r1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\r1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\r0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\r1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\r1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\r0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\r1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\r1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\r1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\r1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\r0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\r0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\r1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\r1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\r1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\r1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\r1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\r1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\r1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\r1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\r'frame': None,\r'target_names': array(['malignant', 'benign'], dtype='\u003cU9'),\r'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n :Number of Instances: 569\\n\\n :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n :Attribute Information:\\n - radius (mean of distances from center to points on the perimeter)\\n - texture (standard deviation of gray-scale values)\\n - perimeter\\n - area\\n - smoothness (local variation in radius lengths)\\n - compactness (perimeter^2 / area - 1.0)\\n - concavity (severity of concave portions of the contour)\\n - concave points (number of concave portions of the contour)\\n - symmetry\\n - fractal dimension (\"coastline approximation\" - 1)\\n\\n The mean, standard error, and \"worst\" or largest (mean of the three\\n worst/largest values) of these features were computed for each image,\\n resulting in 30 features. For instance, field 0 is Mean Radius, field\\n 10 is Radius SE, field 20 is Worst Radius.\\n\\n - class:\\n - WDBC-Malignant\\n - WDBC-Benign\\n\\n :Summary Statistics:\\n\\n ===================================== ====== ======\\n Min Max\\n ===================================== ====== ======\\n radius (mean): 6.981 28.11\\n texture (mean): 9.71 39.28\\n perimeter (mean): 43.79 188.5\\n area (mean): 143.5 2501.0\\n smoothness (mean): 0.053 0.163\\n compactness (mean): 0.019 0.345\\n concavity (mean): 0.0 0.427\\n concave ","date":"2021-07-28","objectID":"/20210728/:2:0","tags":["python","神经网络","机器学习"],"title":"逻辑回归1-乳腺癌数据案例","uri":"/20210728/"},{"categories":["python","数学建模","机器学习"],"content":"前言 数据集合来自kaggle 链接：https://www.kaggle.com/c/digit-recognizer/data 其中test和train的csv数据集为所需数据集。 ","date":"2021-07-27","objectID":"/20210727/:1:0","tags":["python","神经网络","机器学习"],"title":"随机森林在乳腺癌数据上的调参","uri":"/20210727/"},{"categories":["python","数学建模","机器学习"],"content":"代码 from sklearn.datasets import load_breast_cancer from sklearn.ensemble import RandomForestClassifier from sklearn.model_selection import GridSearchCV from sklearn.model_selection import cross_val_score import matplotlib.pyplot as plt import pandas as pd import numpy as np data = load_breast_cancer() data {'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\r1.189e-01],\r[2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\r8.902e-02],\r[1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\r8.758e-02],\r...,\r[1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\r7.820e-02],\r[2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\r1.240e-01],\r[7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\r7.039e-02]]),\r'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\r0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\r0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\r1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\r1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\r1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\r0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\r1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\r1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\r0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\r1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\r1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\r1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\r1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\r0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\r0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\r1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\r1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\r1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\r1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\r1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\r1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\r1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\r1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\r'frame': None,\r'target_names': array(['malignant', 'benign'], dtype='\u003cU9')\rdata.data.shape (569, 30)\rdata.target #可以看到，乳腺癌数据集有569条记录，30个特征，单看维度虽然不算太高，但是样本量非常少。过拟合的情况可能存在。 array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\r0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\r0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\r1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\r1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\r1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\r0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\r1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\r1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\r0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\r1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\r1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\r1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\r1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\r0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\r0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\r1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\r1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\r1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\r1, 0, 1","date":"2021-07-27","objectID":"/20210727/:2:0","tags":["python","神经网络","机器学习"],"title":"随机森林在乳腺癌数据上的调参","uri":"/20210727/"},{"categories":["python","数学建模","机器学习"],"content":"n_estimators 在这里选择学习曲线，可以使用网格搜索吗？可以，但是只有学习曲线，才能看见趋势 个人的倾向是，要看见n_estimators在什么取值开始变得平稳，是否一直推动模型整体准确率的上升等信息 第一次的学习曲线，可以先用来帮助我划定范围，我取每十个数作为一个阶段，来观察n_estimators的变化如何 引起模型整体准确率的变化 #####【TIME WARNING: 30 seconds】##### scorel = [] for i in range(0,200,10): rfc = RandomForestClassifier(n_estimators=i+1, n_jobs=-1, random_state=90) score = cross_val_score(rfc,data.data,data.target,cv=10).mean() scorel.append(score) print(max(scorel),(scorel.index(max(scorel))*10)+1) plt.figure(figsize=[20,5]) plt.plot(range(1,201,10),scorel) plt.show() #list.index([object]) #返回这个object在列表list中的索引 0.9631265664160402 71\rscorel = [] for i in range(35,45): rfc = RandomForestClassifier(n_estimators=i, n_jobs=-1, random_state=90) score = cross_val_score(rfc,data.data,data.target,cv=10).mean() scorel.append(score) print(max(scorel),([*range(35,45)][scorel.index(max(scorel))])) plt.figure(figsize=[20,5]) plt.plot(range(35,45),scorel) plt.show()#确定n_estimators为41 0.9613721804511279 41\r有一些参数是没有参照的，很难说清一个范围，这种情况下我们使用学习曲线，看趋势 从曲线跑出的结果中选取一个更小的区间，再跑曲线 param_grid = {'n_estimators':np.arange(0, 200, 10)} param_grid = {'max_depth':np.arange(1, 20, 1)} param_grid = {'max_leaf_nodes':np.arange(25,50,1)} 对于大型数据集，可以尝试从1000来构建，先输入1000，每100个叶子一个区间，再逐渐缩小范围\r有一些参数是可以找到一个范围的，或者说我们知道他们的取值和随着他们的取值，模型的整体准确率会如何变化，这样的参数我们就可以直接跑网格搜索 param_grid = {'criterion':['gini', 'entropy']} param_grid = {'min_samples_split':np.arange(2, 2+20, 1)} param_grid = {'min_samples_leaf':np.arange(1, 1+10, 1)} param_grid = {'max_features':np.arange(5,30,1)} #调整max_depth param_grid = {'max_depth':np.arange(1, 20, 1)} # 一般根据数据的大小来进行一个试探，乳腺癌数据很小，所以可以采用1~10，或者1~20这样的试探 # 但对于像digit recognition那样的大型数据来说，我们应该尝试30~50层深度（或许还不足够 # 更应该画出学习曲线，来观察深度对模型的影响 rfc = RandomForestClassifier(n_estimators=41 ,random_state=90 ) GS = GridSearchCV(rfc,param_grid,cv=10)#网格搜索 GS.fit(data.data,data.target) GS.best_params_#显示调整出来的最佳参数 {'max_depth': 8}\rGS.best_score_#返回调整好的最佳参数对应的准确率 0.9648809523809524\r#调整max_features param_grid = {'max_features':np.arange(1,30,1)} \"\"\" max_features是唯一一个即能够将模型往左（低方差高偏差）推，也能够将模型往右（高方差低偏差）推的参数。我 们需要根据调参前，模型所在的位置（在泛化误差最低点的左边还是右边）来决定我们要将max_features往哪边调。 现在模型位于图像左侧，我们需要的是更高的复杂度，因此我们应该把max_features往更大的方向调整，可用的特征 越多，模型才会越复杂。max_features的默认最小值是sqrt(n_features)，因此我们使用这个值作为调参范围的 最小值。 \"\"\" rfc = RandomForestClassifier(n_estimators=41 ,random_state=90 ) GS = GridSearchCV(rfc,param_grid,cv=10) GS.fit(data.data,data.target) GS.best_params_ {'max_features': 7}\rGS.best_score_ 0.968421052631579\r#调整min_samples_leaf param_grid={'min_samples_leaf':np.arange(1, 1+10, 1)} #对于min_samples_split和min_samples_leaf,一般是从他们的最小值开始向上增加10或20 #面对高维度高样本量数据，如果不放心，也可以直接+50，对于大型数据，可能需要200~300的范围 #如果调整的时候发现准确率无论如何都上不来，那可以放心大胆调一个很大的数据，大力限制模型的复杂度 rfc = RandomForestClassifier(n_estimators=41 ,random_state=90 ) GS = GridSearchCV(rfc,param_grid,cv=10) GS.fit(data.data,data.target) GS.best_params_ {'min_samples_leaf': 1}\rGS.best_score_ 0.9613721804511279\r#调整min_samples_split param_grid={'min_samples_split':np.arange(2, 2+20, 1)} rfc = RandomForestClassifier(n_estimators=41 ,random_state=90 ) GS = GridSearchCV(rfc,param_grid,cv=10) GS.fit(data.data,data.target) GS.best_params_ {'min_samples_split': 8}\rGS.best_score_ 0.9648809523809524\r#调整Criterion param_grid = {'criterion':['gini', 'entropy']} rfc = RandomForestClassifier(n_estimators=41 ,random_state=90 ) GS = GridSearchCV(rfc,param_grid,cv=10) GS.fit(data.data,data.target) GS.best_params_ {'criterion': 'entropy'}\rGS.best_score_ 0.9666666666666666\rrfc = RandomForestClassifier(n_estimators=41 ,random_state=90 ,max_depth=8 #,max_features=7 #,min_samples_leaf=4 #,min_samples_split= 8 ,criterion= 'entropy' ) #rfc = RandomForestClassifier(n_estimators=39,random_state=90) score = cross_val_score(rfc,data.data,data.target,cv=10).mean() score 0.9666666666666666\rscore - score_pre -0.0035087719298244613\r","date":"2021-07-27","objectID":"/20210727/:3:0","tags":["python","神经网络","机器学习"],"title":"随机森林在乳腺癌数据上的调参","uri":"/20210727/"},{"categories":["电脑技巧"],"content":"删除指定端口的所有进程 sudo kill -9 $(lsof -i:端口号 -t) ","date":"2021-07-26","objectID":"/20210726/:1:0","tags":["linux"],"title":"删除进程操作","uri":"/20210726/"},{"categories":["电脑技巧"],"content":"删除指定名称的所有进程 sudo kill -9 $(pidof 名字) ","date":"2021-07-26","objectID":"/20210726/:2:0","tags":["linux"],"title":"删除进程操作","uri":"/20210726/"},{"categories":["电脑技巧"],"content":"查看指定端口占用情况 sudo lsof -i:端口号 ","date":"2021-07-26","objectID":"/20210726/:3:0","tags":["linux"],"title":"删除进程操作","uri":"/20210726/"},{"categories":["电脑技巧"],"content":"删除指定pid的进程 sudo kill -9 pid号 ","date":"2021-07-26","objectID":"/20210726/:4:0","tags":["linux"],"title":"删除进程操作","uri":"/20210726/"},{"categories":["电脑技巧"],"content":"docker-compose搭建 ","date":"2021-07-25","objectID":"/20210725/:0:0","tags":["github","linux","docker"],"title":"Okteto常用项目","uri":"/20210725/"},{"categories":["电脑技巧"],"content":"wordpress version: '3.3' services: db: image: mysql:latest volumes: - /data/wordpress_db:/var/lib/mysql restart: always environment: MYSQL_ROOT_PASSWORD: rootwordpress MYSQL_DATABASE: wordpress MYSQL_USER: wordpress MYSQL_PASSWORD: wordpress wordpress: depends_on: - db image: wordpress:latest ports: - \"8000:80\" restart: always environment: WORDPRESS_DB_HOST: db:3306 WORDPRESS_DB_USER: wordpress WORDPRESS_DB_PASSWORD: wordpress WORDPRESS_DB_NAME: wordpress ","date":"2021-07-25","objectID":"/20210725/:1:0","tags":["github","linux","docker"],"title":"Okteto常用项目","uri":"/20210725/"},{"categories":["电脑技巧"],"content":"Cloudreve services: cloudreve: public: true container_name: cloudreve image: jialezi/cloudreve ports: - 5212:5212 volumes: - /root/cloudreve ","date":"2021-07-25","objectID":"/20210725/:2:0","tags":["github","linux","docker"],"title":"Okteto常用项目","uri":"/20210725/"},{"categories":["电脑技巧"],"content":"Bitwarden 管理地址为“xxx/admin”。 services: bit: public: true container_name: bitwarden image: bitwardenrs/server:alpine ports: - 80:80 volumes: - /data/ environment: - WEBSOCKET_ENABLED=true - SIGNUPS_ALLOWED=true - WEB_VAULT_ENABLED=true - ADMIN_TOKEN=%管理员Token自己填% ","date":"2021-07-25","objectID":"/20210725/:3:0","tags":["github","linux","docker"],"title":"Okteto常用项目","uri":"/20210725/"},{"categories":["电脑技巧"],"content":"青龙面板 version: '2.0' services: ql: image: whyour/qinglong:latest container_name: ql restart: always volumes: - /qinglong/ql/config:/ql/config - /qinglong/ql/scripts:/ql/scripts - /qinglong/ql/repo:/ql/repo - /qinglong/ql/log:/ql/log - /qinglong/ql/db:/ql/db - /qinglong/ql/jbot:/ql/jbot - /qinglong/ql/raw:/ql/raw ports: - 5801:5700 ","date":"2021-07-25","objectID":"/20210725/:4:0","tags":["github","linux","docker"],"title":"Okteto常用项目","uri":"/20210725/"},{"categories":["电脑技巧"],"content":"docker简易管理面板 version: '3' services: redis: image: redis:latest web: image: registry.cn-hangzhou.aliyuncs.com/seven-tao/simple-docker:0.0.7 ports: - \"9091:4050\" volumes: - /tmp/simple-docker/back:/tmp/back - /var/run/docker.sock:/var/run/docker.sock depends_on: - redis chart搭建 ","date":"2021-07-25","objectID":"/20210725/:5:0","tags":["github","linux","docker"],"title":"Okteto常用项目","uri":"/20210725/"},{"categories":["电脑技巧"],"content":"tensorflow-notebook 改动密码部署即可，内置jupyter-notebook。 ","date":"2021-07-25","objectID":"/20210725/:5:1","tags":["github","linux","docker"],"title":"Okteto常用项目","uri":"/20210725/"},{"categories":["电脑技巧"],"content":"terminal 可以通过命令行安装额外的东西，就是给权限很麻烦。 ","date":"2021-07-25","objectID":"/20210725/:5:2","tags":["github","linux","docker"],"title":"Okteto常用项目","uri":"/20210725/"},{"categories":["数学建模","python","机器学习"],"content":"前言 使用的相关数据链接如下： 点我跳转 代码 ","date":"2021-07-24","objectID":"/20210724/:1:0","tags":["python","数学建模","神经网络","机器学习"],"title":"预处理3-连续值与特征选取","uri":"/20210724/"},{"categories":["数学建模","python","机器学习"],"content":"连续值预处理 import pandas as pd data = pd.read_csv(\"Narrativedata.csv\" ,index_col=0 )#index_col=0将第0列作为索引，不写则认为第0列为特征 data.loc[:,\"Age\"] = data.loc[:,\"Age\"].fillna(data.loc[:,\"Age\"].median()) #将年龄二值化 data_2 = data.copy() data_2.info() \u003cclass 'pandas.core.frame.DataFrame'\u003e\rInt64Index: 891 entries, 0 to 890\rData columns (total 4 columns):\r# Column Non-Null Count Dtype --- ------ -------------- ----- 0 Age 891 non-null float64\r1 Sex 891 non-null object 2 Embarked 889 non-null object 3 Survived 891 non-null object dtypes: float64(1), object(3)\rmemory usage: 34.8+ KB\rfrom sklearn.preprocessing import Binarizer X = data_2.iloc[:,0].values.reshape(-1,1) #类为特征专用，所以不能使用一维数组 transformer = Binarizer(threshold=30).fit_transform(X) #阈值threshold=n, 小于等于n的数值转为0, 大于n的数值转为1 data_2.iloc[:,0] = transformer data_2.head() Age\rSex\rEmbarked\rSurvived\r0\r0.0\rmale\rS\rNo\r1\r1.0\rfemale\rC\rYes\r2\r0.0\rfemale\rS\rYes\r3\r1.0\rfemale\rS\rYes\r4\r1.0\rmale\rS\rNo\rfrom sklearn.preprocessing import KBinsDiscretizer X = data.iloc[:,0].values.reshape(-1,1) est = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform') est.fit_transform(X) #查看转换后分的箱：变成了一列中的三箱 set(est.fit_transform(X).ravel()) {0.0, 1.0, 2.0}\rest = KBinsDiscretizer(n_bins=3, encode='onehot', strategy='uniform') #查看转换后分的箱：变成了哑变量 est.fit_transform(X).toarray() array([[1., 0., 0.],\r[0., 1., 0.],\r[1., 0., 0.],\r...,\r[0., 1., 0.],\r[1., 0., 0.],\r[0., 1., 0.]])\r特征选取 import pandas as pd data = pd.read_csv(\"digit recognizor.csv\") X = data.iloc[:,1:] y = data.iloc[:,0] X.shape (42000, 784)\r","date":"2021-07-24","objectID":"/20210724/:2:0","tags":["python","数学建模","神经网络","机器学习"],"title":"预处理3-连续值与特征选取","uri":"/20210724/"},{"categories":["数学建模","python","机器学习"],"content":"Fliter过滤法 方差过滤 \"\"\" 这个数据量相对夸张，如果使用支持向量机和神经网络，很可能会直接跑不出来。使用KNN跑一次大概需要半个小时。 用这个数据举例，能更够体现特征工程的重要性。 \"\"\" from sklearn.feature_selection import VarianceThreshold selector = VarianceThreshold() #实例化，不填参数默认方差为0 X_var0 = selector.fit_transform(X) #获取删除不合格特征之后的新特征矩阵，删除方差为0的特征 #也可以直接写成 X = VairanceThreshold().fit_transform(X) X_var0.shape (42000, 708)\r#我们希望留下一半的特征， #那可以设定一个让特征总数减半的方差阈值，只要找到特征方差的中位数，再将这个中位数作为参数threshold的值输入就好了 import numpy as np #X.var() 读取每一列的方差 X_fsvar = VarianceThreshold(np.median(X.var().values)).fit_transform(X) #X.var().values np.median(X.var().values) 1352.2867031797243\rX_fsvar.shape (42000, 392)\r#若特征是伯努利随机变量，假设p=0.8，即二分类特征中某种分类占到80%以上的时候删除特征 X_bvar = VarianceThreshold(.8 * (1 - .8)).fit_transform(X) X_bvar.shape (42000, 685)\r相关性过滤 from sklearn.ensemble import RandomForestClassifier as RFC from sklearn.model_selection import cross_val_score from sklearn.feature_selection import SelectKBest from sklearn.feature_selection import chi2 #再结合feature_selection.SelectKBest这个可以输入”评分标准“来选出前K个分数最高的特征的类， X_fschi = SelectKBest(chi2,k=300).fit_transform(X_fsvar,y)#评分标准是卡方chi2 X_fschi.shape (42000, 300)\rcross_val_score(RFC(n_estimators=10,random_state=0),X_fschi,y,cv=5).mean() 0.9344761904761905\r#python中的魔法命令，可以直接使用%%timeit来计算运行这个cell中的代码所需的时间 #为了计算所需的时间，需要将这个cell中的代码运行很多次（通常是7次）后求平均值，因此运行%%timeit的时间会远远超过cell中的代码单独运行的时间 X = data.iloc[:,1:] y = data.iloc[:,0] X_fsvar = VarianceThreshold(np.median(X.var().values)).fit_transform(X) #======【TIME WARNING: 5 mins】======# %matplotlib inline import matplotlib.pyplot as plt score = [] for i in range(390,200,-10): X_fschi = SelectKBest(chi2, k=i).fit_transform(X_fsvar, y) once = cross_val_score(RFC(n_estimators=10,random_state=0),X_fschi,y,cv=5).mean() score.append(once) plt.plot(range(350,200,-10),score) #plt.show() 卡方值越大越好，p值小于0.05时是数据相关 chivalue, pvalues_chi = chi2(X_fsvar,y) #chivalue #pvalues_chi #k取多少？我们想要消除所有p值大于设定值，比如0.05或0.01的特征： k = chivalue.shape[0] - (pvalues_chi \u003e 0.05).sum() #X_fschi = SelectKBest(chi2, k=填写具体的k).fit_transform(X_fsvar, y) #cross_val_score(RFC(n_estimators=10,random_state=0),X_fschi,y,cv=5).mean() k 392\rfrom sklearn.feature_selection import f_classif F,pvalues_f = f_classif(X_fsvar,y) #F #pvalues_f k = F.shape[0] - (pvalues_f \u003e 0.05).sum() k 392\r#X_fsF = SelectKBest(f_classif, k=填写具体的k).fit_transform(X_fsvar, y) #cross_val_score(RFC(n_estimators=10,random_state=0),X_fsF,y,cv=5).mean() from sklearn.feature_selection import mutual_info_classif as MIC result = MIC(X_fsvar,y) k = result.shape[0] - sum(result \u003c= 0) k 392\r#X_fsmic = SelectKBest(MIC, k=填写具体的k).fit_transform(X_fsvar, y) #cross_val_score(RFC(n_estimators=10,random_state=0),X_fsmic,y,cv=5).mean() ","date":"2021-07-24","objectID":"/20210724/:3:0","tags":["python","数学建模","神经网络","机器学习"],"title":"预处理3-连续值与特征选取","uri":"/20210724/"},{"categories":["数学建模","python","机器学习"],"content":"嵌入法 from sklearn.feature_selection import SelectFromModel from sklearn.ensemble import RandomForestClassifier as RFC RFC_ = RFC(n_estimators =10,random_state=0) X_embedded = SelectFromModel(RFC_,threshold=0.005).fit_transform(X,y) #在这里我只想取出来有限的特征。0.005这个阈值对于有780个特征的数据来说，是非常高的阈值，因为平均每个特征只能够分到大约0.001的feature_importances_ X_embedded.shape (42000, 47)\r#模型的维度明显被降低了 #同样的，我们也可以画学习曲线来找最佳阈值 #======【TIME WARNING：10 mins】======# import numpy as np import matplotlib.pyplot as plt RFC_.fit(X,y).feature_importances_ threshold = np.linspace(0,(RFC_.fit(X,y).feature_importances_).max(),20) score = [] for i in threshold: X_embedded = SelectFromModel(RFC_,threshold=i).fit_transform(X,y) once = cross_val_score(RFC_,X_embedded,y,cv=5).mean() score.append(once) plt.plot(threshold,score) plt.show() #上述图找到合适的threshold区间 X_embedded = SelectFromModel(RFC_,threshold=0.00067).fit_transform(X,y) X_embedded.shape (42000, 324)\rcross_val_score(RFC_,X_embedded,y,cv=5).mean() 0.9391190476190475\r#======【TIME WARNING：10 mins】======# #区间内再找合适的值 score2 = [] for i in np.linspace(0,0.00134,20): X_embedded = SelectFromModel(RFC_,threshold=i).fit_transform(X,y) once = cross_val_score(RFC_,X_embedded,y,cv=5).mean() score2.append(once) plt.figure(figsize=[20,5]) plt.plot(np.linspace(0,0.00134,20),score2) plt.xticks(np.linspace(0,0.00134,20)) plt.show() X_embedded = SelectFromModel(RFC_,threshold=0.000564).fit_transform(X,y) X_embedded.shape (42000, 340)\rcross_val_score(RFC_,X_embedded,y,cv=5).mean() 0.9392857142857144\r#=====【TIME WARNING：2 min】=====# #我们可能已经找到了现有模型下的最佳结果，如果我们调整一下随机森林的参数呢？ cross_val_score(RFC(n_estimators=100,random_state=0),X_embedded,y,cv=5).mean() 0.9634285714285715\r","date":"2021-07-24","objectID":"/20210724/:4:0","tags":["python","数学建模","神经网络","机器学习"],"title":"预处理3-连续值与特征选取","uri":"/20210724/"},{"categories":["数学建模","python","机器学习"],"content":"包装法-递归特征消除法 from sklearn.feature_selection import RFE RFC_ = RFC(n_estimators =10,random_state=0) selector = RFE(RFC_, n_features_to_select=340, step=50).fit(X, y) selector.support_.sum() 340\r#selector.ranking_ X_wrapper = selector.transform(X) cross_val_score(RFC_,X_wrapper,y,cv=5).mean() 0.9379761904761905\r#======【TIME WARNING: 15 mins】======# score = [] for i in range(1,751,50): X_wrapper = RFE(RFC_,n_features_to_select=i, step=50).fit_transform(X,y) once = cross_val_score(RFC_,X_wrapper,y,cv=5).mean() score.append(once) plt.figure(figsize=[20,5]) plt.plot(range(1,751,50),score) plt.xticks(range(1,751,50)) plt.show() ","date":"2021-07-24","objectID":"/20210724/:5:0","tags":["python","数学建模","神经网络","机器学习"],"title":"预处理3-连续值与特征选取","uri":"/20210724/"},{"categories":["数学建模","python","机器学习"],"content":"随机森林填补缺失值(实测回归比较好) %matplotlib inline from sklearn.tree import DecisionTreeClassifier from sklearn.ensemble import RandomForestClassifier#随机森林分类树 from sklearn.datasets import load_wine from sklearn.model_selection import train_test_split wine = load_wine() wine {'data': array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\r1.065e+03],\r[1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\r1.050e+03],\r[1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\r1.185e+03],\r...,\r[1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\r8.350e+02],\r[1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\r8.400e+02],\r[1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\r5.600e+02]]),\r'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\r1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\r2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\r2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\r2, 2]),\r'frame': None,\r'target_names': array(['class_0', 'class_1', 'class_2'], dtype='\u003cU7'),\r'DESCR': '.. _wine_dataset:\\n\\nWine recognition dataset\\n------------------------\\n\\n**Data Set Characteristics:**\\n\\n :Number of Instances: 178 (50 in each of three classes)\\n :Number of Attributes: 13 numeric, predictive attributes and the class\\n :Attribute Information:\\n \\t\\t- Alcohol\\n \\t\\t- Malic acid\\n \\t\\t- Ash\\n\\t\\t- Alcalinity of ash \\n \\t\\t- Magnesium\\n\\t\\t- Total phenols\\n \\t\\t- Flavanoids\\n \\t\\t- Nonflavanoid phenols\\n \\t\\t- Proanthocyanins\\n\\t\\t- Color intensity\\n \\t\\t- Hue\\n \\t\\t- OD280/OD315 of diluted wines\\n \\t\\t- Proline\\n\\n - class:\\n - class_0\\n - class_1\\n - class_2\\n\\t\\t\\n :Summary Statistics:\\n \\n ============================= ==== ===== ======= =====\\n Min Max Mean SD\\n ============================= ==== ===== ======= =====\\n Alcohol: 11.0 14.8 13.0 0.8\\n Malic Acid: 0.74 5.80 2.34 1.12\\n Ash: 1.36 3.23 2.36 0.27\\n Alcalinity of Ash: 10.6 30.0 19.5 3.3\\n Magnesium: 70.0 162.0 99.7 14.3\\n Total Phenols: 0.98 3.88 2.29 0.63\\n Flavanoids: 0.34 5.08 2.03 1.00\\n Nonflavanoid Phenols: 0.13 0.66 0.36 0.12\\n Proanthocyanins: 0.41 3.58 1.59 0.57\\n Colour Intensity: 1.3 13.0 5.1 2.3\\n Hue: 0.48 1.71 0.96 0.23\\n OD280/OD315 of diluted wines: 1.27 4.00 2.61 0.71\\n Proline: 278 1680 746 315\\n ============================= ==== ===== ======= =====\\n\\n :Missing Attribute Values: None\\n :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\\n :Creator: R.A. Fisher\\n :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n :Date: July, 1988\\n\\nThis is a copy of UCI ML Wine recognition datasets.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\n\\nThe data is the results of a chemical analysis of wines grown in the same\\nregion in Italy by three different cultivators. There are thirteen different\\nmeasurements taken for different constituents found in the three types of\\nwine.\\n\\nOriginal Owners: \\n\\nForina, M. et al, PARVUS - \\nAn Extendible Package for Data Exploration, Classification and Correlation. \\nInstitute of Pharmaceutical and Food Analysis and Technologies,\\nVia Brigata Salerno, 16147 Genoa, Italy.\\n\\nCitation:\\n\\nLichman, M. (2013). UCI Machine Learning Repository\\n[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\\nSchool of Information and Computer Science. \\n\\n.. topic:: References\\n\\n (1) S. Aeberhard, D. Coomans and O. de Vel, \\n Comparison of Classifiers in High Dimensional Settings, \\n Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of \\n Mathematics and Statistics, James Cook University of North Queensland. \\n (Also submitted to Technometrics). \\n\\n The data was used with many others for compari","date":"2021-07-23","objectID":"/20210723/:1:0","tags":["python","数学建模","神经网络","机器学习"],"title":"预处理2-随机森林填补缺失值","uri":"/20210723/"},{"categories":["数学建模","python","机器学习"],"content":"前言 使用的相关数据链接如下： 点我跳转 ","date":"2021-07-22","objectID":"/20210722/:1:0","tags":["python","数学建模","神经网络","机器学习"],"title":"预处理1-分类数据","uri":"/20210722/"},{"categories":["数学建模","python","机器学习"],"content":"数据预处理 无量纲化 #归一化 收到0~1之间 #正则化不是归一化 from sklearn.preprocessing import MinMaxScaler data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]] #不太熟悉numpy的小伙伴，能够判断data的结构吗？ #如果换成表是什么样子？ import pandas as pd pd.DataFrame(data) 0\r1\r0\r-1.0\r2\r1\r-0.5\r6\r2\r0.0\r10\r3\r1.0\r18\r#实现归一化 #当X中的特征数量非常多的时候，fit会报错并表示，数据量太大了我计算不了 #此时使用partial_fit作为训练接口 #scaler = scaler.partial_fit(data) scaler = MinMaxScaler() #实例化 scaler = scaler.fit(data) #fit，在这里本质是生成min(x)和max(x) result = scaler.transform(data) #通过接口导出结果,归一化 result array([[0. , 0. ],\r[0.25, 0.25],\r[0.5 , 0.5 ],\r[1. , 1. ]])\rresult_ = scaler.fit_transform(data) #训练和导出结果一步达成 result array([[0. , 0. ],\r[0.25, 0.25],\r[0.5 , 0.5 ],\r[1. , 1. ]])\rscaler.inverse_transform(result) #将归一化后的结果逆转 array([[-1. , 2. ],\r[-0.5, 6. ],\r[ 0. , 10. ],\r[ 1. , 18. ]])\r#使用MinMaxScaler的参数feature_range实现将数据归一化到[0,1]以外的范围中 data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]] scaler = MinMaxScaler(feature_range=[5,10]) #依然实例化 result = scaler.fit_transform(data) #fit_transform一步导出结果 result array([[ 5. , 5. ],\r[ 6.25, 6.25],\r[ 7.5 , 7.5 ],\r[10. , 10. ]])\rimport numpy as np X = np.array([[-1, 2], [-0.5, 6], [0, 10], [1, 18]]) X array([[-1. , 2. ],\r[-0.5, 6. ],\r[ 0. , 10. ],\r[ 1. , 18. ]])\r#归一化 X_nor = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0)) X_nor array([[0. , 0. ],\r[0.25, 0.25],\r[0.5 , 0.5 ],\r[1. , 1. ]])\r#逆转归一化 X_returned = X_nor * (X.max(axis=0) - X.min(axis=0)) + X.min(axis=0) X_returned array([[-1. , 2. ],\r[-0.5, 6. ],\r[ 0. , 10. ],\r[ 1. , 18. ]])\rfrom sklearn.preprocessing import StandardScaler data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]] scaler = StandardScaler() #实例化 scaler.fit(data) #fit，本质是生成均值和方差 StandardScaler()\rscaler.mean_ #查看均值的属性mean_ array([-0.125, 9. ])\rscaler.var_ #查看方差的属性var_ array([ 0.546875, 35. ])\rx_std = scaler.transform(data) #通过接口导出结果 x_std array([[-1.18321596, -1.18321596],\r[-0.50709255, -0.50709255],\r[ 0.16903085, 0.16903085],\r[ 1.52127766, 1.52127766]])\rx_std.mean() #导出的结果是一个数组，用mean()查看均值 0.0\rx_std.std() #用std()查看方差 1.0\rscaler.fit_transform(data) #使用fit_transform(data)一步达成结果 array([[-1.18321596, -1.18321596],\r[-0.50709255, -0.50709255],\r[ 0.16903085, 0.16903085],\r[ 1.52127766, 1.52127766]])\rscaler.inverse_transform(x_std) #使用inverse_transform逆转标准化 array([[-1. , 2. ],\r[-0.5, 6. ],\r[ 0. , 10. ],\r[ 1. , 18. ]])\r处理缺失值 import pandas as pd data = pd.read_csv(r\"Narrativedata.csv\" ,index_col=0 )#index_col=0将第0列作为索引，不写则认为第0列为特征 data.head() Age\rSex\rEmbarked\rSurvived\r0\r22.0\rmale\rS\rNo\r1\r38.0\rfemale\rC\rYes\r2\r26.0\rfemale\rS\rYes\r3\r35.0\rfemale\rS\rYes\r4\r35.0\rmale\rS\rNo\rdata.info() #填补年龄 \u003cclass 'pandas.core.frame.DataFrame'\u003e\rInt64Index: 891 entries, 0 to 890\rData columns (total 4 columns):\r# Column Non-Null Count Dtype --- ------ -------------- ----- 0 Age 714 non-null float64\r1 Sex 891 non-null object 2 Embarked 889 non-null object 3 Survived 891 non-null object dtypes: float64(1), object(3)\rmemory usage: 34.8+ KB\rAge = data.loc[:,\"Age\"].values.reshape(-1,1) #sklearn当中特征矩阵必须是二维 Age[:20] array([[22.],\r[38.],\r[26.],\r[35.],\r[35.],\r[nan],\r[54.],\r[ 2.],\r[27.],\r[14.],\r[ 4.],\r[58.],\r[20.],\r[39.],\r[14.],\r[55.],\r[ 2.],\r[nan],\r[31.],\r[nan]])\rfrom sklearn.impute import SimpleImputer imp_mean = SimpleImputer() #实例化，默认均值填补 imp_median = SimpleImputer(strategy=\"median\") #用中位数填补 imp_0 = SimpleImputer(strategy=\"constant\",fill_value=0) #用0填补 imp_mean = imp_mean.fit_transform(Age) #fit_transform一步完成调取结果 imp_median = imp_median.fit_transform(Age) imp_0 = imp_0.fit_transform(Age) imp_mean[:20] array([[22. ],\r[38. ],\r[26. ],\r[35. ],\r[35. ],\r[29.69911765],\r[54. ],\r[ 2. ],\r[27. ],\r[14. ],\r[ 4. ],\r[58. ],\r[20. ],\r[39. ],\r[14. ],\r[55. ],\r[ 2. ],\r[29.69911765],\r[31. ],\r[29.69911765]])\rimp_median[:20] array([[22.],\r[38.],\r[26.],\r[35.],\r[35.],\r[28.],\r[54.],\r[ 2.],\r[27.],\r[14.],\r[ 4.],\r[58.],\r[20.],\r[39.],\r[14.],\r[55.],\r[ 2.],\r[28.],\r[31.],\r[28.]])\rimp_0[:20] array([[22.],\r[38.],\r[26.],\r[35.],\r[35.],\r[ 0.],\r[54.],\r[ 2.],\r[27.],\r[14.],\r[ 4.],\r[58.],\r[20.],\r[39.],\r[14.],\r[55.],\r[ 2.],\r[ 0.],\r[31.],\r[ 0.]])\r#在这里我们使用中位数填补Age data.loc[:,\"Age\"] = imp_median data.","date":"2021-07-22","objectID":"/20210722/:2:0","tags":["python","数学建模","神经网络","机器学习"],"title":"预处理1-分类数据","uri":"/20210722/"},{"categories":["数学建模","python","机器学习"],"content":"前言 数据集来自kaggle 链接：https://www.kaggle.com/c/titanic/data 里面的test和train的csv数据集为所需数据集。 ","date":"2021-07-21","objectID":"/20210721/:1:0","tags":["python","数学建模","神经网络","机器学习"],"title":"决策树3-泰坦尼克号实例(网格搜索,超参数调参)","uri":"/20210721/"},{"categories":["数学建模","python","机器学习"],"content":"代码 import pandas as pd import numpy as np from sklearn.tree import DecisionTreeClassifier #分类器 只能分类数字 import matplotlib.pyplot as plt from sklearn.model_selection import GridSearchCV from sklearn.model_selection import train_test_split from sklearn.model_selection import cross_val_score data = pd.read_csv(\"train.csv\") data.head() PassengerId\rSurvived\rPclass\rName\rSex\rAge\rSibSp\rParch\rTicket\rFare\rCabin\rEmbarked\r0\r1\r0\r3\rBraund, Mr. Owen Harris\rmale\r22.0\r1\r0\rA/5 21171\r7.2500\rNaN\rS\r1\r2\r1\r1\rCumings, Mrs. John Bradley (Florence Briggs Th...\rfemale\r38.0\r1\r0\rPC 17599\r71.2833\rC85\rC\r2\r3\r1\r3\rHeikkinen, Miss. Laina\rfemale\r26.0\r0\r0\rSTON/O2. 3101282\r7.9250\rNaN\rS\r3\r4\r1\r1\rFutrelle, Mrs. Jacques Heath (Lily May Peel)\rfemale\r35.0\r1\r0\r113803\r53.1000\rC123\rS\r4\r5\r0\r3\rAllen, Mr. William Henry\rmale\r35.0\r0\r0\r373450\r8.0500\rNaN\rS\rdata.info() \u003cclass 'pandas.core.frame.DataFrame'\u003e\rRangeIndex: 891 entries, 0 to 890\rData columns (total 12 columns):\r# Column Non-Null Count Dtype --- ------ -------------- ----- 0 PassengerId 891 non-null int64 1 Survived 891 non-null int64 2 Pclass 891 non-null int64 3 Name 891 non-null object 4 Sex 891 non-null object 5 Age 714 non-null float64\r6 SibSp 891 non-null int64 7 Parch 891 non-null int64 8 Ticket 891 non-null object 9 Fare 891 non-null float64\r10 Cabin 204 non-null object 11 Embarked 889 non-null object dtypes: float64(2), int64(5), object(5)\rmemory usage: 83.7+ KB\r#筛选特征 data.drop([\"Name\",\"Ticket\",\"Cabin\"],inplace=True,axis=1) #处理缺失值 data[\"Age\"] = data[\"Age\"].fillna(data[\"Age\"].mean()) #删除缺失值少的行 data = data.dropna() data.info() \u003cclass 'pandas.core.frame.DataFrame'\u003e\rInt64Index: 889 entries, 0 to 890\rData columns (total 9 columns):\r# Column Non-Null Count Dtype --- ------ -------------- ----- 0 PassengerId 889 non-null int64 1 Survived 889 non-null int64 2 Pclass 889 non-null int64 3 Sex 889 non-null object 4 Age 889 non-null float64\r5 SibSp 889 non-null int64 6 Parch 889 non-null int64 7 Fare 889 non-null float64\r8 Embarked 889 non-null object dtypes: float64(2), int64(5), object(2)\rmemory usage: 69.5+ KB\rlabels = data[\"Embarked\"].unique().tolist() #转换多分类为数值 data[\"Embarked\"] = data[\"Embarked\"].apply(lambda x: labels.index(x)) #data[\"Sex\"] = data[\"Sex\"].apply(lambda x: labels.index(x)) #转换二分类为01变量 data[\"Sex\"] = (data[\"Sex\"] == \"male\").astype(\"int\") (data[\"Sex\"] == \"male\").astype(\"int\") 0 0\r1 0\r2 0\r3 0\r4 0\r..\r886 0\r887 0\r888 0\r889 0\r890 0\rName: Sex, Length: 889, dtype: int64\rdata PassengerId\rSurvived\rPclass\rSex\rAge\rSibSp\rParch\rFare\rEmbarked\r0\r1\r0\r3\r1\r22.000000\r1\r0\r7.2500\r0\r1\r2\r1\r1\r0\r38.000000\r1\r0\r71.2833\r1\r2\r3\r1\r3\r0\r26.000000\r0\r0\r7.9250\r0\r3\r4\r1\r1\r0\r35.000000\r1\r0\r53.1000\r0\r4\r5\r0\r3\r1\r35.000000\r0\r0\r8.0500\r0\r...\r...\r...\r...\r...\r...\r...\r...\r...\r...\r886\r887\r0\r2\r1\r27.000000\r0\r0\r13.0000\r0\r887\r888\r1\r1\r0\r19.000000\r0\r0\r30.0000\r0\r888\r889\r0\r3\r0\r29.699118\r1\r2\r23.4500\r0\r889\r890\r1\r1\r1\r26.000000\r0\r0\r30.0000\r1\r890\r891\r0\r3\r1\r32.000000\r0\r0\r7.7500\r2\r889 rows × 9 columns x = data.iloc[:,data.columns != \"Survived\"] x PassengerId\rPclass\rSex\rAge\rSibSp\rParch\rFare\rEmbarked\r0\r1\r3\r1\r22.000000\r1\r0\r7.2500\r0\r1\r2\r1\r0\r38.000000\r1\r0\r71.2833\r1\r2\r3\r3\r0\r26.000000\r0\r0\r7.9250\r0\r3\r4\r1\r0\r35.000000\r1\r0\r53.1000\r0\r4\r5\r3\r1\r35.000000\r0\r0\r8.0500\r0\r...\r...\r...\r...\r...\r...\r...\r...\r...\r886\r887\r2\r1\r27.000000\r0\r0\r13.0000\r0\r887\r888\r1\r0\r19.000000\r0\r0\r30.0000\r0\r888\r889\r3\r0\r29.699118\r1\r2\r23.4500\r0\r889\r890\r1\r1\r26.000000\r0\r0\r30.0000\r1\r890\r891\r3\r1\r32.000000\r0\r0\r7.7500\r2\r889 rows × 8 columns y = data.iloc[:,data.columns == \"Survived\"] y Survived\r0\r0\r1\r1\r2\r1\r3\r1\r4\r0\r...\r...\r886\r0\r887\r1\r888\r0\r889\r1\r890\r0\r889 rows × 1 columns Xtrain,Xtest,ytrain,ytest = train_test_split(x,y,test_size=0.3) Xtrain.index = range(Xtrain.shape[0]) #重构index #Xtrain.reset_index(drop=True,inplace=True) #会多一列index列，不好用 for i in [Xtrain,Xtest,ytrain,ytest]: i.index = range(i.shape[0]) clf = DecisionTreeClassifier(random_state=25) clf = clf.fit(Xtrain,ytrain) score = clf.score(Xtest,ytest) score 0.7602996254681648\rclf = DecisionTreeClassifier(random_state=25) #别划分测试和训练集，自动划分 score = cross_val_score(clf,x,y,cv=","date":"2021-07-21","objectID":"/20210721/:2:0","tags":["python","数学建模","神经网络","机器学习"],"title":"决策树3-泰坦尼克号实例(网格搜索,超参数调参)","uri":"/20210721/"},{"categories":["数学建模","python","机器学习"],"content":"代码 from sklearn import tree from sklearn.datasets import load_wine from sklearn.model_selection import train_test_split wine = load_wine() wine.data.shape (178, 13)\rwine.target array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\r1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\r2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\r2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\r2, 2])\rimport pandas as pd pd.concat([pd.DataFrame(wine.data),pd.DataFrame(wine.target)],axis=1) 0\r1\r2\r3\r4\r5\r6\r7\r8\r9\r10\r11\r12\r0\r0\r14.23\r1.71\r2.43\r15.6\r127.0\r2.80\r3.06\r0.28\r2.29\r5.64\r1.04\r3.92\r1065.0\r0\r1\r13.20\r1.78\r2.14\r11.2\r100.0\r2.65\r2.76\r0.26\r1.28\r4.38\r1.05\r3.40\r1050.0\r0\r2\r13.16\r2.36\r2.67\r18.6\r101.0\r2.80\r3.24\r0.30\r2.81\r5.68\r1.03\r3.17\r1185.0\r0\r3\r14.37\r1.95\r2.50\r16.8\r113.0\r3.85\r3.49\r0.24\r2.18\r7.80\r0.86\r3.45\r1480.0\r0\r4\r13.24\r2.59\r2.87\r21.0\r118.0\r2.80\r2.69\r0.39\r1.82\r4.32\r1.04\r2.93\r735.0\r0\r...\r...\r...\r...\r...\r...\r...\r...\r...\r...\r...\r...\r...\r...\r...\r173\r13.71\r5.65\r2.45\r20.5\r95.0\r1.68\r0.61\r0.52\r1.06\r7.70\r0.64\r1.74\r740.0\r2\r174\r13.40\r3.91\r2.48\r23.0\r102.0\r1.80\r0.75\r0.43\r1.41\r7.30\r0.70\r1.56\r750.0\r2\r175\r13.27\r4.28\r2.26\r20.0\r120.0\r1.59\r0.69\r0.43\r1.35\r10.20\r0.59\r1.56\r835.0\r2\r176\r13.17\r2.59\r2.37\r20.0\r120.0\r1.65\r0.68\r0.53\r1.46\r9.30\r0.60\r1.62\r840.0\r2\r177\r14.13\r4.10\r2.74\r24.5\r96.0\r2.05\r0.76\r0.56\r1.35\r9.20\r0.61\r1.60\r560.0\r2\r178 rows × 14 columns wine.feature_names ['alcohol',\r'malic_acid',\r'ash',\r'alcalinity_of_ash',\r'magnesium',\r'total_phenols',\r'flavanoids',\r'nonflavanoid_phenols',\r'proanthocyanins',\r'color_intensity',\r'hue',\r'od280/od315_of_diluted_wines',\r'proline']\rwine.target_names array(['class_0', 'class_1', 'class_2'], dtype='\u003cU7')\r#XXYY Xtrain,Xtest,ytrain,ytest=train_test_split(wine.data,wine.target,test_size=0.3) Xtrain.shape (124, 13)\rXtest.shape (54, 13)\rytrain array([2, 0, 0, 1, 1, 2, 0, 2, 0, 0, 1, 0, 1, 2, 1, 2, 1, 0, 1, 1, 0, 1,\r1, 1, 0, 0, 0, 2, 0, 2, 1, 0, 2, 1, 1, 1, 1, 2, 1, 0, 2, 0, 0, 2,\r0, 2, 1, 2, 1, 1, 1, 0, 0, 0, 0, 1, 2, 0, 1, 1, 0, 1, 1, 0, 0, 0,\r1, 1, 2, 2, 0, 0, 1, 2, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 2, 1, 1, 0,\r2, 2, 2, 2, 1, 0, 1, 2, 0, 0, 1, 0, 0, 2, 1, 0, 0, 2, 2, 1, 2, 0,\r2, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 2, 0, 0])\r#通过特征计算不纯度进行分类 clf = tree.DecisionTreeClassifier(criterion=\"entropy\",random_state=30,splitter=\"random\")#不纯度 #random_state=30 设置随机数种子复现结果，设置随机参数 #splitter 设置为best 或random 一个设置更重要分支进行分枝，一个更随机防止过拟合 clf = clf.fit(Xtrain,ytrain) score = clf.score(Xtest,ytest)#返回预测的准确度accuracy score 0.8888888888888888\rfeature_names=wine.feature_names #画树 import graphviz dot_data = tree.export_graphviz(clf ,feature_names=feature_names ,class_names=[\"白酒\",\"红酒\",\"伏特加\"] ,filled=True #填充颜色 ,rounded=True#直角框变成圆角框 ,out_file=None ) graph = graphviz.Source(dot_data) graph clf.feature_importances_ array([0.26346976, 0. , 0. , 0. , 0. ,\r0.02075703, 0.36896763, 0. , 0. , 0.03519618,\r0.048165 , 0.20016672, 0.0632777 ])\r#特征重要性-元组列表 [*zip(feature_names,clf.feature_importances_)] [('alcohol', 0.2634697570171739),\r('malic_acid', 0.0),\r('ash', 0.0),\r('alcalinity_of_ash', 0.0),\r('magnesium', 0.0),\r('total_phenols', 0.020757027052013897),\r('flavanoids', 0.36896762677034245),\r('nonflavanoid_phenols', 0.0),\r('proanthocyanins', 0.0),\r('color_intensity', 0.035196177552898056),\r('hue', 0.04816499533787735),\r('od280/od315_of_diluted_wines', 0.20016671726273566),\r('proline', 0.0632776990069589)]\rscroe_train = clf.score(Xtrain,ytrain) scroe_train 1.0\r剪枝策略 #限制深度 max_depth 3 #min_samples_left 分支满足条件才能向下生长 5~1 或者用百分比0.几 #通过特征计算不纯度进行分类 clf = tree.DecisionTreeClassifier(criterion=\"entropy\"#不纯度 ,random_state=30 ,splitter=\"random\" #,max_depth=3 ,min_samples_leaf=10 #,min_impurity_split=1 ) #random_state=30 设置随机数种子复现结果，设置随机参数 #splitter 设置为best 或random 一个设置更重要分支进","date":"2021-07-20","objectID":"/20210720/:1:0","tags":["python","数学建模","神经网络","机器学习"],"title":"决策树2-简单调参","uri":"/20210720/"},{"categories":["数学建模","python","机器学习"],"content":"代码 import numpy as np import matplotlib.pyplot as plt from sklearn import datasets from sklearn.model_selection import train_test_split #分割训练集和测试集 from sklearn.neighbors import KNeighborsClassifier #K近邻 简单案例 iris=datasets.load_iris() iris_X = iris.data iris_y=iris.target iris_X[:2,:]#四个属性两朵花 array([[5.1, 3.5, 1.4, 0.2],\r[4.9, 3. , 1.4, 0.2]])\riris_y#三类花 array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\r0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\r1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\r2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\r2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\r#分割训练集和测试集 X_train,X_test,y_train,y_test=train_test_split(iris_X,iris_y,test_size=0.3)#测试占30% y_train#顺便打乱了数据 array([0, 0, 2, 1, 0, 0, 2, 0, 0, 2, 0, 2, 1, 1, 2, 1, 2, 2, 2, 1, 2, 1,\r1, 0, 0, 2, 1, 1, 2, 1, 2, 1, 0, 2, 2, 0, 1, 1, 1, 0, 2, 0, 1, 0,\r1, 2, 2, 1, 0, 1, 2, 1, 2, 0, 2, 1, 2, 1, 1, 0, 0, 2, 2, 0, 1, 2,\r1, 0, 0, 0, 2, 0, 0, 1, 2, 2, 2, 1, 2, 1, 0, 1, 1, 0, 1, 2, 0, 2,\r1, 2, 0, 1, 0, 0, 0, 1, 1, 0, 0, 2, 2, 2, 0, 2, 0])\rknn = KNeighborsClassifier() #使用K近邻分类 knn.fit(X_train,y_train) #输入测试集 KNeighborsClassifier()\rknn.predict(X_test)#预测 array([2, 2, 2, 1, 0, 2, 0, 2, 2, 0, 0, 0, 1, 0, 0, 2, 1, 0, 1, 1, 0, 2,\r2, 1, 1, 1, 0, 1, 0, 2, 2, 2, 2, 0, 1, 0, 1, 2, 2, 0, 1, 0, 1, 1,\r1])\ry_test array([2, 2, 2, 1, 0, 1, 0, 2, 2, 0, 0, 0, 2, 0, 0, 2, 1, 0, 1, 1, 0, 2,\r2, 1, 1, 1, 0, 1, 0, 2, 1, 2, 2, 0, 1, 0, 1, 2, 2, 0, 1, 0, 1, 1,\r1])\r模型导入训练 from sklearn import datasets #导入基础数据 from sklearn.linear_model import LinearRegression #导入模型 #导入数据 loaded_data = datasets.load_boston() data_X = loaded_data.data data_y = loaded_data.target #定义模型并训练 model = LinearRegression()#线性模型 model.fit(data_X,data_y) LinearRegression()\r#预测 model.predict(data_X[:4,:]) array([30.00384338, 25.02556238, 30.56759672, 28.60703649])\rdata_y[:4] array([24. , 21.6, 34.7, 33.4])\rimport matplotlib.pyplot as plt #创造数据 X,y = datasets.make_regression(n_samples=100,n_features=1,n_targets=1,noise=1) #noise 离散程度 plt.scatter(X,y)#画点 #y=0.1x+0.3 #斜率 截距 model.coef_ array([-1.08011358e-01, 4.64204584e-02, 2.05586264e-02, 2.68673382e+00,\r-1.77666112e+01, 3.80986521e+00, 6.92224640e-04, -1.47556685e+00,\r3.06049479e-01, -1.23345939e-02, -9.52747232e-01, 9.31168327e-03,\r-5.24758378e-01])\rmodel.intercept_ 36.459488385090125\r#输出之前模型定义的参数 model.get_params() {'copy_X': True,\r'fit_intercept': True,\r'n_jobs': None,\r'normalize': False,\r'positive': False}\r#打分评价 model.score(data_X,data_y)#R^2 coffiction of determination 0.7406426641094095\r归一化 from sklearn import preprocessing import numpy as np a = np.array([[10,2.7,3.6], [-100,5,-2], [120,20,40]],dtype=np.float64) a array([[ 10. , 2.7, 3.6],\r[-100. , 5. , -2. ],\r[ 120. , 20. , 40. ]])\r#归一化 preprocessing.scale(a) array([[ 0. , -0.85170713, -0.55138018],\r[-1.22474487, -0.55187146, -0.852133 ],\r[ 1.22474487, 1.40357859, 1.40351318]])\r#生成可以标准化的数据 from sklearn.datasets import make_classification #支持向量机的分类器 from sklearn.svm import SVC X,y = datasets.make_classification(n_samples=300,n_features=2,n_redundant=0,\\ n_informative=2,random_state=22,\\ n_clusters_per_class=1,\\ scale=100) plt.scatter(X[:,0],X[:,1],c=y) \u003cmatplotlib.collections.PathCollection at 0x7f1842f7faf0\u003e\rX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3) clf = SVC() clf.fit(X_train,y_train) clf.score(X_test,y_test) 0.9333333333333333\r#归一化 #X=preprocessing.scale(X,r) #指定范围归一化 X=preprocessing.minmax_scale(X,feature_range=(-1,1)) #归一化后 X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3) clf = SVC() clf.fit(X_train,y_train) clf.score(X_test,y_test) 0.9555555555555556\r交叉验证 # cross_validation 修改为 model_selection from sklearn.datasets import load_iris from sklearn.model_selection import train_test_split #分割训练集和测试集 from sklearn.neighbors import KNeighborsClassifie","date":"2021-07-19","objectID":"/20210719/:1:0","tags":["python","数学建模","神经网络","机器学习"],"title":"决策树1-分类器","uri":"/20210719/"},{"categories":["数学建模","python","机器学习"],"content":"代码 import numpy as np from sklearn.tree import DecisionTreeRegressor #回归树 import matplotlib.pyplot as plt #生成噪声曲线 rng = np.random.RandomState(1) rng.rand(2,3)#生成区分行列的二维数据，一维数据不分行列，生成0~1之间的数 array([[4.17022005e-01, 7.20324493e-01, 1.14374817e-04],\r[3.02332573e-01, 1.46755891e-01, 9.23385948e-02]])\rX = np.sort(5*rng.rand(80,1),axis=0) y = np.sin(X).ravel()#导入二维数据，ravel降维y，可将任意维度降维为一维 plt.scatter(X,y,s=20,edgecolors=\"black\",c=\"darkorange\",label=\"data\") \u003cmatplotlib.collections.PathCollection at 0x7f87d52f56a0\u003e\ry[::5] += 3 * (0.5 - rng.rand(16))#每5个数字加随机+-0.5之间的数当成噪声 plt.scatter(X,y,s=20,edgecolors=\"black\",c=\"darkorange\",label=\"data\") \u003cmatplotlib.collections.PathCollection at 0x7f87d5113e50\u003e\r#设定参数的模型导入并训练 regr_1 = DecisionTreeRegressor(max_depth=2) regr_2 = DecisionTreeRegressor(max_depth=5) regr_1.fit(X,y) regr_2.fit(X,y) DecisionTreeRegressor(max_depth=5)\rX_test = np.arange(0.0,5.0,0.01)[:,np.newaxis] #取0~5以0.01为步长的有顺序点，后面将1维升维2，跟reshape（-1，1）作用一致 y_1 = regr_1.predict(X_test) y_2 = regr_2.predict(X_test) plt.figure() plt.scatter(X,y,s=20,edgecolors=\"black\",c=\"darkorange\",label=\"data\")#边框，点，图例名称 plt.plot(X_test,y_1,color=\"cornflowerblue\",label=\"max_depth=2\",linewidth=2) plt.plot(X_test,y_2,color=\"yellowgreen\",label=\"max_depth=5\",linewidth=2) plt.xlabel(\"data\") plt.ylabel(\"target\") plt.title(\"Decision Tree Regression\") plt.legend()#显示图例 plt.show() ","date":"2021-07-18","objectID":"/20210718/:1:0","tags":["python","数学建模","神经网络","机器学习"],"title":"决策树线性回归","uri":"/20210718/"},{"categories":["数学建模","python"],"content":"我的前提条件，实际能使用jupyternotebook都可 Ubuntu 20.0系统 miniconda3和jupyter ","date":"2021-07-17","objectID":"/20210717/:1:0","tags":["python","linux"],"title":"直接通过jupyternotebook安装库","uri":"/20210717/"},{"categories":["数学建模","python"],"content":"直接通过jupyter notebook安装库 代码： 查找解释器位置 import os os.sys.executable 示例结果： '/usr/bin/python3' 安装示例模板 import os libs = { \"requests\",\"jieba\",\"beautifulsoup4\",\"matplotlib\",\"numpy\",\"pandas\",\"openpyxl\",\"tensorflow\",\"仿照格式这里填写要安装的包\" } try: for lib in libs: #这里的地址是上一步显示的解释器位置 os.system('/usr/bin/python3 -m pip install '+lib) print(\"Successful\") except: print('error') ","date":"2021-07-17","objectID":"/20210717/:2:0","tags":["python","linux"],"title":"直接通过jupyternotebook安装库","uri":"/20210717/"},{"categories":["python","数学建模"],"content":"新型冠状病毒（COVID-19/2019-nCoV）疫情分析 源文档详见：博客相关资源-新冠疫情数据分析文件 ","date":"2021-07-15","objectID":"/20210715/:0:0","tags":["数学建模","python"],"title":"2020新型冠状病毒（COVID-19/2019-nCoV）疫情分析(补档)","uri":"/20210715/"},{"categories":["python","数学建模"],"content":"重要说明 分析文档：完成度：代码质量 3:5:2 其中分析文档是指你数据分析的过程中，对各问题分析的思路、对结果的解释、说明(要求言简意赅，不要为写而写) ps:你自己写的代码胜过一切的代笔，无关美丑，只问今日比昨日更长进！加油！ 由于数据过多，查看数据尽量使用head()或tail()，以免程序长时间无响应 ======================= 本项目数据来源于丁香园。本项目主要目的是通过对疫情历史数据的分析研究，以更好的了解疫情与疫情的发展态势，为抗击疫情之决策提供数据支持。 关于本章使用的数据集，欢迎点击——\u003e我的B站视频 在评论区获取。 ","date":"2021-07-15","objectID":"/20210715/:1:0","tags":["数学建模","python"],"title":"2020新型冠状病毒（COVID-19/2019-nCoV）疫情分析(补档)","uri":"/20210715/"},{"categories":["python","数学建模"],"content":"一. 提出问题 从全国范围，你所在省市，国外疫情等三个方面主要研究以下几个问题： （一）全国累计确诊/疑似/治愈/死亡情况随时间变化趋势如何？ （二）全国新增确诊/疑似/治愈/死亡情况随时间变化趋势如何？ （三）全国新增境外输入随时间变化趋势如何？ （四）你所在的省市情况如何？ （五）国外疫情态势如何？ （六）结合你的分析结果，对个人和社会在抗击疫情方面有何建议？ ","date":"2021-07-15","objectID":"/20210715/:2:0","tags":["数学建模","python"],"title":"2020新型冠状病毒（COVID-19/2019-nCoV）疫情分析(补档)","uri":"/20210715/"},{"categories":["python","数学建模"],"content":"二. 理解数据 原始数据集：AreaInfo.csv，导入相关包及读取数据： r_hex = '#dc2624' # red, RGB = 220,38,36 dt_hex = '#2b4750' # dark teal, RGB = 43,71,80 tl_hex = '#45a0a2' # teal, RGB = 69,160,162 r1_hex = '#e87a59' # red, RGB = 232,122,89 tl1_hex = '#7dcaa9' # teal, RGB = 125,202,169 g_hex = '#649E7D' # green, RGB = 100,158,125 o_hex = '#dc8018' # orange, RGB = 220,128,24 tn_hex = '#C89F91' # tan, RGB = 200,159,145 g50_hex = '#6c6d6c' # grey-50, RGB = 108,109,108 bg_hex = '#4f6268' # blue grey, RGB = 79,98,104 g25_hex = '#c7cccf' # grey-25, RGB = 199,204,207 import numpy as np import pandas as pd import matplotlib,re import matplotlib.pyplot as plt from matplotlib.pyplot import MultipleLocator data = pd.read_csv(r'data/AreaInfo.csv') 查看与统计数据，以对数据有一个大致了解 data.head() continentName\rcontinentEnglishName\rcountryName\rcountryEnglishName\rprovinceName\rprovinceEnglishName\rprovince_zipCode\rprovince_confirmedCount\rprovince_suspectedCount\rprovince_curedCount\rprovince_deadCount\rupdateTime\rcityName\rcityEnglishName\rcity_zipCode\rcity_confirmedCount\rcity_suspectedCount\rcity_curedCount\rcity_deadCount\r0\r北美洲\rNorth America\r美国\rUnited States of America\r美国\rUnited States of America\r971002\r2306247\r0.0\r640198\r120351\r2020-06-23 10:01:45\rNaN\rNaN\rNaN\rNaN\rNaN\rNaN\rNaN\r1\r南美洲\rSouth America\r巴西\rBrazil\r巴西\rBrazil\r973003\r1106470\r0.0\r549386\r51271\r2020-06-23 10:01:45\rNaN\rNaN\rNaN\rNaN\rNaN\rNaN\rNaN\r2\r欧洲\rEurope\r英国\rUnited Kingdom\r英国\rUnited Kingdom\r961007\r305289\r0.0\r539\r42647\r2020-06-23 10:01:45\rNaN\rNaN\rNaN\rNaN\rNaN\rNaN\rNaN\r3\r欧洲\rEurope\r俄罗斯\rRussia\r俄罗斯\rRussia\r964006\r592280\r0.0\r344416\r8206\r2020-06-23 10:01:45\rNaN\rNaN\rNaN\rNaN\rNaN\rNaN\rNaN\r4\r南美洲\rSouth America\r智利\rChile\r智利\rChile\r973004\r246963\r0.0\r44946\r4502\r2020-06-23 10:01:45\rNaN\rNaN\rNaN\rNaN\rNaN\rNaN\rNaN\r","date":"2021-07-15","objectID":"/20210715/:3:0","tags":["数学建模","python"],"title":"2020新型冠状病毒（COVID-19/2019-nCoV）疫情分析(补档)","uri":"/20210715/"},{"categories":["python","数学建模"],"content":"三. 数据清洗 ","date":"2021-07-15","objectID":"/20210715/:4:0","tags":["数学建模","python"],"title":"2020新型冠状病毒（COVID-19/2019-nCoV）疫情分析(补档)","uri":"/20210715/"},{"categories":["python","数学建模"],"content":"（一）基本数据处理 数据清洗主要包括：选取子集，缺失数据处理、数据格式转换、异常值数据处理等。 国内疫情数据选取（最终选取的数据命名为china） 选取国内疫情数据 对于更新时间(updateTime)列，需将其转换为日期类型并提取出年-月-日，并查看处理结果。(提示：dt.date) 因数据每天按小时更新，一天之内有很多重复数据，请去重并只保留一天之内最新的数据。 提示：df.drop_duplicates(subset=[‘provinceName’, ‘updateTime’], keep=‘first’, inplace=False) 其中df是你选择的国内疫情数据的DataFrame 分析：选取countryName一列中值为中国的行组成CHINA。 CHINA = data.loc[data['countryName'] == '中国'] CHINA.dropna(subset=['cityName'], how='any', inplace=True) #CHINA D:\\Anaconda\\envs\\python32\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame\rSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\r分析：取出含所有中国城市的列表 cities = list(set(CHINA['cityName'])) 分析：遍历取出每一个城市的子dataframe，然后用sort对updateTime进行时间排序 for city in cities: CHINA.loc[data['cityName'] == city].sort_values(by = 'updateTime') 分析：去除空值所在行 CHINA.dropna(subset=['cityName'],inplace=True) #CHINA.loc[CHINA['cityName'] == '秦皇岛'].tail(20) D:\\Anaconda\\envs\\python32\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame\rSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\r\"\"\"Entry point for launching an IPython kernel.\r分析：将CHINA中的updateTime列进行格式化处理 CHINA.updateTime = pd.to_datetime(CHINA.updateTime,format=\"%Y-%m-%d\",errors='coerce').dt.date #CHINA.loc[data['cityName'] == '秦皇岛'].tail(15) D:\\Anaconda\\envs\\python32\\lib\\site-packages\\pandas\\core\\generic.py:5303: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\rTry using .loc[row_indexer,col_indexer] = value instead\rSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\rself[name] = value\rCHINA.head() continentName\rcontinentEnglishName\rcountryName\rcountryEnglishName\rprovinceName\rprovinceEnglishName\rprovince_zipCode\rprovince_confirmedCount\rprovince_suspectedCount\rprovince_curedCount\rprovince_deadCount\rupdateTime\rcityName\rcityEnglishName\rcity_zipCode\rcity_confirmedCount\rcity_suspectedCount\rcity_curedCount\rcity_deadCount\r136\r亚洲\rAsia\r中国\rChina\r陕西省\rShaanxi\r610000\r317\r1.0\r307\r3\r2020-06-23\r境外输入\rNaN\r0.0\r72.0\r0.0\r65.0\r0.0\r137\r亚洲\rAsia\r中国\rChina\r陕西省\rShaanxi\r610000\r317\r1.0\r307\r3\r2020-06-23\r西安\rXi'an\r610100.0\r120.0\r0.0\r117.0\r3.0\r138\r亚洲\rAsia\r中国\rChina\r陕西省\rShaanxi\r610000\r317\r1.0\r307\r3\r2020-06-23\r安康\rAnkang\r610900.0\r26.0\r0.0\r26.0\r0.0\r139\r亚洲\rAsia\r中国\rChina\r陕西省\rShaanxi\r610000\r317\r1.0\r307\r3\r2020-06-23\r汉中\rHanzhong\r610700.0\r26.0\r0.0\r26.0\r0.0\r140\r亚洲\rAsia\r中国\rChina\r陕西省\rShaanxi\r610000\r317\r1.0\r307\r3\r2020-06-23\r咸阳\rXianyang\r610400.0\r17.0\r0.0\r17.0\r0.0\r分析：每日数据的去重只保留第一个数据，因为前面已经对时间进行排序，第一个数据即为当天最新数据 分析：考虑到合并dataframe需要用到concat，需要创建一个初始china real = CHINA.loc[data['cityName'] == cities[1]] real.drop_duplicates(subset='updateTime', keep='first', inplace=True) china = real D:\\Anaconda\\envs\\python32\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame\rSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\r分析：遍历每个城市dataframe进行每日数据的去重，否则会出现相同日期只保留一个城市的数据的情况 for city in cities[2:]: real_data = CHINA.loc[data['cityName'] == city] real_data.drop_duplicates(subset='updateTime', keep='first', inplace=True) china = pd.concat([real_data, china],sort=False) D:\\Anaconda\\envs\\python32\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame\rSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\rThis is separate from the ipykernel package so we can avoid doing imports until\r查看数据信息，是否有缺失数据/数据类型是否正确。 提示：若不会处理缺失值，可以将其舍弃 分析：有的城市不是每日都上报的，如果某日只统计上报的那些城市，那","date":"2021-07-15","objectID":"/20210715/:4:1","tags":["数学建模","python"],"title":"2020新型冠状病毒（COVID-19/2019-nCoV）疫情分析(补档)","uri":"/20210715/"},{"categories":["python","数学建模"],"content":"四. 数据分析及可视化 在进行数据分析及可视化时，依据每个问题选取所需变量并新建DataFrame再进行分析和可视化展示，这样数据不易乱且条理更清晰。 ","date":"2021-07-15","objectID":"/20210715/:5:0","tags":["数学建模","python"],"title":"2020新型冠状病毒（COVID-19/2019-nCoV）疫情分析(补档)","uri":"/20210715/"},{"categories":["python","数学建模"],"content":"基础分析 基础分析，只允许使用numpy、pandas和matplotlib库。 可以在一张图上多个坐标系展示也可以在多张图上展示 请根据分析目的选择图形的类型(折线图、饼图、直方图和散点图等等)，实在没有主意可以到百度疫情地图或其他疫情分析的站点激发激发灵感。 （一）全国累计确诊/疑似/治愈/死亡情况随时间变化趋势如何？ 分析：要获得全国累计情况随时间变化趋势，首先需要整合每日全国累计确诊情况做成date_confirmed 分析：要整合每日全国累计确诊情况，首先得提取每个省份每日当天最新累计确诊人数，省份数据求和后形成dataframe， for循环拼接到date_confirmed中 date = list(set(china['updateTime'])) date.sort() date [datetime.date(2020, 1, 24), datetime.date(2020, 1, 25), datetime.date(2020, 1, 26), datetime.date(2020, 1, 27), datetime.date(2020, 1, 28), datetime.date(2020, 1, 29), datetime.date(2020, 1, 30), datetime.date(2020, 1, 31), datetime.date(2020, 2, 1), datetime.date(2020, 2, 2), datetime.date(2020, 2, 3), datetime.date(2020, 2, 4), datetime.date(2020, 2, 5), datetime.date(2020, 2, 6), datetime.date(2020, 2, 7), datetime.date(2020, 2, 8), datetime.date(2020, 2, 9), datetime.date(2020, 2, 10), datetime.date(2020, 2, 11), datetime.date(2020, 2, 12), datetime.date(2020, 2, 13), datetime.date(2020, 2, 14), datetime.date(2020, 2, 15), datetime.date(2020, 2, 16), datetime.date(2020, 2, 17), datetime.date(2020, 2, 18), datetime.date(2020, 2, 19), datetime.date(2020, 2, 20), datetime.date(2020, 2, 21), datetime.date(2020, 2, 22), datetime.date(2020, 2, 23), datetime.date(2020, 2, 24), datetime.date(2020, 2, 25), datetime.date(2020, 2, 26), datetime.date(2020, 2, 27), datetime.date(2020, 2, 28), datetime.date(2020, 2, 29), datetime.date(2020, 3, 1), datetime.date(2020, 3, 2), datetime.date(2020, 3, 3), datetime.date(2020, 3, 4), datetime.date(2020, 3, 5), datetime.date(2020, 3, 6), datetime.date(2020, 3, 7), datetime.date(2020, 3, 8), datetime.date(2020, 3, 9), datetime.date(2020, 3, 10), datetime.date(2020, 3, 11), datetime.date(2020, 3, 12), datetime.date(2020, 3, 13), datetime.date(2020, 3, 14), datetime.date(2020, 3, 15), datetime.date(2020, 3, 16), datetime.date(2020, 3, 17), datetime.date(2020, 3, 18), datetime.date(2020, 3, 19), datetime.date(2020, 3, 20), datetime.date(2020, 3, 21), datetime.date(2020, 3, 22), datetime.date(2020, 3, 23), datetime.date(2020, 3, 24), datetime.date(2020, 3, 25), datetime.date(2020, 3, 26), datetime.date(2020, 3, 27), datetime.date(2020, 3, 28), datetime.date(2020, 3, 29), datetime.date(2020, 3, 30), datetime.date(2020, 3, 31), datetime.date(2020, 4, 1), datetime.date(2020, 4, 2), datetime.date(2020, 4, 3), datetime.date(2020, 4, 4), datetime.date(2020, 4, 5), datetime.date(2020, 4, 6), datetime.date(2020, 4, 7), datetime.date(2020, 4, 8), datetime.date(2020, 4, 9), datetime.date(2020, 4, 10), datetime.date(2020, 4, 11), datetime.date(2020, 4, 12), datetime.date(2020, 4, 13), datetime.date(2020, 4, 14), datetime.date(2020, 4, 15), datetime.date(2020, 4, 16), datetime.date(2020, 4, 17), datetime.date(2020, 4, 18), datetime.date(2020, 4, 19), datetime.date(2020, 4, 20), datetime.date(2020, 4, 21), datetime.date(2020, 4, 22), datetime.date(2020, 4, 23), datetime.date(2020, 4, 24), datetime.date(2020, 4, 25), datetime.date(2020, 4, 26), datetime.date(2020, 4, 27), datetime.date(2020, 4, 28), datetime.date(2020, 4, 29), datetime.date(2020, 4, 30), datetime.date(2020, 5, 1), datetime.date(2020, 5, 2), datetime.date(2020, 5, 3), datetime.date(2020, 5, 4), datetime.date(2020, 5, 5), datetime.date(2020, 5, 6), datetime.date(2020, 5, 7), datetime.date(2020, 5, 8), datetime.date(2020, 5, 9), datetime.date(2020, 5, 10), datetime.date(2020, 5, 11), datetime.date(2020, 5, 12), datetime.date(2020, 5, 13), datetime.date(2020, 5, 14), datetime.date(2020, 5, 15), datetime.date(2020, 5, 16), datetime.date(2020, 5, 17), datetime.date(2020, 5, 18), datetime.date(2020, 5, 19), datetime.date(2020, 5, 20), datetime.date(2020, 5, 21), datetime.date(2020, 5, 22), datetime.date(2020, 5, 23), datetime.date(2020, 5, 24), datetime.date(2020, 5, 25), datetime.date(2020, 5, 26), datetime.date(2020, 5, 27), datetime.date(2020, 5, 28), datetime.date(2020, 5, 29), datetime.date(2020, 5, 30), datetime.date(2020, 5, 31), datetime.date(2020, 6, 1), datetime.date(2020, 6, 2), datetime.date(2","date":"2021-07-15","objectID":"/20210715/:5:1","tags":["数学建模","python"],"title":"2020新型冠状病毒（COVID-19/2019-nCoV）疫情分析(补档)","uri":"/20210715/"},{"categories":["python","数学建模"],"content":"附加分析(选做) 附加分析，所使用的库不限，比如可以使用seaborn、pyecharts等库。 限于个人能力，没有做。 ","date":"2021-07-15","objectID":"/20210715/:5:2","tags":["数学建模","python"],"title":"2020新型冠状病毒（COVID-19/2019-nCoV）疫情分析(补档)","uri":"/20210715/"},{"categories":["python","数学建模"],"content":"前言 帮舍友整的，不知道具体实际意义。 ","date":"2021-07-14","objectID":"/20210714/:1:0","tags":["数学建模","python"],"title":"某区域流体数据处理(只会写操作，不知道具体意义)","uri":"/20210714/"},{"categories":["python","数学建模"],"content":"代码 import numpy as np import pandas as pd data = pd.read_excel(r'C:\\Users\\祈LHL\\Desktop\\data.xlsx') data.head() cellnumber\rx-coordinate y-coordinate\rz-coordinate density z-velocity relative-z-velocity x-coordinate.1 y-coordinate z-face-area boundary-cell-dist boundary-normal-dist 0 1 -12.597898 -2.404495 -6.320497 1.226 -22.205814 -22.205814 -12.597899 -2.404528 -0.006824 1 0.010276 1 2 -12.597898 -2.321485 -6.320487 1.226 -23.532957 -23.532957 -12.597899 -2.321584 -0.006824 1 0.020553 2 3 -12.515688 -2.404495 -6.320500 1.226 -23.167622 -23.167622 -12.515688 -2.404528 -0.006824 1 0.020636 3 4 -12.515688 -2.321485 -6.320500 1.226 -24.882029 -24.882029 -12.515688 -2.321584 -0.006824 1 0.051111 4 5 -12.433477 -2.404495 -6.320500 1.226 -23.488083 -23.488083 -12.433478 -2.404528 -0.006824 1 0.020719 y = data.sort_values(by=\"y-coordinate\" , ascending=False) step = 4.892/6 i = 0 y_list = [] section = [] #y6 x3 #分y while i \u003c 6: step_y = float(\"%.8f\"%(i*step)) a_y = step_y-2.446 y_min = y.loc[y['y-coordinate'] \u003e= a_y] i +=1 step_y = float(\"%.8f\"%(i*step)) b_y = step_y-2.446 y_max = y_min.loc[y_min['y-coordinate'] \u003c b_y] y_list.append(y_max) section_y = (a_y,b_y) section.append(section_y) #section[5] j = 0 step = 1.562/3 x_list = [] section_x_list = [] section_y_list = [] #在y中分x while j \u003c= 5: temp = y_list[j] m = 0 while m \u003c= 2: step_x = float(\"%.8f\"%(m*step)) a_x = step_x-12.639 x_min = temp.loc[temp['x-coordinate'] \u003e= a_x] m +=1 step_x = float(\"%.8f\"%(m*step)) b_x = step_x-12.639 x_max = x_min.loc[temp['x-coordinate'] \u003c b_x] x_list.append(x_max) section_x = (a_x,b_x) section_x_list.append(section_x) section_y_list.append(section[j]) j += 1 #18个块 section_list = [] Q_list = [] i = 0 while i \u003c= 17: temp_l = x_list[i] Q = (temp_l[\"density\"]*temp_l[\"z-velocity\"]*temp_l[\"z-face-area\"]).sum() i +=1 Q_list.append(Q) section_x_list [(-12.639, -12.118333329999999), (-12.118333329999999, -11.597666669999999), (-11.597666669999999, -11.077), (-12.639, -12.118333329999999), (-12.118333329999999, -11.597666669999999), (-11.597666669999999, -11.077), (-12.639, -12.118333329999999), (-12.118333329999999, -11.597666669999999), (-11.597666669999999, -11.077), (-12.639, -12.118333329999999), (-12.118333329999999, -11.597666669999999), (-11.597666669999999, -11.077), (-12.639, -12.118333329999999), (-12.118333329999999, -11.597666669999999), (-11.597666669999999, -11.077), (-12.639, -12.118333329999999), (-12.118333329999999, -11.597666669999999), (-11.597666669999999, -11.077)] section_y_list [(-2.446, -1.63066667), (-2.446, -1.63066667), (-2.446, -1.63066667), (-1.63066667, -0.8153333300000001), (-1.63066667, -0.8153333300000001), (-1.63066667, -0.8153333300000001), (-0.8153333300000001, 0.0), (-0.8153333300000001, 0.0), (-0.8153333300000001, 0.0), (0.0, 0.8153333299999996), (0.0, 0.8153333299999996), (0.0, 0.8153333299999996), (0.8153333299999996, 1.6306666699999997), (0.8153333299999996, 1.6306666699999997), (0.8153333299999996, 1.6306666699999997), (1.6306666699999997, 2.446), (1.6306666699999997, 2.446), (1.6306666699999997, 2.446)] index = [] i = 0 while i \u003c= 2: index.append(section_x_list[i]) i+=1 index [(-12.639, -12.118333329999999), (-12.118333329999999, -11.597666669999999), (-11.597666669999999, -11.077)] cols = [] i = 0 while i \u003c= 17: cols.append(section_y_list[i]) i+=3 cols [(-2.446, -1.63066667), (-1.63066667, -0.8153333300000001), (-0.8153333300000001, 0.0), (0.0, 0.8153333299999996), (0.8153333299999996, 1.6306666699999997), (1.6306666699999997, 2.446)] j = 0 data = {} while j \u003c=5: col = cols[j] data[col]= 1 j += 1 data {(-2.446, -1.63066667): 1, (-1.63066667, -0.8153333300000001): 1, (-0.8153333300000001, 0.0): 1, (0.0, 0.8153333299999996): 1, (0.8153333299999996, 1.6306666699999997): 1, (1.6306666699999997, 2.446): 1} temp_list = Q_list.copy() r = 0 l = 0 for i in data: content = [] for j in range(3): content.append(Q_list[l]) l+=1 data[i] = content data {(-2.446, -1.63066667): [12.427282344087539, 12.86438295520224, 8.104732674789329]","date":"2021-07-14","objectID":"/20210714/:2:0","tags":["数学建模","python"],"title":"某区域流体数据处理(只会写操作，不知道具体意义)","uri":"/20210714/"},{"categories":["数学建模"],"content":"前言 感谢组员书写书面报告，代码部分由我书写，我写的很烂，将就看吧。 ","date":"2021-07-13","objectID":"/20210713/:1:0","tags":["matlab","数学建模","皮尔逊相关系数","熵值法","多元函数拟合"],"title":"多元回归和熵值评价法及多目标遗传优化算法","uri":"/20210713/"},{"categories":["数学建模"],"content":"第一届长三角数学建模 ","date":"2021-07-13","objectID":"/20210713/:2:0","tags":["matlab","数学建模","皮尔逊相关系数","熵值法","多元函数拟合"],"title":"多元回归和熵值评价法及多目标遗传优化算法","uri":"/20210713/"},{"categories":["数学建模"],"content":"B题 锅炉水冷壁温度曲线 ","date":"2021-07-13","objectID":"/20210713/:3:0","tags":["matlab","数学建模","皮尔逊相关系数","熵值法","多元函数拟合"],"title":"多元回归和熵值评价法及多目标遗传优化算法","uri":"/20210713/"},{"categories":["数学建模"],"content":"1Stopt多元拟合 个人体会： 只能确定2个自变量1个因变量的拟合函数形式，更高维的无法寻找公式进行拟合。 优点是优化算法基本包含，可以拿来做模型优化（简单的函数形式）。 多于2个自变量的拟合可以使用逐步线性回归法（matlab内置工具箱），缺点是拟合项数会很多，难以写出函数形式。 ps：相关资源在右上角博客资源页面 ","date":"2021-07-13","objectID":"/20210713/:4:0","tags":["matlab","数学建模","皮尔逊相关系数","熵值法","多元函数拟合"],"title":"多元回归和熵值评价法及多目标遗传优化算法","uri":"/20210713/"},{"categories":["数学建模"],"content":"逐步线性回归 clc clear all X1=xlsread('附件1.xlsx');%因变量 data1=X1(3172:end,11); X2=xlsread('附件2.xlsx');%自变量 data2=X2(3172:end,2:50); %1 2 3 4 6 12 13 31 34 37 38 39 %temp=[data2,data2.^2,data2.^3,log10(data2)]; %stepwise(temp,data1);%0.6990 %temp1=data2; temp1=[data2(:,1),data2(:,2),data2(:,3),data2(:,4),data2(:,6),data2(:,12),data2(:,13),data2(:,31),data2(:,34),data2(:,37),data2(:,38),data2(:,39)]; temp2=[temp1,temp1.^2,temp1.^3,temp1.^4,temp1.^5,log10(temp1),1./temp1]; %stepwise(temp2,data1);%0.6990 stepwise(temp2,data1); %12列拟合相关度54% %stats beta %temp3=[x1,x2,x3,x4,x6,x12,x13,x31,x34,x37,x38,x39]; 重点是这个： stepwise(自变量函数项,因变量); ","date":"2021-07-13","objectID":"/20210713/:5:0","tags":["matlab","数学建模","皮尔逊相关系数","熵值法","多元函数拟合"],"title":"多元回归和熵值评价法及多目标遗传优化算法","uri":"/20210713/"},{"categories":["数学建模"],"content":"皮尔逊相关系数 clc clear all X1=xlsread('附件1.xlsx'); data1=X1(:,11); X2=xlsread('附件2.xlsx'); data2=X2(:,44:end); data=[data1,data2]; %data=zscore(data);%对变量标准化 temp=corrcoef(data);%生成皮尔森相关性系数计算公式 pershen=temp(1,2:end);%求附件一管道十对附件二111个操作变量的皮尔森相关性系数 pershen=abs(pershen); %将皮尔森相关性系数求取绝对值 csvwrite('wenti4.csv',pershen); 类似照着写10个管道的 clc clear all X1=xlsread('附件1.xlsx'); data1=X1(:,2:11); X2=xlsread('附件2.xlsx'); data2=X2(:,2:end); data=[data1,data2]; %data=zscore(data);%对变量进行标准化 temp=corrcoef(data);% 生成皮尔森相关性系数计算公式 pershen=temp(1:10,11:end);%求附件一十个管道对附件二111个操作变量和53个状态变量的皮尔森相关性系数 pershen=abs(pershen);%将皮尔森相关性系数求取绝对值 csvwrite('wenti3.csv',pershen); %经过Excel筛选皮尔森相关性系数最大列数分别为119 112 114 5 115 121 91 92 1 73 result=[data2(:,119),data2(:,112)]; csvwrite('data10.csv',result); 拟合函数图像代码： clc; clear subplot(5,2,1) x1=(1:1:5000); M=csvread('C:\\Users\\86152\\Desktop\\data\\data1.csv'); x=M(:,1); y=M(:,2); p1=-366.623574952674; p2=-6309.81591583794; p3=-57878.3062818374; p4=15903.1406517026; p5=-53.4927163299915; p6=0.0889609164030065; p7=542.236136002024; p8=-218.986158913513; p9=17.338434284516; z=(p1+p2.*log(x)+p3.*(log(x)).^2+p4*y+p5*y.^2+p6*y.^3)./(1+p7*log(x)+p8*(log(x)).^2+p9.*y); plot(x1,z); xlabel('采样点'); ylabel('温度'); title('管道一温度曲线') subplot(5,2,2) x1=(1:1:5000); M=xlsread('C:\\Users\\86152\\Desktop\\data\\data2.xlsx'); x=M(:,1); y=M(:,2); p1=-760228.816854935; p2=9.40803736929389; p3=-0.0110468670816608; p4=2.36049470120192E-7; p5=10924.026332869; p6=-58.9224433132279; p7=0.141102010823114; p8=-0.000126582641617285; z=p1+p2.*x+p3.*x.^2+p4.*x.^3+p5.*y+p6.*y.^2+p7.*y.^3+p8.*y.^4; plot(x1,z); xlabel('采样点'); ylabel('温度'); title('管道二温度曲线') subplot(5,2,3) x1=(1:1:5000); M=csvread('C:\\Users\\86152\\Desktop\\data\\data3.csv'); x=M(:,1); y=M(:,2); p1=-278364.765528611; p2=-8053.13293300719; p3=702.700979973376; p4=4525.26042721373; p5=-25.4017726090204; p6=0.063270352619814; p7=-5.9005816668393E-5; z=p1+p2.*log(x)+p3.*(log(x)).^2+p4.*y+p5.*y.^2+p6.*y.^3+p7.*y.^4; plot(x1,z); xlabel('采样点'); ylabel('温度'); title('管道三温度曲线') subplot(5,2,4) x1=(1:1:5000); M=csvread('C:\\Users\\86152\\Desktop\\data\\data4.csv'); x=M(:,1); y=M(:,2); p1=-72.9520473758939; p2=-556.535840804353; p3=-6289.99299391888; p4=38088.2044118192; p5=-187.688895088328; p6=-0.314791034083831; p7=-36.6632213229309; p8=-7693.38639121209; p9=65.3375954195133; p10=135.981090347525; p11=4418.78480395924; z=(p1+p3.*x+p5.*log(y)+p7*x.^2+p9.*(log(y)).^2+p11.*x.*log(y))./(1+p2.*x+p4.*log(y)+p6.*x.^2+p8.*(log(y)).^2+p10.*x.*log(y)); plot(x1,z); xlabel('采样点'); ylabel('温度'); title('管道四温度曲线') subplot(5,2,5) x1=(1:1:5000); M=csvread('C:\\Users\\86152\\Desktop\\data\\data5.csv'); x=M(:,1); y=M(:,2); p1=6636.72503715224; p2=826099.455060947; p3=-498.995296492192; p4=1.80238545972406; p5=-1143812.65641828; p6=3030.85414746531; p7=-4932.54637234801; p8=3.5943846329167; z=(p1+p2.*x+p3.*x.^2+p4.*x.^3+p5.*y)./(1+p6.*x+p7.*y+p8.*y.^2); plot(x1,z); xlabel('采样点'); ylabel('温度'); title('管道五温度曲线') subplot(5,2,6) x1=(1:1:5000); M=csvread('C:\\Users\\86152\\Desktop\\data\\data6.csv'); x=M(:,1); y=M(:,2); p1=-5883.284880402; p2=60.424921963928; p3=-0.164225401010505; p4=0.000149967919524129; p5=61332.3184515964; p6=79523.3753333665; p7=-54368.4125968335; p8=10405.5019030654; p9=-639.850116036068; z=p1+p2.*x+p3.*x.^2+p4.*x.^3+p5.*log(y)+p6.*(log(y)).^2+p7.*(log(y)).^3+p8.*(log(y)).^4+p9.*(log(y)).^5; plot(x1,z); xlabel('采样点'); ylabel('温度'); title('管道六温度曲线') subplot(5,2,7) x1=(1:1:5000); M=csvread('C:\\Users\\86152\\Desktop\\data\\data7.csv'); x=M(:,1); y=M(:,2); p1=201478.39441699; p2=372414.059548135; p3=-147089.218042618; p4=12485.7289898091; p5=-224.561025015429; p6=3.32272031088369; p7=-173.088899267814; p8=4.01866601526878; z = (p1+p2.*log(x)+p3.*(log(x)).^2+p4.*(log(x)).^3+p5.*y+p6.*y.^2)./(1+p7.*log(x)+p8.*y); plot(x1,z); xlabel('采样点'); ylabel('温度'); title('管道七温度曲线') subplot(5,2,8) x1=(1:1:5000); M=csvread('C:\\Users\\86152\\Desktop\\data\\data8.csv'); x=M(:,1); y=M(:,2); p1=682051.099193563; p2=-166.30866016075; p3=0.443241999640146; p4=-0.0003925","date":"2021-07-13","objectID":"/20210713/:6:0","tags":["matlab","数学建模","皮尔逊相关系数","熵值法","多元函数拟合"],"title":"多元回归和熵值评价法及多目标遗传优化算法","uri":"/20210713/"},{"categories":["数学建模"],"content":"熵值法 function y=guiyi(x,type,ymin,ymax) %实现正向或负向指标归一化，返回归一化后的数据矩阵 %x为原始数据矩阵, 一行代表一个样本, 每列对应一个指标 %type设定正向指标1,负向指标2 %ymin,ymax为归一化的区间端点 [n,m]=size(x); y=zeros(n,m); xmin=min(x); xmax=max(x); switch type case 1 for j=1:m y(:,j)=(ymax-ymin)*(x(:,j)-xmin(j))/(xmax(j)-xmin(j))+ymin; end case 2 for j=1:m y(:,j)=(ymax-ymin)*(xmax(j)-x(:,j))/(xmax(j)-xmin(j))+ymin; end end clc clear all X=xlsread('附件1.xlsx'); data=X(:,2:end); [max_data,index1]=max(data); [min_data,index]=min(data); fangcha=var(data); [max_data,index1]=max(data); D=[fangcha;max_data]'; temp=[2 2]; [pj w]=shang(D,temp); pj%pj 评价分 w%w 权重 function [s,w]=shang(x,ind) %实现用熵值法求各指标(列）的权重及各数据行的得分 %x为原始数据矩阵, 一行代表一个样本, 每列对应一个指标 %ind指示向量，指示各列正向指标还是负向指标，1表示正向指标，2表示负向指标 %s返回各行（样本）得分，w返回各列权重 [n,m]=size(x); % n个样本, m个指标 %%数据的归一化处理 for i=1:m if ind(i)==1 %正向指标归一化 X(:,i)=guiyi(x(:,i),1,0.002,0.996); %若归一化到[0,1], 0会出问题 else %负向指标归一化 X(:,i)=guiyi(x(:,i),2,0.002,0.996); end end %%计算第j个指标下，第i个样本占该指标的比重p(i,j) for i=1:n for j=1:m p(i,j)=X(i,j)/sum(X(:,j)); end end %%计算第j个指标的熵值e(j) k=1/log(n); for j=1:m e(j)=-k*sum(p(:,j).*log(p(:,j))); end d=ones(1,m)-e; %计算信息熵冗余度 w=d./sum(d); %求权值w s=100*w*X'; %求综合得分 ","date":"2021-07-13","objectID":"/20210713/:7:0","tags":["matlab","数学建模","皮尔逊相关系数","熵值法","多元函数拟合"],"title":"多元回归和熵值评价法及多目标遗传优化算法","uri":"/20210713/"},{"categories":["数学建模"],"content":"第一问代码 抄的某公众号 Y=xlsread('C:\\Users\\86152\\Desktop\\附件1.xlsx'); X=Y(:,[2:11]); x1=mean(X,1) %求十个管道温度平均值 [max_X,index]=max(X) %求十个管道温度最大值 [min_X,index]=min(X) %求十个管道温度最小值 DX=var(X) %求十个管道温度方差 ","date":"2021-07-13","objectID":"/20210713/:8:0","tags":["matlab","数学建模","皮尔逊相关系数","熵值法","多元函数拟合"],"title":"多元回归和熵值评价法及多目标遗传优化算法","uri":"/20210713/"},{"categories":["数学建模"],"content":"多目标遗传优化算法 先写目标函数，再给定约束，求符合的自变量取值。 function y=fun(x) y(1)=-(x(1)*100/3 + x(3)*90/3 + x(2)*80/2+x(4)*70/2); y(2)=x(3)+x(4); end clear clc fitnessfcn=@fun; % 变量个数 nvars=4; % lb\u003c= X \u003c= ub lb=[0,0,0,0]; ub=[]; % A*X \u003c= b A = [0 0 1 1 -1/3 0 0 0 0 -1/2 0 0 0 0 0 0]; b = [48 ; 30 ; 30 ; 0]; % Aeq*X = beq Aeq=[1 1 0 0;0 0 0 0; 0 0 0 0; 0 0 0 0]; beq=[120;0;0;0]; %最优个体系数paretoFraction %种群大小populationsize %最大进化代数generations %停止代数stallGenLimit %适应度函数偏差TolFun %函数gaplotpareto：绘制Pareto前沿 options=gaoptimset('paretoFraction',0.3,'populationsize',200,'generations',300,'stallGenLimit',200,'TolFun',1e-10,'PlotFcns',@gaplotpareto); [x,fval]=gamultiobj(fitnessfcn,nvars,A,b,Aeq,beq,lb,ub,options) plot(-fval(:,1),fval(:,2),'pr') xlabel('f_1(x)') ylabel('f_2(x)') title('Pareto front') grid on 完整文档详见：博客相关资源-长三角数学建模B题 ","date":"2021-07-13","objectID":"/20210713/:9:0","tags":["matlab","数学建模","皮尔逊相关系数","熵值法","多元函数拟合"],"title":"多元回归和熵值评价法及多目标遗传优化算法","uri":"/20210713/"},{"categories":["数学建模"],"content":"前言 感谢组员的共同协作，做组长的有些东西帮不上实在抱歉。 ","date":"2021-07-09","objectID":"/20210709/:1:0","tags":["matlab","数学建模","python"],"title":"改进的SIR差分模型及三个模型的应用","uri":"/20210709/"},{"categories":["数学建模"],"content":"改进的SIR差分模型 %% SIR差分模型 frame=importdata('美国covid19疫情数据l-history改.csv'); date_row=size(frame.data,1); data=frame.data; date=frame.textdata(:,1); real_date=date(2:date_row+1,:); E=zeros(2,90); l=0.000125; %日接触率 m=0.01; %日治愈率0.0005 E(1,1)=data(345,12)/300000000; E(2,1)=1-E(1,1); for i=1:90 E(1,i+1)=l*E(2,i)-m*E(1,i)+E(1,i); E(2,i+1)=E(2,i)-l*E(1,i)*E(2,i); end X=flip(data(311:345,12)');% 5.31 4.2 rate=flip(data(311:345,12)')%现阳性率 rate(isnan(rate))=0; n=length(rate); rt=0:1:n-1; %a0=[100,10]; %初值 figure(1) h1 = plot(rt,X/300000000,'*'); %画点 hold on; a=E(1,:); b=E(2,:); h2 = plot(a,'r') xlabel('日期'); %设置横坐标名 ylabel('感染人数'); %设置纵坐标名 legend([h1 h2],'3~5月感染人数','SIR模型迭代曲线','Location','NorthWest'); hold on %% 预测 X=flip(data(255:345,12)');%311行后为第一题 rate=flip(data(255:345,12)')%现阳性率 rate(isnan(rate))=0; n=length(rate); rt=0:1:n-1; figure(2) h3 = plot(rt,X/300000000,'*'); %画点 hold on; a=E(1,:); b=E(2,:); h4=plot(a,'r') xlabel('日期'); ylabel('感染人数'); legend([h3 h4],'3~6月感染人数','SIR模型迭代曲线','Location','NorthWest'); hold on %% 接种疫苗前 frame=importdata('usc.csv'); date_row=size(frame.data,1); data=frame.data; date=frame.textdata(:,1); real_date=date(2:date_row+1,:); E=zeros(3,150); l=0.0018; %日接触率 0.0018 m=0.01; %日治愈率 0.01 E(1,1)=data(320,1)/300000000; E(3,1)=28664448/300000000%43714928 33714928 28664448 E(2,1)=1-E(1,1)-E(3,1); for i=1:150 E(1,i+1)=E(1,i)+l*E(2,i)-m*E(1,i); E(2,i+1)=E(2,i)-l*E(1,i)*E(2,i); E(3,i+1)=1-E(1,i+1)- E(2,i+1); end X=data(320:486,1)';%80-482 3.1-7.1 rate=data(320:486,1)'% rate(isnan(rate))=0; n=length(rate); rt=0:1:n-1; figure(6) h11 = plot(rt,X/300000000,'*'); %画点 hold on; a=E(1,:); b=E(2,:); c=E(3,:); t=1:151; h1=plot(t,a,'r')%感染人数 %plot(t,b,'b')%健康人数 plot(t,c,'r')%移除者 %legend('i(t)','s(t)','r(t)') hold on %% 接种疫苗后 E=zeros(3,150); l=0.0018; %日接触率 0.0018 m=0.01; %日治愈率 0.01 E(1,1)=data(320,1)/300000000; E(3,1)=53714928/300000000%43714928 33714928 28664448 E(2,1)=1-E(1,1)-E(3,1); for i=1:150 E(1,i+1)=E(1,i)+l*E(2,i)-m*E(1,i); E(2,i+1)=E(2,i)-l*E(1,i)*E(2,i); E(3,i+1)=1-E(1,i+1)- E(2,i+1); end X=data(320:486,1)';%80-482 3.1-7.1 rate=data(320:486,1)'% rate(isnan(rate))=0; n=length(rate); rt=0:1:n-1; figure(6) %h11 = plot(rt,X/300000000,'*'); %画点 hold on; a=E(1,:); b=E(2,:); c=E(3,:); t=1:151; h2=plot(t,a,'b')%感染人数 %plot(t,b,'b')%健康人数 plot(t,c,'b')%移除者 %legend('i(t)','s(t)','r(t)') hold on xlabel('日期'); %设置横坐标名 ylabel('r(t)与i（t）'); %设置纵坐标名 legend([h1 h2 h11],'接种疫苗前','接种疫苗后','感染人数原始数据','Location','NorthWest'); ","date":"2021-07-09","objectID":"/20210709/:2:0","tags":["matlab","数学建模","python"],"title":"改进的SIR差分模型及三个模型的应用","uri":"/20210709/"},{"categories":["数学建模"],"content":"logistic模型预测美国人口 %改进的指数增长模型 x=flip([324985536 322941312 320635168 318300992 315993728 313830976 311556864 309321664 306771520 304093952 301231200 298379904 295516608 292805312 290107936 287625184 284968960 282162400 279040000 275854016 272656992]) y=flip([0.006330017,0.007192424,0.007333235,0.007301613,0.006891455,0.007299188,0.007226135,0.008312845,0.008805068,0.009503504,0.009555925,0.00968912,0.009259723,0.009297836,0.008631901,0.009321099,0.009946612,0.011189794,0.011549529,0.011725443,0.012112401]) n=length(x); t=0:1:n-1; rk=zeros(1,n); rk(1)=(-3*x(1)+4*x(2)-x(3))/2; rk(n)=(x(n-2)-4*x(n-1)+3*x(n))/2; for i=2:n-1 rk(i)=(x(i+1)-x(i-1))/2; end rk=rk./x; p=polyfit(t,rk,2); r0=p(1); r1=p(2); r2=p(3); x0=x(1); R=r0*t.^2+r1*t+r2; X=x0*exp((r0*t.^3)/3+(r1*t.^2)/2+r2*t); figure(1) hold on; xlabel('year'); %设置横坐标名 ylabel('rate'); %设置纵坐标名 grid on %网格线 plot(t,y,'r*') figure(2) hold on; xlabel('year'); %设置横坐标名 ylabel('population'); %设置纵坐标名 grid on %网格线 plot(t,x,'r*',t,X) figure(3) hold on; xlabel('year'); %设置横坐标名 ylabel('rate'); %设置纵坐标名 grid on %网格线 plot(t,y,'r*',t,R') %2018 t1=t(21)+1; x2018=x0*exp((r0*t1.^3)/3+(r1*t1.^2)/2+r2*t1) y2018=r0*t1.^2+r1*t1+r2 %2019 t1=t(21)+2; x2019=x0*exp((r0*t1.^3)/3+(r1*t1.^2)/2+r2*t1) y2019=r0*t1.^2+r1*t1+r2 ","date":"2021-07-09","objectID":"/20210709/:3:0","tags":["matlab","数学建模","python"],"title":"改进的SIR差分模型及三个模型的应用","uri":"/20210709/"},{"categories":["数学建模"],"content":"药物中毒急救建模 clc; clear all; syms x t; f(t)=6*(exp(-0.1155*t)-exp(-0.1386*t)); h(t)=exp(-0.1386*t); figure(1); fplot(f,[0 25]); hold on; fplot(h,[0,25]); grid on; xlabel('时间t/h'); ylabel('药量'); legend('血液中的药量y/mg','胃肠道中的药量x/mg'); figure(2) fplot(f,[0,25]); hold on; fplot(h,[0,25]); f(t)=-(exp(-0.693*t)-exp(-0.1386*t))/4; fplot(f,[0,25]); xlabel('时间t/h'); ylabel('药量'); legend('血液中的药量y/mg','胃肠道中的药量x/mg','施救后血液中的药量y/mg'); ","date":"2021-07-09","objectID":"/20210709/:4:0","tags":["matlab","数学建模","python"],"title":"改进的SIR差分模型及三个模型的应用","uri":"/20210709/"},{"categories":["数学建模"],"content":"热传导差分偏微分模型应用 clear; close all; clc; pho=[300;862;74.2;1.18]; c=[1377;2100;1726;1005]; lamda=[0.082;0.37;0.045;0.028]; a=lamda./(pho.*c); d=[0.6;6;3.6;5]*10^-3; TT=273.15; T_in=37; T_out=75; T_s=48.08; xmin=0; xmax=sum(d); N=5400; h=0.05*10^-3; k=1; r=k/h^2; I=round((xmax-xmin)/h); A=zeros(1,I); B=zeros(1,I+1); C=zeros(1,I); N1=round(d(1)/h); N2=round(d(2)/h); N3=round(d(3)/h); N4=round(d(4)/h); for i=1:N1 A(i)=-a(1)*r; B(i)=2+2*r*a(1); C(i)=-r*a(1); end for i=N1+1:N1+N2 A(i)=-a(2)*r; B(i)=2+2*r*a(2); C(i)=-r*a(2); end for i=N1+N2+1:N1+N2+N3 A(i)=-a(3)*r; B(i)=2+2*r*a(3); C(i)=-r*a(3); end for i=N1+N2+N3+1:N1+N2+N3+N4 A(i)=-a(4)*r; B(i)=2+2*r*a(4); C(i)=-r*a(4); end T=zeros(I+1,N+1); T(:,1)=(T_in+TT)*ones(I+1,1); T_xt=xlsread('CUMCM-2018-Problem-A-Chinese-Appendix.xlsx'); h_min=110; h_max=120; delta_h=0.1; H1=h_min:delta_h:h_max; delta=zeros(1,length(H1)); for j=1:length(H1) h1=h_min+(j-1)*delta_h; k1=lamda(1);k2=lamda(2);k3=lamda(3);k4=lamda(4); x1=d(1);x2=d(1)+d(2);x3=d(1)+d(2)+d(3);x4=d(1)+d(2)+d(2)+d(4); t1=T_out+TT;t2=T_in+TT;t3=T_s+TT; h5=-((h1*k2*k3*k4*t1)/(k1*k2*k3*k4-h1*k1*k2*k3*x3-h1*k1*k2*k4*x2 ... -h1*k1*k3*k4*x1+h1*k1*k2*k3*x4+h1*k1*k2*k4*x3+h1*k1*k3*k4*x2+h1*k2*k3*k4*x1)-(h1*k2*k3*k4*t3)... /(k1*k2*k3*k4-h1*k1*k2*k3*x3-h1*k1*k2*k4*x2-h1*k1*k3*k4*x1+h1*k1*k2*k3*x4+h1*k1*k2*k4*x3+h1*k1*k3*k4*x2+h1*k2*k3*k4*x1))... /(t2/k1-t3/k1); AA=diag(B)+diag(A,1)+diag(C,-1); AA(1,1)=lamda(1)/h+h1; AA(1,2)=-lamda(1)/h; AA(I+1,I)=-lamda(4)/h; AA(I+1,I+1)=lamda(4)/h+h5; AA(N1+1,N1)=-lamda(1); AA(N1+1,N1+1)=lamda(1)+lamda(2); AA(N1+1,N1+2)=-lamda(2); AA(N1+N2+1,N1+N2)=-lamda(2); AA(N1+N2+1,N1+N2+1)=lamda(2)+lamda(3); AA(N1+N2+1,N1+N2+2)=-lamda(3); AA(N1+N2+N3+1,N1+N2+N3)=-lamda(3); AA(N1+N2+N3+1,N1+N2+N3+1)=lamda(3)+lamda(4); AA(N1+N2+N3+1,N1+N2+N3+2)=-lamda(4); for n=1:k:N D=zeros(I+1,1); D(1)=h1*(T_out+TT); D(I+1)=h5*(T_in+TT); for i=2:1:N1 D(i)=r*a(1)*T(i-1,n)+(2-2*r*a(1))*T(i,n)+r*a(1)*T(i+1,n); end for i=N1+1:1:N1+N2 D(i)=r*a(2)*T(i-1,n)+(2-2*r*a(2))*T(i,n)+r*a(2)*T(i+1,n); end for i=N1+N2+1:1:N1+N2+N3 D(i)=r*a(3)*T(i-1,n)+(2-2*r*a(3))*T(i,n)+r*a(3)*T(i+1,n); end for i=N1+N2+N3+1:1:N1+N2+N3+N4 D(i)=r*a(4)*T(i-1,n)+(2-2*r*a(4))*T(i,n)+r*a(4)*T(i+1,n); end D(N1+1)=0; D(N1+N2+1)=0; D(N1+N2+N3+1)=0; T(:,n+1)=AA\\D; end delta(j)=sqrt(sum((T_xt(:,2)-T(end,:)'+TT).^2)/length(T_xt(:,1))); end %图二 figure(1); mesh(0:k:N,1000*(0:h:sum(d)),(T-TT)); %图三 T_problem1=zeros(N+1,4); T_problem1(:,1)=T(1,:)'; T_problem1(:,2)=T(N1+1,:)'; T_problem1(:,3)=T(N2+N1+1,:)'; T_problem1(:,4)=T(N3+N2+N1+1,:)'; T_problem1=T_problem1-TT; figure(2); plot(0:k:N,T_problem1(:,1)',0:k:N,T_problem1(:,2)',0:k:N,T_problem1(:,3)',0:k:N,T_problem1(:,4)',0:k:N,T_xt(:,2)'); ","date":"2021-07-09","objectID":"/20210709/:5:0","tags":["matlab","数学建模","python"],"title":"改进的SIR差分模型及三个模型的应用","uri":"/20210709/"},{"categories":["数学建模"],"content":"python数据处理(写的很乱) 为了写第一个模型整合各种数据。。。有点乱，将就看吧。 #导入需要的数据库和文件 import numpy as np import pandas as pd import matplotlib.pyplot as plt from matplotlib.pyplot import MultipleLocator odata=pd.read_csv(r'us_state_vaccinations.csv') plt.rcParams['font.sans-serif'] = ['SimHei'] plt.rcParams['axes.unicode_minus'] = False r_hex = '#dc2624' # red, RGB = 220,38,36 dt_hex = '#2b4750' # dark teal, RGB = 43,71,80 tl_hex = '#45a0a2' # teal, RGB = 69,160,162 r1_hex = '#e87a59' # red, RGB = 232,122,89 tl1_hex = '#7dcaa9' # teal, RGB = 125,202,169 g_hex = '#649E7D' # green, RGB = 100,158,125 o_hex = '#dc8018' # orange, RGB = 220,128,24 tn_hex = '#C89F91' # tan, RGB = 200,159,145 g50_hex = '#6c6d6c' # grey-50, RGB = 108,109,108 bg_hex = '#4f6268' # blue grey, RGB = 79,98,104 g25_hex = '#c7cccf' # grey-25, RGB = 199,204,207 odata date\rlocation\rtotal_vaccinations\rtotal_distributed\rpeople_vaccinated\rpeople_fully_vaccinated_per_hundred\rtotal_vaccinations_per_hundred\rpeople_fully_vaccinated\rpeople_vaccinated_per_hundred\rdistributed_per_hundred\rdaily_vaccinations_raw\rdaily_vaccinations\rdaily_vaccinations_per_million\rshare_doses_used\r0\r2021-01-12\rAlabama\r78134.0\r377025.0\r70861.0\r0.15\r1.59\r7270.0\r1.45\r7.69\rNaN\rNaN\rNaN\r0.207\r1\r2021-01-13\rAlabama\r84040.0\r378975.0\r74792.0\r0.19\r1.71\r9245.0\r1.53\r7.73\r5906.0\r5906.0\r1205.0\r0.222\r2\r2021-01-14\rAlabama\r92300.0\r435350.0\r80480.0\rNaN\r1.88\rNaN\r1.64\r8.88\r8260.0\r7083.0\r1445.0\r0.212\r3\r2021-01-15\rAlabama\r100567.0\r444650.0\r86956.0\r0.28\r2.05\r13488.0\r1.77\r9.07\r8267.0\r7478.0\r1525.0\r0.226\r4\r2021-01-16\rAlabama\rNaN\rNaN\rNaN\rNaN\rNaN\rNaN\rNaN\rNaN\r7557.0\r7498.0\r1529.0\rNaN\r...\r...\r...\r...\r...\r...\r...\r...\r...\r...\r...\r...\r...\r...\r...\r11328\r2021-06-30\rWyoming\r421749.0\r516025.0\r226911.0\r34.38\r72.87\r198958.0\r39.21\r89.16\r55.0\r913.0\r1578.0\r0.817\r11329\r2021-07-01\rWyoming\r423238.0\r516325.0\r227741.0\r34.51\r73.13\r199743.0\r39.35\r89.21\r1489.0\r1113.0\r1923.0\r0.820\r11330\r2021-07-02\rWyoming\r424025.0\r516865.0\r228162.0\r34.59\r73.26\r200184.0\r39.42\r89.31\r787.0\r847.0\r1463.0\r0.820\r11331\r2021-07-03\rWyoming\r431008.0\r517365.0\r230914.0\r35.34\r74.47\r204522.0\r39.90\r89.39\r6983.0\r1680.0\r2903.0\r0.833\r11332\r2021-07-04\rWyoming\r431101.0\r517365.0\r230993.0\r35.35\r74.49\r204598.0\r39.91\r89.39\r93.0\r1682.0\r2906.0\r0.833\r11333 rows × 14 columns states = list(set(odata['location'])) len(states) 65\rdate = list(set(odata['date'])) date.sort() date date[0] '2020-12-20'\rUS = odata.loc[odata['date'] == '2021-01-12'] US date\rlocation\rtotal_vaccinations\rtotal_distributed\rpeople_vaccinated\rpeople_fully_vaccinated_per_hundred\rtotal_vaccinations_per_hundred\rpeople_fully_vaccinated\rpeople_vaccinated_per_hundred\rdistributed_per_hundred\rdaily_vaccinations_raw\rdaily_vaccinations\rdaily_vaccinations_per_million\rshare_doses_used\r0\r2021-01-12\rAlabama\r78134.0\r377025.0\r70861.0\r0.15\r1.59\r7270.0\r1.45\r7.69\rNaN\rNaN\rNaN\r0.207\r174\r2021-01-12\rAlaska\r35838.0\r141600.0\r22486.0\r0.74\r4.90\r5400.0\r3.07\r19.36\rNaN\rNaN\rNaN\r0.253\r348\r2021-01-12\rAmerican Samoa\r2124.0\r10650.0\r842.0\r0.47\r3.81\r260.0\r1.51\r19.12\rNaN\rNaN\rNaN\r0.199\r522\r2021-01-12\rArizona\r141355.0\r563025.0\r95141.0\r0.11\r1.94\r8343.0\r1.31\r7.74\rNaN\rNaN\rNaN\r0.251\r696\r2021-01-12\rArkansas\r40879.0\r274400.0\r39357.0\r0.00\r1.35\r8.0\r1.30\r9.09\rNaN\rNaN\rNaN\r0.149\r...\r...\r...\r...\r...\r...\r...\r...\r...\r...\r...\r...\r...\r...\r...\r10463\r2021-01-12\rVirginia\r190607.0\r797150.0\rNaN\rNaN\r2.23\rNaN\rNaN\r9.34\rNaN\rNaN\rNaN\r0.239\r10637\r2021-01-12\rWashington\r195567.0\r567725.0\r162105.0\r0.23\r2.57\r17689.0\r2.13\r7.46\rNaN\rNaN\rNaN\r0.344\r10811\r2021-01-12\rWest Virginia\r103330.0\r160975.0\rNaN\rNaN\r5.77\rNaN\rNaN\r8.98\rNaN\rNaN\rNaN\r0.642\r10985\r2021-01-12\rWisconsin\r137253.0\r429500.0\r125895.0\r0.19\r2.36\r11343.0\r2.16\r7.38\rNaN\rNaN\rNaN\r0.320\r11159\r2021-01-12\rWyoming\r16467.0\r47800.0\r13577.0\r0.37\r2.85\r2116.0\r2.35\r8.26\rNaN\rNaN\rNaN\r0.344\r65 rows × 14 columns US['people_vaccinated'].sum() 15746663.0\rdata=[] for i in date: temp = odata.loc[odata['date'] == i] data.append(temp['people_vaccinated'].sum()) data dataframe=pd.DataFrame(data=data, index=date, columns=['vaccinations'], dtype=None, copy=False) dataframe vaccinations\r2020-12","date":"2021-07-09","objectID":"/20210709/:6:0","tags":["matlab","数学建模","python"],"title":"改进的SIR差分模型及三个模型的应用","uri":"/20210709/"},{"categories":["电脑技巧"],"content":"一、使用说明 更新一个整库脚本 ql repo \u003crepourl\u003e \u003cpath\u003e \u003cblacklist\u003e \u003cdependence\u003e \u003cbranch\u003e 更新单个脚本文件 ql raw \u003cfileurl\u003e ","date":"2021-07-06","objectID":"/20210706/:1:0","tags":["linux"],"title":"JD脚本仓库合集","uri":"/20210706/"},{"categories":["电脑技巧"],"content":"二、拉取整库实例【以下仓库排名不分先后，纯粹随机排列】 （一）某已退圈并不愿透露姓名大佬库 的现存备份托管库`（下列方案选1个就行，排名不分先后） panghu999维护版仓库 名称： 拉取胖虎代维护 命令： ql repo https://github.com/panghu999/jd_scripts.git \"jd_|jx_|getJDCookie\" \"activity|backUp|jd_delCoupon|format_\" \"^jd[^_]|USER\" 定时规则： 0 */6 * * * JDHelloWorld维护版仓库 名称： 拉取Hello 命令： ql repo https://github.com/JDHelloWorld/jd_scripts.git \"jd_|jx_|getJDCookie\" \"activity|backUp|jd_delCoupon\" \"^jd[^_]|USER\" 定时规则： 5 */6 * * * chinnkarahoi维护版仓库 名称： 拉取chinnkarahoi 命令： ql repo https://github.com/chinnkarahoi/jd_scripts.git \"jd_|jx_|getJDCookie\" \"activity|backUp|jd_delCoupon\" \"^jd[^_]|USER\" 定时规则： 10 */6 * * * he1pu（自动提交助力码-京喜工厂、种豆得豆、东东工厂、东东农场、健康社区、京喜财富岛、东东萌宠、闪购盲盒，随机从数据库中选取助力码互助） 名称： 拉取he1pu 命令： ql repo https://github.com/he1pu/JDHelp.git \"jd_|jx_|getJDCookie\" \"activity|backUp|jd_delCoupon\" \"^jd[^_]|USER\" 定时规则： 15 */6 * * * （二）longzhuzhu（龙珠）仓库 名称： 拉取龙珠 命令： ql repo https://github.com/longzhuzhu/nianyu.git \"qx\" 定时规则： 20 */6 * * * （三）whyour/hundun（混沌）仓库 名称： 拉取混沌 命令： ql repo https://github.com/whyour/hundun.git \"quanx\" \"tokens|caiyun|didi|donate|fold|Env\" 定时规则： 25 */6 * * * （四）passerby-b仓库 名称： 拉取passerby-b 命令： ql repo https://github.com/passerby-b/JDDJ.git \"jddj_\" \"scf_test_event\" \"jddj_cookie\" 定时规则： 30 */6 * * * （五）Wenmoux（温某人）仓库 名称： 拉取温某人 命令： ql repo https://github.com/Wenmoux/scripts.git \"other|jd\" \"\" \"\" \"wen\" 定时规则： 0 */4 * * * （六）panghu999/panghu（胖虎原创）仓库 名称： 拉取胖虎原创 命令： ql repo https://github.com/panghu999/panghu.git \"jd_\" 定时规则： 0 */4 * * * （七）zoopanda（动物园）仓库 名称： 拉取动物园 命令： ql repo https://github.com/zooPanda/zoo.git \"zoo\" 定时规则： 0 */4 * * * （八）hyzaw（ddo）仓库 名称： 拉取ddo 命令： ql repo https://github.com/hyzaw/scripts.git \"ddo_\" 定时规则： 0 */4 * * * （九）Ariszy (原名Zhiyi-N)仓库 名称： 拉取执意 命令： ql repo https://github.com/Ariszy/Private-Script.git \"JD\" 定时规则： 0 */5 * * * （十）ZCY01仓库 名称： 拉取ZCY01 命令： ql repo https://github.com/ZCY01/daily_scripts.git \"jd_\" 定时规则： 0 */5 * * * （十一）monk-dust/dust（藏经阁）oreomeow备份版仓库 名称： 拉取藏经阁 命令： ql repo https://github.com/Oreomeow/dust.git \"i-chenzhe|normal|member|car\" \"backup\" 定时规则： 0 */5 * * * （十二）star261仓库 名称： 拉取star 命令： ql repo https://github.com/star261/jd.git \"scripts\" \"code\" 定时规则： 0 */5 * * * （十三）curtinlv（TopStyle）仓库 名称： 拉取TopStyle 命令： ql repo https://github.com/curtinlv/JD-Script.git 定时规则： 0 */5 * * * （十四）moposmall仓库 名称： 拉取moposmall 命令： ql repo https://github.com/moposmall/Script.git \"Me\" 定时规则： 0 */6 * * * （十五） photonmang（宠汪汪及兑换、点点券修复） 名称： 拉取photonman 命令： ql repo https://github.com/photonmang/quantumultX.git \"JDscripts\" 定时规则： 0 */6 * * * （十六）cdle 名称： 拉取cdle 命令： ql repo https://github.com/cdle/jd_study.git 定时规则： 0 */6 * * * ","date":"2021-07-06","objectID":"/20210706/:2:0","tags":["linux"],"title":"JD脚本仓库合集","uri":"/20210706/"},{"categories":["电脑技巧"],"content":"三、单脚本（定时规则都设置为 0 */8 * * * 即可） （一）翻翻乐提现单文件 ql raw https://raw.githubusercontent.com/jiulan/platypus/main/scripts/jd_ffl.js （二）curtinlv（上面拉过仓库的可以不用拉了） 15 8 * * * 赚京豆 ql raw https://raw.githubusercontent.com/curtinlv/JD-Script/main/jd_zjd.py 入会 ql raw https://raw.githubusercontent.com/curtinlv/JD-Script/main/OpenCard/jd_OpenCard.py 关注 ql raw https://raw.githubusercontent.com/curtinlv/JD-Script/main/getFollowGifts/jd_getFollowGift.py 欢迎请站长喝一杯 ","date":"2021-07-06","objectID":"/20210706/:3:0","tags":["linux"],"title":"JD脚本仓库合集","uri":"/20210706/"},{"categories":["数学建模"],"content":"7个组长分60个上机座位 ","date":"2021-07-05","objectID":"/20210705/:1:0","tags":["博弈论","数学建模"],"title":"海盗分金问题变种-组长分座位","uri":"/20210705/"},{"categories":["数学建模"],"content":"问题 1.5月3日从早晨到晚上上机，207机房有60个机位, 请7个组长分上机座位 2.按照ABCDE组顺序开始分配, 每个组长都是足够聪明,A组长制定分配方案时,剩余的组长投票, 如有一半人不同意, A组就失去上机机会,同时失 去再次分配的权利,A组也失去投票机会. 3.A组失败后就是BCDE组分配规则一样. 4.请问我们最后得到的分配方案是什么?!各组所 得上机都是多少席?! ","date":"2021-07-05","objectID":"/20210705/:1:1","tags":["博弈论","数学建模"],"title":"海盗分金问题变种-组长分座位","uri":"/20210705/"},{"categories":["数学建模"],"content":"逻辑化 该问题与海盗博弈模型较为类似，可以参考该模型解答。 A组长会要求给自己组57个座位，给C，E，G组长各一个座位，不给B，D，F组座位。 首先反过来看： 1.如果只有F和G组长，F给自己60个座位，给G组0个。 因为F有决定权，所以分配达成。 2.如果有三个组长E，F和G，E知道F下轮会给G组0个座位，所以E这轮给G组 1个座位，让G组长支持自己以使得提议通过。 因此如果有三个组长，结果是E：59，F：0，G：1。 3.如果有四个组长D，E，F，G，D知道上述推理。 所以为了避免失去座位，他只需要给F组长1个座位，因为他有决定权，只需要F的支持就足够了。 因此他会提议 D：59， E：0， F：1，G：0。 4.照此推广，当有7位组长时，A组长只需要隔一个人拉拢一个组长，给他们每人一个座位即可。 所以最后的分配方案如下： A：57， B：0， C：1，D：0，E：1， F：0，G：1。 ","date":"2021-07-05","objectID":"/20210705/:1:2","tags":["博弈论","数学建模"],"title":"海盗分金问题变种-组长分座位","uri":"/20210705/"},{"categories":["电脑技巧"],"content":"共用提取码 QLHL 蓝奏云盘 电脑Telegram 远程SSH工具,下载解压即可使用 各大文库PDF下载神器冰点文库 论文查重(需加Q群验证)(网络源) ↑↑↑需要加群后用管理员身份打开，每次打开软件需要在电脑打开那个Q群窗口检测 百度云盘提速IDM破解无需注册版软件 百度云盘不限速下载软件01(每日无限制，需要保存到自己网盘下载且易掉线) 百度网盘不限速下载软件02(每日4G限制，且有环境安装限制) 高数计算器 微星电脑性能测试软件 专业流程图制作软件 视频直播源破解软件 百度云盘 IDM破解无需注册版软件附有教程 ↑教程与配套软件 ↑↑↑看在资源的份上，麻烦点赞投币收藏我的文章—\u003ehttps://www.bilibili.com/read/cv6826074↑↑↑ 百度云盘分享链接直链解析新脚本 万分感谢！！！ 计算机等级考试模拟器 谷歌地球软件本地版 太极常用全套(含太极客户端) AI换脸软件(N卡/A卡) 天翼云盘 论文翻译器 MatlabR2018a AI人声伴奏分离器 ","date":"2021-07-05","objectID":"/20210707/:0:0","tags":["windows","实用软件"],"title":"实用软件","uri":"/20210707/"},{"categories":["电脑技巧"],"content":"后言 上述链接如有问题，请在-\u003e我的文章评论区\u003c-里留言，我会及时更新失效链接。 该页面的资源均由网络收集 本人不负任何法律责任，仅仅作为展出使用。 欢迎请站长喝一杯 ","date":"2021-07-05","objectID":"/20210707/:1:0","tags":["windows","实用软件"],"title":"实用软件","uri":"/20210707/"},{"categories":["电脑技巧"],"content":"CentOS8安装VNC窗口桌面并使用 ","date":"2021-07-04","objectID":"/20210704/:1:0","tags":["VNC","linux"],"title":"CentOS8的VNC窗口桌面使用","uri":"/20210704/"},{"categories":["电脑技巧"],"content":"Step1 安装vnc软件 终端窗口输入 sudo -i dnf install tigervnc tigervnc-server ","date":"2021-07-04","objectID":"/20210704/:1:1","tags":["VNC","linux"],"title":"CentOS8的VNC窗口桌面使用","uri":"/20210704/"},{"categories":["电脑技巧"],"content":"Step2 修改vncserver-config-defaults ， 如果添加一行localhost ，外部不能访问 终端窗口输入 vim /etc/tigervnc/vncserver-config-defaults 按i键进入编辑模式，复制粘贴下面内容替换原来的内容 session=gnome securitytypes=vncauth,tlsvnc desktop=sandbox geometry=2000x1200 alwaysshared 按Esc键关闭编辑模式，输入 :wq 再按回车退出vim，下面编辑方式一样，不再赘述，将内容和打开文件命令变一下即可。 ","date":"2021-07-04","objectID":"/20210704/:1:2","tags":["VNC","linux"],"title":"CentOS8的VNC窗口桌面使用","uri":"/20210704/"},{"categories":["电脑技巧"],"content":"Step3 编辑vncserver.users 终端窗口输入 vim /etc/tigervnc/vncserver.users 替换内容 :1=root :2=admin ","date":"2021-07-04","objectID":"/20210704/:1:3","tags":["VNC","linux"],"title":"CentOS8的VNC窗口桌面使用","uri":"/20210704/"},{"categories":["电脑技巧"],"content":"Step4 配置vnc密码 终端 [root@OS-CentOS8 ~]$vncpasswd Password:你的登陆密码，输入不会显示，自己记住 Verify:你的登陆密码，输入不会显示，自己记住 Would you like to enter a view-only password (y/n)? n A view-only password is not used ","date":"2021-07-04","objectID":"/20210704/:1:4","tags":["VNC","linux"],"title":"CentOS8的VNC窗口桌面使用","uri":"/20210704/"},{"categories":["电脑技巧"],"content":"Step5 复制vncserver@x.service 文件 终端输入 cp /lib/systemd/system/vncserver@.service /etc/systemd/system/vncserver@:1.service ","date":"2021-07-04","objectID":"/20210704/:1:5","tags":["VNC","linux"],"title":"CentOS8的VNC窗口桌面使用","uri":"/20210704/"},{"categories":["电脑技巧"],"content":"Step6 配置vnc开机自启服务 终端输入 systemctl enable vncserver@:1 ","date":"2021-07-04","objectID":"/20210704/:1:6","tags":["VNC","linux"],"title":"CentOS8的VNC窗口桌面使用","uri":"/20210704/"},{"categories":["电脑技巧"],"content":"Step7 启动vnc服务 终端输入 systemctl start vncserver@:1 ","date":"2021-07-04","objectID":"/20210704/:1:7","tags":["VNC","linux"],"title":"CentOS8的VNC窗口桌面使用","uri":"/20210704/"},{"categories":["电脑技巧"],"content":"Step8 查看状态 终端输入 systemctl status vncserver@\\:1 看到绿色和active字样就是成功安装并启动了。 ","date":"2021-07-04","objectID":"/20210704/:1:8","tags":["VNC","linux"],"title":"CentOS8的VNC窗口桌面使用","uri":"/20210704/"},{"categories":["电脑技巧"],"content":"Step9 vncview客户端连接 文件下载链接： 太平洋下载 使用说明： 简书说明，从Step2开始看，前面安装不用看，点我跳转 ","date":"2021-07-04","objectID":"/20210704/:1:9","tags":["VNC","linux"],"title":"CentOS8的VNC窗口桌面使用","uri":"/20210704/"},{"categories":["电脑技巧"],"content":"后言 除了不能使用exe文件，其他和win系统没啥区别，浏览器默认安装火狐的好像，不用更新，不然占用会很大。 欢迎请站长喝一杯 ","date":"2021-07-04","objectID":"/20210704/:1:10","tags":["VNC","linux"],"title":"CentOS8的VNC窗口桌面使用","uri":"/20210704/"},{"categories":["博客建站相关"],"content":"鸣谢： 中文主题配置 ","date":"2021-07-03","objectID":"/20210703/:0:0","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"主题文档 - 基本概念 探索 Hugo - LoveIt 主题的全部内容和背后的核心概念. ","date":"2021-07-03","objectID":"/20210703/:1:0","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"1 准备 由于 Hugo 提供的便利性, Hugo 本身是这个主题唯一的依赖. 直接安装满足你操作系统 (Windows, Linux, macOS) 的最新版本  Hugo (\u003e 0.62.0). 为什么不支持早期版本的 Hugo? 由于 Markdown 渲染钩子函数 在 Hugo 圣诞节版本 中被引入, 本主题只支持高于 0.62.0 的 Hugo 版本. 推荐使用 Hugo extended 版本 由于这个主题的一些特性需要将  SCSS 转换为  CSS, 推荐使用 Hugo extended 版本来获得更好的使用体验. ","date":"2021-07-03","objectID":"/20210703/:2:0","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"2 安装 以下步骤可帮助你初始化新网站. 如果你根本不了解 Hugo, 我们强烈建议你按照此 快速入门文档 进一步了解它. ","date":"2021-07-03","objectID":"/20210703/:3:0","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"2.1 创建你的项目 Hugo 提供了一个 new 命令来创建一个新的网站: hugo new site my_website cd my_website ","date":"2021-07-03","objectID":"/20210703/:3:1","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"2.2 安装主题 LoveIt 主题的仓库是: https://github.com/dillonzq/LoveIt. 你可以下载主题的 最新版本  .zip 文件 并且解压放到 themes 目录. 另外, 也可以直接把这个主题克隆到 themes 目录: git clone https://github.com/dillonzq/LoveIt.git themes/LoveIt 或者, 初始化你的项目目录为 git 仓库, 并且把主题仓库作为你的网站目录的子模块: git init git submodule add https://github.com/dillonzq/LoveIt.git themes/LoveIt ","date":"2021-07-03","objectID":"/20210703/:3:2","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"2.3 基础配置 以下是 LoveIt 主题的基本配置: baseURL = \"http://example.org/\" # [en, zh-cn, fr, ...] 设置默认的语言 defaultContentLanguage = \"zh-cn\" # 网站语言, 仅在这里 CN 大写 languageCode = \"zh-CN\" # 是否包括中日韩文字 hasCJKLanguage = true # 网站标题 title = \"我的全新 Hugo 网站\" # 更改使用 Hugo 构建网站时使用的默认主题 theme = \"LoveIt\" [params] # LoveIt 主题版本 version = \"0.2.X\" [menu] [[menu.main]] identifier = \"posts\" # 你可以在名称 (允许 HTML 格式) 之前添加其他信息, 例如图标 pre = \"\" # 你可以在名称 (允许 HTML 格式) 之后添加其他信息, 例如图标 post = \"\" name = \"文章\" url = \"/posts/\" # 当你将鼠标悬停在此菜单链接上时, 将显示的标题 title = \"\" weight = 1 [[menu.main]] identifier = \"tags\" pre = \"\" post = \"\" name = \"标签\" url = \"/tags/\" title = \"\" weight = 2 [[menu.main]] identifier = \"categories\" pre = \"\" post = \"\" name = \"分类\" url = \"/categories/\" title = \"\" weight = 3 # Hugo 解析文档的配置 [markup] # 语法高亮设置 (https://gohugo.io/content-management/syntax-highlighting) [markup.highlight] # false 是必要的设置 (https://github.com/dillonzq/LoveIt/issues/158) noClasses = false 注意 在构建网站时, 你可以使用 --theme 选项设置主题. 但是, 我建议你修改配置文件 (config.toml) 将本主题设置为默认主题. ","date":"2021-07-03","objectID":"/20210703/:3:3","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"2.4 创建你的第一篇文章 以下是创建第一篇文章的方法: hugo new posts/first_post.md 通过添加一些示例内容并替换文件开头的标题, 你可以随意编辑文章. 注意 默认情况下, 所有文章和页面均作为草稿创建. 如果想要渲染这些页面, 请从元数据中删除属性 draft: true, 设置属性 draft: false 或者为 hugo 命令添加 -D/--buildDrafts 参数. ","date":"2021-07-03","objectID":"/20210703/:3:4","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"2.5 在本地启动网站 使用以下命令启动网站: hugo serve 去查看 http://localhost:1313. 基本配置下的预览 技巧 当你运行 hugo serve 时, 当文件内容更改时, 页面会随着更改自动刷新. 注意 由于本主题使用了 Hugo 中的 .Scratch 来实现一些特性, 非常建议你为 hugo server 命令添加 --disableFastRender 参数来实时预览你正在编辑的文章页面. hugo serve --disableFastRender ","date":"2021-07-03","objectID":"/20210703/:3:5","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"2.6 构建网站 当你准备好部署你的网站时, 运行以下命令: hugo 会生成一个 public 目录, 其中包含你网站的所有静态内容和资源. 现在可以将其部署在任何 Web 服务器上. 技巧 网站内容可以通过 Netlify 自动发布和托管 (了解有关通过 Netlify 进行 HUGO 自动化部署 的更多信息). 或者, 您可以使用 AWS Amplify, Github pages, Render 以及更多… ","date":"2021-07-03","objectID":"/20210703/:3:6","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"3 配置 ","date":"2021-07-03","objectID":"/20210703/:4:0","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"3.1 网站配置 除了 Hugo 全局配置 和 菜单配置 之外, LoveIt 主题还允许您在网站配置中定义以下参数 (这是一个示例 config.toml, 其内容为默认值). 请打开下面的代码块查看完整的示例配置 : [params] # LoveIt 主题版本 version = \"0.2.X\" # 网站描述 description = \"这是我的全新 Hugo 网站\" # 网站关键词 keywords = [\"Theme\", \"Hugo\"] # 网站默认主题样式 (\"light\", \"dark\", \"auto\") defaultTheme = \"auto\" # 公共 git 仓库路径，仅在 enableGitInfo 设为 true 时有效 gitRepo = \"\" # 哪种哈希函数用来 SRI, 为空时表示不使用 SRI # (\"sha256\", \"sha384\", \"sha512\", \"md5\") fingerprint = \"\" # 日期格式 dateFormat = \"2006-01-02\" # 网站图片, 用于 Open Graph 和 Twitter Cards images = [\"/logo.png\"] # 应用图标配置 [params.app] # 当添加到 iOS 主屏幕或者 Android 启动器时的标题, 覆盖默认标题 title = \"LoveIt\" # 是否隐藏网站图标资源链接 noFavicon = false # 更现代的 SVG 网站图标, 可替代旧的 .png 和 .ico 文件 svgFavicon = \"\" # Android 浏览器主题色 themeColor = \"#ffffff\" # Safari 图标颜色 iconColor = \"#5bbad5\" # Windows v8-10磁贴颜色 tileColor = \"#da532c\" # 搜索配置 [params.search] enable = true # 搜索引擎的类型 (\"lunr\", \"algolia\") type = \"lunr\" # 文章内容最长索引长度 contentLength = 4000 # 搜索框的占位提示语 placeholder = \"\" # 最大结果数目 maxResultLength = 10 # 结果内容片段长度 snippetLength = 50 # 搜索结果中高亮部分的 HTML 标签 highlightTag = \"em\" # 是否在搜索索引中使用基于 baseURL 的绝对路径 absoluteURL = false [params.search.algolia] index = \"\" appID = \"\" searchKey = \"\" # 页面头部导航栏配置 [params.header] # 桌面端导航栏模式 (\"fixed\", \"normal\", \"auto\") desktopMode = \"fixed\" # 移动端导航栏模式 (\"fixed\", \"normal\", \"auto\") mobileMode = \"auto\" # 页面头部导航栏标题配置 [params.header.title] # LOGO 的 URL logo = \"\" # 标题名称 name = \"\" # 你可以在名称 (允许 HTML 格式) 之前添加其他信息, 例如图标 pre = \"\" # 你可以在名称 (允许 HTML 格式) 之后添加其他信息, 例如图标 post = \"\" # 是否为标题显示打字机动画 typeit = false # 页面底部信息配置 [params.footer] enable = true # 自定义内容 (支持 HTML 格式) custom = '' # 是否显示 Hugo 和主题信息 hugo = true # 是否显示版权信息 copyright = true # 是否显示作者 author = true # 网站创立年份 since = 2019 # ICP 备案信息，仅在中国使用 (支持 HTML 格式) icp = \"\" # 许可协议信息 (支持 HTML 格式) license = '\u003ca rel=\"license external nofollow noopener noreffer\" href=\"https://creativecommons.org/licenses/by-nc/4.0/\" target=\"_blank\"\u003eCC BY-NC 4.0\u003c/a\u003e' # Section (所有文章) 页面配置 [params.section] # section 页面每页显示文章数量 paginate = 20 # 日期格式 (月和日) dateFormat = \"01-02\" # RSS 文章数目 rss = 10 # List (目录或标签) 页面配置 [params.list] # list 页面每页显示文章数量 paginate = 20 # 日期格式 (月和日) dateFormat = \"01-02\" # RSS 文章数目 rss = 10 # 主页配置 [params.home] # RSS 文章数目 rss = 10 # 主页个人信息 [params.home.profile] enable = true # Gravatar 邮箱，用于优先在主页显示的头像 gravatarEmail = \"\" # 主页显示头像的 URL avatarURL = \"/images/avatar.png\" # 主页显示的网站标题 (支持 HTML 格式) title = \"\" # 主页显示的网站副标题 subtitle = \"这是我的全新 Hugo 网站\" # 是否为副标题显示打字机动画 typeit = true # 是否显示社交账号 social = true # 免责声明 (支持 HTML 格式) disclaimer = \"\" # 主页文章列表 [params.home.posts] enable = true # 主页每页显示文章数量 paginate = 6 # 被 params.page 中的 hiddenFromHomePage 替代 # 当你没有在文章前置参数中设置 \"hiddenFromHomePage\" 时的默认行为 defaultHiddenFromHomePage = false # 作者的社交信息设置 [params.social] GitHub = \"xxxx\" Linkedin = \"\" Twitter = \"xxxx\" Instagram = \"xxxx\" Facebook = \"xxxx\" Telegram = \"xxxx\" Medium = \"\" Gitlab = \"\" Youtubelegacy = \"\" Youtubecustom = \"\" Youtubechannel = \"\" Tumblr = \"\" Quora = \"\" Keybase = \"\" Pinterest = \"\" Reddit = \"\" Codepen = \"\" FreeCodeCamp = \"\" Bitbucket = \"\" Stackoverflow = \"\" Weibo = \"\" Odnoklassniki = \"\" VK = \"\" Flickr = \"\" Xing = \"\" Snapchat = \"\" Soundcloud = \"\" Spotify = \"\" Bandcamp = \"\" Paypal = \"\" Fivehundredpx = \"\" Mix = \"\" Goodreads = \"\" Lastfm = \"\" Foursquare = \"\" Hackernews = \"\" Kickstarter = \"\" Patreon = \"\" Steam = \"\" Twitch = \"\" Strava = \"\" Skype = \"\" Whatsapp = \"\" Zhihu = \"\" Douban = \"\" Angellist = \"\" Slidershare = \"\" Jsfiddle = \"\" Deviantart = \"\" Behance = \"\" Dribbble = \"\" Wordpress = \"\" Vine = \"\" Googlescholar = \"\" Researchgate = \"\" Mastodon = \"\" Thingiverse = \"\" Devto = \"\" Gitea = \"\" XMPP = \"\" Matrix = \"\" Bilibili = \"\" Email = \"xxxx@xxxx.com\" RSS = true # # 文章页面配置 [params.page] # 是否在主页隐藏一篇文章 hiddenFromHomePage = false # 是否在搜索结果中隐藏一篇文章 hiddenFromSearch = false # 是否使用 twemoji twemoji = false # 是否使用 lightgallery lightgallery = false # 是否使用 ruby 扩展语法 ruby = true # 是否使用 fraction 扩展语法 fraction = true # 是否使用 fontawesome 扩展语法 fontawesome = true # 是否在文章页面显示原始 Markdown 文档链接 linkToMarkdown = true # 是否在 RSS 中显示全文内容 rssFullText = ","date":"2021-07-03","objectID":"/20210703/:4:1","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"3.2 网站图标, 浏览器配置, 网站清单 强烈建议你把: apple-touch-icon.png (180x180) favicon-32x32.png (32x32) favicon-16x16.png (16x16) mstile-150x150.png (150x150) android-chrome-192x192.png (192x192) android-chrome-512x512.png (512x512) 放在 /static 目录. 利用 https://realfavicongenerator.net/ 可以很容易地生成这些文件. 可以自定义 browserconfig.xml 和 site.webmanifest 文件来设置 theme-color 和 background-color. ","date":"2021-07-03","objectID":"/20210703/:4:2","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"3.3 自定义样式 注意 Hugo extended 版本对于自定义样式是必需的. 通过定义自定义 .scss 样式文件, LoveIt 主题支持可配置的样式. 包含自定义 .scss 样式文件的目录相对于 你的项目根目录 的路径为 assets/css. 在 assets/css/_override.scss 中, 你可以覆盖 themes/LoveIt/assets/css/_variables.scss 中的变量以自定义样式. 这是一个例子: @import url('https://fonts.googleapis.com/css?family=Fira+Mono:400,700\u0026display=swap\u0026subset=latin-ext'); $code-font-family: Fira Mono, Source Code Pro, Menlo, Consolas, Monaco, monospace; 在 assets/css/_custom.scss 中, 你可以添加一些 CSS 样式代码以自定义样式. ","date":"2021-07-03","objectID":"/20210703/:4:3","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"4 多语言和 i18n LoveIt 主题完全兼容 Hugo 的多语言模式, 并且支持在网页上切换语言. 语言切换 ","date":"2021-07-03","objectID":"/20210703/:5:0","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"4.1 兼容性 语言 Hugo 代码 HTML lang 属性 主题文档 Lunr.js 支持 英语 en en 简体中文 zh-cn zh-CN 法语 fr fr 波兰语 pl pl 巴西葡萄牙语 pt-br pt-BR 意大利语 it it 西班牙语 es es 德语 de de 塞尔维亚语 pl pl 俄语 ru ru 罗马尼亚语 ro ro 越南语 vi vi ","date":"2021-07-03","objectID":"/20210703/:5:1","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"4.2 基本配置 学习了 Hugo如何处理多语言网站 之后, 请在 站点配置 中定义你的网站语言. 例如, 一个支持英语, 中文和法语的网站配置: # [en, zh-cn, fr, pl, ...] 设置默认的语言 defaultContentLanguage = \"zh-cn\" [languages] [languages.en] weight = 1 title = \"My New Hugo Site\" languageCode = \"en\" languageName = \"English\" [[languages.en.menu.main]] identifier = \"posts\" pre = \"\" post = \"\" name = \"Posts\" url = \"/posts/\" title = \"\" weight = 1 [[languages.en.menu.main]] identifier = \"tags\" pre = \"\" post = \"\" name = \"Tags\" url = \"/tags/\" title = \"\" weight = 2 [[languages.en.menu.main]] identifier = \"categories\" pre = \"\" post = \"\" name = \"Categories\" url = \"/categories/\" title = \"\" weight = 3 [languages.zh-cn] weight = 2 title = \"我的全新 Hugo 网站\" # 网站语言, 仅在这里 CN 大写 languageCode = \"zh-CN\" languageName = \"简体中文\" # 是否包括中日韩文字 hasCJKLanguage = true [[languages.zh-cn.menu.main]] identifier = \"posts\" pre = \"\" post = \"\" name = \"文章\" url = \"/posts/\" title = \"\" weight = 1 [[languages.zh-cn.menu.main]] identifier = \"tags\" pre = \"\" post = \"\" name = \"标签\" url = \"/tags/\" title = \"\" weight = 2 [[languages.zh-cn.menu.main]] identifier = \"categories\" pre = \"\" post = \"\" name = \"分类\" url = \"/categories/\" title = \"\" weight = 3 [languages.fr] weight = 3 title = \"Mon nouveau site Hugo\" languageCode = \"fr\" languageName = \"Français\" [[languages.fr.menu.main]] identifier = \"posts\" pre = \"\" post = \"\" name = \"Postes\" url = \"/posts/\" title = \"\" weight = 1 [[languages.fr.menu.main]] identifier = \"tags\" pre = \"\" post = \"\" name = \"Balises\" url = \"/tags/\" title = \"\" weight = 2 [[languages.fr.menu.main]] identifier = \"categories\" pre = \"\" post = \"\" name = \"Catégories\" url = \"/categories/\" title = \"\" weight = 3 然后, 对于每个新页面, 将语言代码附加到文件名中. 单个文件 my-page.md 需要分为三个文件: 英语: my-page.en.md 中文: my-page.zh-cn.md 法语: my-page.fr.md 注意 请注意, 菜单中仅显示翻译的页面. 它不会替换为默认语言内容. 技巧 也可以使用 文章前置参数 来翻译网址. ","date":"2021-07-03","objectID":"/20210703/:5:2","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"4.3 修改默认的翻译字符串 翻译字符串用于在主题中使用的常见默认值. 目前提供一些语言的翻译, 但你可能自定义其他语言或覆盖默认值. 要覆盖默认值, 请在你项目的 i18n 目录 i18n/\u003clanguageCode\u003e.toml 中创建一个新文件，并从 themes/LoveIt/i18n/en.toml 中获得提示. 另外, 由于你的翻译可能会帮助到其他人, 请花点时间通过  创建一个 PR 来贡献主题翻译, 谢谢! ","date":"2021-07-03","objectID":"/20210703/:5:3","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"5 搜索 基于 Lunr.js 或 algolia, LoveIt 主题支持搜索功能. ","date":"2021-07-03","objectID":"/20210703/:6:0","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"5.1 输出配置 为了生成搜索功能所需要的 index.json, 请在你的 网站配置 中添加 JSON 输出文件类型到 outputs 部分的 home 字段中. [outputs] home = [\"HTML\", \"RSS\", \"JSON\"] ","date":"2021-07-03","objectID":"/20210703/:6:1","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"5.2 搜索配置 基于 Hugo 生成的 index.json 文件, 你可以激活搜索功能. 这是你的 网站配置 中的搜索部分: [params.search] enable = true # 搜索引擎的类型 (\"lunr\", \"algolia\") type = \"lunr\" # 文章内容最长索引长度 contentLength = 4000 # 搜索框的占位提示语 placeholder = \"\" # 最大结果数目 maxResultLength = 10 # 结果内容片段长度 snippetLength = 50 # 搜索结果中高亮部分的 HTML 标签 highlightTag = \"em\" # 是否在搜索索引中使用基于 baseURL 的绝对路径 absoluteURL = false [params.search.algolia] index = \"\" appID = \"\" searchKey = \"\" 怎样选择搜索引擎? 以下是两种搜索引擎的对比: lunr: 简单, 无需同步 index.json, 没有 contentLength 的限制, 但占用带宽大且性能低 (特别是中文需要一个较大的分词依赖库) algolia: 高性能并且占用带宽低, 但需要同步 index.json 且有 contentLength 的限制 文章内容被 h2 和 h3 HTML 标签切分来提高查询效果并且基本实现全文搜索. contentLength 用来限制 h2 和 h3 HTML 标签开头的内容部分的最大长度. 关于 algolia 的使用技巧 你需要上传 index.json 到 algolia 来激活搜索功能. 你可以使用浏览器来上传 index.json 文件但是一个自动化的脚本可能效果更好. Algolia Atomic 是一个不错的选择. 为了兼容 Hugo 的多语言模式, 你需要上传不同语言的 index.json 文件到对应的 algolia index, 例如 zh-cn/index.json 或 fr/index.json… ","date":"2021-07-03","objectID":"/20210703/:6:2","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"主题文档 - 内容 了解如何在 LoveIt 主题中快速, 直观地创建和组织内容. ","date":"2021-07-03","objectID":"/20210703/:7:0","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"1 内容组织 以下是一些方便你清晰管理和生成文章的目录结构建议: 保持博客文章存放在 content/posts 目录, 例如: content/posts/我的第一篇文章.md 保持简单的静态页面存放在 content 目录, 例如: content/about.md 本地资源组织 本地资源引用 有三种方法来引用图片和音乐等本地资源: 使用页面包中的页面资源. 你可以使用适用于 Resources.GetMatch 的值或者直接使用相对于当前页面目录的文件路径来引用页面资源. 将本地资源放在 assets 目录中, 默认路径是 /assets. 引用资源的文件路径是相对于 assets 目录的. 将本地资源放在 static 目录中, 默认路径是 /static. 引用资源的文件路径是相对于 static 目录的. 引用的优先级符合以上的顺序. 在这个主题中的很多地方可以使用上面的本地资源引用, 例如 链接, 图片, image shortcode, music shortcode 和前置参数中的部分参数. 页面资源或者 assets 目录中的图片处理会在未来的版本中得到支持. 非常酷的功能! ","date":"2021-07-03","objectID":"/20210703/:8:0","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"2 前置参数 Hugo 允许你在文章内容前面添加 yaml, toml 或者 json 格式的前置参数. 注意 不是所有的以下前置参数都必须在你的每篇文章中设置. 只有在文章的参数和你的 网站设置 中的 page 部分不一致时才有必要这么做. 这是一个前置参数例子: --- title: \"我的第一篇文章\" subtitle: \"\" date: 2020-03-04T15:58:26+08:00 lastmod: 2020-03-04T15:58:26+08:00 draft: true author: \"\" authorLink: \"\" description: \"\" license: \"\" images: [] tags: [] categories: [] featuredImage: \"\" featuredImagePreview: \"\" hiddenFromHomePage: false hiddenFromSearch: false twemoji: false lightgallery: true ruby: true fraction: true fontawesome: true linkToMarkdown: true rssFullText: false toc: enable: true auto: true code: copy: true # ... math: enable: true # ... mapbox: accessToken: \"\" # ... share: enable: true # ... comment: enable: true # ... library: css: # someCSS = \"some.css\" # 位于 \"assets/\" # 或者 # someCSS = \"https://cdn.example.com/some.css\" js: # someJS = \"some.js\" # 位于 \"assets/\" # 或者 # someJS = \"https://cdn.example.com/some.js\" seo: images: [] # ... --- title: 文章标题. subtitle: 文章副标题. date: 这篇文章创建的日期时间. 它通常是从文章的前置参数中的 date 字段获取的, 但是也可以在 网站配置 中设置. lastmod: 上次修改内容的日期时间. draft: 如果设为 true, 除非 hugo 命令使用了 --buildDrafts/-D 参数, 这篇文章不会被渲染. author: 文章作者. authorLink: 文章作者的链接. description: 文章内容的描述. license: 这篇文章特殊的许可. images: 页面图片, 用于 Open Graph 和 Twitter Cards. tags: 文章的标签. categories: 文章所属的类别. featuredImage: 文章的特色图片. featuredImagePreview: 用在主页预览的文章特色图片. hiddenFromHomePage: 如果设为 true, 这篇文章将不会显示在主页上. hiddenFromSearch: 如果设为 true, 这篇文章将不会显示在搜索结果中. twemoji: 如果设为 true, 这篇文章会使用 twemoji. lightgallery: 如果设为 true, 文章中的图片将可以按照画廊形式呈现. ruby: 如果设为 true, 这篇文章会使用 上标注释扩展语法. fraction: 如果设为 true, 这篇文章会使用 分数扩展语法. fontawesome: 如果设为 true, 这篇文章会使用 Font Awesome 扩展语法. linkToMarkdown: 如果设为 true, 内容的页脚将显示指向原始 Markdown 文件的链接. rssFullText: 如果设为 true, 在 RSS 中将会显示全文内容. toc: 和 网站配置 中的 params.page.toc 部分相同. code: 和 网站配置 中的 params.page.code 部分相同. math: 和 网站配置 中的 params.page.math 部分相同. mapbox: 和 网站配置 中的 params.page.mapbox 部分相同. share: 和 网站配置 中的 params.page.share 部分相同. comment: 和 网站配置 中的 params.page.comment 部分相同. library: 和 网站配置 中的 params.page.library 部分相同. seo: 和 网站配置 中的 params.page.seo 部分相同. 技巧 featuredImage 和 featuredImagePreview 支持本地资源引用的完整用法. 如果带有在前置参数中设置了 name: featured-image 或 name: featured-image-preview 属性的页面资源, 没有必要在设置 featuredImage 或 featuredImagePreview: resources: - name: featured-image src: featured-image.jpg - name: featured-image-preview src: featured-image-preview.jpg ","date":"2021-07-03","objectID":"/20210703/:9:0","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"3 内容摘要 LoveIt 主题使用内容摘要在主页中显示大致文章信息。Hugo 支持生成文章的摘要. 文章摘要预览 ","date":"2021-07-03","objectID":"/20210703/:10:0","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"自动摘要拆分 默认情况下, Hugo 自动将内容的前 70 个单词作为摘要. 你可以通过在 网站配置 中设置 summaryLength 来自定义摘要长度. 如果您要使用 CJK中文/日语/韩语 语言创建内容, 并且想使用 Hugo 的自动摘要拆分功能，请在 网站配置 中将 hasCJKLanguage 设置为 true. ","date":"2021-07-03","objectID":"/20210703/:10:1","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"手动摘要拆分 另外, 你也可以添加 \u003c!--more--\u003e 摘要分割符来拆分文章生成摘要. 摘要分隔符之前的内容将用作该文章的摘要. 注意 请小心输入\u003c!--more--\u003e ; 即全部为小写且没有空格. ","date":"2021-07-03","objectID":"/20210703/:10:2","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"前置参数摘要 你可能希望摘要不是文章开头的文字. 在这种情况下, 你可以在文章前置参数的 summary 变量中设置单独的摘要. ","date":"2021-07-03","objectID":"/20210703/:10:3","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"使用文章描述作为摘要 你可能希望将文章前置参数中的 description 变量的内容作为摘要. 你仍然需要在文章开头添加 \u003c!--more--\u003e 摘要分割符. 将摘要分隔符之前的内容保留为空. 然后 LoveIt 主题会将你的文章描述作为摘要. ","date":"2021-07-03","objectID":"/20210703/:10:4","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"摘要选择的优先级顺序 由于可以通过多种方式指定摘要, 因此了解顺序很有用. 如下: 如果文章中有 \u003c!--more--\u003e 摘要分隔符, 但分隔符之前没有内容, 则使用描述作为摘要. 如果文章中有 \u003c!--more--\u003e 摘要分隔符, 则将按照手动摘要拆分的方法获得摘要. 如果文章前置参数中有摘要变量, 那么将以该值作为摘要. 按照自动摘要拆分方法. 注意 不建议在摘要内容中包含富文本块元素, 这会导致渲染错误. 例如代码块, 图片, 表格等. ","date":"2021-07-03","objectID":"/20210703/:10:5","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"4 Markdown 基本语法 这部分内容在 Markdown 基本语法页面 中介绍. ","date":"2021-07-03","objectID":"/20210703/:11:0","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"5 Markdown 扩展语法 LoveIt 主题提供了一些扩展的语法便于你撰写文章. ","date":"2021-07-03","objectID":"/20210703/:12:0","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"Emoji 支持 这部分内容在 Emoji 支持页面 中介绍. ","date":"2021-07-03","objectID":"/20210703/:12:1","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"数学公式 LoveIt 基于 $ \\KaTeX $ 提供数学公式的支持. 在你的 网站配置 中的 [params.math] 下面设置属性 enable = true, 并在文章的前置参数中设置属性 math: true来启用数学公式的自动渲染. 技巧 有一份 $ \\KaTeX $ 中支持的 $ \\TeX $ 函数 清单. 公式块 默认的公式块分割符是 $$/$$ 和 \\\\[/\\\\]: $$ c = \\pm\\sqrt{a^2 + b^2} $$ \\\\[ f(x)=\\int_{-\\infty}^{\\infty} \\hat{f}(\\xi) e^{2 \\pi i \\xi x} d \\xi \\\\] 呈现的输出效果如下: $$ c = \\pm\\sqrt{a^2 + b^2} $$ \\[ f(x)=\\int_{-\\infty}^{\\infty} \\hat{f}(\\xi) e^{2 \\pi i \\xi x} d \\xi \\] 行内公式 默认的行内公式分割符是 $/$ 和 \\\\(/\\\\): $ c = \\pm\\sqrt{a^2 + b^2} $ 和 \\\\( f(x)=\\int_{-\\infty}^{\\infty} \\hat{f}(\\xi) e^{2 \\pi i \\xi x} d \\xi \\\\) 呈现的输出效果如下: $ c = \\pm\\sqrt{a^2 + b^2} $ 和 \\( f(x)=\\int_{-\\infty}^{\\infty} \\hat{f}(\\xi) e^{2 \\pi i \\xi x} d \\xi \\) 技巧 你可以在 网站配置 中自定义公式块和行内公式的分割符. Copy-tex Copy-tex 是一个 $ \\KaTeX $ 的插件. 通过这个扩展, 在选择并复制 $ \\KaTeX $ 渲染的公式时, 会将其 $ \\LaTeX $ 源代码复制到剪贴板. 在你的 网站配置 中的 [params.math] 下面设置属性 copyTex = true 来启用 Copy-tex. 选择并复制上一节中渲染的公式, 可以发现复制的内容为 LaTeX 源代码. mhchem mhchem 是一个 $ \\KaTeX $ 的插件. 通过这个扩展, 你可以在文章中轻松编写漂亮的化学方程式. 在你的 网站配置 中的 [params.math] 下面设置属性 mhchem = true 来启用 mhchem. $$ \\ce{CO2 + C -\u003e 2 CO} $$ $$ \\ce{Hg^2+ -\u003e[I-] HgI2 -\u003e[I-] [Hg^{II}I4]^2-} $$ 呈现的输出效果如下: $$ \\ce{CO2 + C -\u003e 2 CO} $$ $$ \\ce{Hg^2+ -\u003e[I-] HgI2 -\u003e[I-] [Hg^{II}I4]^2-} $$ ","date":"2021-07-03","objectID":"/20210703/:12:2","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"字符注音或者注释 LoveIt 主题支持一种 字符注音或者注释 Markdown 扩展语法: [Hugo]^(一个开源的静态网站生成工具) 呈现的输出效果如下: Hugo一个开源的静态网站生成工具 ","date":"2021-07-03","objectID":"/20210703/:12:3","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"分数 LoveIt 主题支持一种 分数 Markdown 扩展语法: [浅色]/[深色] [99]/[100] 呈现的输出效果如下: 浅色/深色 90/100 ","date":"2021-07-03","objectID":"/20210703/:12:4","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["博客建站相关"],"content":"Font Awesome LoveIt 主题使用 Font Awesome 作为图标库. 你同样可以在文章中轻松使用这些图标. 从 Font Awesome 网站 上获取所需的图标 class. 去露营啦! :(fas fa-campground fa-fw): 很快就回来. 真开心! :(far fa-grin-tears): 呈现的输出效果如下: 去露营啦!  很快就回来. 真开心! ","date":"2021-07-03","objectID":"/20210703/:12:5","tags":["hugo"],"title":"hugo的Lovelt主题配置","uri":"/20210703/"},{"categories":["电脑技巧"],"content":"官方安装教程 官方教程 ","date":"2021-07-02","objectID":"/20210702/:1:0","tags":["linux"],"title":"go-cqhttp搭建教程","uri":"/20210702/"},{"categories":["电脑技巧"],"content":"个人使用经验 压缩包里的是适配Linux环境的二进制文件 按照官方文档操作后，发现一些小问题 首先是config.yml的部分配置应该是这样子的 (我只使用http协议) uin: # 必填QQ账号 password: '' # 千万别填 只做推送用不需要数据库监控 database: # 数据库相关设置 leveldb: # 是否启用内置leveldb数据库 # 启用将会增加10-20MB的内存占用和一定的磁盘空间 # 关闭将无法使用 撤回 回复 get_msg 等上下文相关功能 enable: false 服务器这块需要改0.0.0.0 # HTTP 通信设置 - http: # 服务端得填0.0.0.0 host: 0.0.0.0 # 服务端监听端口，只要是端口开放了没被占用就行 port: 3500 下面是我使用的版本的压缩包，上传宝塔中的一个空文件夹里解压参照官方文档和我的个人经验使用即可 本人使用的go-cqhttp压缩包：博客相关资源-go-cqhttp 如果是参照官方文档搭的本地版本 本地搭建这块需要改127.0.0.1 # HTTP 通信设置 - http: # 本地搭建得填127.0.0.1 host: 127.0.0.1 # 服务端监听端口，只要是端口开放了没被占用就行 port: 3500 云服务器需要使用screen命令后台24小时运行 在go-cqhttp文件所在的文件夹终端中输入 screen -S QQ 创建会话窗口 然后输入 sudo ./go-cqhttp 运行程序 等待初始化后，QQ扫码登陆即可 登陆完成后 在当前会话窗口中按住Ctrl,a,d三个快捷键可以实现分离会话窗口，这时窗口会弹出[detached]的提示，并回到主窗口，此时可以关闭终端，已经成功挂上了。 如果想要恢复查看 终端输入 screen -ls 显示 There is a screen on: 2637.QQ (12/17/2015/10:00:32 AM) (Detached) 终端输入 screen -r 2637 进入2637线程，恢复QQ会话窗口 或 screen -r QQ 这样就能回到QQ窗口了 如果输入screen -ls后看到QQ窗口后面的(???dead)字样，说明窗口死了，但是仍在占用空间。这时需要清除窗口 输入 screen -wipe 自动清除死去的窗口 ps:突然断网导致无法重登窗口 首先使用screen -d *****(id)，先退出，然后再使用 screen -r *****(id)重新连接 鸣谢： 参考的csdn博客 欢迎请站长喝一杯 ","date":"2021-07-02","objectID":"/20210702/:2:0","tags":["linux"],"title":"go-cqhttp搭建教程","uri":"/20210702/"},{"categories":["电脑技巧"],"content":"2.8版本青龙面板搭建教程 ","date":"2021-07-01","objectID":"/20210701/:0:0","tags":["linux"],"title":"青龙面板搭建教程","uri":"/20210701/"},{"categories":["电脑技巧"],"content":"step1 需要有一个云服务器，推荐我自用的腾讯云无忧计划： 优惠渠道 优点：每月续费同价，可随时重置服务器系统。 我的配置： 1核2g内存的北京-轻量云服务器 每月续费15元 系统应用重置为Ubuntu20.0版本 学生机优惠 优点：一年98，可同价位续费三次 缺点：有资格限制，需要实名认证在25岁以下 腾讯云买完后进入轻量云服务器后台有个防火墙管理，添加端口号5700,8888，给面板开放端口。 ","date":"2021-07-01","objectID":"/20210701/:0:1","tags":["linux"],"title":"青龙面板搭建教程","uri":"/20210701/"},{"categories":["电脑技巧"],"content":"step2 装宝塔页面，方便文件管理，不用到处cd开文件夹 宝塔安装页面：点我跳转 等待宝塔安装完成并进入宝塔面板，等待默认LAMP安装完成。 ","date":"2021-07-01","objectID":"/20210701/:0:2","tags":["linux"],"title":"青龙面板搭建教程","uri":"/20210701/"},{"categories":["电脑技巧"],"content":"step3 在软件商店搜索docker，安装docker管理器 ","date":"2021-07-01","objectID":"/20210701/:0:3","tags":["linux"],"title":"青龙面板搭建教程","uri":"/20210701/"},{"categories":["电脑技巧"],"content":"step4 在终端输入进入管理员模式 终端输入，一行一行执行 sudo -i yum update curl -sSL https://get.daocloud.io/docker | sh sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo sudo systemctl start docker ","date":"2021-07-01","objectID":"/20210701/:0:4","tags":["linux"],"title":"青龙面板搭建教程","uri":"/20210701/"},{"categories":["电脑技巧"],"content":"step5 拉取镜像 终端输入 docker pull whyour/qinglong:latest ","date":"2021-07-01","objectID":"/20210701/:0:5","tags":["linux"],"title":"青龙面板搭建教程","uri":"/20210701/"},{"categories":["电脑技巧"],"content":"step6 安装青龙 终端输入 docker run -dit \\ -v $pwd/ql/config:/ql/config \\ -v $pwd/ql/log:/ql/log \\ -v $pwd/ql/db:/ql/db \\ -v $pwd/ql/scripts:/ql/scripts \\ -v $pwd/ql/jbot:/ql/jbot \\ -p 5700:5700 \\ -e ENABLE_HANGUP=true \\ -e ENABLE_WEB_PANEL=true \\ --name qinglong \\ --hostname qinglong \\ --restart always \\ whyour/qinglong:latest 等待运行完成后，终端输入 firewall-cmd --zone=public --add-port=5700/tcp --permanent ","date":"2021-07-01","objectID":"/20210701/:0:6","tags":["linux"],"title":"青龙面板搭建教程","uri":"/20210701/"},{"categories":["电脑技巧"],"content":"step6 查看密码 先浏览器打开http://你服务器外网IP:5700 默认帐号密码均为admin，输入登录后提示查看密码 在宝塔面板的文件页面搜索ql，找到文件夹后在ql/config文件夹里找到auth.json,里面是账号和密码。 ","date":"2021-07-01","objectID":"/20210701/:0:7","tags":["linux"],"title":"青龙面板搭建教程","uri":"/20210701/"},{"categories":["电脑技巧"],"content":"step7 更新密码 你服务器ip:5700 是你的青龙面板地址，登陆青龙面板后在设置里修改面板用户名和密码。 如果忘了用户名和密码可以自己看step6中的auth.json找回。 ","date":"2021-07-01","objectID":"/20210701/:0:8","tags":["linux"],"title":"青龙面板搭建教程","uri":"/20210701/"},{"categories":["电脑技巧"],"content":"step8 新建任务 定时任务里添加任务 名称命名(命名任务保证搜索容易查找拉取库) 任务1 XXX 任务2 XXX …… 命令内容 一行一个新建定时，定时写 0 6 * * * 定时拉取脚本更新 ql repo https://github.com/passerby-b/JDDJ.git ql repo https://github.com/ZCY01/daily_scripts.git \"jd_\" ql repo https://github.com/longzhuzhu/nianyu.git \"qx\" “main” ql repo https://github.com/whyour/hundun.git \"quanx\" \"tokens|caiyun|didi|donate|fold|Env\" ql repo https://github.com/huiyi9420/monk-coder_dust.git \"i-chenzhe|normal|member|car\" \"backup\" ql repo https://github.com/zooPanda/zoo.git \"zoo\" ql repo https://github.com/star261/jd.git \"scripts\" \"code\" ql repo https://github.com/panghu999/jd_scripts.git \"jd_|jx_|getJDCookie\" \"activity|backUp\" \"^jd[^_]|USER\" 确认完后点操作列中的开始按钮执行一次，等待完成后点操作列中的禁用按钮禁用，建议禁用，避免作者删库跑路，也可以不禁用，但不建议新手如此操作。 7月6日更新的JD脚本仓库合集，拉取库点这个用最新的 ","date":"2021-07-01","objectID":"/20210701/:0:9","tags":["linux"],"title":"青龙面板搭建教程","uri":"/20210701/"},{"categories":["电脑技巧"],"content":"step9 添加ck 在环境变量里 变量名 JD_COOKIE 变量值 一行一个ck 格式 pt_key=1111111111;pt_pin=111111; pt_key=2222222222;pt_pin=222222; 备注随便写，没影响 ","date":"2021-07-01","objectID":"/20210701/:0:10","tags":["linux"],"title":"青龙面板搭建教程","uri":"/20210701/"},{"categories":["电脑技巧"],"content":"step10 配置推送 在配置文件里看注释说明配置 推荐： ## Push Plus export PUSH_PLUS_TOKEN=\"\" export PUSH_PLUS_USER=\"\" 其中 PUSH_PLUS_TOKEN 是http://pushplus.plus/ 注册登录后提供的Token，必填 PUSH_PLUS_USER 选填，一对一则不填，一对多必填，填入pushplus群组编号 完事了 ","date":"2021-07-01","objectID":"/20210701/:0:11","tags":["linux"],"title":"青龙面板搭建教程","uri":"/20210701/"},{"categories":["电脑技巧"],"content":"ck获取教程 获取教程 注意：这里不推荐用扫码登陆，因为cookie有效期只有一天，用手机跟验证码登陆后，cookie可以保持很久，大概有效期1个月多。 按照教程获取到的ck，使用它的pt_key=抓到的对应值内容;,pt_pin=抓到的对应值内容;，填入step9。 ","date":"2021-07-01","objectID":"/20210701/:0:12","tags":["linux"],"title":"青龙面板搭建教程","uri":"/20210701/"},{"categories":["电脑技巧"],"content":"本地ck获取 某大佬仓库： https://github.com/scjtqs/jd_cookie ","date":"2021-07-01","objectID":"/20210701/:0:13","tags":["linux"],"title":"青龙面板搭建教程","uri":"/20210701/"},{"categories":["电脑技巧"],"content":"个人挂机项目收集 ↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓ 相关挂机项目点我跳转 欢迎请站长喝一杯 ","date":"2021-07-01","objectID":"/20210701/:0:14","tags":["linux"],"title":"青龙面板搭建教程","uri":"/20210701/"},{"categories":["数学建模"],"content":"前言 感谢组员的共同协作。 ","date":"2021-06-27","objectID":"/20210627/:1:0","tags":["matlab","数学建模"],"title":"基于常微分及时间序列模型的印度人口增长预测","uri":"/20210627/"},{"categories":["数学建模"],"content":"问题 以人口总数、人口年度增长率为研究对象，利用并根据世界人口网搜索1959年到2018年印度国家人口统计数据进行参数估计，即数据拟合，并对2019年印度人口进行增长预测。 用数学建模预测人口增长的方法主要有差分方程、微分方程、回归分析、时间序列等，结合题目、搜索到的数据以及《常微分方程》课本中所学知识，本小组以微分方程形式表示的改进指数增长模型、logistic模型为基础，以时间序列模型为拓展课题，建立以时间为自变量的印度人口增长模型。利用历史数据带入模型求解并做出预测。 ","date":"2021-06-27","objectID":"/20210627/:2:0","tags":["matlab","数学建模"],"title":"基于常微分及时间序列模型的印度人口增长预测","uri":"/20210627/"},{"categories":["数学建模"],"content":"代码 ","date":"2021-06-27","objectID":"/20210627/:3:0","tags":["matlab","数学建模"],"title":"基于常微分及时间序列模型的印度人口增长预测","uri":"/20210627/"},{"categories":["数学建模"],"content":"改进指数增长模型 %改进的指数增长模型 data=csvread('data.csv',1,0); x=data(:,2)'; real_rate=data(:,3)*0.01; n=length(x); t=0:1:n-1; rk=zeros(1,n); rk(1)=(-3*x(1)+4*x(2)-x(3))/2; rk(n)=(x(n-2)-4*x(n-1)+3*x(n))/2; for i=2:n-1 rk(i)=(x(i+1)-x(i-1))/2; end rk=rk./x; p=polyfit(t,rk,2); r0=p(1); r1=p(2); r2=p(3); x0=x(1); R=r0*t.^2+r1*t+r2; X=x0*exp((r0*t.^3)/3+(r1*t.^2)/2+r2*t); figure(1) hold on; xlabel('year'); %设置横坐标名 ylabel('rate'); %设置纵坐标名 grid on %网格线 plot(t,real_rate,'r*') title('印度人口的年增长率') figure(2) hold on; xlabel('year'); %设置横坐标名 ylabel('population'); %设置纵坐标名 grid on %网格线 plot(t,x,'r*',t,X) title('改进的指数模型拟合的人口') figure(3) hold on; xlabel('year'); %设置横坐标名 ylabel('rate'); %设置纵坐标名 grid on %网格线 plot(t,real_rate,'r*',t,R') title('改进的指数模型拟合的增长率') t1=t(59)+1; y2019=x0*exp((r0*t1.^3)/3+(r1*t1.^2)/2+r2*t1) rate2019=r0*t1.^2+r1*t1+r2 ","date":"2021-06-27","objectID":"/20210627/:3:1","tags":["matlab","数学建模"],"title":"基于常微分及时间序列模型的印度人口增长预测","uri":"/20210627/"},{"categories":["数学建模"],"content":"logistic模型 % 线性最小二乘法拟合 data=csvread('data.csv',1,0); x=data(:,2)'; real_rate=data(:,3)*0.01; n=length(x); t=0:1:n-1; rk=zeros(1,n); rk(1)=(-3*x(1)+4*x(2)-x(3))/2; rk(n)=(x(n-2)-4*x(n-1)+3*x(n))/2; for i=2:n-1 rk(i)=(x(i+1)-x(i-1))/2; end rk=rk./x; p=polyfit(t,rk,1);%一阶拟合 b=p(1); a=p(2); r=a; xm=-r/b; x0=x(1); for i=1:n X(i)=xm/(1+((xm/x0)-1)*exp(-r*t(i)));%各个年份的预测人口总数 end figure(1) hold on; xlabel('year'); %设置横坐标名 ylabel('population'); %设置纵坐标名 grid on %网格线 plot(t,x,'r*',t,X) title('线性最小二乘法模型拟合的人口') figure(2) hold on; xlabel('year'); %设置横坐标名 ylabel('rate'); %设置纵坐标名 grid on %网格线 plot(t,real_rate,'r*',t,b*t+a) title('线性最小二乘法模型拟合的增长率') %非线性最小二乘法拟合： function f=logistic_fun(a,t) f=a(1)./(1+(a(1)/3.9-1)*exp(-a(2)*(t))); end clc; clear all; data=csvread('data.csv',1,0); x=data(:,2)'*(10^(-8)); real_rate=data(:,3)*0.01; n=length(x); t=0:1:58; a0=[100,7.6]; %初值 plot(t,x,'*',t,x); %画点，并且画一条直线把各点连起来 hold on; %最重要的函数，第1个参数是函数名(一个同名的m文件定义)，第2个参数是初值，第3、4个参数是已知数据点 a=lsqcurvefit('logistic_fun',a0,t, x); disp([' a=' num2str(a)]); %显示结果 %画图检验结果 ti=0:1:59; xi=logistic_fun(a,ti); xlabel('year'); %设置横坐标名 ylabel('population'); %设置纵坐标名 plot(ti,xi,'r'); %预测2019 t2019=59; x2019=logistic_fun(a,t2019) title('非线性最小二乘法模型拟合的人口') ","date":"2021-06-27","objectID":"/20210627/:3:2","tags":["matlab","数学建模"],"title":"基于常微分及时间序列模型的印度人口增长预测","uri":"/20210627/"},{"categories":["数学建模"],"content":"时间序列模型 Y=[1038058156,1056575549,1075000085,1093317189,1111523144,1129623456,1147609927,1165486291,1183209472,1200669765,1217726215,1234288729,1265782790,1280846129,1295604184,1310152403,1324509589,1338658835,1352617328]; adf=adftest(Y'); kpss=kpsstest(Y'); Yd1=diff(Y'); adf1=adftest(Yd1); kpss1=kpsstest(Yd1); Yd2=diff(Yd1); adf2=adftest(Yd2); kpss2=kpsstest(Yd2); Yd3=diff(Yd2); adf3=adftest(Yd3); kpss3=kpsstest(Yd3); figure autocorr(Yd3); figure parcorr(Yd3); p=1; q=1; Mdl = arima(p, 3, q); EstMdl=estimate(Mdl,Yd3); [res,logL] = infer(EstMdl,Yd3); figure subplot(2,2,1) plot(res./sqrt(EstMdl.Variance)) title('Standardized Residuals') subplot(2,2,2),qqplot(res) subplot(2,2,3),autocorr(res) subplot(2,2,4),parcorr(res) [yF,yMSE]=forecast(EstMdl,1,'y0',Y'); UB=yF+1.96*sqrt(yMSE); LB=yF-1.96*sqrt(yMSE); data=Y';step=1; figure() plot(data,'Color',[.7,.7,.7]); hold on h1 = plot(length(data):length(data)+step,[data(end);LB],'r:','LineWidth',2); plot(length(data):length(data)+step,[data(end);UB],'r:','LineWidth',2) h2 = plot(length(data):length(data)+step,[data(end);yF],'k','LineWidth',2); legend([h1 h2],'95% ÖÃÐÅÇø¼ä','Ô¤²âÖµ',... 'Location','NorthWest') title('Forecast') hold off ","date":"2021-06-27","objectID":"/20210627/:3:3","tags":["matlab","数学建模"],"title":"基于常微分及时间序列模型的印度人口增长预测","uri":"/20210627/"},{"categories":["数学建模"],"content":"时间序列预测 Y=[1.81,1.77,1.73,1.69,1.65,1.62,1.58,1.55,1.51,1.46,1.41,1.35,1.29,1.23,1.18,1.15,1.12,1.09,1.06,1.04]; adf=adftest(Y'); kpss=kpsstest(Y'); Yd1=diff(Y'); adf1=adftest(Yd1); kpss1=kpsstest(Yd1); Yd2=diff(Yd1); adf2=adftest(Yd2); kpss2=kpsstest(Yd2); figure autocorr(Yd2); figure parcorr(Yd2); p=1; q=1; Mdl = arima(p, 2, q); EstMdl=estimate(Mdl,Yd2); [res,logL] = infer(EstMdl,Yd2); figure subplot(2,2,1) plot(res./sqrt(EstMdl.Variance)) title('Standardized Residuals') subplot(2,2,2),qqplot(res) subplot(2,2,3),autocorr(res) subplot(2,2,4),parcorr(res) [yF,yMSE]=forecast(EstMdl,1,'y0',Y'); UB=yF+1.96*sqrt(yMSE); LB=yF-1.96*sqrt(yMSE); data=Y';step=1; figure() plot(data,'Color',[.7,.7,.7]); hold on h1 = plot(length(data):length(data)+step,[data(end);LB],'r:','LineWidth',2); plot(length(data):length(data)+step,[data(end);UB],'r:','LineWidth',2) h2 = plot(length(data):length(data)+step,[data(end);yF],'k','LineWidth',2); legend([h1 h2],'95% ÖÃÐÅÇø¼ä','Ô¤²âÖµ',... 'Location','NorthWest') title('Forecast') hold off ","date":"2021-06-27","objectID":"/20210627/:3:4","tags":["matlab","数学建模"],"title":"基于常微分及时间序列模型的印度人口增长预测","uri":"/20210627/"},{"categories":["数学建模"],"content":"总结 改进的指数增长模型和时间序列的拟合效果较好。 完整文档详见：博客相关资源-常微分项目文件 ","date":"2021-06-27","objectID":"/20210627/:3:5","tags":["matlab","数学建模"],"title":"基于常微分及时间序列模型的印度人口增长预测","uri":"/20210627/"},{"categories":["C++","数据结构"],"content":"前言 感谢组员的共同协作。 ","date":"2021-06-25","objectID":"/20210625/:1:0","tags":["C++","数据结构"],"title":"多重算法实现的迷宫求解问题","uri":"/20210625/"},{"categories":["C++","数据结构"],"content":"题目背景 迷宫问题是取自心理学的一个古典实验。在该实验中，将一只老鼠放入一个无顶大盒子的门口处，在出口处放置一块奶酪，奶酪吸引老鼠在盒子中寻找出口。对同一只老鼠进行反复实验，最终老鼠学会走通迷宫路线并不走错一步。 ","date":"2021-06-25","objectID":"/20210625/:1:1","tags":["C++","数据结构"],"title":"多重算法实现的迷宫求解问题","uri":"/20210625/"},{"categories":["C++","数据结构"],"content":"题目重述 “迷宫求解”是指在规定的迷宫中寻找从入口到出口路径的问题。即从入口出发，顺着某一方向向前探索，若能走通，则继续向前走；否则沿原路退回，换一个方向继续探索，直到探索到所有可能连通的路径为止。 ","date":"2021-06-25","objectID":"/20210625/:1:2","tags":["C++","数据结构"],"title":"多重算法实现的迷宫求解问题","uri":"/20210625/"},{"categories":["C++","数据结构"],"content":"题目分析 解决迷宫问题，首先需要利用一种方式，如二维数组将其存储起来。由于计算机解迷宫时，常用的是“穷举求解”的办法，即从入口出发，顺某一方向向前探索，若能走通，则继续往前走；否则沿原路返回，换一个方向继续探索，直至所有可能的通路都探索为止。为了保证在任何位置上都能按原路返回，显然需要用一个后进先出的结构来保存从入口到当前位置的路径。 ","date":"2021-06-25","objectID":"/20210625/:1:3","tags":["C++","数据结构"],"title":"多重算法实现的迷宫求解问题","uri":"/20210625/"},{"categories":["C++","数据结构"],"content":"算法设计 （1）回溯法 （2）基于深度遍历的算法 （3）基于广度遍历的算法 （4）转换为图的图论算法 ","date":"2021-06-25","objectID":"/20210625/:1:4","tags":["C++","数据结构"],"title":"多重算法实现的迷宫求解问题","uri":"/20210625/"},{"categories":["C++","数据结构"],"content":"整体代码 ","date":"2021-06-25","objectID":"/20210625/:2:0","tags":["C++","数据结构"],"title":"多重算法实现的迷宫求解问题","uri":"/20210625/"},{"categories":["C++","数据结构"],"content":"回溯法-顺序栈 #include\u003cstdlib.h\u003e #include\u003cstdio.h\u003e #include\u003ciostream\u003e using namespace std; #define RANGE 4 #define row 4 #define col 4 #define OK 1 #define ERROR 0 #define INFEASIBLE -1 #define OVER_FLOW -2 typedef int Status; typedef int DirectiveType; //位置坐标 typedef struct { int x, y;//表示迷宫中的位置信息x行y列 }PostType; //迷宫类型 typedef struct { int map[row + 2][col + 2];//用户输入矩阵（0，1）表示迷宫的初始生成 char arr[RANGE + 2][RANGE + 2];//程序的输入矩阵，以字符“@# ”表示探索状态 }MazeType; //栈类型 typedef struct { int step;//当前位置在路径上的“序号” PostType seat;//当前位置坐标 DirectiveType di;//往下一坐标位置的方向 }ElemType;//栈元素类型 typedef struct { ElemType* base; ElemType* top; int stacksize; }Stack;//利用顺序栈实现 Status InitStack(Stack\u0026 S) { S.base = new ElemType[100]; if (!S.base) exit(OVER_FLOW); S.top = S.base; S.stacksize = 100; return OK; } Status StackEmpty(Stack S) { if (S.top == S.base) return OK; else return ERROR; } Status Push(Stack\u0026 S, ElemType e) { if (S.top - S.base \u003e= S.stacksize) { ElemType* newbase = (ElemType*)realloc(S.base, (S.stacksize + 10) * sizeof(ElemType)); if (!newbase) exit(OVER_FLOW); S.base = newbase; S.top = S.base + S.stacksize; S.stacksize += 10; } *S.top++ = e; return OK; } Status Pop(Stack\u0026 S, ElemType\u0026 e) { if (S.top == S.base) return ERROR; e = *--S.top; return OK; } void InitMaze(MazeType\u0026 maze) { for (int i = 0; i \u003c row + 2; i++) { for (int j = 0; j \u003c col + 2; j++) { if (i == 0 || j == 0 || i == row + 1 || j == col + 1) { maze.map[i][j] = 0; maze.arr[i][j] = '#'; } else { cout \u003c\u003c \"第\" \u003c\u003c i \u003c\u003c \"行\" \u003c\u003c \"第\" \u003c\u003c j \u003c\u003c \"列：\"; cin \u003e\u003e maze.map[i][j]; if (maze.map[i][j] == 1) maze.arr[i][j] = '#'; else maze.arr[i][j] = ' '; } } } } Status Pass(MazeType maze, PostType curpos) {//判断格子是否走过且能走 if (maze.arr[curpos.x][curpos.y] == ' ') return OK; return ERROR; } Status FootPrint(MazeType\u0026 maze, PostType curpos) {//记录走过的格子 if (maze.arr[curpos.x][curpos.y] == ' ') { maze.arr[curpos.x][curpos.y] = '*'; return OK; } return ERROR; } Status Same(PostType curpos, PostType end) {//判断两个格子位置是否一样 if (curpos.x == end.x \u0026\u0026 curpos.y == end.y) return OK; return ERROR; } PostType NextPos(PostType curpos, int di) { switch (di) { case 1: {curpos.y = curpos.y + 1; return curpos; break; }//向右移动一格 case 2: {curpos.x = curpos.x + 1; return curpos; break; }//向下移动一格 case 3: {curpos.y = curpos.y - 1; return curpos; break; }//向左移动一格 case 4: {curpos.x = curpos.x - 1; return curpos; break; }//向上移动一格 } } Status MarkPrint(MazeType\u0026 maze, PostType pos) { maze.arr[pos.x][pos.y] = '@'; return OK; } Status MazePath(MazeType\u0026 maze, PostType start, PostType end) { Stack S; InitStack(S); PostType curpos = start;//设定“当前位置”为“入口位置” int curstep = 1;//探索第一步,记录探索步数 bool found = ERROR;//判断是否达到终点 ElemType e;//Stack元素 do { if (Pass(maze, curpos)) { //当前位置可以通过，即是未曾走到过的通道留下足迹 FootPrint(maze, curpos); e.di = 1; e.seat = curpos; e.step = curstep; Push(S, e);//加入路径 if (Same(curpos, end)) found = OK; //到达终点（出口） else { curpos = NextPos(curpos, 1);//下一位置是当前位置的东邻（向右移动一格） //NextPos(curpos, 1); curstep++;//探索下一步 } } else {//当前位置不能通过 if (!StackEmpty(S)) { Pop(S, e);//将刚才不能前进的Stack元素出栈，相当于退回一步 while (e.di == 4 \u0026\u0026 !StackEmpty(S)) { MarkPrint(maze, e.seat);//对刚才出栈的元素的位置标记 Pop(S, e);//下一个元素出栈，与上一步的e不一样 } if (e.di \u003c 4) { e.di++; Push(S, e);//换下一个方向探索 curpos = NextPos(e.seat, e.di);//设定当前位置是该新方向向上 } } } } while (!StackEmpty(S) \u0026\u0026 !found); return found; } Status PrintMaze(MazeType maze) { for (int i = 0; i \u003c RANGE + 2; i++) { for (int j = 0; j \u003c RANGE + 2; j++) { cout \u003c\u003c maze.arr[i][j] \u003c\u003c \" \"; } cout \u003c\u003c \"\\n\"; } return OK; } int main() { MazeType maze; InitMaze(maze); cout \u003c\u003c \"生成的迷宫为：\" \u003c\u003c endl; PrintMaze(maze); PostType start, end; cout \u003c\u003c \"请输入起点：\"; cin \u003e\u003e start.x \u003e\u003e start.y; cout \u003c\u003c \"请输入终点：\"; cin \u003e\u003e end.x \u003e\u003e end.y; if (MazePath(maze, start, end)) { cout \u003c\u003c \"路径存在，迷宫求解路径为：\" \u003c\u003c endl; PrintMaze(maze); } else { cout \u003c\u003c \"路径不存在，迷宫求解路径为：\" \u003c\u003c endl; PrintMaze(maze); } return 0; } ","date":"2021-06-25","objectID":"/20210625/:2:1","tags":["C++","数据结构"],"title":"多重算法实现的迷宫求解问题","uri":"/20210625/"},{"categories":["C++","数据结构"],"content":"回溯法—链栈 只有结构体定义与顺序栈不同，其他程序均相同 typedef int Status; typedef int DirectiveType; //位置坐标 typedef struct { int x, y;//表示迷宫中的位置信息x行y列 }PostType; //迷宫类型 typedef struct { int map[row+2][col+2];//用户输入矩阵（0，1）表示迷宫的初始生成 char arr[RANGE+2][RANGE+2];//程序的输入矩阵，以字符“@# ”表示探索状态 }MazeType; //栈类型 typedef struct { int step;//当前位置在路径上的“序号” PostType seat;//当前位置坐标 DirectiveType di;//往下一坐标位置的方向 }ElemType;//栈元素类型 typedef struct StackNode{ ElemType data; struct StackNode * next; }StackNode, * LinkStack;//节点类型，指针类型 ### 深度优先搜索遍历法 ```C++ //显示中文 #define _CRT_SECURE_NO_WARNINGS #include \u003cwindows.h\u003e//用于函数SetConsoleOutputCP(65001);更改cmd编码为utf8 #include\u003cstdlib.h\u003e #include\u003cstdio.h\u003e #include\u003ciostream\u003e #define M 4 #define N 4 #define MaxSize M * N #define OK 1 #define ERROR 0 #define INFEASIBLE -1 #define OVER_FLOW -2 using namespace std; typedef int Status; typedef struct { int map[M + 2][N + 2];//用户输入矩阵（0，1）表示迷宫的初始生成 }MazeType; //初始化迷宫 void InitMaze(MazeType\u0026maze) { for (int i = 0; i \u003c M + 2; i++) { for (int j = 0; j \u003c N + 2; j++) { if (i == 0 || j == 0 || i == M + 1 || j == N + 1) { maze.map[i][j] = 1; } else { cout \u003c\u003c \"第\" \u003c\u003c i \u003c\u003c \"行\" \u003c\u003c \"第\" \u003c\u003c j \u003c\u003c \"列：\"; cin \u003e\u003e maze.map[i][j]; } } } } //x与y的增量 typedef struct { int incX,incY; }Direction; //位置 typedef struct{ int x,y; //当前坐标 int di; //当前方向 }Box; //栈 typedef struct { Box data[MaxSize]; int top; }SqStack; //初始化栈 void InitStack(SqStack \u0026S) { S=*(SqStack *)malloc(sizeof(SqStack)); S.top=0; } //四个方向增量初始化 void Init(Direction direct[]) { //右 direct[0].incX = 0; direct[0].incY = 1; //下 direct[1].incX = 1; direct[1].incY = 0; //左 direct[2].incX = 0; direct[2].incY = -1; //上 direct[3].incX = -1; direct[3].incY = 0; } //判栈空 Status StackEmpty(SqStack \u0026S) { if(S.top==0) { return OK;//栈空返回真 } else { return ERROR; } } //入栈 void Push(SqStack \u0026S,Box e) { if(S.top==MaxSize) { printf(\"入栈失败！\\n\"); } S.data[S.top]=e; S.top++; } //出栈 Box Pop(SqStack \u0026S) { Box e; S.top--; e = S.data[S.top]; return e; } //销毁 void Destroy(SqStack \u0026S) { free(\u0026S); cout\u003c\u003c\"栈已销毁！\"\u003c\u003cendl; } //寻找路径 Status findPath(int maze[][N + 2],Direction direct[], SqStack \u0026S) { Box temp; int x, y, di; int L, C; maze[1][1] = -1; temp.x = 1; temp.y = 1; temp.di = -1; Push(S, temp);//将temp压入到堆栈 while (!StackEmpty(S))//当栈不空的时候 { temp = Pop(S); x = temp.x; y = temp.y; di = temp.di + 1; while (di \u003c 4) { L = x + direct[di].incX; C = y + direct[di].incY; if (maze[L][C] == 0) { temp.x = x; temp.y = y; temp.di = di; Push(S, temp); x = L; y = C; maze[L][C] = -1; if (x == M \u0026\u0026 y == N) { return OK; } else { di = 0; } } else { di++; } } } return ERROR; } //打印创建的迷宫 Status PrintMaze(MazeType maze) { for (int i = 0; i \u003c M + 2; i++) { for (int j = 0; j \u003c N + 2; j++) { cout \u003c\u003c maze.map[i][j] \u003c\u003c \" \"; } cout \u003c\u003c \"\\n\"; } return OK; } //画路径 Status printPath(MazeType maze,Box path[], int count) { //描绘路径 for(int i = count-1; i \u003e= 0; i--) { int x = path[i].x; int y = path[i].y; maze.map[x][y] = 9; } maze.map[M][N] = 9; PrintMaze(maze); return OK; } int main() { //显示中文 SetConsoleOutputCP(65001); cout \u003c\u003c \"迷宫只能从左上角开始走到右下角\" \u003c\u003c endl; MazeType MAZE; InitMaze(MAZE); MazeType* result = new MazeType(MAZE); cout \u003c\u003c \"生成的迷宫为：\" \u003c\u003c endl; PrintMaze(MAZE); cout\u003c\u003cendl; cout \u003c\u003c \"找到通路的迷宫为(以9表示找到的路径)：\" \u003c\u003c endl; Direction direct[4];//初始化方向结构体 Init(direct);//初始化方向结构体 SqStack S; InitStack(S); StackEmpty(S); Box path[MaxSize]; if(findPath(MAZE.map, direct, S)) { int count = 0; for(int i = 0; !StackEmpty(S); i++) { path[i] = Pop(S); count++; } printPath(*result,path,count); Destroy(S); } else { cout\u003c\u003c\"迷宫没有通路\"\u003c\u003cendl; } system(\"pause\"); return 0; } ","date":"2021-06-25","objectID":"/20210625/:2:2","tags":["C++","数据结构"],"title":"多重算法实现的迷宫求解问题","uri":"/20210625/"},{"categories":["C++","数据结构"],"content":"广度优先搜索遍历法 解法一 #include \u003ciostream\u003e using namespace std; #define nRow 100 #define nCol 100 struct note // 队列中的元素类型 { int x; int y; }; // 地图 int ROW_NUM, COL_NUM; int nMatrix[nRow][nCol] = { 0 }; int flag[100][100] = { 0 }; // 标记是否走过的路 int head = 0; // 队列的头部索引 int tail = 0; // 队列的尾部索引 // 方向 int direction[4][2] = { 0, 1, 1, 0, 0, -1, -1, 0 }; struct note que[10000]; // 队列 int main() { for (int i = 0; i \u003c 100; i++) for (int j = 0; j \u003c 100; j++) flag[i][j] = 1; cout \u003c\u003c \"你想要构造迷宫的长度为:\" \u003c\u003c endl; cin \u003e\u003e ROW_NUM; cout \u003c\u003c \"你想要构造迷宫的宽度为：\" \u003c\u003c endl; cin \u003e\u003e COL_NUM; cout \u003c\u003c \"以0为通路，以非零实数，如1为墙壁，构造你想要的迷宫：\" \u003c\u003c endl; int m = 1; for (int i = 0; i \u003c ROW_NUM; i++) { cout \u003c\u003c \"请输入第\" \u003c\u003c m \u003c\u003c \"行的数字\" \u003c\u003c endl; for (int j = 0; j \u003c COL_NUM; j++) { cin \u003e\u003e nMatrix[i][j]; flag[i][j] = 0; } if (m \u003c ROW_NUM) { m++; } } cout \u003c\u003c \"你构造的迷宫为：\" \u003c\u003c endl; for (int i = 0; i \u003c ROW_NUM; i++) { for (int j = 0; j \u003c COL_NUM; j++) { if (nMatrix[i][j] == 0) cout \u003c\u003c \" \"; else cout \u003c\u003c \"[ ]\"; } cout \u003c\u003c endl; }// 输出二维迷宫图 // 初始化每一个队列元素的值（开始寻找的地方） que[head].x = que[head].y = 0; tail++; // 尾部索引 + 1 flag[0][0] = 1; // 标记初始位置已经查找过了 cout \u003c\u003c \"它走过的路径为：\" \u003c\u003c endl; cout \u003c\u003c \"(0,0)\" \u003c\u003c endl; while (head \u003c tail) { int i = 0; for (; i \u003c ROW_NUM; i++) { // 每次都是以队头为单位向四个方向开始 int nx = que[head].x + direction[i][0]; int ny = que[head].y + direction[i][1]; if (nx \u003c 0 || nx \u003e ROW_NUM || ny \u003c 0 || ny \u003e COL_NUM) continue; if (nMatrix[nx][ny] == 0 \u0026\u0026 flag[nx][ny] == 0) { flag[nx][ny] = 1; que[tail].x = nx; // 加入队列 que[tail].y = ny; cout \u003c\u003c \"(\"\u003c\u003cque[tail].x \u003c\u003c\",\"\u003c\u003c que[tail].y\u003c\u003c\")\" \u003c\u003c endl; tail++; } } head++; } return 0; } 解法二 #include \u003cthread\u003e//多线程头文件 #include\u003cWindows.h\u003e//用于窗口等待Sleep #include \u003ciostream\u003e using namespace std; #define WAIT_TIME 1000//加载时间，越小越快 string* maze = NULL;//输入的迷宫 int maze_height = 0;//迷宫高度 int flag = 0;//结束标志 int aim_x = 0, aim_y = 0;//终点坐标 int** maze_road;//迷宫数组 int road_num = 0, road_num_flag = -1;//创建寻路线程次数，寻路线程次数标记 void printMap(); void findRoad(int x, int y, int direction); void continuePrintMap(); int main() { /*输入数据*/ cout \u003c\u003c \"迷宫高为：\"; cin \u003e\u003e maze_height; cout \u003c\u003c \"请输入迷宫（墙壁为#）：\" \u003c\u003c endl; maze = new string[maze_height]; for (int i = 0; i \u003c maze_height; i++) { cin \u003e\u003e maze[i]; } cout \u003c\u003c \"请输入迷宫终点(x,y)：\" \u003c\u003c endl; cin \u003e\u003e aim_x \u003e\u003e aim_y; /*构造迷宫数组*/ maze_road = new int* [maze_height]; if (maze_road) memset(maze_road, 0, sizeof(int*) * maze_height); for (int i = 0; i \u003c maze_height; i++) { maze_road[i] = new int[maze[i].size() + 1]; for (unsigned int j = 0; j \u003c maze[i].size() + 1; j++) { if (maze[i][j] != \u0026apos;#\u0026apos;) maze_road[i][j] = 0; else maze_road[i][j] = -1; } } /*打开多线程*/ system(\"cls\");//清屏 thread print_map(continuePrintMap); print_map.detach(); thread find_road(findRoad, 1, 1, 0); find_road.detach(); /*后续*/ while (1) { /*没找到路径不继续*/ if (flag == 1) break; } system(\"cls\"); printMap();//最终迷宫图 /*收尾删除*/ for (int i = 0; i \u003c maze_height; i++) { delete[] maze_road[i]; } if (maze_road) delete[] maze_road; maze_road = NULL; delete[] maze; maze = NULL; return 0; } /*多线程持续打印迷宫*/ void continuePrintMap() { while (1) { /*不再找了也停止（机器人全灭）*/ if (road_num_flag == road_num) { flag = 1; return; } /*找到位置就停止*/ if (flag == 1) return; printMap(); } } /*打印迷宫*/ void printMap() { /*光标移动到（0，0），不用cls因为会闪*/ road_num_flag = road_num; printf_s(\"\\33[0;0H\"); for (int i = 0; i \u003c maze_height; i++) { for (unsigned int j = 0; j \u003c maze[i].size(); j++) { if (maze_road[i][j] == -1) printf_s(\"%3c\", maze[i][j]);//打印墙 else printf_s(\"%3d\", maze_road[i][j]);//打印路 //if //(maze_road[i][j] == -2); //printf_s(\"Y\"); } cout \u003c\u003c endl; } Sleep(WAIT_TIME); } /* 多线程迷宫寻路机器人 x 当前x坐标 y 当前y坐标 direction: 0 没有前一个位置 1 前一个位置在↑ 2 前一个位置在↓ 3 前一个位置在← 4 前一个位置在→ */ void findRoad(int x, int y, int direction) { Sleep(WAIT_TIME); road_num++; /**/ if (flag == 1)//寻路完成提前退出 return; /*记录此地距离原点距离*/ switch (direction) { case 1: { maze_road[x][y] = maze_road[x - 1][y] + 1; break; } case 2: { maze_road[x][y] = maze_road[x + 1][y] + 1; break; } case 3: { maze_road[x][y] = maze_road[x][y - 1] + 1; break; } case 4: { maze_road[x][y] = maze_road[x][y + 1] + 1; break; ","date":"2021-06-25","objectID":"/20210625/:2:3","tags":["C++","数据结构"],"title":"多重算法实现的迷宫求解问题","uri":"/20210625/"},{"categories":["C++"],"content":"前言 感谢组员的共同协作。 ","date":"2021-06-20","objectID":"/20210620/:1:0","tags":["C++","数值逼近"],"title":"几种数值算法的简单分析","uri":"/20210620/"},{"categories":["C++"],"content":"四阶龙格-库塔公式计算微分方程数值解 #include\u003ciostream\u003e #include\u003ciomanip\u003e using namespace std; double f(double t, double x, double y) { double dx; dx = x + 2 * y; return(dx); } double g(double t, double x, double y) { double dy; dy = 3 * x + 2 * y; return(dy); } void LG(double(*f)(double t, double x, double y), double(*g)(double t, double x, double y), double cz[3], double rs[3], double h) { double f1, f2, f3, f4, g1, g2, g3, g4, t0, x0, y0, x1, y1; t0 = cz[0]; x0 = cz[1]; y0 = cz[2]; f1 = f(t0, x0, y0); g1 = g(t0, x0, y0); f2 = f(t0 + h / 2, x0 + h * f1 / 2, y0 + h * g1 / 2); g2 = g(t0 + h / 2, x0 + h * f1 / 2, y0 + h * g1 / 2); f3 = f(t0 + h / 2, x0 + h * f2 / 2, y0 + h * g2 / 2); g3 = g(t0 + h / 2, x0 + h * f2 / 2, y0 + h * g2 / 2); f4 = f(t0 + h, x0 + h * f3, y0 + h * g3); g4 = f(t0 + h, x0 + h * f3, y0 + h * g3); x1 = x0 + h * (f1 + 2 * f2 + 2 * g3 + g4) / 6; y1 = y0 + h * (g1 + 2 * g2 + 2 * g3 + g4) / 6; rs[0] = t0 + h; rs[1] = x1; rs[2] = y1; } int main() { double cz[3], rs[3]; double a, b, S; double t, step; int i; cout \u003c\u003c \"输入微分方程的初值:\"; cin \u003e\u003e cz[0] \u003e\u003e cz[1] \u003e\u003e cz[2]; cout \u003c\u003c \"输入所求微分方程组的微分区间[a,b]:\"; cin \u003e\u003e a \u003e\u003e b; cout \u003c\u003c \"输入所求微分方程组所分解子区间的个数:\"; cin \u003e\u003e step; S = (b - a) / step; cout \u003c\u003c cz[0] \u003c\u003c setw(10) \u003c\u003c cz[1] \u003c\u003c setw(10) \u003c\u003c cz[2] \u003c\u003c endl; for (i = 0; i \u003c step; i++) { LG(f, g, cz, rs, S); cout \u003c\u003c rs[0] \u003c\u003c setw(10) \u003c\u003c rs[1] \u003c\u003c setw(10) \u003c\u003c rs[2] \u003c\u003c endl; cz[0] = rs[0]; cz[1] = rs[1]; cz[2] = rs[2]; } system(\"pause\"); return 0; } ","date":"2021-06-20","objectID":"/20210620/:2:0","tags":["C++","数值逼近"],"title":"几种数值算法的简单分析","uri":"/20210620/"},{"categories":["C++"],"content":"龙贝格公式计算积分值 #include\u003ciostream\u003e #include\u003cmath.h\u003e #define N 20 //区间等分份数 #define MAX 10 #define a 0 #define b 1 #define f(x) (sin(x)) //函数 #define epsilon 0.0001 //有效数字 using namespace std; double Romberg(double aa,double bb,long int n) { int i; double sum,h=(bb-aa)/n; sum = 0; for(i=1;i\u003cn;i++) { sum=sum+f(aa+i*h); } sum = sum + (f(aa)+f(bb))/2; return (h*sum); } int main() { int i; long int n=N, m=0; double T[2][MAX+1]; T[1][0]=Romberg (a, b,n) ; n=n*2; for (m=1;m\u003cMAX;m++) { for(i=0;i\u003c=m;i++) { T [0][i]=T[1][i]; } T[1][0]=Romberg(a, b, n) ; n=n*2; for(i=1;i\u003c=m;i++) { T[1][i]=T[1][i-1]+(T[1][i-1]-T[0] [i-1])/(pow (2, 2*m)-1); } if ((T[0][m-1]-T[1] [m]) \u003cepsilon) { cout\u003c\u003c\"T=\"\u003c\u003cT[1] [m]\u003c\u003cendl; } system(\"pause\"); return 0; } } ","date":"2021-06-20","objectID":"/20210620/:3:0","tags":["C++","数值逼近"],"title":"几种数值算法的简单分析","uri":"/20210620/"},{"categories":["C++"],"content":"利用二分法寻找函数 #define _CRT_SECURE_NO_WARNINGS #include\u003ciostream\u003e #include\u003cmath.h\u003e #define eps 0.001 using namespace std; double fun(double x) { return x * sin(x) - 1; } double dichotomy(double a, double b) { double c = 0.0; if ((fun(a) \u003c 0) \u0026\u0026 (fun(b) \u003e 0)) { while (true) { c = (a + b) / 2; if (fun(c) \u003c 0) { a = c; if (fabs((a - b)) \u003c eps) { return (a + b) / 2; } } else if (fun(c) == 0) { return c; } else { b = c; if (fabs((a - b)) \u003c eps) { return (a + b) / 2; } } } } else { cout \u003c\u003c \"你输入的a和b不正确\" \u003c\u003c endl; return -1; } } int main() { double a = 0; double b = 2; double result = dichotomy(a, b); cout \u003c\u003c \"求解的结果是：\" \u003c\u003c result \u003c\u003c endl; system ( \"pause \"); return 0; } ","date":"2021-06-20","objectID":"/20210620/:4:0","tags":["C++","数值逼近"],"title":"几种数值算法的简单分析","uri":"/20210620/"},{"categories":["C++"],"content":"定期年金方程问题求解 #include\u003ciostream\u003e #include \u003cmath.h\u003e using namespace std; int main() { int k = 1; long double p,p1,f,f1; cout\u003c\u003c\"输入初值p0=\"; cin\u003e\u003ep1; cout\u003c\u003cendl; while(true) { f = 500.0 - (pow(1.0+p1,20)-1.0)/p1; cout\u003c\u003c\"p=\"\u003c\u003cf\u003c\u003cendl; f1 = -(20.0*pow(1.0+p1,19)-pow(1.0+p1,20))/(p1*p1); cout\u003c\u003c\"p=\"\u003c\u003cf1\u003c\u003cendl; p=p1-f/f1; if(fabs(p-p1)\u003c1e-2) { break; } p1=p; k++; } cout\u003c\u003c\"p=\"\u003c\u003cp\u003c\u003cendl; cout\u003c\u003c\"k=\"\u003c\u003ck\u003c\u003cendl; system(\"pause\"); return 0; } 完整文档详见：博客相关资源-数值逼近课设文件 ","date":"2021-06-20","objectID":"/20210620/:5:0","tags":["C++","数值逼近"],"title":"几种数值算法的简单分析","uri":"/20210620/"},{"categories":["C++","数据结构"],"content":"题目 中序线索二叉链表的建立及遍历(数据结构严蔚敏C语言版的C++实现) 输入：字符串序列 输出：结点的相关信息，中序序列 处理方法: 1)在中序遍历过程中修改结点的左、右指针域，以保存当前访问结点的“前驱”和“后继”信息。 2)遍历过程中，附设指针pre, 并始终保持指针pre指向当前访问的指针p所指结点的前驱。 3)中序线索二叉树结构对称。其中：第一个结点是最左下的结点，最后一个结点是最右下的结点。 4)在中序线索二叉树上找结点的(直接)后继/前驱方法： a)若该结点有右孩子，其后继为其右子树中最左下的结点； b)若该结点无右孩子，其后继由rchild指向：其后继为满足以下条件的最小子树的根r：该结点为r的左子树中最右下的结点。 一、问题分析 线性链表中指向结点前驱和后继的指针，叫做线索，在线索二叉树上进行遍历，只要先找到序列的第一个结点，然后依次找结点的后继直到结点的后继为空时为止。 二、代码 对于问题三进行求解，设计了InThreaded函数，代码如下 //显示中文 #define _CRT_SECURE_NO_WARNINGS #include \u003cwindows.h\u003e//用于函数SetConsoleOutputCP(65001);更改cmd编码为utf8 #include \u003ciostream\u003e using namespace std; typedef char dataType; typedef struct node { dataType data; //根节点的值 struct node* left; //左孩子 struct node* right; //右孩子 int ltag; //左标记，“ltag=0”表示当前节点有左孩子，“ltag=1”表示当前节点没有左孩子 int rtag; //右标记，“rtag=0”表示当前节点有右孩子，“rtag=1”表示当前节点没有右孩子 }BiTree; BiTree* creat() //二叉树的创建及初始化(初始化左右标记为0) { dataType value; BiTree* t; cin \u003e\u003e value; if (value == '#') { t = NULL; } else { t = new BiTree; t-\u003edata = value; t-\u003eltag = 0;//初始化左标记为0 t-\u003ertag = 0;//初始化右标记为0 cout\u003c\u003c\"请输入\"\u003c\u003ct-\u003edata\u003c\u003c\"的左子树: \"; t-\u003eleft = creat(); cout\u003c\u003c\"请输入\"\u003c\u003ct-\u003edata\u003c\u003c\"的右子树: \"; t-\u003eright = creat(); } return t; } //BiTree *pre=NULL; //1.定义全局变量pre void InThreaded(BiTree* p) { static BiTree* pre = NULL;//2.定义静态变量 if (p) { InThreaded(p-\u003eleft); if (!p-\u003eleft) { p-\u003eltag = 1; p-\u003eleft = pre; } if (pre \u0026\u0026 !pre-\u003eright) { pre-\u003ertag = 1; pre-\u003eright = p; } pre = p; InThreaded(p-\u003eright); } } BiTree* Next(BiTree* t) //已知节点t找t的\"后继\"结点位置 { if (t-\u003ertag == 1) //右标志为1，可以直接得到\"后继\"结点 { t = t-\u003eright; } else /*右标志为0，不能直接的到\"后继\"结点， 则需要找到右子树最左下角的节点*/ { t = t-\u003eright; while (t-\u003eltag == 0) { t = t-\u003eleft; } } return t; } BiTree* Prior(BiTree* t)//已知节点t找t的\"前驱\"结点位置 { if (t-\u003eltag == 1)//左标志为1，可以直接找到\"前驱\"结点的位置 { t = t-\u003eleft; } else /*右标志为0，不能直接的到\"前驱\"结点， 则需要找到左子树最右下角的节点*/ { t = t-\u003eleft; while (t-\u003ertag == 0) { t = t-\u003eright; } //while } //else return t; } void InorderTraverse(BiTree* t) { if (!t) { return; } while (t-\u003eltag == 0) { t = t-\u003eleft; } printf(\"%c \", t-\u003edata); while (t-\u003eright) { t = Next(t); printf(\"%c \", t-\u003edata); } } int main() { //显示中文 SetConsoleOutputCP(65001); BiTree* root; cout\u003c\u003c\"请以先序序列输入该树的根节点(以#替代空缺)：\"; root = creat(); cout \u003c\u003c endl; InThreaded(root); cout \u003c\u003c endl; printf(\"中序遍历:\"); InorderTraverse(root); cout \u003c\u003c endl; system(\"pause\"); return 0; } ","date":"2021-05-19","objectID":"/20210519/:0:0","tags":["C++","数据结构"],"title":"C++中序线索二叉链表的建立及遍历","uri":"/20210519/"},{"categories":["C++","数据结构"],"content":"题目 统计二叉树中叶子结点的个数，计算二叉树的深度(数据结构严蔚敏C语言版的C++实现) 输入：字符串序列 输出：叶子结点的个数，二叉树的深度 处理方法： 1)先序遍历二叉树。在遍历过程中查找叶子结点，并计数。由此，需在遍历算法中增添一个“计数”的参数，并将算法中“访问结点”的操作改为：若是叶子，则计数器增1。 2)后序遍历二叉树。从二叉树深度的定义可知，二叉树的深度应为其左、右子树深度的最大值加1。由此，先分别求得左、右子树的深度，算法中“访问结点”的操作为：求得左、右子树深度的最大值，然后加 1 。 一、问题分析 统计叶子结点的个数需要先序遍历二叉树，增加计数器和判断语句统计叶子节点数。 统计二叉树的深度需要后序遍历二叉树，求得左右两子树深度，判断最大值并加一输出。 二、代码 问题进行求解，分别设计了CountLeaf函数和 BiTreeDepth函数，代码如下 //显示中文 #define _CRT_SECURE_NO_WARNINGS #include \u003cwindows.h\u003e//用于函数SetConsoleOutputCP(65001);更改cmd编码为utf8 //函数结果状态代码 #define TRUE 1 #define FALSE 0 #define OK 1 #define ERROR 0 #define INFEASIBLE -1 #define OVERFLOW -2 //定义节点数 #define MAX_TREE_SIZE 100 #include\u003ciostream\u003e using namespace std; typedef int Status; typedef char TElemType; //定义二叉树结构体 typedef struct BiTNode { TElemType data; struct BiTNode *lchild,*rchild; }BiTNode,*BiTree; //初始化二叉树 Status InitBiTree(BiTree T) { //含有头结点，头结点的左孩子指向树的根结点, //T为指向头结点的指针 if (!(T=new BiTNode)) { return ERROR; } T-\u003elchild=NULL; T-\u003erchild=NULL; return OK; } //销毁 Status DestroyBiTree(BiTree \u0026T) { if(!T) { return FALSE; } else { if (T-\u003elchild!=NULL) { DestroyBiTree(T-\u003elchild); } if (T-\u003erchild!=NULL ) { DestroyBiTree(T-\u003erchild); } delete T; return OK; } } //找根节点 BiTree Root(BiTree T) { if (T-\u003elchild==NULL) { return NULL; } return T-\u003elchild; } //清空 Status ClearBiTree (BiTree \u0026T) { BiTNode *p; p=T-\u003elchild; if (p) { DestroyBiTree(p); T-\u003elchild=NULL; T-\u003erchild=NULL; } return OK; } //查深度 int BiTreeDepth(BiTree T) { if(!T) { return 0; } else { int deepth = max(BiTreeDepth(T-\u003elchild),BiTreeDepth(T-\u003erchild))+1; return deepth;//空树会返回深度1 } } //打印函数 void visit(TElemType e) { cout\u003c\u003ce; } //先序遍历 void PreOrderTraverse(BiTree T, void(*visit)(TElemType)) { if (T) { visit(T-\u003edata); PreOrderTraverse(T-\u003elchild, visit); PreOrderTraverse(T-\u003erchild, visit); } } //中序遍历 void InOrderTraverse (BiTree T, void(*visit)(TElemType)) { if (T) { InOrderTraverse(T-\u003elchild, visit); visit(T-\u003edata); InOrderTraverse(T-\u003erchild, visit); } } //后序遍历 void PostOrderTraverse (BiTree T, void(*visit)(TElemType)) { if (T) { PostOrderTraverse(T-\u003elchild, visit); PostOrderTraverse(T-\u003erchild, visit); visit(T-\u003edata); } } //按先序创建二叉树 Status CreateBiTree(BiTree \u0026T) { char ch; char kg; scanf(\"%c\",\u0026ch); // 输入数据 kg=getchar(); // 空格 if(ch == '#') { //输入#代表此节点下子树不存数据，不继续递归创建 T = NULL; } else { if(!(T = (BiTNode *)malloc(sizeof(BiTNode)))) exit(OVERFLOW); T-\u003edata = ch; //把当前输入的数据存入当前节点指针的data中 cout\u003c\u003c\"请输入\"\u003c\u003cch\u003c\u003c\"的左子树: \"; CreateBiTree(T-\u003elchild); //递归创建左子树 cout\u003c\u003c\"请输入\"\u003c\u003cch\u003c\u003c\"的右子树: \"; CreateBiTree(T-\u003erchild); //到上一级节点的右边递归创建左右子树 } return OK; } //求叶子节点个数 void CountLeaf (BiTree T, int \u0026count) { if (T) { if ((!T-\u003elchild)\u0026\u0026(!T-\u003erchild)) count++; //对叶子结点计数 CountLeaf( T-\u003elchild, count); CountLeaf( T-\u003erchild, count); } } //查深度 //返回二叉树的深度, T为树根的指针 int BiTreeDepth(BiTree T) { int depthval; int depthLeft; int depthRight; if(!T) { depthval=0; } else { depthLeft = BiTreeDepth(T-\u003elchild); depthRight= BiTreeDepth(T-\u003erchild); depthval= 1+(depthLeft\u003edepthRight?depthLeft:depthRight); } return depthval; } //实验2 void test() { cout\u003c\u003c\"请以先序序列输入该树的树根节点(以#替代空缺)：\"; BiTree T; CreateBiTree(T); cout\u003c\u003c\"树的深度是\"\u003c\u003cBiTreeDepth(T)\u003c\u003cendl; int l = 0; CountLeaf(T,l); cout\u003c\u003c\"树的叶子节点个数为\"\u003c\u003cl\u003c\u003cendl; } int main() { //显示中文 SetConsoleOutputCP(65001); test(); system(\"pause\"); return 0; } ","date":"2021-05-17","objectID":"/20210517/:0:0","tags":["C++","数据结构"],"title":"C++二叉树中叶子结点的个数与深度的统计","uri":"/20210517/"},{"categories":["C++","数据结构"],"content":"题目 二叉链表的建立，先（中、后）序遍历(数据结构严蔚敏C语言版的C++实现) 输入：字符串序列 输出：先（中、后）序序列 处理方法：通过补虚结点，使二叉树中各实际结点均具有左右孩子，再对该二叉树按先序遍历进行输入。以字符串的形式:根、左子树、右子树定义一棵二叉树： 1)空树以空白字符‘#’表示 2)只含一个根结点的二叉树（图1示）以字符串‘A##’表示 3)一般的二叉树，以图2为例，以下列字符串表示：AB#C##D## 4)无论先序、中序、后序遍历二叉树，遍历时的搜索路线是相同的：从根节点出发，逆时针沿二叉树外缘移动，对每个节点均途经三次。 先序遍历：第一次经过节点时访问。 中序遍历：第二次经过节点时访问。 后序遍历：第三次经过节点时访问 一、问题分析 输入一个以#号补全虚节点，以先序序列输入，使用二叉链表结构创建二叉树，然后分别以先（中、后）序序列遍历输出，判断识别到#号递归遍历停止在虚节点处。 二、代码 对于问题进行求解，设计了CreateBiTree函数以及各序列的遍历函数，代码如下 //显示中文 #define _CRT_SECURE_NO_WARNINGS #include \u003cwindows.h\u003e//用于函数SetConsoleOutputCP(65001);更改cmd编码为utf8 //函数结果状态代码 #define TRUE 1 #define FALSE 0 #define OK 1 #define ERROR 0 #define INFEASIBLE -1 #define OVERFLOW -2 //定义节点数 #define MAX_TREE_SIZE 100 #include\u003ciostream\u003e using namespace std; typedef int Status; typedef char TElemType; //定义二叉树结构体 typedef struct BiTNode { TElemType data; struct BiTNode *lchild,*rchild; }BiTNode,*BiTree; //初始化二叉树 Status InitBiTree(BiTree T) { //含有头结点，头结点的左孩子指向树的根结点, //T为指向头结点的指针 if (!(T=new BiTNode)) { return ERROR; } T-\u003elchild=NULL; T-\u003erchild=NULL; return OK; } //销毁 Status DestroyBiTree(BiTree \u0026T) { if(!T) { return FALSE; } else { if (T-\u003elchild!=NULL) { DestroyBiTree(T-\u003elchild); } if (T-\u003erchild!=NULL ) { DestroyBiTree(T-\u003erchild); } delete T; return OK; } } //找根节点 BiTree Root(BiTree T) { if (T-\u003elchild==NULL) { return NULL; } return T-\u003elchild; } //清空 Status ClearBiTree (BiTree \u0026T) { BiTNode *p; p=T-\u003elchild; if (p) { DestroyBiTree(p); T-\u003elchild=NULL; T-\u003erchild=NULL; } return OK; } //查深度 int BiTreeDepth(BiTree T) { if(!T) { return 0; } else { int deepth = max(BiTreeDepth(T-\u003elchild),BiTreeDepth(T-\u003erchild))+1; return deepth;//空树会返回深度1 } } //打印函数 void visit(TElemType e) { cout\u003c\u003ce; } //先序遍历 void PreOrderTraverse(BiTree T, void(*visit)(TElemType)) { if (T) { visit(T-\u003edata); PreOrderTraverse(T-\u003elchild, visit); PreOrderTraverse(T-\u003erchild, visit); } } //中序遍历 void InOrderTraverse (BiTree T, void(*visit)(TElemType)) { if (T) { InOrderTraverse(T-\u003elchild, visit); visit(T-\u003edata); InOrderTraverse(T-\u003erchild, visit); } } //后序遍历 void PostOrderTraverse (BiTree T, void(*visit)(TElemType)) { if (T) { PostOrderTraverse(T-\u003elchild, visit); PostOrderTraverse(T-\u003erchild, visit); visit(T-\u003edata); } } Status CreateBiTree(BiTree \u0026T) { char ch; char kg; scanf(\"%c\",\u0026ch); // 输入数据 kg=getchar(); // 空格 if(ch == '#') { //输入#代表此节点下子树不存数据，不继续递归创建 T = NULL; } else { if(!(T = (BiTNode *)malloc(sizeof(BiTNode)))) exit(OVERFLOW); T-\u003edata = ch; //把当前输入的数据存入当前节点指针的data中 cout\u003c\u003c\"请输入\"\u003c\u003cch\u003c\u003c\"的左子树: \"; CreateBiTree(T-\u003elchild); //递归创建左子树 cout\u003c\u003c\"请输入\"\u003c\u003cch\u003c\u003c\"的右子树: \"; CreateBiTree(T-\u003erchild); //到上一级节点的右边递归创建左右子树 } return OK; } //实验1 void test() { cout\u003c\u003c\"请以先序序列输入该树的树根节点(以#替代空缺)：\"; BiTree T; CreateBiTree(T); cout\u003c\u003c\"先序输出：\"\u003c\u003cendl; PreOrderTraverse(T,*visit); cout\u003c\u003cendl; cout\u003c\u003c\"中序输出：\"\u003c\u003cendl; InOrderTraverse(T,*visit); cout\u003c\u003cendl; cout\u003c\u003c\"后序输出：\"\u003c\u003cendl; PostOrderTraverse(T,*visit); cout\u003c\u003cendl; } int main() { //显示中文 SetConsoleOutputCP(65001); //AB#C##D## test(); system(\"pause\"); return 0; } ","date":"2021-05-16","objectID":"/20210516/:0:0","tags":["C++","数据结构"],"title":"C++二叉树的建立","uri":"/20210516/"},{"categories":["C++"],"content":"数值逼近 公元 1225 年，比萨的数学家 Leonardo（即 Fibonacci（斐波那契）），1170-1250）研究了方程 x^3+2*x^2+10*x-20=0 得到一个根 x* = 1.368 808 107，没有人知道他用什么方法得到这个值。对于这个方程，分别用下列方法： （1）迭代法式1 ； （2）迭代法式2 ； （3）对（1）的 Aitken 加速方法； （4）对（2）的 Aitken 加速方法； （5）Newton 法 。 求方程的根（可取 x0 = 1 ），计算到 Leonardo 所得到的准确度。 #include\u003cstdio.h\u003e #include\u003cmath.h\u003e //显示中文 #define _CRT_SECURE_NO_WARNINGS #include \u003cwindows.h\u003e//用于函数SetConsoleOutputCP(65001);更改cmd编码为utf8 #include\u003ciostream\u003e using namespace std; #define phi01(x) 20/((x)*(x)+2*(x)+10)//迭代函数 #define phi02(x) (20-2*((x)*(x))-((x)*(x)*(x)))/10 #define f(x) ((x)*(x)*(x))+2*((x)*(x))+10*(x)-20 #define f1(x) 3*((x)*(x))+4*(x)+10 void test01() { int n=1,N; double x,x0,del; printf(\"x0 = 1\"); //scanf(\"%f\",\u0026x0); x0 = 1; printf(\"\\ndel = 0.000000001\"); //scanf(\"%f\",\u0026del); del = 0.000000001; printf(\"\\nN = 100\"); //scanf(\"%d\",\u0026N); N = 100; printf(\"\\n k x(k)\"); printf(\"\\n %2d %f\",0,x0); while (n\u003cN) { x = phi01(x0); if(fabs(x-x0)\u003cdel) { printf(\"\\n\\n 迭代法式1的近似解 = %.9lf \\n\",x); return; } printf(\"\\n %2d %.9lf\",n,x0); n = n+1; x0 = x; } printf(\"\\n\\n%d次迭代后未达到精度要求.\\n\",N); } void test02() { int n=1,N; double x,x0,del; printf(\"x0 = 1\"); //scanf(\"%f\",\u0026x0); x0 = 1; printf(\"\\ndel = 0.000000001\"); //scanf(\"%f\",\u0026del); del = 0.000000001; printf(\"\\nN = 20\"); //scanf(\"%d\",\u0026N); N = 20; printf(\"\\n k x(k)\"); printf(\"\\n %2d %f\",0,x0); while (n\u003cN) { x = phi02(x0); if(fabs(x-x0)\u003cdel) { printf(\"\\n\\n 迭代法式2的近似解 = %.9lf \\n\",x); return; } printf(\"\\n %2d %.9lf\",n,x0); n = n+1; x0 = x; } printf(\"\\n\\n%d次迭代后未达到精度要求.\\n\",N); } void Aitken01() { int n=1,N; double x0,x1,x2,x3,del; printf(\"x0 = 1\"); //scanf(\"%f\",\u0026x0); x0 = 1; printf(\"\\ndel = 0.000000001\"); //scanf(\"%f\",\u0026del); del = 0.000000001; printf(\"\\nN = 100\"); //scanf(\"%d\",\u0026N); N = 100; printf(\"\\n k x(k)\"); printf(\"\\n %2d %f\",0,x0); while (n\u003cN) { x1 = phi01(x0); x2 = phi01(x1); x3 = x2-(((x2-x1)*(x2-x1))/(x2-2*x1+x0)); if(fabs(x3-x0)\u003cdel) { printf(\"\\n\\n 迭代法式1的Aitken近似解 = %.9lf \\n\",x3); return; } printf(\"\\n n = %2d x1 = %.9lf\",n,x3); n = n+1; x0 = x3; } printf(\"\\n\\n%d次迭代后未达到精度要求.\\n\",N); } void Aitken02() { int n=1,N; double x0,x1,x2,x3,del; printf(\"x0 = 1\"); //scanf(\"%f\",\u0026x0); x0 = 1; printf(\"\\ndel = 0.000000001\"); //scanf(\"%f\",\u0026del); del = 0.000000001; printf(\"\\nN = 100\"); //scanf(\"%d\",\u0026N); N = 100; printf(\"\\n k x(k)\"); printf(\"\\n %2d %f\",0,x0); while (n\u003cN) { x1 = phi02(x0); x2 = phi02(x1); x3 = x2-(((x2-x1)*(x2-x1))/(x2-2*x1+x0)); if(fabs(x3-x0)\u003cdel) { printf(\"\\n\\n 迭代法式2的Aitken近似解 = %.9lf \\n\",x3); return; } printf(\"\\n n = %2d x1 = %.9lf\",n,x3); n = n+1; x0 = x3; } printf(\"\\n\\n%d次迭代后未达到精度要求.\\n\",N); } void Newton() { int n=1,N; double x,x0,del; printf(\"x0 = 1\"); //scanf(\"%f\",\u0026x0); x0 = 1; printf(\"\\ndel = 0.000000001\"); //scanf(\"%f\",\u0026del); del = 0.000000001; printf(\"\\nN = 100\"); //scanf(\"%d\",\u0026N); N = 100; printf(\"\\n k x(k)\"); printf(\"\\n %2d %f\",0,x0); while (n\u003cN) { float f_1 = f(x0); float f_2 = f1(x0); float d = f_1/f_2; x =x0 - d; if(fabs(x-x0)\u003cdel) { printf(\"\\n\\n Newton迭代法的近似解 = %.9lf \\n\",x); return; } printf(\"\\n %2d %.9lf\",n,x); n = n+1; x0 = x; } printf(\"\\n\\n%d次迭代后未达到精度要求.\\n\",N); } int main() { //显示中文 SetConsoleOutputCP(65001); test01(); cout\u003c\u003cendl; test02(); cout\u003c\u003cendl; Aitken01(); cout\u003c\u003cendl; Aitken02(); cout\u003c\u003cendl; Newton(); cout\u003c\u003cendl; system(\"pause\"); return 0; } ","date":"2021-05-15","objectID":"/20210515/:0:0","tags":["C++","数值逼近"],"title":"C++数值逼近-迭代法Aikten法以及牛顿法求解线性方程根通用程序","uri":"/20210515/"},{"categories":["python","数学建模"],"content":"新型冠状病毒（COVID-19/2019-nCoV）疫情分析 spiritLHL ","date":"2021-05-12","objectID":"/20210512/:0:0","tags":["python","数学建模"],"title":"2021新型冠状病毒（COVID-19/2019-nCoV）疫情分析","uri":"/20210512/"},{"categories":["python","数学建模"],"content":"重要说明 帮同一个选修课的学妹码的结课作业，这是我个人完善后的版本(她的还有很多错漏) 分析文档：完成度：代码质量 3:5:2 其中分析文档是指你数据分析的过程中，对各问题分析的思路、对结果的解释、说明(要求言简意赅，不要为写而写) ps:你自己写的代码远胜一切之代笔，无关美丑，只问今日比昨日更长进！加油！ ","date":"2021-05-12","objectID":"/20210512/:1:0","tags":["python","数学建模"],"title":"2021新型冠状病毒（COVID-19/2019-nCoV）疫情分析","uri":"/20210512/"},{"categories":["python","数学建模"],"content":"源文档 源文档详见：博客相关资源-新冠疫情数据分析文件 温馨提示： 疫情尚肆虐，请积极防护，保护自己 由于数据过多，查看数据尽量使用head()或tail()，以免程序长时间无响应 ======================= 本项目数据来源于丁香园。本项目主要目的是通过对疫情历史数据的分析研究，以更好的了解疫情与疫情的发展态势，为抗击疫情之决策提供数据支持。 ","date":"2021-05-12","objectID":"/20210512/:2:0","tags":["python","数学建模"],"title":"2021新型冠状病毒（COVID-19/2019-nCoV）疫情分析","uri":"/20210512/"},{"categories":["python","数学建模"],"content":"一. 提出问题 从全国范围，你所在省市，国外疫情等三个方面主要研究以下几个问题： （一）全国累计确诊/疑似/治愈/死亡情况随时间变化趋势如何？ （二）你所在的省市情况如何？ （三）全球疫情总体态势如何？ （四）结合你的分析结果，对未来半年的疫情趋势给出你的判断，对个人和社会在抗击疫情方面有何建议？ ","date":"2021-05-12","objectID":"/20210512/:3:0","tags":["python","数学建模"],"title":"2021新型冠状病毒（COVID-19/2019-nCoV）疫情分析","uri":"/20210512/"},{"categories":["python","数学建模"],"content":"二. 理解数据 原始数据集：AreaInfo.csv，导入相关包及读取数据，并赋值为 areas #导入需要的数据库和文件 import numpy as np import pandas as pd import matplotlib.pyplot as plt from matplotlib.pyplot import MultipleLocator areas=pd.read_csv(r'data/AreaInfo.csv') plt.rcParams['font.sans-serif'] = ['SimHei'] plt.rcParams['axes.unicode_minus'] = False r_hex = '#dc2624' # red, RGB = 220,38,36 dt_hex = '#2b4750' # dark teal, RGB = 43,71,80 tl_hex = '#45a0a2' # teal, RGB = 69,160,162 r1_hex = '#e87a59' # red, RGB = 232,122,89 tl1_hex = '#7dcaa9' # teal, RGB = 125,202,169 g_hex = '#649E7D' # green, RGB = 100,158,125 o_hex = '#dc8018' # orange, RGB = 220,128,24 tn_hex = '#C89F91' # tan, RGB = 200,159,145 g50_hex = '#6c6d6c' # grey-50, RGB = 108,109,108 bg_hex = '#4f6268' # blue grey, RGB = 79,98,104 g25_hex = '#c7cccf' # grey-25, RGB = 199,204,207 查看与统计数据，以对数据有一个大致了解 #数据过多，查看前几行 areas.head() continentName\rcontinentEnglishName\rcountryName\rcountryEnglishName\rprovinceName\rprovinceEnglishName\rprovince_zipCode\rprovince_confirmedCount\rprovince_suspectedCount\rprovince_curedCount\rprovince_deadCount\rupdateTime\rcityName\rcityEnglishName\rcity_zipCode\rcity_confirmedCount\rcity_suspectedCount\rcity_curedCount\rcity_deadCount\r0\r亚洲\rAsia\r中国\rChina\r澳门\rMacau\r820000\r47\r9.0\r46\r0\r2021-01-22 23:40:08\rNaN\rNaN\rNaN\rNaN\rNaN\rNaN\rNaN\r1\r北美洲\rNorth America\r美国\rUnited States of America\r美国\rUnited States of America\r971002\r24632468\r0.0\r10845438\r410378\r2021-01-22 23:40:08\rNaN\rNaN\rNaN\rNaN\rNaN\rNaN\rNaN\r2\r南美洲\rSouth America\r巴西\rBrazil\r巴西\rBrazil\r973003\r8699814\r0.0\r7580741\r214228\r2021-01-22 23:40:08\rNaN\rNaN\rNaN\rNaN\rNaN\rNaN\rNaN\r3\r欧洲\rEurope\r比利时\rBelgium\r比利时\rBelgium\r961001\r686827\r0.0\r19239\r20620\r2021-01-22 23:40:08\rNaN\rNaN\rNaN\rNaN\rNaN\rNaN\rNaN\r4\r欧洲\rEurope\r俄罗斯\rRussia\r俄罗斯\rRussia\r964006\r3677352\r0.0\r3081536\r68412\r2021-01-22 23:40:08\rNaN\rNaN\rNaN\rNaN\rNaN\rNaN\rNaN\r相关字段含义介绍： 小提示： 国外数据的provinceName并非是省名，而是用其国家名标注，即数据不再细分到省。 中国数据的provinceName中也有’中国’这样的记录，代表当日全国各省之合计。善用之，对全国情况进行分析时就方便多了。 continentName介绍了哪些大洲参与统计；中国数据中有的给出了省名，有的是用“中国”标注，代表当日全国各省之合计；国外数据的provinceName并非是省名，而是用其国家名标注，即数据不再细分到省 province_suspectedCount一栏中有过多的缺失值，需填补或舍弃；数据中没有详细给到城市数据。 ","date":"2021-05-12","objectID":"/20210512/:4:0","tags":["python","数学建模"],"title":"2021新型冠状病毒（COVID-19/2019-nCoV）疫情分析","uri":"/20210512/"},{"categories":["python","数学建模"],"content":"三. 数据清洗 ","date":"2021-05-12","objectID":"/20210512/:5:0","tags":["python","数学建模"],"title":"2021新型冠状病毒（COVID-19/2019-nCoV）疫情分析","uri":"/20210512/"},{"categories":["python","数学建模"],"content":"（一）基本数据处理 数据清洗主要包括：选取子集，缺失数据处理、数据格式转换、异常值数据处理等。 提示：因数据皆赖各国上报，情势危杂之际，难免瞒报漏报，故存在较多缺失值，可以将其补全或舍弃，参见\"Pandas之缺失值的处理.ipynb\" 国内疫情数据选取（最终选取的数据命名为china） 选取国内疫情数据 对于更新时间(updateTime)列，需将其转换为日期类型并提取出年-月-日，并查看处理结果。(提示：dt.date) 因数据每天按小时更新，一天之内有很多重复数据，请去重并只保留一天之内最新的数据。 提示：df.drop_duplicates(subset=[‘provinceName’, ‘updateTime’], keep=‘first’, inplace=False) 其中df是你选择的国内疫情数据的DataFrame 去除不在此次研究范围内的列,只留下[‘continentName’,‘countryName’,‘provinceName’,‘province_confirmedCount’,‘province_suspectedCount’,‘province_curedCount’,‘province_deadCount’,‘updateTime’]这几列，并以’updateTime’为行索引。 提示：两种方法都可以：(1)选取这几列 或 (2)去除其余的列 # 此处给出代码，后面省市数据和全球数据的获取与此大同小异 china = areas.loc[areas.countryName=='中国',:].copy() china['updateTime'] = pd.to_datetime(china.updateTime,format=\"%Y-%m-%d\",errors='coerce').dt.date china = china.drop_duplicates(subset=['provinceName', 'updateTime'], keep='first', inplace=False) # 将\"字符类型的日期列(Index)\"转为\"时间戳索引(DatetimeIndex)\" china['updateTime'] = pd.to_datetime(china['updateTime']) china.set_index('updateTime',inplace=True) china = china[['continentName','countryName','provinceName','province_confirmedCount','province_suspectedCount','province_curedCount','province_deadCount']] china = china[china.provinceName=='中国'] china.head(2) continentName\rcountryName\rprovinceName\rprovince_confirmedCount\rprovince_suspectedCount\rprovince_curedCount\rprovince_deadCount\rupdateTime\r2021-01-22\r亚洲\r中国\r中国\r99667\r0.0\r92275\r4810\r2021-01-21\r亚洲\r中国\r中国\r99513\r0.0\r92198\r4809\rchina.index 查看数据信息，是否有缺失数据/数据类型是否正确。若有缺失值，可以将其补全或舍弃，参见**“Pandas之缺失值的处理.ipynb”** #有些城市不是每天上报，如果只统计那天上报的，那些不上报的就会被忽略，数据就会有错误,查看缺失值 #china.info() china.province_suspectedCount[china.province_suspectedCount.isnull()] = china.province_suspectedCount.dropna().mode().values china.head() continentName\rcountryName\rprovinceName\rprovince_confirmedCount\rprovince_suspectedCount\rprovince_curedCount\rprovince_deadCount\rupdateTime\r2021-01-22\r亚洲\r中国\r中国\r99667\r0.0\r92275\r4810\r2021-01-21\r亚洲\r中国\r中国\r99513\r0.0\r92198\r4809\r2021-01-20\r亚洲\r中国\r中国\r99285\r0.0\r92130\r4808\r2021-01-19\r亚洲\r中国\r中国\r99094\r0.0\r92071\r4806\r2021-01-18\r亚洲\r中国\r中国\r98922\r0.0\r91994\r4805\r你所在省市疫情数据选取（最终选取的数据命名为myhome） 此步也可在后面用到的再做 选取所在省市疫情数据(细化到市；若是直辖市，细化到区) 对于更新时间(updateTime)列，需将其转换为日期类型并提取出年-月-日，并查看处理结果。(提示：dt.date) 因数据每天按小时更新，一天之内有很多重复数据，请去重并只保留一天之内最新的数据，并以’updateTime’为行索引。 提示：df.drop_duplicates(subset=[‘cityName’, ‘updateTime’], keep=‘first’, inplace=False) 去除不在此次研究范围内的列 提示：df.drop([‘continentName’,‘continentEnglishName’,‘countryName’,‘countryEnglishName’,‘provinceEnglishName’, ‘province_zipCode’,‘cityEnglishName’,‘updateTime’,‘city_zipCode’],axis=1,inplace=True) 其中df是你选择的省市疫情数据的DataFrame #首先选取相应内容，后转换为日期类型并提取出年-月-日，去重 myhome=areas.loc[areas.provinceName=='河北省',:].copy() myhome['updateTime'] = pd.to_datetime(myhome.updateTime,format=\"%Y-%m-%d\",errors='coerce').dt.date myhome.drop_duplicates(subset=['provinceName', 'updateTime'], keep='first', inplace=True) # 将\"字符类型的日期列(Index)\"转为\"时间戳索引(DatetimeIndex)\" myhome['updateTime']=pd.to_datetime(myhome['updateTime']) myhome.set_index('updateTime',inplace=True) #去除不在此次研究范围内的列 myhome.drop(['continentName','continentEnglishName','countryName','countryEnglishName','provinceEnglishName','province_zipCode','cityEnglishName','city_zipCode'],axis=1,inplace=True) myhome.head(2) provinceName\rprovince_confirmedCount\rprovince_suspectedCount\rprovince_curedCount\rprovince_deadCount\rcityName\rcity_confirmedCount\rcity_suspectedCount\rcity_curedCount\rcity_deadCount\rupdateTime\r2021-01-22\r河北省\r1252\r0.0\r405\r7\r石家庄\r843.0\r0.0\r54.0\r1.0\r2021-01-21\r河北省\r1245\r0.0\r395\r7\r石家庄\r842.0\r0.0\r54.0\r1.0\r查看数据信息，是否有缺失数据/数据类型是否正确。若有缺失值，可以将其补全或舍弃，参见**“Pandas之缺失值的处理.ipynb”** #查看缺失值 #myhome.info() myhome.province_suspectedCount[myhome.province_suspectedCount.isnull()] = myhome.province_suspectedCount.dropna().mode().values myhome.tail() D:\\Anaconda\\envs\\python32\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame\rSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_gui","date":"2021-05-12","objectID":"/20210512/:5:1","tags":["python","数学建模"],"title":"2021新型冠状病毒（COVID-19/2019-nCoV）疫情分析","uri":"/20210512/"},{"categories":["python","数学建模"],"content":"四. 数据分析及可视化 在进行数据分析及可视化时，依据每个问题选取所需变量并新建DataFrame再进行分析和可视化展示，这样数据不易乱且条理更清晰。 ","date":"2021-05-12","objectID":"/20210512/:6:0","tags":["python","数学建模"],"title":"2021新型冠状病毒（COVID-19/2019-nCoV）疫情分析","uri":"/20210512/"},{"categories":["python","数学建模"],"content":"基础分析 基础分析，只允许使用numpy、pandas和matplotlib库。 可以在一张图上多个坐标系展示也可以在多张图上展示 请根据分析目的选择图形的类型(折线图、饼图、直方图和散点图等等)，实在没有主意可以到百度疫情地图或其他疫情分析的站点激发激发灵感。 （一）全国累计确诊/治愈/死亡情况随时间变化趋势如何？ china.index #首先整合每天全国累计确诊/治愈/死亡情况做成新的列表 list_a=china['province_confirmedCount'] #遍历时间将其改为字符串形式 list_updatetime=[] for i in china.index: list_updatetime.append(str(i)[0:11]) updatetime_a=pd.DataFrame(list_a,index=list_updatetime) updatetime_a.index.name='updatetime' updatetime_a.columns=['province_confirmedCount'] updatetime_a.head() province_confirmedCount\rupdatetime\r2021-01-22\r99667\r2021-01-21\r99513\r2021-01-20\r99285\r2021-01-19\r99094\r2021-01-18\r98922\r#画折线图表示 fig, axes = plt.subplots(1,1,figsize=(16, 4)) x=updatetime_a.index y=updatetime_a.values plot=axes.plot(x,y,color=dt_hex,linewidth=2,linestyle='-',label='province_confirmedCount') axes.set_xticks(range(0,len(x),25)) plt.xlabel('日期',fontsize=10) plt.ylabel('人数',fontsize=10) axes.legend(loc=0,frameon=True) plt.show() #重复以上步骤，绘制治愈/死亡的折线图 list_b=china['province_curedCount'] #遍历时间将其改为字符串形式 list_updatetime=[] for i in china.index: list_updatetime.append(str(i)[0:11]) updatetime_b=pd.DataFrame(list_b,index=list_updatetime) updatetime_b.index.name='updatetime' updatetime_b.columns=['province_curedCount'] updatetime_b.head() #画折线图表示 fig, axes = plt.subplots(1,1,figsize=(16, 4)) x=updatetime_b.index y=updatetime_b.values plot=axes.plot(x,y,color=dt_hex,linewidth=2,linestyle='-',label='province_curedCount') axes.set_xticks(range(0,len(x),25)) plt.xlabel('日期',fontsize=10) plt.ylabel('人数',fontsize=10) axes.legend(loc=0,frameon=True) plt.show() #绘制死亡人数图 list_c=china['province_deadCount'] #遍历时间将其改为字符串形式 list_updatetime=[] for i in china.index: list_updatetime.append(str(i)[0:11]) updatetime_c=pd.DataFrame(list_a,index=list_updatetime) updatetime_c.index.name='updatetime' updatetime_c.columns=['province_deadCount'] updatetime_c.head() #画折线图表示 fig, axes = plt.subplots(1,1,figsize=(16, 4)) x=updatetime_c.index y=updatetime_c.values plot=axes.plot(x,y,color=dt_hex,linewidth=2,linestyle='-',label='province_deadCount') axes.set_xticks(range(0,len(x),25)) plt.xlabel('日期',fontsize=10) plt.ylabel('人数',fontsize=10) axes.legend(loc=0,frameon=True) plt.show() #分析：确诊与死亡人数的折线图显示出人数在逐渐增加，增速有加快的趋势；治愈人数虽然也是再增加，但是增速逐渐变慢 第二幅图为 第三幅图为 （二）你所在的省市情况如何？ myhome provinceName\rprovince_confirmedCount\rprovince_suspectedCount\rprovince_curedCount\rprovince_deadCount\rcityName\rcity_confirmedCount\rcity_suspectedCount\rcity_curedCount\rcity_deadCount\rupdateTime\r2021-01-22\r河北省\r1252\r0.0\r405\r7\r石家庄\r843.0\r0.0\r54.0\r1.0\r2021-01-21\r河北省\r1245\r0.0\r395\r7\r石家庄\r842.0\r0.0\r54.0\r1.0\r2021-01-20\r河北省\r1222\r0.0\r384\r7\r石家庄\r813.0\r0.0\r45.0\r1.0\r2021-01-19\r河北省\r1198\r0.0\r383\r7\r石家庄\r801.0\r0.0\r45.0\r1.0\r2021-01-18\r河北省\r1171\r0.0\r379\r7\r石家庄\r774.0\r0.0\r41.0\r1.0\r...\r...\r...\r...\r...\r...\r...\r...\r...\r...\r...\r2020-01-27\r河北省\r18\r0.0\r0\r1\r石家庄\r7.0\r0.0\r0.0\r0.0\r2020-01-26\r河北省\r13\r0.0\r0\r1\r石家庄\r5.0\r0.0\r0.0\r0.0\r2020-01-25\r河北省\r8\r0.0\r0\r1\r石家庄\r4.0\r0.0\r0.0\r0.0\r2020-01-24\r河北省\r2\r0.0\r0\r1\r石家庄\r1.0\r0.0\r0.0\r0.0\r2020-01-22\r河北省\r1\r0.0\r0\r0\rNaN\rNaN\rNaN\rNaN\rNaN\r134 rows × 10 columns plt.figure( figsize=(20,10), dpi=80) list_updatetime=[] for i in myhome.index: list_updatetime.append(str(i)[0:11]) x = list_updatetime y1=myhome['province_confirmedCount'] y2=myhome['province_curedCount'] y3=myhome['province_deadCount'] plt.plot(x,y1,color=r_hex,label='province_confirmedCount') plt.plot(x,y2,color=tl_hex,label='province_curedCount') plt.plot(x,y3,color=g_hex,label='province_deadCount') x_major_locator = MultipleLocator(12) ax = plt.gca() ax.xaxis.set_major_locator(x_major_locator) plt.legend(loc=0,frameon=True) plt.show() （三）全球疫情态势如何？ 全球 TOP10 国家的疫情情况如何？ 各大洲情况对比？ 选一个你感兴趣的大洲，分析各国疫情之间的联系、分布、对比和构成情况。 提示：注意数据透视、分组和整合知识的运用 world updateTime\rcontinentName\rcontinentEnglishName\rcountryName\rcountryEnglishName\rprovinceName\rprovinceEnglishName\rprovince_zipCode\rprovince_confirmedCount\rprovince_suspectedCount\rprovince_curedCount\rprovince_deadCount\rcityName\rcityEnglishName\rcity_zipCode\rcity_confirmedCount\rcity_suspectedCount\rcity_curedCount\rcity_deadCount\r0\r2021","date":"2021-05-12","objectID":"/20210512/:6:1","tags":["python","数学建模"],"title":"2021新型冠状病毒（COVID-19/2019-nCoV）疫情分析","uri":"/20210512/"},{"categories":["C++"],"content":"数值逼近 用迭代法求非线性方程(x+1)^2-sinx-3=0的根。 取迭代函数0.5*(3+sin((x))-1-(x)*(x))，精度要求为1*10^-2，最多迭代 100 次。 #include\u003cstdio.h\u003e #include\u003cmath.h\u003e #define phi(x) 0.5*(3+sin((x))-1-(x)*(x)) //迭代函数 //显示中文 #define _CRT_SECURE_NO_WARNINGS #include \u003cwindows.h\u003e//用于函数SetConsoleOutputCP(65001);更改cmd编码为utf8 #include\u003ciostream\u003e using namespace std; int main() { //显示中文 SetConsoleOutputCP(65001); int n=1,N; float x,x0,del; printf(\"x0 = \"); scanf(\"%f\",\u0026x0); printf(\"\\ndel = \"); scanf(\"%f\",\u0026del); printf(\"\\nN = \"); scanf(\"%d\",\u0026N); printf(\"\\n k x(k)\"); printf(\"\\n %2d %f\",0,x0); while (n\u003cN) { x = phi(x0); if(fabs(x-x0)\u003cdel) { printf(\"\\n\\n 近似解 = %f \\n\",x); return 0; } printf(\"\\n %2d %f\",n,x0); n = n+1; x0 = x; } printf(\"\\n\\n%d次迭代后未达到精度要求.\\n\",N); system(\"pause\"); } ","date":"2021-04-26","objectID":"/20210426/:0:0","tags":["C++","数值逼近"],"title":"C++数值逼近-迭代法求非线性方程的根","uri":"/20210426/"},{"categories":["C++"],"content":"数值积分 取步长 h = 0.1 ，分别用 Euler 方法、改进 Euler 方法和经典四阶 Runge-Kutta 方法求解初值问题 f(x,y) = ((y)-2*(x)/(y)) f(0) = 0 并将计算结果与sqrt(1+2*(x))精确解相比较。 #include\u003cstdio.h\u003e #include\u003cmath.h\u003e #include\u003ciostream\u003e #define _CRT_SECURE_NO_WARNINGS #include \u003cwindows.h\u003e//用于函数SetConsoleOutputCP(65001);更改cmd编码为utf8 using namespace std; #define f(x,y) ((y)-2*(x)/(y)) #define y(x) sqrt(1+2*(x)) int main() { //显示中文 SetConsoleOutputCP(65001); float a = 0,b = 1.0f,h=0.1f,y0=1.0f,x,ye,yp,ym,k1,k2,k3,k4,yr,yx; printf(\"\\n 精确解 Euler方法\"); printf(\" 改进Euler方法 4阶Runge-Kutta方法\"); printf(\"\\n x y ye[k] |ye[k]-y| \"); printf(\"ym[k] |ym[k]-y| yr[k] |yr[k]-y|\\n\"); printf(\"%3.1f %8.6f %8.6f %8.6f \",a,y0,y0,0); printf(\"%8.6f %8.6f %8.6f %8.6f \\n\",y0,0,y0,0.0); x=a; ye=y0; //Euler方法的初值 ym=y0; //改进的Euler方法的初值 yr=y0; //4阶Runge-Kutta方法的初值 while(x\u003cb) { ye = ye + h*f(x,ye); yp = ym + h*f(x,ym); ym = ym + h/2*(f(x,ym)+f(x+h,yp)); k1 = f(x,yr); k2 = f(x+h/2,yr+h/2*k1); k3 = f(x+h/2,yr+h/2*k2); k4 = f(x+h,yr+h*k3); yr = yr + h/6*(k1+2*k2+2*k3+k4); x = x + h; yx = y(x); printf(\"%3.1f %8.6f %8.6f %8.6f %8.6f %8.6f %8.6f %8.6f\\n\",x,yx,ye,fabs(ye-yx),ym,fabs(ym-yx),yr,fabs(yr-yx)); } system(\"pause\"); return 0; } ","date":"2021-04-25","objectID":"/20210425/:0:0","tags":["C++","数值逼近"],"title":"C++数值逼近-Euler方法、改进Euler方法和经典四阶Runge-Kutta方法求解初值问题","uri":"/20210425/"},{"categories":["C++"],"content":"数值逼近 将区间[0,1]四等分，分别用复化梯形公式和复化 Simpson 公式计算定积分 f(x) 4.0 / (1 + (x) * (x)) 的近似值。 #include\u003ciostream\u003e using namespace std; #include\u003cstdio.h\u003e //显示中文 #define _CRT_SECURE_NO_WARNINGS #include \u003cwindows.h\u003e//用于函数SetConsoleOutputCP(65001);更改cmd编码为utf8 #define f(x) 4.0 / (1 + (x) * (x)) void test() { float h = (1.0 - 0) / 4, temp, xk, yk, xkh, ykh, xk1, yk1; int i; temp = f(0); xk = 0; for (i = 1; i \u003c 4; i++) { xk = xk + h; temp = temp + 2 * f(xk); } temp = temp + f(1); temp = temp * h / 2; cout \u003c\u003c endl; cout \u003c\u003c \"复化梯形公式计算的结果：\" \u003c\u003c temp \u003c\u003c endl; temp = 0; h = (1.0 - 0) / 2; xk = 0; yk = f(0); for (i = 0; i \u003c 2; i++) { xkh = xk + h / 2; ykh = f(xkh); xk1 = xk + h; yk1 = f(xk1); temp = temp + h * (yk + 4 * ykh + yk1) / 6; xk = xk1; yk = yk1; } cout \u003c\u003c endl; cout \u003c\u003c \"复化 Simpson 公式计算的结果：\" \u003c\u003c temp \u003c\u003c endl; cout \u003c\u003c endl; } int main() { //显示中文 SetConsoleOutputCP(65001); test(); system(\"pause\"); return 0; } ","date":"2021-04-24","objectID":"/20210424/:0:0","tags":["C++","数值逼近"],"title":"C++数值逼近-复化梯形公式和复化 Simpson 公式计算定积分的近似值","uri":"/20210424/"},{"categories":["C++"],"content":"数值逼近 天安门广场升旗的时间是日出的时刻，而降旗的时间是日落时分。根据天安门广场管理委员会的公告，某年 10 月份升降旗的时间如下： 日期 1 15 22 升旗 6:09 6:23 6:31 降旗 17:58 17:36 17:26 请根据上述数据构造 Newton 插值多项式，并计算当年 10 月 8 日北京市的日照时长。 //显示中文 #define _CRT_SECURE_NO_WARNINGS #include \u003cwindows.h\u003e//用于函数SetConsoleOutputCP(65001);更改cmd编码为utf8 #include\u003ciostream\u003e #include\u003cstdio.h\u003e #include\u003cmath.h\u003e #define n 3 //节点个数 #define f(x) 4.0/(1+(x)*(x)) using namespace std; //Newton插值多项式 void test01() { int i,j,xx,x[3] = {1,15,22}; float y[3] = {17-6+(58-9)/60.0,17-6+(36-23)/60.0,17-6+(26-31)/60.0}; float N[3][3],yy,temp; for(i=0;i\u003cn;i++) { N[i][0] = y[i]; //0阶差商 } for(j=1;j\u003cn;j++) { for(i=j;i\u003cn;i++) { N[i][j] = (N[i][j-1]-N[i-1][j-1])/(x[i]-x[i-j]); //构造差商 } } xx = 8; yy = 0.0; temp = 1.0; for(i=0;i\u003cn;i++) { yy = yy + N[i][i]*temp; temp = temp*(xx-x[i]); } printf(\"\\n这年10月%d日北京日照时长为%7.4f小时.\\n\",xx,yy); printf(\"即%d小时%3.0f分.\\n\",(int)floor(yy),60*fmod(yy,1.0)); } int main() { //显示中文 SetConsoleOutputCP(65001); test01(); system(\"pause\"); return 0; } ","date":"2021-04-23","objectID":"/20210423/:0:0","tags":["C++","数值逼近"],"title":"C++数值逼近-Newton插值法","uri":"/20210423/"},{"categories":["C++"],"content":"数值逼近 参考matlab程序：https://www.ilovematlab.cn/thread-450391-1-1.html 个人编写的c++版本如下 #include\u003ciostream\u003e #include\u003cstdio.h\u003e #include\u003cmath.h\u003e #include\u003ccmath\u003e using namespace std; float X[10] = {0.10,0.15,0.30,0.45,0.55,0.60,0.70,0.85,0.90,1.00}; float Y[10] = {0.904837,0.860708,0.740818,0.637628,0.576950,0.548812,0.496585,0.427415,0.406570,0.367879}; float YY[10] = {-0.904837,-0.860708,-0.740818,-0.637628,-0.576950,-0.548812,-0.496585,-0.427415,-0.406570,-0.367879}; //#define f(x) e^(-x); float f(float x) { return exp(-x); } float Hermite(float *x, float *y, float *dy, int n, float t) { float result[10]; for(int i = 0;i\u003cn;i++) { float h = 1.0; float a = 0.0; for(int j = 0;j\u003cn;j++) { if(j!=i) { h = h*(pow(t-x[j],2))/(pow(x[i]-x[j],2)); a = a + 1/(x[i]-x[j]); } } result[i] = h*((x[i]-t)*(2*a*y[i]-dy[i])+y[i]); } float r = 0; for(int k = 0;k\u003cn;k++) { r = r + result[k]; } return r; } int main() { float t = 0.356; cout\u003c\u003cHermite(X, Y, YY, 10, t)\u003c\u003cendl; cout\u003c\u003cf(t)\u003c\u003cendl; return 0; } ","date":"2021-04-22","objectID":"/20210422/:0:0","tags":["C++","数值逼近"],"title":"C++数值逼近-Hermite插值法通用程序","uri":"/20210422/"},{"categories":["C++","数据结构"],"content":"题目 行编辑(数据结构严蔚敏C语言版的C++实现) 输入：一行有误的数据 输出：一行正确的数据 处理方法： 允许用户输入出差错，并在发现有误时及时更正。例如：可用一个退格符“#”表示前一个字符无效；可用一个退行符“@”表示当前行中的字符均无效。 步骤： 1）初始化栈S 2）读入字符ch 3）ch!=EOF 3.1) ch!=EOF \u0026\u0026 ch!=‘\\n’ 3.1.1)ch为‘#’：Pop(S, c),转3.1.4) 3.1.2)ch为‘@’：ClearStack (S),转3.1.4) 3.1.3)ch为其它： Push (S, ch),转3.1.4) 3.1.4)再读入字符ch,继续3.1) 3.2) 处理完一行,清空栈 3.3) 如ch!=EOF,读入字符ch,继续3) ","date":"2021-04-17","objectID":"/20210417/:0:0","tags":["C++","数据结构"],"title":"C++栈结构实现行编辑","uri":"/20210417/"},{"categories":["C++","数据结构"],"content":"一、问题分析 需要使用由char类型元素组成的栈，写一个LinkEdit函数对输入进行检索判断，遇到字符类型时判断一下需要进行的对应操作。 ","date":"2021-04-17","objectID":"/20210417/:1:0","tags":["C++","数据结构"],"title":"C++栈结构实现行编辑","uri":"/20210417/"},{"categories":["C++","数据结构"],"content":"二、代码 对于问题三进行求解，设计了LinkEdit函数，代码如下 //识别 void LinkEdit(SqStack\u0026 S) { char ch; SElemType e; ch = getchar(); while (ch != EOF \u0026\u0026 ch != '\\n') { switch (ch) { case '@': ClearStack(S); break; case '#': Pop(S, e); break; default: Push(S, ch); } ch = getchar(); } } ","date":"2021-04-17","objectID":"/20210417/:2:0","tags":["C++","数据结构"],"title":"C++栈结构实现行编辑","uri":"/20210417/"},{"categories":["C++","数据结构"],"content":"三、分析 这里使用一个新栈对输入后的结果进行输出，避免栈的“先进后出”的结构特点导致直接输出逆序。 ","date":"2021-04-17","objectID":"/20210417/:3:0","tags":["C++","数据结构"],"title":"C++栈结构实现行编辑","uri":"/20210417/"},{"categories":["C++","数据结构"],"content":"四、实验过程记录 这个程序我写了一个打印函数，上一个实验直接进行输出了，这个进行了遍历再输出。这个程序我使用了switch结构进行多次判断，这里的判断比较简单，判断后再进行入栈操作。 完整代码 //显示中文 #define _CRT_SECURE_NO_WARNINGS #include \u003cwindows.h\u003e//用于函数SetConsoleOutputCP(65001);更改cmd编码为utf8 #define OK 1 #define ERROR -1 #define OVERFLOW -2 #define TRUE 1 #define FALSE 0 #define STACK_INIT_SIZE 100 #define STACKINCREMENT 10 #define EOF -1 //C++中需要声明 #include \u003ccstdio\u003e #include \u003ccstdlib\u003e #include \u003ciostream\u003e using namespace std; //定义数据类型 typedef char SElemType; typedef int status; //定义栈 typedef struct { SElemType* base; SElemType* top; int stacksize; }SqStack; //初始化 status InitStack(SqStack\u0026 S) { S.base = new SElemType[STACK_INIT_SIZE]; if (!S.base) return(OVERFLOW); S.top = S.base; S.stacksize = STACK_INIT_SIZE; return OK; } //判栈空 status StackEmpty(SqStack S) { if (S.top == S.base) return TRUE; } //求栈长 status StackLength(SqStack S) { return S.top - S.base; } //求栈顶 status GetTop(SqStack S, SElemType\u0026 e) { if (S.top == S.base) return ERROR; e = *(S.top - 1); return OK; } //入栈 status Push(SqStack\u0026 S, SElemType e) { if (S.top - S.base \u003e= S.stacksize) { SElemType* newbase = (SElemType*)realloc(S.base, (S.stacksize + STACKINCREMENT) * sizeof(SElemType)); if (!newbase) return(OVERFLOW); S.base = newbase; S.top = S.base + S.stacksize; S.stacksize += STACKINCREMENT; } *S.top++ = e; return OK; } //出栈 status Pop(SqStack\u0026 S, SElemType\u0026 e) { if (S.top == S.base) return ERROR; e = *--S.top; return OK; } //清空栈 status ClearStack(SqStack\u0026 S) { S.top = S.base; S.stacksize = 0; return OK; } //销毁栈 status DestroyStack(SqStack\u0026 S) { S.top = S.base; free(S.base); S.base = NULL; S.top = NULL; return OK; } //遍历输出 status PrintStack(SqStack S) { SElemType* p = new SElemType[sizeof(SElemType)]; p = S.top; if (p == S.base) cout \u003c\u003c \"栈空\" \u003c\u003c endl; else { cout \u003c\u003c \"有效字符为：\" \u003c\u003c endl; p--; while (p != S.base - 1) { cout \u003c\u003c *p; p--; } } cout\u003c\u003cendl; return OK; } //识别判断 void LinkEdit(SqStack\u0026 S) { char ch; SElemType e; ch = getchar();//读取字符，读错误返回EOF while (ch != EOF \u0026\u0026 ch != '\\n')//EOF为全文结束符 { switch (ch) { case '@':// 重置S为空栈 ClearStack(S); break; case '#'://栈不空，退栈 Pop(S, e); break; default: Push(S, ch); } ch = getchar();//读取下一个字符 } } //实验6 void test() { SqStack S, Q; SElemType e;//中间变量 InitStack(S); InitStack(Q); while (true) { cout\u003c\u003c\"输入：\"\u003c\u003cendl; LinkEdit(S);//识别 while (StackLength(S))//如果识别判断后不空 { //正序输出转换 Pop(S, e); Push(Q, e); } PrintStack(Q); ClearStack(Q); } DestroyStack(S); DestroyStack(Q); } int main() { //显示中文 SetConsoleOutputCP(65001); //实验6 test(); system(\"pause\"); return 0; } ","date":"2021-04-17","objectID":"/20210417/:4:0","tags":["C++","数据结构"],"title":"C++栈结构实现行编辑","uri":"/20210417/"},{"categories":["C++","数据结构"],"content":"题目 括号匹配检验(数据结构严蔚敏C语言版的C++实现) 输入：一串括号 输出：检验结果（缺左括号、有多余左括号、左右不匹配、匹配成功） 处理方法： 检验括号是否匹配的方法可用“期待的急迫程度”这个概念来描述： 后出现的“左括弧”，它等待与其匹配的“右括弧”出现的“急迫”心情要比先出现的左括弧高。对“左括弧”来说，后出现的比先出现的“优先”等待检验。 对“右括弧”来说，每个出现的右括弧要去找在它之前“最后”出现的那个左括弧去匹配。显然，必须将先后出现的左括弧依次保存，为了反映这个优先程度，保存左括弧的结构用栈最合适。 对出现的右括弧来说，只要“栈顶元素”相匹配即可。如果在栈顶的那个左括弧正好和它匹配，就可将左括弧从栈顶删除。 步骤： 1）凡出现左括弧，则进栈； 2）凡出现右括弧，首先检查栈是否空 若栈空，则表明该“右括弧”多余， 否则和栈顶元素比较， 若相匹配，则“左括弧出栈”， 否则，表明不匹配。 3）表达式检验结束时， 若栈空，表明表达式中匹配正确， 否则，表明“左括弧”有余 ","date":"2021-04-15","objectID":"/20210415/:0:0","tags":["C++","数据结构"],"title":"C++栈结构实现括号匹配","uri":"/20210415/"},{"categories":["C++","数据结构"],"content":"一、问题分析 先对输入字符串进行遍历提取，将左括号入栈，遇到右括号，出栈一个左括号，判断是否出栈的是左括号，如果不是，缺一个左括号，如果是，判断左括号与右括号是否匹配。最后如果栈中还剩余括号，则证明有多余括号，不匹配。 ","date":"2021-04-15","objectID":"/20210415/:1:0","tags":["C++","数据结构"],"title":"C++栈结构实现括号匹配","uri":"/20210415/"},{"categories":["C++","数据结构"],"content":"二、代码 对于问题三进行求解，设计了match函数，代码如下 Status match(char *exp) { //检验表达式中所含括弧是否正确嵌套，若是则返回OK,否则返回ERROR SElemType left; SqStack S; InitStack(S); //初始化栈S char *p=exp; char ch = *p; //当字符串exp未扫描 while (ch != '#' ) { if(is_left(ch)) { Push(S,ch);//左括号进栈 } if(is_right(ch)) { Pop(S,left); if(!is_left(left) || left == *\"$\") { return FALSE; //缺左括号 } else if(!peidui(left,ch)) { return FALSE; //左右不匹配 } } p++; ch = *p; } if(!StackEmpty(S)) { return FALSE; //有多余的左括号 } else { return TRUE; } } ","date":"2021-04-15","objectID":"/20210415/:2:0","tags":["C++","数据结构"],"title":"C++栈结构实现括号匹配","uri":"/20210415/"},{"categories":["C++","数据结构"],"content":"三、分析 分析：缺一个左括号和缺一个右括号的情况都可以正常识别，这得益于先对左括号和右括号的分类，最后再进行匹配的检验的程序结构。 ","date":"2021-04-15","objectID":"/20210415/:3:0","tags":["C++","数据结构"],"title":"C++栈结构实现括号匹配","uri":"/20210415/"},{"categories":["C++","数据结构"],"content":"四、实验过程记录 刚看到题目的时候，我想着是使用switch对输入进行匹配检验，后来发现这需要嵌套比对，比较麻烦。后来看到老师对括号进行左括号右括号分类，找到了不需要嵌套比较的方法。最后有发现缺左括号情况栈已经空了，但是仍然匹配的情况，这里栈空后pop函数没有更新left值，修改这种情况以￥标识空栈，完善了匹配识别函数 完整代码 //显示中文 #define _CRT_SECURE_NO_WARNINGS #include \u003cwindows.h\u003e//用于函数SetConsoleOutputCP(65001);更改cmd编码为utf8 //函数结果状态代码 #define TRUE 1 #define FALSE 0 #define OK 1 #define ERROR 0 #define INFEASIBLE -1 #define OVERFLOW -2 #define STACK_INIT_SIZE 100 //存储空间初始分配量 #define STACKINCREMENT 10 //存储空间分配增量 #include\u003ciostream\u003e using namespace std; //设置状态码和数据类型 typedef int Status; typedef char SElemType; typedef struct { SElemType *base; //数组首地址,在栈构造之前和销毁之后，base的值为NULL SElemType *top; //栈顶指针 int stacksize;//当前已分配的存储空间，以元素为单位 }SqStack; //初始化 Status InitStack(SqStack \u0026S ) { // 构造一个空的顺序栈 S.base=new SElemType[STACK_INIT_SIZE]; if (!S.base) { exit(OVERFLOW); } //存储分配失败 S.top = S.base; //长度为0 S.stacksize = STACK_INIT_SIZE;//初始存储容量 return OK; } //销毁 Status DestroyStack(SqStack \u0026S) { free(S.base); S.top == S.base == NULL; S.stacksize = 0; return OK; } //判栈空 Status StackEmpty(SqStack S) { //若栈空，返回TRUE；否则返回FALSE。 if(S.top==S.base) { return TRUE; //栈空 } else { return FALSE; } } //求栈长 Status LengthStack(SqStack \u0026S) { return (S.top-S.base);//栈顶指针减去栈底指针 } //清空栈 Status ClearStack(SqStack \u0026S) { S.top=S.base;//让栈顶指针指向栈底位置 return OK; } //读栈顶 Status GetTop(SqStack S, SElemType \u0026e) { //若栈不空，则用e返回S的栈顶元素，并返OK， //否则返回ERROR if(S.top==S.base) { return ERROR; //栈空 } e=*(S.top-1); return OK; } //进栈 //int Status Push(SqStack \u0026S, SElemType e) { //插入元素e为新的栈顶元素 if(S.top-S.base \u003e= S.stacksize) {//栈满，追加空间 SElemType *newbase=(SElemType *)realloc(S.base, (S.stacksize+STACKINCREMENT)*sizeof(SElemType)); if(!newbase) exit(OVERFLOW); S.base=newbase; S.top=S.base+S.stacksize; S.stacksize+=STACKINCREMENT; } //if *S.top++=e; return OK; } //出栈 //int Status Pop(SqStack \u0026S, SElemType \u0026e) { //若栈不空，则删除栈顶元素，用e返回其值，并返回OK； //否则返回ERROR if(S.top==S.base) { e = *\"$\"; return ERROR; //栈空 } e=*--S.top; return OK; } //括号匹配 //判断左括号函数 Status is_left(char ch) { if(ch == '(' || ch=='[' || ch=='{' ) { return TRUE; } else { return FALSE; } } //判断右括号函数 Status is_right(char ch) { if(ch == ')' || ch==']' || ch=='}') { return TRUE; } else { return FALSE; } } //判断是否配对 Status peidui(char a, char b) { if(a == '(' \u0026\u0026 b == ')') { return TRUE; } else if(a == '[' \u0026\u0026 b == ']') { return TRUE; } else if(a == '{' \u0026\u0026 b == '}') { return TRUE; } else { return FALSE; } } Status match(char *exp) { //检验表达式中所含括弧是否正确嵌套，若是则返回OK,否则返回ERROR SElemType left; SqStack S; InitStack(S); //初始化栈S char *p=exp; char ch = *p; //当字符串exp未扫描 while (ch != '#' ) { if(is_left(ch)) { Push(S,ch);//左括号进栈 } if(is_right(ch)) { Pop(S,left); if(!is_left(left) || left == *\"$\") { return FALSE; //缺左括号 } else if(!peidui(left,ch)) { return FALSE; //左右不匹配 } } p++; ch = *p; } if(!StackEmpty(S)) { return FALSE; //有多余的左括号 } else { return TRUE; } } //实验5 void test() { char str[20]; cout\u003c\u003c\"输入括号(#结束):\"; cin\u003e\u003estr; bool result = match(str); if(result != true) { cout\u003c\u003c\"不匹配\"; } else { cout\u003c\u003c\"匹配\"; } cout\u003c\u003cendl; } int main() { //显示中文 SetConsoleOutputCP(65001); //实验5 test(); system(\"pause\"); } ","date":"2021-04-15","objectID":"/20210415/:4:0","tags":["C++","数据结构"],"title":"C++栈结构实现括号匹配","uri":"/20210415/"},{"categories":["C++","数据结构"],"content":"题目 数制转换(数据结构严蔚敏C语言版的C++实现) 输入：十进制整数 输出：八进制整数 处理方法：基于下列原理： N = (N div d)×d + N mod d (其中：div为整除运算，mod为求余运算) 步骤：（举例说明）（1348)10 = (2504)8 ","date":"2021-04-14","objectID":"/20210414/:0:0","tags":["C++","数据结构"],"title":"C++栈结构实现进制转换","uri":"/20210414/"},{"categories":["C++","数据结构"],"content":"一、问题分析 需要对一个输入变量进行除模运算，将余数压入栈中，将商再赋值给输入变量，再将栈中的元素出栈并输出，这个倒序输出的结果正好是进制转换的结果。 ","date":"2021-04-14","objectID":"/20210414/:1:0","tags":["C++","数据结构"],"title":"C++栈结构实现进制转换","uri":"/20210414/"},{"categories":["C++","数据结构"],"content":"二、代码 对于问题三进行求解，设计了translate函数，代码如下 void translate(SqStack \u0026S,int a,int \u0026result) { while (a!=0)//取余数N = (N div d)×d + N mod d { result = a%8; a = a/8; Push(S,result); } while (!StackEmpty(S))//从栈中取出结果，先进后出 { Pop(S,result); cout\u003c\u003cresult; } cout\u003c\u003cendl; } ","date":"2021-04-14","objectID":"/20210414/:2:0","tags":["C++","数据结构"],"title":"C++栈结构实现进制转换","uri":"/20210414/"},{"categories":["C++","数据结构"],"content":"三、分析 分析：这里的结果是栈“先进后出”结构的一个运用。 ","date":"2021-04-14","objectID":"/20210414/:3:0","tags":["C++","数据结构"],"title":"C++栈结构实现进制转换","uri":"/20210414/"},{"categories":["C++","数据结构"],"content":"四、实验过程记录 在完成这个程序时我遇到的苦难在于操作函数的编写，这耗费了我很长时间，后面的进制转换函数比较简单，将数学公式转化为代码即可。 完整代码 //显示中文 #define _CRT_SECURE_NO_WARNINGS #include \u003cwindows.h\u003e//用于函数SetConsoleOutputCP(65001);更改cmd编码为utf8 //函数结果状态代码 #define TRUE 1 #define FALSE 0 #define OK 1 #define ERROR 0 #define INFEASIBLE -1 #define OVERFLOW -2 #define STACK_INIT_SIZE 100 //存储空间初始分配量 #define STACKINCREMENT 10 //存储空间分配增量 #include\u003ciostream\u003e using namespace std; //设置状态码和数据类型 typedef int Status; typedef int SElemType; typedef struct { SElemType *base; //数组首地址,在栈构造之前和销毁之后，base的值为NULL SElemType *top; //栈顶指针 int stacksize;//当前已分配的存储空间，以元素为单位 }SqStack; //初始化 Status InitStack(SqStack \u0026S ) { // 构造一个空的顺序栈 S.base=new SElemType[STACK_INIT_SIZE]; if (!S.base) { exit(OVERFLOW); } //存储分配失败 S.top = S.base; //长度为0 S.stacksize = STACK_INIT_SIZE;//初始存储容量 return OK; } //销毁 Status DestroyStack(SqStack \u0026S) { free(S.base); S.top == S.base == NULL; S.stacksize = 0; return OK; } //判栈空 Status StackEmpty(SqStack S) { //若栈空，返回TRUE；否则返回FALSE。 if(S.top==S.base) { return TRUE; //栈空 } else { return FALSE; } } //求栈长 Status LengthStack(SqStack \u0026S) { return (S.top-S.base);//栈顶指针减去栈底指针 } //清空栈 Status ClearStack(SqStack \u0026S) { S.top=S.base;//让栈顶指针指向栈底位置 return OK; } //读栈顶 Status GetTop(SqStack S, SElemType \u0026e) { //若栈不空，则用e返回S的栈顶元素，并返OK， //否则返回ERROR if(S.top==S.base) { return ERROR; //栈空 } e=*(S.top-1); return OK; } //进栈 //int Status Push(SqStack \u0026S, SElemType e) { //插入元素e为新的栈顶元素 if(S.top-S.base \u003e= S.stacksize) {//栈满，追加空间 SElemType *newbase=(SElemType *)realloc(S.base, (S.stacksize+STACKINCREMENT)*sizeof(SElemType)); if(!newbase) exit(OVERFLOW); S.base=newbase; S.top=S.base+S.stacksize; S.stacksize+=STACKINCREMENT; } //if *S.top++=e; return OK; } //出栈 //int Status Pop(SqStack \u0026S, SElemType \u0026e) { //若栈不空，则删除栈顶元素，用e返回其值，并返回OK； //否则返回ERROR if(S.top==S.base) return ERROR; //栈空 e=*--S.top; return OK; } //进制转换 void translate(SqStack \u0026S,int a,int \u0026result) { while (a!=0)//取余数N = (N div d)×d + N mod d { result = a%8; a = a/8; Push(S,result); } while (!StackEmpty(S))//从栈中取出结果，先进后出 { Pop(S,result); cout\u003c\u003cresult; } cout\u003c\u003cendl; } //实验4 void test() { int input_num; int result; cout\u003c\u003c\"输入十进制数\"\u003c\u003cendl; cin\u003e\u003einput_num; SqStack S; InitStack(S); cout\u003c\u003c\"十进制数\"\u003c\u003cinput_num\u003c\u003c\"转换八进制数为：\"; translate(S,input_num,result); } int main() { //显示中文 SetConsoleOutputCP(65001); //实验4 test(); system(\"pause\"); return 0; } ","date":"2021-04-14","objectID":"/20210414/:4:0","tags":["C++","数据结构"],"title":"C++栈结构实现进制转换","uri":"/20210414/"},{"categories":["C++","数据结构"],"content":"题目 尾插法(数据结构严蔚敏C语言版的C++实现) 输入：键盘输入 输出：带头结点的单链表L 处理方法：待插结点*s插入到最后一个结点之后。 步骤： 1)获得最后一个结点的位置,使p指向该结点 2)p-\u003enext = new LNode; 3)p = p-\u003enext; 4)cin\u003e\u003ep-\u003edata; 5)p-\u003enext = NULL; 分析：要想获取最后一个结点的位置，必须从头指针开始顺着next链搜索链表的全部结点，该过程的时间复杂度是O( )。如果每次插入都按此方法获取最后一个结点的位置，则整个创建算法的时间复杂度为O( )。 ","date":"2021-04-13","objectID":"/20210413/:0:0","tags":["C++","数据结构"],"title":"C++单链表尾插法","uri":"/20210413/"},{"categories":["C++","数据结构"],"content":"一、问题分析 创建一个单链表，在尾插函数中添加尾指针，将输入获的int类型数据元素一个个尾插到单链表最后一个。 ","date":"2021-04-13","objectID":"/20210413/:1:0","tags":["C++","数据结构"],"title":"C++单链表尾插法","uri":"/20210413/"},{"categories":["C++","数据结构"],"content":"二、代码 对于问题三进行求解，设计了Tail_Insert函数，代码如下 void Tail_Insert(LinkList \u0026L) { int e; LNode *p, *s; L = new LNode; L-\u003enext = NULL;//定义头结点 p = L; //p是L的尾指针 cout\u003c\u003c\"请输入节点(输入0结束并输出结果)：\"\u003c\u003cendl; cin \u003e\u003e e; //从键盘输入一个结点 while (e != 0) { s = new LNode; s-\u003edata = e; s-\u003enext = NULL; p-\u003enext = s; p = s; //插入链表 cin \u003e\u003e e; //继续读 } } ","date":"2021-04-13","objectID":"/20210413/:2:0","tags":["C++","数据结构"],"title":"C++单链表尾插法","uri":"/20210413/"},{"categories":["C++","数据结构"],"content":"三、分析 通过尾插法插入后，输入的数字是按照倒序在栈S中存储的，如果使用S进行输出，输出结果会是倒叙，需要再创建一个栈Q，将栈S中的元素顺序倒置，再由打印函数输出。 ","date":"2021-04-13","objectID":"/20210413/:3:0","tags":["C++","数据结构"],"title":"C++单链表尾插法","uri":"/20210413/"},{"categories":["C++","数据结构"],"content":"四、实验过程记录 我在码这个程序时碰到的困难是对指针节点的使用，试过在链接各节点时顺序弄反了，导致数据丢失了，后面经过一段排查后程序正常运行了。 完整代码 //显示中文 #define _CRT_SECURE_NO_WARNINGS #include \u003cwindows.h\u003e//用于函数SetConsoleOutputCP(65001);更改cmd编码为utf8 #define TRUE 1 #define FALSE 0 #define OK 1 #define ERROR 0 #define INFEASIBLE -1 #define OVERFLOW -2 #include\u003ciostream\u003e using namespace std; typedef int ElemType; typedef int status; //创建节点结构体 typedef struct LNode { ElemType data; struct LNode *next; }LNode, *LinkList; //初始化 status InitList(LinkList\u0026L) { L = new LNode; if (!L) exit(OVERFLOW); L-\u003enext = NULL; return OK; } // status Getelem(LinkList L, int i, ElemType\u0026e) { LNode *p; int j; p = L-\u003enext; j = 1; while (p\u0026\u0026j \u003c 1) { p = p-\u003enext; j++; } if (!p || j \u003e i)return ERROR; e = p-\u003edata; return OK; } void Tail_Insert(LinkList \u0026L) { int e; LNode *p, *s; L = new LNode; L-\u003enext = NULL;//定义头结点 p = L; //p是L的尾指针 cout\u003c\u003c\"请输入节点(输入0结束并输出结果)：\"\u003c\u003cendl; cin \u003e\u003e e; //从键盘输入一个结点 while (e != 0) { s = new LNode; s-\u003edata = e; s-\u003enext = NULL; p-\u003enext = s;//插入链表 p = s; //更新尾指针 cin \u003e\u003e e; //继续读 } } //打印 void PrintList(LinkList L) { LinkList tem = L; while (tem-\u003enext != NULL) { tem = tem-\u003enext; cout \u003c\u003c tem-\u003edata \u003c\u003c \" \"; } } //实验3 void test() { LinkList L; Tail_Insert(L); cout \u003c\u003c \"输出：\"; PrintList(L); cout\u003c\u003cendl; } int main() { //显示中文 SetConsoleOutputCP(65001); //实验3 test(); system(\"pause\"); return 0; } ","date":"2021-04-13","objectID":"/20210413/:4:0","tags":["C++","数据结构"],"title":"C++单链表尾插法","uri":"/20210413/"},{"categories":["C++","数据结构"],"content":"题目 按值非递减有序排列表合并(数据结构严蔚敏C语言版的C++实现) 已知线性表La和Lb中的数据元素按值非递减有序排列，要求将La和Lb归并成一个新的线性表Lc，且Lc中的数据元素仍按值非递减有序排列。（用顺序表实现） 输入：线性表La、线性表Lb(均按值非递减有序排列) 输出：Lc(按值非递减有序排列)，使用函数merge(La, Lb, \u0026Lc) 处理方法： 由La和Lb均按值非递减有序排列，可设置两个位置指示器i和j，分别指向La和Lb中的当前元素，初始均指向第1个。 比较i和j所指向的元素ai和bj，选取值小的插入到Lc的尾部，并使相应的位置指示器向后移。 ","date":"2021-04-12","objectID":"/20210412/:0:0","tags":["C++","数据结构"],"title":"C++非递减有序顺序表合并","uri":"/20210412/"},{"categories":["C++","数据结构"],"content":"一、问题分析 需要创建三个表La，Lb，Lc，创建与之对应的位置指示器i，j，k，然后在La与Lb中各取一个元素进行比较，较小的插入Lc中，相应的位置指示器往后移一位。 如果La插入完毕，将Lc中剩余元素全部插入Lc中，如果Lb插入完毕，将La中剩余元素全部插入Lc尾部。 ","date":"2021-04-12","objectID":"/20210412/:1:0","tags":["C++","数据结构"],"title":"C++非递减有序顺序表合并","uri":"/20210412/"},{"categories":["C++","数据结构"],"content":"二、代码 对于问题二进行求解，设计了merge函数，代码如下 void merge(SqList La, SqList Lb,SqList \u0026Lc) { //求表长 int la_len = ListLength(La); int lb_len = ListLength(Lb); //初始化存储索引的a，b和位置i，j，k ElemType a,b; int i = 1; int j = 1; int k = 0; //比较入表 while(i \u003c= la_len \u0026\u0026 j \u003c= lb_len) { GetElem(La,i,a); GetElem(Lb,j,b); if(a\u003cb) { ListInsert(Lc, ++k, a); ++i; } if(b\u003ca) { ListInsert(Lc, ++k, b); ++j; } } //比较入表后将剩余元素入表 while(i \u003c= la_len) //LB已到达表尾，依次将LA的剩余元素插入LC的后面 { GetElem(La,i,a); i++; ListInsert(Lc, ++k, a); } while(j \u003c= lb_len) //LA已到达表尾，依次将LB的剩余元素插入LC的后面 { GetElem(Lb,j,b); j++; ListInsert(Lc, ++k, b); } } ","date":"2021-04-12","objectID":"/20210412/:2:0","tags":["C++","数据结构"],"title":"C++非递减有序顺序表合并","uri":"/20210412/"},{"categories":["C++","数据结构"],"content":"三、分析 通过读表元函数将La和Lb中的一个元素读取出来，再对两元素进行大小比较，如果找到较小的一个元素，在Lc表的最后面插入该元素；如果La插入完毕，将Lc中剩余元素全部插入Lc中；如果Lb插入完毕，将La中剩余元素全部插入Lc尾部。 ","date":"2021-04-12","objectID":"/20210412/:3:0","tags":["C++","数据结构"],"title":"C++非递减有序顺序表合并","uri":"/20210412/"},{"categories":["C++","数据结构"],"content":"四、实验过程记录 这个程序我在实际码的过程中碰到的困难在于和前一个实验使用了同一个文件里的表结构，一个文件写了两个小实验程序。我一开始忘记在使用表后得销毁表，导致后面使用同名表时报错，后来我注释掉前一个实验程序的调用就正常运行了。 完整代码 //显示中文 #define _CRT_SECURE_NO_WARNINGS #include \u003cwindows.h\u003e//用于函数SetConsoleOutputCP(65001);更改cmd编码为utf8 //函数结果状态代码 #define TRUE 1 #define FALSE 0 #define OK 1 #define ERROR 0 #define INFEASIBLE -1 #define OVERFLOW -2 //初始空间参数 #define LIST_INIT_SIZE 100 //线性表的初始存储空间 #define LISTINCREMENT 10 //线性表的增量空间 #include\u003ciostream\u003e #include \u003cstdlib.h\u003e using namespace std; //设置状态码和数据类型 typedef int Status; typedef int ElemType; //定义顺序表 typedef struct SqList{ ElemType *elem; //头指针指向数组首元素 int Length; //线性表的当前长度 int Listsize; //线性表的当前容量 }; //初始化 Status InitList(SqList \u0026L) { //给表分配空间 L.elem = new ElemType(LIST_INIT_SIZE); //判断是否生成 if(!L.elem) { return OVERFLOW; } else { L.Listsize = LIST_INIT_SIZE; //表长度为初始值 L.Length = 0; //表默认长度0 return OK; } }; //销毁 Status DestroyList(SqList \u0026L) { if(L.elem != NULL)//判断表是否已存在 { free(L.elem); L.elem = NULL; L.Length = 0; L.Listsize = 0; return OK; } else { return ERROR; } } //判空 bool ListEmpty(SqList L) { if(L.Listsize == 0)//如果顺序表的长度为0，则表为空 { return true; } else { return false; } } //求表长 int ListLength(SqList L) { return L.Length;//返回顺序表表长 } //查找返回下标 int LocateElem(SqList L,ElemType e) //bool compare(int p,int e) { int *p,i; p = L.elem; i = 1; while (i \u003c= L.Length \u0026\u0026 *p++ != e)//后置++高于* i++; if (i \u003e L.Length) i = 0; return i; } //读表元(已经自动转换下标了) Status GetElem(SqList L,int i,ElemType \u0026e) { if(i\u003c1 || i\u003eListLength(L)) return OVERFLOW; int *p; p = \u0026(L.elem[i-1]); e = *p; return OK; } //打印函数 void Print(SqList L) { for (int i = 0; i \u003c L.Length; i++) { cout \u003c\u003c L.elem[i] \u003c\u003c \"\"; } cout \u003c\u003c endl; } //求前驱 ElemType PriorElem(SqList L,ElemType cur_e,ElemType \u0026pre_e) { if(L.elem != NULL) { int i = LocateElem(L,cur_e); if(i==0 || i ==1) { pre_e = NULL; } else { pre_e = L.elem[i-2]; } return pre_e; } } //求后继 ElemType NextElem(SqList L,ElemType cur_e,ElemType \u0026next_e) { if(L.elem != NULL) { int i = LocateElem(L,cur_e); if(i==0 || i ==1) { next_e = NULL; } else { next_e = L.elem[i]; } return next_e; } } //线性表置空 Status ClearList(SqList \u0026L) { if(L.elem != NULL) { L.Length = 0; return OK; } else { return ERROR; } } //赋值 Status PutElem(SqList \u0026L,int i,ElemType \u0026e) { if(L.elem != NULL \u0026\u0026 !i\u003c1 \u0026\u0026 !i\u003eListLength(L)) { L.elem[i] = e; return OK; } else { return ERROR; } } //插入元素 Status ListInsert(SqList \u0026L,int i,ElemType e) { //判断是否非法 if(i\u003c1||i\u003eL.Length+1) { return OVERFLOW; } //判断是否满了，如果满动态扩展 if (L.Length \u003e= L.Listsize) { //计算新表大小 int newsize = L.Listsize + LISTINCREMENT; //分配新空间 int *newbase = (ElemType *)realloc(L.elem,newsize*sizeof(ElemType));//已经自动释放原L，并拷贝数据到新空间 //判断是否成功分配 if(!newbase) exit(OVERFLOW); //更新新空间指向 L.elem = newbase; //更新容量 L.Listsize += LISTINCREMENT; } int *q,*p; q = \u0026L.elem[i-1];//令q指向ai，静态 for(p = L.elem+L.Length-1; p\u003e=q ;--p)//下标从0开始，第几个元素得减1 { //从后往前检索，逐个元素后移 *(p+1) = *p; } *q = e; ++L.Length; return OK; } //删除元素 Status ListDelete(SqList \u0026L,int i,ElemType \u0026e) { if(i\u003c1||i\u003eL.Length) { return ERROR; //i非法 } ElemType *p=L.elem+i-1;//p为被删除元素的位置 e=*p;//被删除元素的值赋给e ElemType *q=L.elem+L.Length-1;//表尾元素的位置 for(++p;p\u003c=q;++p) { *(p-1)=*p; //左移一位 } L.Length--; //表长减1 return OK; } //非递减有序排列表合并 void merge(SqList La, SqList Lb,SqList \u0026Lc) { //求表长 int la_len = ListLength(La); int lb_len = ListLength(Lb); //初始化存储索引的a，b和位置i，j，k ElemType a,b; int i = 1; int j = 1; int k = 0; //比较入表 while(i \u003c= la_len \u0026\u0026 j \u003c= lb_len) { GetElem(La,i,a); GetElem(Lb,j,b); if(a\u003cb) { ListInsert(Lc, ++k, a); ++i; } if(b\u003ca) { ListInsert(Lc, ++k, b); ++j; } } //比较入表后将剩余元素入表 while(i \u003c= la_len) //LB已到达表尾，依次将LA的剩余元素插入LC的后面 { GetElem(La,i,a); i++; ListInsert(Lc, ++k, a); } while(j \u003c= lb_len) //LA已到达表尾，依次将LB的剩余元素插入LC的后面 { GetElem(Lb,j,b); j++; ListInsert(Lc, ++k, b); } } //实验2 void test02() { SqList La; InitList(La); int a; cout \u003c\u003c \"顺序表La的5个元素：\" \u003c\u003c endl; for (int j = 0; j \u003c 5; j++) { cin \u003e\u003e a; ListInsert(La,j+1, a); } SqList Lb; InitList(Lb); int b; cout \u003c\u003c \"顺序表Lb的5个元素：\" \u003c\u003c endl; for (int k = 0; k \u003c 5; k++) { cin \u003e\u003e b; ListInsert(Lb, k+1, b); } Sq","date":"2021-04-12","objectID":"/20210412/:4:0","tags":["C++","数据结构"],"title":"C++非递减有序顺序表合并","uri":"/20210412/"},{"categories":["C++","数据结构"],"content":"题目 C++顺序表合并(数据结构严蔚敏C语言版的C++实现) 求两个线性表La和Lb的并集La = La U Lb （用顺序表实现） ( 要求：“就地运算”，运算结果仍然存放在La中 ) 输入：线性表La、线性表Lb 输出：变化了的La 处理方法：扩大线性表La，将存在于线性表Lb 而不存在于线性表La中的数据元素插入到线性表La中去 ","date":"2021-04-11","objectID":"/20210411/:0:0","tags":["C++","数据结构"],"title":"C++顺序表合并","uri":"/20210411/"},{"categories":["C++","数据结构"],"content":"一、问题分析 需要创建两个线性顺序表La和Lb，先从线性表Lb中依次取得每个数据元素，依值在线性表La中进行遍历比较查访，若La中该元素不存在，则在La的表尾插入。 ","date":"2021-04-11","objectID":"/20210411/:1:0","tags":["C++","数据结构"],"title":"C++顺序表合并","uri":"/20210411/"},{"categories":["C++","数据结构"],"content":"二、代码 对于问题一进行求解，设计了unionL函数，代码如下 Status unionL(SqList \u0026La,SqList Lb) { // 求各表的长度 int La_len = ListLength(La); int Lb_len = ListLength(Lb); int e; //初始化e for (int i = 1; i \u003c= Lb_len; i++) { GetElem(Lb,i,e); if (!LocateElem(La, e)) { ListInsert(La, ++La_len, e); } } return OK; } ","date":"2021-04-11","objectID":"/20210411/:2:0","tags":["C++","数据结构"],"title":"C++顺序表合并","uri":"/20210411/"},{"categories":["C++","数据结构"],"content":"三、分析 通过读表元函数将Lb中的元素读取出来，再对该元素对La进行下标查找，如果查找不到，在表的最后面插入该元素。 ","date":"2021-04-11","objectID":"/20210411/:3:0","tags":["C++","数据结构"],"title":"C++顺序表合并","uri":"/20210411/"},{"categories":["C++","数据结构"],"content":"四、实验过程记录 这个程序我在码的过程中难点是操作函数的编写，特别是一些自增自减符，写着写着就忘记是先运算再使用还是先使用再运算了，这给我后面写实际解决方案时带来了很大的困难，没有报错却又找不到哪里有错误使得结果有误。 完整代码 //显示中文 #define _CRT_SECURE_NO_WARNINGS #include \u003cwindows.h\u003e//用于函数SetConsoleOutputCP(65001);更改cmd编码为utf8 //函数结果状态代码 #define TRUE 1 #define FALSE 0 #define OK 1 #define ERROR 0 #define INFEASIBLE -1 #define OVERFLOW -2 //初始空间参数 #define LIST_INIT_SIZE 100 //线性表的初始存储空间 #define LISTINCREMENT 10 //线性表的增量空间 #include\u003ciostream\u003e #include\u003cstdlib.h\u003e using namespace std; //设置状态码和数据类型 typedef int Status; typedef int ElemType; //定义顺序表 typedef struct SqList{ ElemType *elem; //头指针指向数组首元素 int Length; //线性表的当前长度 int Listsize; //线性表的当前容量 }; //初始化 Status InitList(SqList \u0026L) { //给表分配空间 L.elem = new ElemType(LIST_INIT_SIZE); //判断是否生成 if(!L.elem) { return OVERFLOW; } else { L.Listsize = LIST_INIT_SIZE; //表长度为初始值 L.Length = 0; //表默认长度0 return OK; } }; //销毁 Status DestroyList(SqList \u0026L) { if(L.elem != NULL)//判断表是否已存在 { free(L.elem); L.elem = NULL; L.Length = 0; L.Listsize = 0; return OK; } else { return ERROR; } } //判空 bool ListEmpty(SqList L) { if(L.Listsize == 0)//如果顺序表的长度为0，则表为空 { return true; } else { return false; } } //求表长 int ListLength(SqList L) { return L.Length;//返回顺序表表长 } //查找返回下标 int LocateElem(SqList L,ElemType e) //bool compare(int p,int e) { int *p,i; p = L.elem; i = 1; while (i \u003c= L.Length \u0026\u0026 *p++ != e)//后置++高于* i++; if (i \u003e L.Length) i = 0; return i; } //读表元(已经自动转换下标了) Status GetElem(SqList L,int i,ElemType \u0026e) { if(i\u003c1 || i\u003eListLength(L)) return OVERFLOW; int *p; p = \u0026(L.elem[i-1]); e = *p; return OK; } //打印函数 void Print(SqList L) { for (int i = 0; i \u003c L.Length; i++) { cout \u003c\u003c L.elem[i] \u003c\u003c \"\"; } cout \u003c\u003c endl; } //求前驱 ElemType PriorElem(SqList L,ElemType cur_e,ElemType \u0026pre_e) { if(L.elem != NULL) { int i = LocateElem(L,cur_e); if(i==0 || i ==1) { pre_e = NULL; } else { pre_e = L.elem[i-2]; } return pre_e; } } //求后继 ElemType NextElem(SqList L,ElemType cur_e,ElemType \u0026next_e) { if(L.elem != NULL) { int i = LocateElem(L,cur_e); if(i==0 || i ==1) { next_e = NULL; } else { next_e = L.elem[i]; } return next_e; } } //线性表置空 Status ClearList(SqList \u0026L) { if(L.elem != NULL) { L.Length = 0; return OK; } else { return ERROR; } } //赋值 Status PutElem(SqList \u0026L,int i,ElemType \u0026e) { if(L.elem != NULL \u0026\u0026 !i\u003c1 \u0026\u0026 !i\u003eListLength(L)) { L.elem[i] = e; return OK; } else { return ERROR; } } //插入元素 Status ListInsert(SqList \u0026L,int i,ElemType e) { //判断是否非法 if(i\u003c1||i\u003eL.Length+1) { return OVERFLOW; } //判断是否满了，如果满动态扩展 if (L.Length \u003e= L.Listsize) { //计算新表大小 int newsize = L.Listsize + LISTINCREMENT; //分配新空间 int *newbase = (ElemType *)realloc(L.elem,newsize*sizeof(ElemType));//已经自动释放原L，并拷贝数据到新空间 //判断是否成功分配 if(!newbase) exit(OVERFLOW); //更新新空间指向 L.elem = newbase; //更新容量 L.Listsize += LISTINCREMENT; } int *q,*p; q = \u0026L.elem[i-1];//令q指向ai，静态 for(p = L.elem+L.Length-1; p\u003e=q ;--p)//下标从0开始，第几个元素得减1 { //从后往前检索，逐个元素后移 *(p+1) = *p; } *q = e; ++L.Length; return OK; } //删除元素 Status ListDelete(SqList \u0026L,int i,ElemType \u0026e) { if(i\u003c1||i\u003eL.Length) { return ERROR; //i非法 } ElemType *p=L.elem+i-1;//p为被删除元素的位置 e=*p;//被删除元素的值赋给e ElemType *q=L.elem+L.Length-1;//表尾元素的位置 for(++p;p\u003c=q;++p) { *(p-1)=*p; //左移一位 } L.Length--; //表长减1 return OK; } //合并两表 Status unionL(SqList \u0026La,SqList Lb) { int La_len = ListLength(La); // 求各表的长度 int Lb_len = ListLength(Lb); int e; //初始化e for (int i = 1; i \u003c= Lb_len; i++) { GetElem(Lb,i,e); // 取Lb中第i个数据元素赋给e if (!LocateElem(La, e)) { ListInsert(La, ++La_len, e); // La中不存在和 e 相同的数据元素，则插入 } } return OK; } //实验1 void test01() { SqList La; InitList(La); int a; cout \u003c\u003c \"顺序表La的5个元素：\" \u003c\u003c endl; for (int j = 0; j \u003c 5; j++) { cin \u003e\u003e a; ListInsert(La, j+1, a); } SqList Lb; InitList(Lb); int b; cout \u003c\u003c \"顺序表Lb的5个元素：\" \u003c\u003c endl; for (int k = 0; k \u003c 5; k++) { cin \u003e\u003e b; ListInsert(Lb, k+1, b); } unionL(La,Lb); cout \u003c\u003c \"La与Lb的并集为：\" \u003c\u003c endl; int l = 0; while(l\u003cLa.Length) { cout\u003c\u003cLa.elem[l]\u003c\u003cendl; l++; } cout\u003c\u003cendl; DestroyList(La); DestroyList(Lb); } int main() { //显示中文 SetConsoleOutputCP(65001); //实验1 test01(); system(\"pause\"); return 0; } ","date":"2021-04-11","objectID":"/20210411/:4:0","tags":["C++","数据结构"],"title":"C++顺序表合并","uri":"/20210411/"},{"categories":["C++"],"content":"vscode2021新版的C++函数分文件编写配置 如图所示，需要下载这个插件 C/C++ Project Generator 安装并启用后，使用方法如下 创建工程文件后目录结构如下 main.cpp文件使用自定义的swap函数，swap函数的头文件放include文件夹，源文件放src文件夹 下面是运行c++程序生成可执行exe文件的步骤，如图 在终端运行，得到结果 ","date":"2021-03-08","objectID":"/20210308/:0:0","tags":["C++"],"title":"C++函数分文件编写(VScode2021配置教程)","uri":"/20210308/"},{"categories":["C++"],"content":"注意，千万不要用右上角的run code执行！ ↓↓↓我在我的博客首发这篇文章，欢迎在我的自建博客查看 我的博客文章 如果运行后显示中文乱码可以试试下面的代码 #include\u003ciostream\u003e #include \u003cwindows.h\u003e//用于函数SetConsoleOutputCP(65001);更改cmd编码为utf8 using namespace std; int main() { SetConsoleOutputCP(65001); cout\u003c\u003c\"中文正常显示\"\u003c\u003cendl; system(\"pause\"); return 0; } ","date":"2021-03-08","objectID":"/20210308/:1:0","tags":["C++"],"title":"C++函数分文件编写(VScode2021配置教程)","uri":"/20210308/"},{"categories":["C++"],"content":"指针的概念 内存地址 内存空间的编排是以字节为单位的，每一个字节（也称单元）都有一个编号，这就是地址。内存地址通常是一个大小为4个字节的整数（这与具体的计算机有关），一般用十六进制数表示。 指针 指针变量是一种用来存放地址的特殊变量，简称为指针。例如： int * iPointer; 编译时，系统将为指针变量iPointer分配另一个内存空间，用于存放某个变量的起始地址。 例如： iPointer = \u0026i; 则：指针变量iPointer里存放的就是变量i的起始地址 直接访问和间接访问 1.直接访问：按变量存取值。 根据变量的地址直接访问变量的内容。 变量名经编译后自动转换为变量的地址，直接访问时对变量的存取都是直接通过变量地址进行的。 例如，运算式k=i+j。 2.间接访问： 将变量a的地址存放在变量b中，先访问变量b得到变量b的值（即变量a的地址）后，再访问变量a。 对变量内容的访问要经过两次：先访问地址，后访问内容。 例如，先访问iPointer，即找到存放“i的地址”的单元，从中获得i的起始地址0x20000000，然后到0x20000000起始的4个字节中取出i的值。 指针的变量 指针变量简称指针，指针变量保存的是另一个变量b的地址； 实际上，这个地址就是一个有特殊意义的32位整数，它是系统为变量b分配的存储空间的起始地址，简称首地址。 在C++中，可以通过指针操作直接访问存储器中的单元。 ","date":"2021-02-06","objectID":"/20210206/:0:0","tags":["C++"],"title":"C++指针","uri":"/20210206/"},{"categories":["C++"],"content":"指针变量的声明 指针变量声明的一般形式为： \u003c类型标识符\u003e *指针变量名 注意： (1)申明指针变量时的 * ,只是一个标志，不表示取内容运算。 (2)指针变量名必须符合标识符的命名规则； (3)申明指针变量时的数据类型是指针变量所指的变量的数据类型； (4)申明指针变量时,””前后可以加空格，也可以不加； 比如：int *p1; 或者int* p1; 都可以 注意： int p1, p2; //p1是int变量，p2是指向int的指针 int p1, p2; //p2是int变量，p1是指向int的指针 建议紧跟指针变量名。 指针声明时需要特别注意： （1）指针变量具有数据类型 虽然指针存放的都是内存地址，但一个指针变量只能存放声明中指定类型数据的地址，否则编译时会出错。 例如：````int ip; float * fp; ``` 则：ip只能指向int型变量、fp只能指向float型变量。 （2）void型指针 void型指针是一个类型不确定的指针。根据需要可以将void型指针强制转换成int或其它类型的指针。 （3）空指针NULL C++语言中定义了一个符号常数NULL用来代表空指针，用来表示“无效”的指针值，其值为0。 ","date":"2021-02-06","objectID":"/20210206/:1:0","tags":["C++"],"title":"C++指针","uri":"/20210206/"},{"categories":["C++"],"content":"指针的基本操作 \u0026变量名 \u0026为取地址运算符，用来获取变量的首地址。 指针变量名 这里的星号“”为指向运算符（也称之为：取内容运算符、间接访问运算符），用来获取指针变量所指向的变量的值。 “\u0026”和“*”运算符都是一元运算符，其优先级高于所有二元运算符，采用从右到左的结合性。 例如： int i=5,j=3, *pInt; pInt = \u0026i; j=*pInt; 注意其中的差别： 第1句话中pInt是申明指针变量，只是一个标志； 第2句话取i的地址为已经申明过的指针变量赋值，pInt前不再加 第3句话中pInt表示取出指针pInt所指内存中的值，*表示取内容运算 体会差别： int *pInt = \u0026i; pInt = \u0026i; *pInt = j; ","date":"2021-02-06","objectID":"/20210206/:2:0","tags":["C++"],"title":"C++指针","uri":"/20210206/"},{"categories":["C++"],"content":"指针变量的初始化 指针变量也可以在声明时赋初值，完成指针变量的初始化。 注意： （1）对指针变量所赋的初始值必须是同类型变量的地址； 如： int i=5,j, *pInt=\u0026i; //可以 double f=0.3; int *pInt=\u0026f; //不可以 （2）指针变量使用之前必须做初始化（赋初值），即把某个普通变量的地址赋给它。否则指针变量的值就是不确定的，也称之为指针的指向不定，那么贸然使用，就会导致运行错误！ 例如： int a=0; int *x; *x=a; //错误！指向不定时无法为x所指的变量赋值！ a=*x; //错误！指向不定时无法读取x所指的变量！（即无法获取指针变量所指向的变量的值） //指针变量的定义和使用 #include\u003ciostream\u003e using namespace std; int main() { int m,n,\u0026k=m,*p1=\u0026m,*p2=\u0026n,*pInt=NULL; k=n=6; cout\u003c\u003c\"m=\"\u003c\u003cm\u003c\u003c\" ， n=\"\u003c\u003cn\u003c\u003c\" ， k=\"\u003c\u003ck\u003c\u003cendl; cout\u003c\u003c\"\u0026m=\"\u003c\u003c\u0026m\u003c\u003c\" ， \u0026n=\"\u003c\u003c\u0026n\u003c\u003c\" ， \u0026k=\"\u003c\u003c\u0026k\u003c\u003cendl; cout\u003c\u003c\"p1=\"\u003c\u003cp1\u003c\u003c\" ， p2=\"\u003c\u003cp2\u003c\u003c\" , pInt=\"\u003c\u003cpInt\u003c\u003cendl; cout\u003c\u003c\"*p1=\"\u003c\u003c*p1\u003c\u003c\" ， *p2=\"\u003c\u003c*p2\u003c\u003cendl; *p1+=3; p2=p1; *p2*=4; pInt=p2; cout\u003c\u003c\"*p1=\"\u003c\u003c*p1\u003c\u003c\" ， *p2=\"\u003c\u003c*p2\u003c\u003cendl; cout\u003c\u003c\"p1=\"\u003c\u003cp1\u003c\u003c\" ， p2=\"\u003c\u003cp2\u003c\u003cendl; cout\u003c\u003c\"m=\"\u003c\u003cm\u003c\u003c\" ， n=\"\u003c\u003cn\u003c\u003cendl; cout\u003c\u003c\"pInt=\"\u003c\u003cpInt\u003c\u003cendl; return 0; } ","date":"2021-02-06","objectID":"/20210206/:3:0","tags":["C++"],"title":"C++指针","uri":"/20210206/"},{"categories":["C++"],"content":"指针的赋值运算 （1）指针变量在赋值时，不允许直接将与指针变量类型不同的指针值赋予指针变量。 例如： int *iPointer, iValue;char ch='A'; iPointer= \u0026ch; //不允许 iValue = ch; //允许,将字符变量ch对应的ASCII码（整型数据）赋值给iValue （2）用数据类型不兼容的指针指向该数据类型的变量，可以使用强制类型转换。 如上例中，可以： iPointer=(int *)\u0026ch;//允许 注意：iPointer被强制指向了ch的起始地址，但ch是字符变量，因此若取指针iPointer所指的内容，则只有最低一个字节内有值（65），高位的三个字节都是随机值（调试显示：*iPointer=-858993599）。 （3）将其他的任何一种指针值赋予void*型指针变量都必须通过强制类型转换。 如： void *vPointer = (void *)iPointer; （4）通过强制类型转换，也可以将指针变量赋值给一个整型变量，或将一个整型常量赋予一个指针变量。例如： iValue = (int)iPointer; iPointer=(int *)0x98980000;//但这样的地址通常不能做取内容运算！ 但下面两种做法是错误的： int *iPointer = \u0026100; int *iPointer = \u0026(100*20+iValue); ","date":"2021-02-06","objectID":"/20210206/:4:0","tags":["C++"],"title":"C++指针","uri":"/20210206/"},{"categories":["C++"],"content":"指针的算数运算 对于非void*型的指针变量，只能进行加一个整数、减一个整数和两个指针变量相减3种运算。void*型指针变量不能做任何算术运算。 对非void* 型的指针变量做加减整数的运算，实际上就是对地址进行加法或减法运算，但这种加减是按照指针所指变量的类型所占的字节数为单位进行的。 例如： int iValue; int* iPointer1=\u0026iValue，*iPointer2; iPointer2=iPointer1+1; 假设iValue的初始地址是0x20000000，即iPointer1的值为0x20000000，则iPointer2=iPointer1+1后，iPointer2的值为0x20000004（注意不是0x20000001） 指针的自加（++）与自减（–）运算，即： iPointer2++; --iPointer1; 分别等价于： iPointer2 = iPointer2+1； iPointer1 = iPointer1-1； ","date":"2021-02-06","objectID":"/20210206/:5:0","tags":["C++"],"title":"C++指针","uri":"/20210206/"},{"categories":["C++"],"content":"指针的关系运算 指针间的关系运算结果就是两个指针所指的地址值的大小的关系运算结果。两个进行关系运算的指针一般要求是同一类型的指针。 #include\u003ciostream\u003e using namespace std; int main(){ int n=3,*p1=\u0026n,*p2=NULL; cout\u003c\u003c\"p1=\"\u003c\u003cp1\u003c\u003c\" ， p2=\"\u003c\u003cp2\u003c\u003cendl; p1=p2+4; //以int所占字节数为单位进行加减，注意地址采用16进制表示。 p2++; cout\u003c\u003c\"p1=\"\u003c\u003cp1\u003c\u003c\" ，p2=\"\u003c\u003cp2\u003c\u003cendl; p2=p1-2; cout\u003c\u003c\"p1=\"\u003c\u003cp1\u003c\u003c\" ， p2=\"\u003c\u003cp2\u003c\u003cendl; return 0; ","date":"2021-02-06","objectID":"/20210206/:6:0","tags":["C++"],"title":"C++指针","uri":"/20210206/"},{"categories":["C++"],"content":"指针与数组 在声明一个数组时，C++语言将在内存中开辟两个空间，一个用于保存数组元素，另一个用于保存数组的第1个元素的地址，称为数组的首地址，数组名就是保存了数组首地址的指针。 因此对数组元素的访问除了常用的下标法外，还可以用指针操作代替。 例如，如果定义： int iArray[10],*iPointer=iArray; //或者int *iPointer=\u0026iArray[0]; 这样通过指针iPointer也可以访问数组中的任意一个元素，即： iArray[n]等同于*(iPointer+n) 同样，也可以把指针作为数组名使用，使用下标法访问数组元素，以下4句是等价的： iValue = iArray[5]; iValue = iPointer[5]; iValue = *(iPointer+5); iValue = *(iArray+5); 尽管指针和数组名都是指针，但它们也有区别： 指针变量是变量，是可以不断赋值的；而数组名则是指针型常量，只能指向固定的内存地址（即系统为数组所分配的内存空间的首地址），因此不能给数组名赋值，如： char cArray[10],ch; cArray = \u0026ch; //错误，不允许将一个指针值赋给数组名！ ","date":"2021-02-06","objectID":"/20210206/:7:0","tags":["C++"],"title":"C++指针","uri":"/20210206/"},{"categories":["C++"],"content":"使用指针访问数组元素 如果定义一维数组int a[10];则一维数组a中的任何一个元素a[i]等同于*(a+i) //如何将中间的while循环，改为for循环 for(int i=0;i\u003cn;i++,iPointer++) iSum+=*iPointer; //或者： for(int i=0;i\u003cn;i++) iSum+=*iPointer++; 使用指针求一维数组中所有元素之和。 int sum(int *iPointer,int n) { int iSum=0; while(n\u003e0) { iSum+=*iPointer; iPointer++; n--; } return iSum; } int main() { int iArray[10]={6,7,8,9,5,4,3,2,10,1}; cout\u003c\u003c\"数组各元素和: sum=\"\u003c\u003csum(iArray,10)\u003c\u003cendl; return 0; } 使用指针对数组中各元素进行排序。 void order(int *iPointer,int n) { int i,j,t,p; for(i=0;i\u003cn-1;i++) { p=i; for(j=i+1;j\u003cn;j++) { if(*(iPointer+p)\u003c=*(iPointer+j)) p=j; } if(p!=i) { t=*(iPointer+i); *(iPointer+i)=*(iPointer+p); *(iPointer+p)=t; } } } int main(){ int iArray[10]={6,7,8,9,5,4,3,2,10,1}; order(iArray,10); cout\u003c\u003c\"排序后的数组为：\"\u003c\u003cendl; for(int i=0;i\u003c10;i++) cout\u003c\u003ciArray[i]\u003c\u003c\" \"; cout\u003c\u003cendl; return 0; } order函数的其它实现方法：下标法访问数组元素 void order(int iPointer[],int n) { int i,j,t,p; for(i=0;i\u003cn-1;i++) { p=i; for(j=i+1;j\u003cn;j++) { if(iPointer[p]\u003c=iPointer[j]) p=j; } if(p!=i) { t=iPointer[i]; iPointer[i]=iPointer[p]; iPointer[p]=t; } } } ","date":"2021-02-06","objectID":"/20210206/:8:0","tags":["C++"],"title":"C++指针","uri":"/20210206/"},{"categories":["C++"],"content":"指向多维数组的指针 多维数组的元素在计算机中也是线性存储的(C++采用按行顺序保存的原则)，只要知道保存某个多维数组的内存区域的首地址，就可以通过指针访问多维数组中的任何一个元素。例如，声明以下二维数组： int iMatrix [3][4]; 现在定义一个指针变量，并将该二维数组的首地址赋予它： int *iPointer=\u0026iMatrix[0][0]; 则二维数组iMatrix中的任何一个元素使用iPointer这个指针来访问的规则是： *(iPointer+m*4+n) //等同于iMatrix [m][n] 多维数组的数组名同样也是指针，但它不指向多维数组的第一个元素，而是指向存放第一个数组元素地址的指针，即多维数组的数组名是指向（指向第一个数组元素的）指针的指针。 比如：将二维数组iMatrix[3][4]看成由3个一维数组iMatrix[i] (0\u003ci\u003c3)组成的数组，其中： iMatrix[0]等同于\u0026iMatrix[0][0] iMatrix[1]等同于\u0026iMatrix[1][0] iMatrix[2]等同于\u0026iMatrix[2][0] 因而，有二维数组iMatrix就是指向这3个一维数组iMatrix[i]组成的数组的第一个元素iMatrix[0]的指针，而iMatrix[0]是指向iMatrix[0][0]的指针。 故：iMatrix的数据类型是int**，即指向int指针变量的指针，也称二级指针 从地址值的角度看，iMatrix、iMatrix[0]和\u0026iMatrix[0][0]所代表的值是相同的，但其本质含义却不同。 //使用指针实现二维数组转置（行列互换），并输出结果。 #include\u003ciostream\u003e #include\u003ciomanip\u003e using namespace std; int main(){ int iMatrix[3][4]={1,2,3,4,5,6,7,8,9,10,11,12}; int i,j,*iP; cout\u003c\u003c\"转置前的矩阵：\"\u003c\u003cendl; for(i=0;i\u003c3;i++) { iP=iMatrix[i]; //iP存放各行的起始地址(在内循环外) for(j=0;j\u003c4;j++) cout\u003c\u003csetw(6)\u003c\u003c*(iP+j); cout\u003c\u003cendl; } cout\u003c\u003c\"转置后的矩阵：\"\u003c\u003cendl; for(j=0;j\u003c4;j++) { for(i=0;i\u003c3;i++) { iP=iMatrix[i]; //iP存放各行的起始地址(在内循环中) cout\u003c\u003csetw(6)\u003c\u003c*(iP+j); } cout\u003c\u003cendl; } return 0; } ","date":"2021-02-06","objectID":"/20210206/:9:0","tags":["C++"],"title":"C++指针","uri":"/20210206/"},{"categories":["C++"],"content":"多级指针 多级指针一般又称为指针的指针。如果指针变量保存的是另一个指针变量的地址，则这个指针变量就是指针的指针。定义二级指针变量的一般形式是： \u003c类型标识符\u003e **二级指针变量名 例如： int i=5,*p=\u0026i,**pp=\u0026p; 使用指针操作二维数组，并输出相应的指针值（地址）。 注意：比较各级指针加1后，地址实际增加的量。 ","date":"2021-02-06","objectID":"/20210206/:10:0","tags":["C++"],"title":"C++指针","uri":"/20210206/"},{"categories":["C++"],"content":"指针数组 如果数组的每一个元素都是类型相同的指针变量，则该数组称为指针数组。声明指针变量数组的形式如下： \u003c类型标识符\u003e *指针数组名[数组长度] 例如： char *pString[6]; //声明一个保存6个char *型元素的指针数组 //今天星期几？ int i; char *pDay[]={\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\", \"Friday\",\"Saturday\",\"Sunday\"}; char **ppDay; cout\u003c\u003c\"输入整数1~7:\"; cin\u003e\u003ei; ppDay=pDay+i-1; cout\u003c\u003c\"Today is \"\u003c\u003c*ppDay\u003c\u003cendl; ","date":"2021-02-06","objectID":"/20210206/:11:0","tags":["C++"],"title":"C++指针","uri":"/20210206/"},{"categories":["C++"],"content":"指针变量作为函数参数 普通变量作为函数参数实现的是数值传递，而指针变量作为函数参数实现的是地址传递。 数值传递 数值传递是普通变量作为函数形参，主调函数中的实参内容是一个数值确定的表达式，适合少量数据的传递。 void change(int,int); //函数声明语句 int main(){ int a=5,b=10; cout\u003c\u003c\"函数调用前：a=\"\u003c\u003ca\u003c\u003c\" ,b=\"\u003c\u003cb\u003c\u003cendl; change(a,b); //以a、b的值为实参调用函数 cout\u003c\u003c\"函数调用后：a=\"\u003c\u003ca\u003c\u003c\" ,b=\"\u003c\u003cb\u003c\u003cendl; return 0; } void change(int m,int n){ int temp; temp=m; m=n; n=temp; cout\u003c\u003c\"函数中参数：m=\"\u003c\u003cm\u003c\u003c\",n=\"\u003c\u003cn\u003c\u003cendl; } 地址传递 地址传递是指针变量作为函数参数,这时主调函数中的实参是某个变量的内存地址，被调函数的形参则必须是与实参类型相同的指针变量，用以接受由实参传过来的地址。函数调用时，通过地址传递的实参与形参指向相同的内存单元，即形参所指内容与实参所指内容为同一段内存空间，因此形参所指内容发生更改，实参也会发生相应的更改。 从键盘输入两个整数，使用地址传递实现两数的真正交换。 void change(int *,int *); //函数声明语句 int main() { int a=5,b=10; cout\u003c\u003c\"函数调用前：a=\"\u003c\u003ca\u003c\u003c\" ,b=\"\u003c\u003cb\u003c\u003cendl; change(\u0026a,\u0026b); //以a、b值的地址为实参调用函数 cout\u003c\u003c\"函数调用后：a=\"\u003c\u003ca\u003c\u003c\" ,b=\"\u003c\u003cb\u003c\u003cendl; return 0; } void change(int *m,int *n) { int temp; temp=*m; *m=*n; *n=temp; cout\u003c\u003c\"函数中参数：m=\"\u003c\u003c*m\u003c\u003c\",n=\"\u003c\u003c*n\u003c\u003cendl; } 在C++中，需要返回多个变量值时，也可以采用地址传递的方式，将变量地址传给函数形参，在函数内通过指针直接修改位于函数外部的变量的值，从而实现返回多个值的目的。 ","date":"2021-02-06","objectID":"/20210206/:12:0","tags":["C++"],"title":"C++指针","uri":"/20210206/"},{"categories":["C++"],"content":"指向函数的指针 要调用一个函数，只要知道被调用函数的入口地址即可。函数名实际上就是一个指针，它指向函数的入口地址。因此可以定义一个指针变量，并赋予它函数名，这样的指针变量就指向该函数的入口地址。称这样的指针变量为指向函数的指针变量，简称函数指针变量，通过函数指针变量就可以实现调用它所指函数的目的。 1．函数指针变量的声明与使用 函数指针变量声明的一般形式为： \u003c类型标识符\u003e (*函数指针变量名)(参数表) 注意： 类型标识符说明函数指针变量所指函数返回值的数据类型； 定义中的(*函数指针变量名)的两对圆括号都不能遗漏，否则就成了返回指针的函数； 参数表中形参的类型、个数都必须与所指的函数一致。 若定义函数：void func(int m,int n); 则指向该函数的函数指针变量可定义为： void (*pFpointer) (int,int); 使用已经定义的函数指针变量来调用函数，分以下两步： （1）将函数名赋予己定义的函数指针变量，其形式为： 函数指针变量名=函数名 如：pFpointer = func; （2）使用函数指针变量调用它所指的函数，可用的形式有： (*函数指针变量名)(实参表) 或： 函数指针变量名(实参表) 如，下面三个函数调用语句的功能是相同的： func(3,4); (* pFpointer)(3,4); pFpointer(3,4); 注意：函数的指针不能进行算术运算,因此不能： pFpointer++ //错误！ pFpointer-1 //错误！ 函数指针变量作为函数的参数 函数指针的用处在于可以作为函数参数传递给被调函数，使得被调函数可以根据情况，调用不同的的函数，增强其通用性。 将函数指针变量作为函数参数。 int add(int x,int y) { return x+y; } int sub(int x,int y) { return x-y; } int funct(int (*pFunc)(int,int),int x,int y) { int result; result=(*pFunc)(x,y); //等价于result=pFunc(x,y); return result; } int main() { int a,b; cin\u003e\u003ea\u003e\u003eb; cout\u003c\u003c\"a+b=\"\u003c\u003cfunct(add,a,b)\u003c\u003cendl; cout\u003c\u003c\"a-b=\"\u003c\u003cfunct(sub,a,b)\u003c\u003cendl; return 0; } ","date":"2021-02-06","objectID":"/20210206/:13:0","tags":["C++"],"title":"C++指针","uri":"/20210206/"},{"categories":["C++"],"content":"用梯形积分公式求两个函数的积分 #include\u003ciostream\u003e #include\u003ciomanip\u003e using namespace std; float f1(float x);//函数声明 float f2(float x);//函数声明 float integral(float (*p)(float),float a,float b);//函数声明 int main() { float s1,s2; s1=integral(f1,1,1.1);//函数调用 s2=integral(f2,1,1.1);//函数调用 cout\u003c\u003c\"s1=\"\u003c\u003csetprecision(5)\u003c\u003cs1\u003c\u003cendl; cout\u003c\u003c\"s2=\"\u003c\u003csetprecision(5)\u003c\u003cs2\u003c\u003cendl; system(\"pause\"); return(0); } float integral(float (*p)(float),float a,float b) { float sum; sum=0.5*(b-a)*(p(a)+p(b));//利用函数指针间接调用函数 return(sum); } float f1(float x) { float s; s=2*x+3; return(s); } float f2(float x) { float s; s=x*x-3*x+5; return(s); } ","date":"2021-02-06","objectID":"/20210206/:14:0","tags":["C++"],"title":"C++指针","uri":"/20210206/"},{"categories":["C++"],"content":"指针作为函数的返回类型 返回值是地址的函数称为指针函数，其定义的一般形式为： \u003c类型标识符\u003e*函数名(形参表) { 函数体 } //函数的返回值是指针类型。 #include\u003ciostream\u003e using namespace std; int *pfun(int *p){ if(*p!=0) { cout\u003c\u003cp+1\u003c\u003cendl; return p+1; } else return p; } int main(){ int s[]={1,2,3}; cout\u003c\u003c*pfun(\u0026s[1])\u003c\u003cendl; // cout\u003c\u003cpfun(\u0026s[1])\u003c\u003cendl; system(\"pause\"); return 0; } 注意：作为函数的返回的指针，不能是在函数体内定义的局部变量。 ","date":"2021-02-06","objectID":"/20210206/:15:0","tags":["C++"],"title":"C++指针","uri":"/20210206/"},{"categories":["C++"],"content":"字符型指针与字符串 对字符串的再认识: 字符串由一系列字符组成，每一个字符在内存中按顺序存放，最后一个字符后面一定是结束符’\\0’ 。 在内存中识别字符串关键有以下两点： ①字符串的首地址。 ②字符串结束符’\\0’。 对字符串的处理通常是采用循环语句，从字符串的首地址开始，依次取出指针所指内存里的各个字符，直至遇到’\\0’为止。 ","date":"2021-02-06","objectID":"/20210206/:16:0","tags":["C++"],"title":"C++指针","uri":"/20210206/"},{"categories":["C++"],"content":"使用字符型指针定义字符串 使用字符型指针定义字符串的形式如下： char *指针变量名=\"字符串\" 注意：字符型指针比字符型数组更灵活（因为字符型数组只能初始化，不能再次赋值，而字符型指针定义字符串却可以！）。 char pString1[]=\"I love China!\"; char *pString2=\"This is a string2.\"; pString2=\"This is a new string2.\"; //允许，且新字符串更长！ pString1=\"This is a new string1.\"; //不允许，数组名不能再赋值pString2=pString1; //允许 pString1=pString2; //不允许，数组名不能被赋值 但是： *pString1 = 'a';//允许, pString1[0]= 'a' *pString2 = 'a';//不允许，使用字符型指针定义字符串后，指针所指单个内存的内容只允许读，不允许写！ *pString1 = *pString2;//允许, pString1[0]= pString2[0]=‘T' 使用字符型指针实现字符串的复制。 void copy_string(char *to,char *from)//复制函数 { for(;*from!='\\0';from++,to++) *to=*from; *to='\\0'; //赋值字符串结束标识 } int main() { char pSource[]=\"I am a teacher.\";//可以用char *pSource替换 char pDestination[]=\"you are a student.\"; //不能用char *pDestination替换（使用字符型指针定义字符串后，指针所指单个内存的内容只允许读，不允许写！ ） //pDestination字符数组长度\u003e=pSource字符数组长度 copy_string(pDestination,pSource); cout\u003c\u003c\"pSource:\"\u003c\u003cpSource\u003c\u003cendl; cout\u003c\u003c\"pDestination:\"\u003c\u003cpDestination\u003c\u003cendl; return 0; } ","date":"2021-02-06","objectID":"/20210206/:17:0","tags":["C++"],"title":"C++指针","uri":"/20210206/"},{"categories":["C++"],"content":"字符串标准库函数 C++提供了许多操作字符串的标准库函数，这些函数使用时，必须在应用程序的开头添加包含头文件string.h的预处理命令： #include \u003cstring\u003e //使用C++的标准库函数strcpy( )实现字符串的复制。 #include\u003ciostream\u003e #include \u003cstring\u003e using namespace std; int main() { char pSource[]=\"I am a teacher.\"; //15个字符 char pDestination[]=\"you are a student.\"; //18个字符 //若char pDestination[]=“student.”; 后面拷贝时会错误！ //pDestination字符串长度\u003e=pSource字符串长度 strcpy(pDestination,pSource); //等价于strncpy(pDestination,pSource,16); cout\u003c\u003c\"pSource:\"\u003c\u003cpSource\u003c\u003cendl; cout\u003c\u003c\"pDestination:\"\u003c\u003cpDestination\u003c\u003cendl; return 0; } ","date":"2021-02-06","objectID":"/20210206/:18:0","tags":["C++"],"title":"C++指针","uri":"/20210206/"},{"categories":["C++"],"content":"动态内存分配与new和delete运算符 静态内存分配是指在编译阶段就分配好存储空间，其空间大小在程序运行过程中不可更改；动态内存分配则是在程序中通过调用内存分配函数malloc或内存分配运算符new取得存储空间； 区别：静态内存分配的变量空间，在其生存期结束后自动收回；而动态内存分配的存储空间，必须由程序员通过语句显式地将其归还给系统。 ","date":"2021-02-06","objectID":"/20210206/:19:0","tags":["C++"],"title":"C++指针","uri":"/20210206/"},{"categories":["C++"],"content":"new运算符 new运算符用于在内存中动态分配一块存储空间。new运算符的使用形式为： 指针变量=new \u003c类型标识符\u003e[长度] 例如： char *cBuffer=new char [256]; //分配256个char型数据的存储空间 注意： ①如果分配的存储空间长度为1个单位，则可以省略new运算符格式中的中括号和中括号中的整数。 如：int *pInt=new int; //等价于int *pInt=new int[1]; ②使用new运算符分配存储空间时，其空间长度可以是变量，也可以是数值表达式，但无论是什么，其类型必须是整型。 int nSize=5; int *pInt=new int[nSize+5]; ③由new所分配的存储空间是连续的，且通常将存储空间的首地址赋予一个指针变量，所以可以通过该指针的变化访问所分配存储空间的每一个元素。 ④如果当前内存无足够的存储空间可分配，则new运算符返回NULL。 由new运算符分配的内存空间在使用完毕之后必须使用delete运算符释放。 delete运算符的使用有两种形式： 形式一： delete指针 //释放空间长度为1个单位（与指针类型有关）的内存空间 形式二： delete [ ]指针 //释放空间长度大于1的内存空间 delete后面的是使用new运算符分配内存空间时返回的指针 ，也可以是NULL，若是NULL，则delete运算符什么也不做。 例如： int *pInt=new int; delete pInt; int *pManyInt = new int[10]; delete []pManyInt; 注意： ①用new运算符获得的内存空间，只许使用一次delete，不允许多次对同一块空间进行多次释放，否则将会产生严重错误。 ②delete只能用来释放由new运算符分配的动态内存空间，对于程序中的变量、数组的存储空间，不得使用delete运算符释放。 复制字符串，依据源字符串的长度动态分配目的字符串的存储空间。 #include \u003ciostream\u003e using namespace std; void copy_string(char *to, char *from)//复制字符串函数 { char * tt=to; while(*from!='\\0’) *tt++=*from++; *tt='\\0';//赋值字符串结束标识 } int main() { char pSource[]=\"I am a teacher.\"; int nSize=0; while(pSource[nSize]!=0) nSize++; //定义目的字符串并申请分配内存空间(源字符串长度并加1) char *pDestination=new char[nSize+1]; if(pDestination!=NULL) { copy_string(pDestination,pSource); cout\u003c\u003c\"pSource:\"\u003c\u003cpSource\u003c\u003cendl; cout\u003c\u003c\"pDestination:\"\u003c\u003cpDestination\u003c\u003cendl; } else cout\u003c\u003c\"No memory space to copy operation!\"\u003c\u003cendl; delete []pDestination; system(\"pause\"); return 0; } ","date":"2021-02-06","objectID":"/20210206/:20:0","tags":["C++"],"title":"C++指针","uri":"/20210206/"},{"categories":["C++"],"content":"结构体 C++里数组是由相同数据类型的一组元素构成的集合，但实际问题中，经常会遇到由相互关联的，但类型不同的数据组成的数据结构。比如：描述一个学生的数据实体应该包括其学号、姓名、性别、年龄、成绩等数据。如果用多个独立的简单数据类型表示的话，就无法体现其整体性，也不便于数据的整体操作。 C++语言提供了结构体类型对这样的数据结构进行描述。 这里类似Python中的字典嵌套其他类型的键值对。 形式 struct \u003c结构体类型名\u003e { \u003c类型标识符\u003e 成员名l; \u003c类型标识符\u003e 成员名2; ………… \u003c类型标识符\u003e 成员名n; }; 例如： struct Student //定义学生结构体类型 { unsigned int no; //学号 char name[20]; //姓名 bool sex; //性别 int math; //高数成绩 int english; //英语成绩 int computer; //计算机成绩 float aver; //平均成绩 }; 注意： 1.结构体定义时，使用关键字struct,结构体类型的命名应符合C++标识符命名的规则，之后就可以用定义好的结构体类型的名字，与C++中的基本数据类型一样，也可以用来申明该结构体类型的变量。 2.花括号内是对该结构体各个成员的类型声明，成员声明的形式与变量定义的形式类似，成员可以是基本数据类型，也可以是另一个诸如结构体这样的复杂数据类型； 3.C++语言规定，结构体类型成员列表中不能包含自身,即不能递归定义，但可以包括其他结构体类型，或者是同类型的结构体指针。 4.结尾处的分号不能省略。 5.若同一个结构体类型要被多个源文件使用，则通常将这些结构体类型的定义集中存放在一个头文件中，使用该结构体的源文件只要用#include命令包含此头文件即可，不必再每个源文件中重复同样的结构体定义。 6.结构体类型定义只是说明了一个数据结构的模型，并没有定义实例，也不要求分配实际的存储空间。只有在定义结构体变量时，C++才为其分配内存。 ","date":"2021-02-02","objectID":"/20210202/:1:0","tags":["C++"],"title":"C++自定义数据类型","uri":"/20210202/"},{"categories":["C++"],"content":"声明结构体变量 通常使用形式一，形式二是C语言形式。 形式： 形式一：\u003c结构体类型名\u003e 变量名 形式二：struct \u003c结构体类型名\u003e 变量名 声明结构体变量也可在定义结构体类型的同时进行： struct 结构体类型名 { \u003c类型标识符\u003e 成员名l; \u003c类型标识符\u003e 成员名2; ………… \u003c类型标识符\u003e 成员名n; }变量1,变量2,…… ,变量n; 实例： struct date { int year; int month; int day; }d1,d2; date d3,d4; 若省略结构体类型名，即成为无名结构体类型,无法再次使用该无名结构体类型再定义新的变量。 ","date":"2021-02-02","objectID":"/20210202/:2:0","tags":["C++"],"title":"C++自定义数据类型","uri":"/20210202/"},{"categories":["C++"],"content":"结构体长度 结构体的长度是各个成员在内存中所占字节数之和。例如： Student stu; 则stu将在内存中占用41个字节，其中： unsigned int no; //4个字节 char name[20]; //20个字节 bool sex; //1个字节 int math; //4个字节 int english; //4个字节 int computer; //4个字节 float aver; //4个字节 ","date":"2021-02-02","objectID":"/20210202/:3:0","tags":["C++"],"title":"C++自定义数据类型","uri":"/20210202/"},{"categories":["C++"],"content":"结构体变量的初始化 结构体变量的初始化形式为： \u003c结构体类型\u003e 变量名={表达式1,表达式2,…,表达式n} 注意： 1.表达式各类型要与结构体成员的类型对应一致。 2.只可在声明结构体变量时对其进行初始化，不可在定义结构体类型时，对结构体变量初始化。 //错误写法如下 struct date { int year; int month; int day; }d1; d1 ={2000,1,1}; //结构体的变量定义和初始化也不能分开 //错误写法如下 struct date { int year=2000; int month=1; int day=1; }; ","date":"2021-02-02","objectID":"/20210202/:4:0","tags":["C++"],"title":"C++自定义数据类型","uri":"/20210202/"},{"categories":["C++"],"content":"结构体变量引用其成员的形式 访问一个结构体变量的成员的形式是： \u003c结构体变量名\u003e.\u003c成员名\u003e 其中，“.”称为成员运算符，它的优先级高于所有的算术运算符、条件运算符和逻辑运算符。 例子： Student stu={20130101,”XuXin”,false,86,90,98}; stu.ave=(stu.math+stu.english+stu.computer)/3; 如果一个结构体中包含另一个结构体作为其成员，则访问该成员中的成员时，要使用如下形式： \u003c结构体变量名\u003e.\u003c结构体成员名\u003e.\u003c成员名\u003e 例如在学生结构体Student中有一个成员表示学生的出生日期birthday，其类型是如下Date结构体: struct Date { int year; int month; int day; }; struct Student //定义新的学生结构体类型 { unsigned int no; //学号 char name[20]; //姓名 bool sex; //性别 Date birthday; //出生日期 int math; //高数成绩 int english; //英语成绩 int computer; //计算机成绩 float aver; //平均成绩 }stu1; 结构体变量本身不代表一个特定的值，因此无法直接对结构体变量进行算术运算、比较运算和逻辑运算，但作为一个整体结构体可以作为函数参数，同类型的结构体之间也可以相互赋值，其赋值规则是按成员依次进行赋值，如： date d1,d2={2001,1,15}; d1 = d2; ","date":"2021-02-02","objectID":"/20210202/:5:0","tags":["C++"],"title":"C++自定义数据类型","uri":"/20210202/"},{"categories":["C++"],"content":"结构体数组 多个同一类型的结构体变量也可以用数组的形式来处理，称为结构体数组。 ","date":"2021-02-02","objectID":"/20210202/:6:0","tags":["C++"],"title":"C++自定义数据类型","uri":"/20210202/"},{"categories":["C++"],"content":"共用体 C++允许同一段内存空间中存储不同类型的数据，用于节省内存空间或数据共享。这就需要使用共用体类型。 共用体在同一段内存空间存储不同类型的数据。共用体类型的定义： union [共用体类型名] { \u003c类型标识符\u003e 成员名1； \u003c类型标识符\u003e 成员名2； ………… \u003c类型标识符\u003e 成员名n； }[变量1,变量2,……,变量n]; 例如： union UnionDate { int nIntData; char cCharData; float fRealData; }; ","date":"2021-02-02","objectID":"/20210202/:7:0","tags":["C++"],"title":"C++自定义数据类型","uri":"/20210202/"},{"categories":["C++"],"content":"共用体类型的定义和结构体类型定义很相似，不同之处在于结构体中的成员所占有的存储空间是各自分开，且整体连续的，而共用体的成员所占用的空间是共享的，即共用体的各个成员拥有同样的起始地址。因此对共用体中一个成员的赋值会影响到其他所有成员，且共用体所占空间的长度由其中所占空间的长度最长的成员决定。 声明共用体变量的形式为： \u003c共用体类型名\u003e 变量名 注意：共用体变量不允许赋初始值。 共用体变量中成员的访问形式为： \u003c共用体变量名\u003e.\u003c成员名\u003e ","date":"2021-02-02","objectID":"/20210202/:7:1","tags":["C++"],"title":"C++自定义数据类型","uri":"/20210202/"},{"categories":["C++"],"content":"共用体与结构体的区别 struct Student { int no; char name[15]; int score[3]; float aver; } stu; union Utest { char a; int b; char c[15]; } uni; cout\u003c\u003c\"结构体变量stu的长度：\"\u003c\u003csizeof(stu)\u003c\u003cendl; cout\u003c\u003c\"共用体变量uni的长度：\"\u003c\u003csizeof(uni)\u003c\u003cendl; 注意：由于cpu的对界问题，sizeof返回的和实际长度不一致。这里采用4对齐。 struct S { int c1; int c2; }; union U { int a; int b; S d; }; int main() { U g; g.b=10; g.b=g.a+20; g.d.c1=g.a+g.b; cout\u003c\u003cg.a\u003c\u003c\", \" \u003c\u003cg.b\u003c\u003c\", \"\u003c\u003cg.d.c1\u003c\u003cendl; return(0); } 说明： 结构体类型S的长度为4+4=8字节，又由于结构体变量d是共用体类型U中占空间最长的成员，所以共用体变量g的长度为8个字节。其中a、b以及结构体变量d的成员c1占据同一段内存空间。因此：当g的成员b被赋值10后，g的成员a和d的成员c1也均为10，所以经过运算后，g.a、g.b、g.d.c1均为60. ","date":"2021-02-02","objectID":"/20210202/:8:0","tags":["C++"],"title":"C++自定义数据类型","uri":"/20210202/"},{"categories":["C++"],"content":"枚举类型 枚举类型是一系列有标识名的整型常量的集合。枚举类型也是唯一允许用符号代表数据的数据类型，定义形式如下： enum \u003c枚举类型名\u003e{〈枚举常量表〉}[枚举变量] 例如： enum Days{Sun ,Mon,Tue,Wed,Thu,Fri,Sat} today; 说明：缺省时，系统为每一个枚举常量都对应一个整数，并从0开始，逐个增1，这些缺省的值也可重新指定，例如： enum Days{Sun ,Mon,Tue=4,Wed,Thu=8,Fri,Sat}today; 则各枚举常量对应的整数依次为0,1,4,5,8,9,10。 注意：枚举变量的取值只能是枚举常量表中的某个枚举常量，而不能用一个整型数据或其它类型数据直接赋值。例如： today=Mon; //合法，值为1 today=3; //不合法，不能直接赋值, today=(enum Days)3;//可以,也可以today=(Days)3;即强制类型转换！ int i=today; // 枚举变量直接赋值给整型变量，合法，值为3 注意：不要在定义枚举类型的同时，再对枚举常量、枚举变量或枚举类型名重新定义，例如下列定义均不合法： int today; int Sun; ","date":"2021-02-02","objectID":"/20210202/:9:0","tags":["C++"],"title":"C++自定义数据类型","uri":"/20210202/"},{"categories":["C++"],"content":"实例 五色球中取三种不同颜色球的组合 #include\u003ciostream\u003e using namespace std; int main() { enum color{red,yellow,blue,white,black}; int count=0; int i,j,k,t,temp; for(i=red;i\u003c=blue;++i) for(j=i+1;j\u003c=white;++j) { for(k=j+1;k\u003c=black;k++) { ++count; for(t=0;t\u003c3;++t) { switch(t) { case 0: temp=i;break; case 1: temp=j;break; case 2: temp=k;break; default: cout\u003c\u003c\"Impossible\\n\"; } switch((enum color)temp) { case red: cout\u003c\u003c\"red\\t\";break; case yellow: cout\u003c\u003c\"yellow\\t\";break; case blue: cout\u003c\u003c\"blue\\t\";break; case white: cout\u003c\u003c\"white\\t\";break; case black: cout\u003c\u003c\"black\\t\";break; default: cout\u003c\u003c\"Impossible\\n\"; } }//for t cout\u003c\u003cendl; } //for k } //for j cout\u003c\u003c\"共有\"\u003c\u003ccount\u003c\u003c\"种组合\\n\"; return(0); } ","date":"2021-02-02","objectID":"/20210202/:10:0","tags":["C++"],"title":"C++自定义数据类型","uri":"/20210202/"},{"categories":["C++"],"content":"类型自定义语句 用户使用typedef语句可以将一个标识符定义为数据类型标识符。typedef语句的形式是： typedef\u003c已有的类型名\u003e\u003c类型别名\u003e 注意：typedef语句只可以将一个已有的类型名用一个新的类型名来代替； 例如： typedef float FLOAT; typedef char CH10[10]; //注意写法，不能用typedef char[10] CH10; 则可以： FLOAT x,y; CH10 str; //str是具有10个元素的字符型数组 它们等价于： float x,y; char[10] str; 又例如： struct complex { int real; int imag; }; typedef complex comp; comp cc ={1,2}; 或： typedef struct complex { int real; int imag; }comp; comp cc ={1,2}; ","date":"2021-02-02","objectID":"/20210202/:11:0","tags":["C++"],"title":"C++自定义数据类型","uri":"/20210202/"},{"categories":["C++"],"content":"类和对象 类是面向对象程序设计的基础和核心，也是实现数据抽象的工具。 类实际上是一种特殊的用户自定义数据类型，但与一般的数据类型不同的是，类中不仅包含有一组数据，还有一组函数。 定义好的类，就可以用来声明变量，类的变量习惯称之为类的对象。 ","date":"2021-02-02","objectID":"/20210202/:12:0","tags":["C++"],"title":"C++自定义数据类型","uri":"/20210202/"},{"categories":["C++"],"content":"类的定义 类定义的一般形式为： class \u003c类名\u003e { Private: \u003c私有成员函数和数据成员的声明\u003e Public: \u003c公有成员函数和数据成员的声明\u003e }; \u003c各个成员函数的定义\u003e 一般类中成员函数的原型声明写在类定义体内，而成员函数的定义一般写在类定义之外。通常采用下面的形式定义成员函数： \u003c类型标识符\u003e\u003c类名\u003e::\u003c成员函数名\u003e(形参表) { \u003c函数体\u003e } 作用域运算符（::）指出该成员函数所属的类 class CRectangle { private: int length,width; public: CRectangle(int l,int w) { length=l;width=w; } int get_area(); }; int CRectangle::get_area() { return length*width; } 说明： C++定义类时，可以将类的各个成员划分为不同的访问级别，即可以设置三种访问控制属性：public表示成员是公有的；private表示成员是私有的；protected表示成员是受保护的； 公有成员可以在程序中任何地方访问；而私有成员和保护成员都只有在类的内部能够访问（提高数据的安全性！） 设置三种访问控制属性的关键字： public,private,protected在类内出现的先后次序无关，并可以多次出现，但一个成员只能有一种访问控制属性。 ","date":"2021-02-02","objectID":"/20210202/:13:0","tags":["C++"],"title":"C++自定义数据类型","uri":"/20210202/"},{"categories":["C++"],"content":"对象的使用 类与对象的关系，相当于普通数据类型与其变量的关系。类是一种抽象概念，一个类只是定义了一种新的数据类型，而只有申明对象时才真正创建了这种数据类型的物理实体。如： class CRectangle { private: int length = 0; //错误 int width = 0; //错误 }; 对象声明的一般形式为：\u003c类名\u003e \u003c对象名\u003e(实参表) 如： CRectangle c1(10,20); 可以用成员访问运算符“.”来引用类的成员，其一般形式为： \u003c对象名\u003e.\u003c数据成员名\u003e 或： \u003c对象名\u003e.\u003c成员函数名(实参表)\u003e 如： c1.get_area(); 注意：一般只有类的公有成员才能使用类成员访问运算符“.”，类的保护或私有成员不允许在类的外部被直接访问，只能通过类的公有成员函数来间接访问它们。 get、set函数 也可以通过设置友元（friend）,在类中为友元函数或友元类设置后门，允许它们访问类的保护或私有成员。 //通过长方形类的成员函数求长方形的面积。 class CRectangle { private: int length,width; public: //直接定义在类主体中的成员函数将自动成为内联函数（Inline Function） CRectangle(int l,int w) { length=l;width=w; } int get_area(); }; int CRectangle::get_area() { return length*width; } int main() { CRectangle c1(10,20); cout\u003c\u003c\"The area of rectangle:\"\u003c\u003cc1.get_area()\u003c\u003cendl; return 0; } ","date":"2021-02-02","objectID":"/20210202/:14:0","tags":["C++"],"title":"C++自定义数据类型","uri":"/20210202/"},{"categories":["C++"],"content":"构造函数与析构函数 1.构造函数 构造函数的作用是在对象创建时使用特定的值构造对象，将对象初始化为一个特定的状态。构造函数的名字与它所属的类名相同，被声明为公有函数，且没有任何类型的返回值，在创建对象时被自动调用。例如： CRectangle(int l,int w) { length=l;width=w; } 每个类都必须有构造函数，若类定义时没有定义任何构造函数，编译器也会自动生成一个不带参数的缺省构造函数。当创建一个对象时，系统将自动调用该缺省构造函数来初始化对象，缺省的构造函数将对象的所有数据成员分配内存空间，但不进行初始化(数据成员的值为内存的随机值，所以必须提供公有set函数，设置私有数据的值）。 不建议这样使用！ 构造函数可以有默认的参数值,如： CRectangle(int l=1,int w=1){length=l;width=w;} CRectangle c1; 则 c1.length=c1. width=1; 构造函数可以有多个重载版本,例如： 若已经在类外定义了结构体： struct rect{int ll;int ww;}; 则可以： CRectangle(rect rc) {length=rc.ll;width=rc.ww;} 拷贝构造函数是构造函数的特例，它的作用是自动用一个已经存在的同类对象，去初始化另一个新的对象。 语法形式为：类名(类名 \u0026对象名); 拷贝构造函数是构造函数的重载形式，它的形参是本类对象的一个引用，实参为一个已存在的本类对象。 C++自动为每个类提供一个缺省的拷贝构造函数； 例如： CRectangle c1(10,20),c2(c1); 2.析构函数 析构函数的功能是用来释放一个对象的，析构函数本身并不删除对象，而是进行系统放弃对象之前的清理工作，它与构造函数的功能正好相反。 注意： 析构函数的名字是在类名前加字符“～”。 析构函数没有参数，也没有返回值。 析构函数不能重载，也就是说，一个类中只可能定义一个析构函数。 例如： ~CRectangle(); ","date":"2021-02-02","objectID":"/20210202/:15:0","tags":["C++"],"title":"C++自定义数据类型","uri":"/20210202/"},{"categories":["C++"],"content":"最后一个实例 //CRectangle类的完整代码 #include\u003ciostream\u003e using namespace std; struct rect { int ll; int ww; }; class CRectangle { private: int length,width; public: CRectangle(int l=1,int w=1){length=l;width=w;} CRectangle(rect rc); CRectangle(CRectangle \u0026rc); ~CRectangle(){ } int get_area(); void set(int l,int w); void get(int \u0026l,int \u0026w); }; CRectangle::CRectangle(rect rc) { length=rc.ll; width=rc.ww; } CRectangle::CRectangle(CRectangle \u0026rc) { length=rc.length; width=rc.width; } int CRectangle::get_area() { return length*width; } void CRectangle::set(int l,int w) {length = l; width = w; } void CRectangle::get(int \u0026l,int \u0026w) {l = length; w = width; } int main() { rect rr={1,2}; CRectangle c2(rr); CRectangle c1(c2); //c1.length=2; //无法存取类中的私有数据成员 //c1.width=3; //无法存取类中的私有数据成员 c1.set(2,3); cout\u003c\u003c\"The area of rectangle:\"\u003c\u003cc1.get_area()\u003c\u003cendl; int ll,ww; c1.get(ll,ww); cout\u003c\u003c\"length=\"\u003c\u003cll\u003c\u003c“,width=\"\u003c\u003cww\u003c\u003cendl; //cout\u003c\u003cc1.length\u003c\u003cendl; //无法存取类中的私有数据成员 return 0; } ","date":"2021-02-02","objectID":"/20210202/:16:0","tags":["C++"],"title":"C++自定义数据类型","uri":"/20210202/"},{"categories":["matlab","数学建模"],"content":"代码 clc;close all; %% 获取数据 day_i=3/10000 %日息 number_of_periods_i=day_i*30 %月利率 P=10000 %借款金额 N = 12 %还款期数 %% 模型选取及计算 Amount=P %借款金额 rate=number_of_periods_i %月利率 number_of_periods=N %贷款期数 command=input(‘输入0为等额本金还款，输入1为等额本息还款，输入2为等本等息还款，输入3为先息后本还款： ‘) if command==0 %等额本金还款方式 M=Amount/number_of_periods %每月偿还本金 for j=1:number_of_periods-1 Amount(j+1)=Amount(j)-M %月初余额 end R=Amount*rate %月底的利息 debt=Amount+R %月底欠款 M1=M+Amount*rate %月还款额 sum_R=sum(R) %总利息 sum_Amount=sum(M1) %还款总额 M=M-zeros(1,number_of_periods) data=[Amount’,R’,debt’,M’,M1’]%月初所欠金额 利息额 月末所欠金额 偿还本金 月末付款 [n,m]=size(data) result= cell(n+1,m) result(1,:)={‘月初所欠金额’,’利息额’,’月末所欠金额’,’偿还本金’,’月末付款’} result(2:end,:) = num2cell(data) xlswrite(‘data.xlsx’,result,’等额本金还款方式’)%输出excel fprintf(‘sum_R=%f’,sum_R) fprintf(‘sum_Amount=%f’,sum_Amount) elseif command==1 %等额本息还款方式 M=Amount*(rate*(1+rate)^number_of_periods)/((1+rate)^number_of_periods-1)%月还款额 for i=1:number_of_periods-1 Amount(i+1)=Amount(i)*(1+rate)-M %月初金额 end R=Amount*rate %月底的利息 mon=M-R %每月偿还本金 debt=Amount+R %月底欠款 sum_R=sum(R) %总利息 sum_Amount=M*number_of_periods %还款总额 M=M-zeros(1,number_of_periods) data=[Amount’,R’,debt’,M’-R’,M’]%月初所欠金额 利息额 月末所欠金额 偿还本金 月末付款 [n,m]=size(data) result= cell(n+1,m) result(1,:)={‘月初所欠金额’,’利息额’,’月末所欠金额’,’偿还本金’,’月末付款’} result(2:end,:) = num2cell(data) xlswrite(‘data.xlsx’,result,’等额本息还款方式’)%输出excel fprintf(‘sum_R=%f’,sum_R) fprintf(‘sum_Amount=%f’,sum_Amount) elseif command==2 %等本等息还款方式 M=Amount/number_of_periods %月还本金 for i=1:number_of_periods-1 Amount(i+1)=Amount(i)-M %月初金额 end R=[P*rate,P*rate,P*rate,P*rate,P*rate,P*rate,P*rate,P*rate,P*rate,P*rate,P*rate,P*rate] %月底的利息 debt=Amount+R %月底欠款 M2=M+R %月还款额 sum_R=sum(R) %总利息 sum_Amount=M*number_of_periods+P*rate*number_of_periods %还款总额 M=M-zeros(1,number_of_periods) data=[Amount’,R’,debt’,M’-R’,M2’]%月初所欠金额 利息额 月末所欠金额 偿还本金 月末付款 [n,m]=size(data) result= cell(n+1,m) result(1,:)={‘月初所欠金额’,’利息额’,’月末所欠金额’,’偿还本金’,’月末付款’} result(2:end,:) = num2cell(data) xlswrite(‘data.xlsx’,result,’等本等息还款方式’)%输出excel fprintf(‘sum_R=%f’,sum_R) fprintf(‘sum_Amount=%f’,sum_Amount) elseif command==3 %先息后本还款方式 M=0 %月还本金 for i=1:number_of_periods-1 Amount(i+1)=Amount(i)-M %月初金额 end R=Amount*rate %月底的利息 debt=Amount+R %月底欠款 M3=R %月还款额 sum_R=sum(R) %总利息 M4=debt sum_Amount=P+sum_R %还款总额 last_number_of_periods_debt=P+P*rate %最后一个月还款金额 M=M-zeros(1,number_of_periods) data=[Amount’,R’,debt’,M’,M3’]%月初所欠金额 利息额 月末所欠金额 偿还利息 月末付款 [n,m]=size(data) result= cell(n+1,m) result(1,:)={‘月初所欠金额’,’利息额’,’月末所欠金额’,’偿还本金’,’月末付款利息’} result(2:end,:) = num2cell(data) xlswrite(‘data.xlsx’,result,’先息后本还款方式’)%输出excel fprintf(‘sum_R=%f’,sum_R) fprintf(‘sum_Amount=%f’,sum_Amount) end ","date":"2021-02-01","objectID":"/20210201/:1:0","tags":["matlab","数学建模"],"title":"小额贷款的划算问题(matlab数学建模)","uri":"/20210201/"},{"categories":["matlab","数学建模"],"content":"源文档 完整文档详见：博客相关资源-小额贷款的划算问题 ","date":"2021-02-01","objectID":"/20210201/:2:0","tags":["matlab","数学建模"],"title":"小额贷款的划算问题(matlab数学建模)","uri":"/20210201/"},{"categories":["C++"],"content":"前言 这部分类同于Python，比如从0开始，都用[]来表示第几个元素。 ","date":"2021-01-28","objectID":"/20210128/:1:0","tags":["C++"],"title":"C++数组","uri":"/20210128/"},{"categories":["C++"],"content":"一维数组(score) 形式如下 \u003c类型标识符\u003e\u003c数组名\u003e[数组长度] 实例 int score[10]; int const N = 10; int n,m; int a[N]; //合法，N为常量 double[n],c[m*2]; //非法，n和m是变量 如果要访问一维数组的元素，形式如下： \u003c数组名\u003e[下标] 这里类似Python，不过下标不能从后往前检索使用负数，这里不同于Python。 实例： //声明一个数组，每个元素按顺序赋予从50到70以1递增的数。 int nDate[20]; for(int i=0;i\u003c20;i++) nDate[i]=i+50 //生成长度10的连续偶数序列，从2开始，保存在数组中，并输出此数组每个元素的值 #include\u003ciostream\u003e using namespace std; int main() { int nEven(10); //定义用于存放的数组 int i; for(i=0;i\u003c10;i++) nEven[i]=i*2+2; //将生成偶数值赋给数组元素 for(i=0;i\u003c10;i++) { cout\u003c\u003cnEven[i]\u003c\u003c\"\"; //输出数组元素 } cout\u003c\u003cendl; return 0; } ","date":"2021-01-28","objectID":"/20210128/:2:0","tags":["C++"],"title":"C++数组","uri":"/20210128/"},{"categories":["C++"],"content":"一维数组的初始化(赋值元素) 形式： \u003c类型标识符\u003e\u003c数组名\u003e[数组长度]={元素值按顺序排列用,分开} 或 \u003c类型标识符\u003e\u003c数组名\u003e[]={第0个元素值,第1个元素值,……,第n个元素值} 注意： 第一种形式不给满元素值，剩下元素默认赋值0，赋值多于数组长度会报错；第二种形式不给定数组长度，赋值多少个就是有几个元素。 赋值时元素值不能为空。 ","date":"2021-01-28","objectID":"/20210128/:3:0","tags":["C++"],"title":"C++数组","uri":"/20210128/"},{"categories":["C++"],"content":"多维数组 多维数组不同在于下标的数目，这里以二维数组为主要方向学习。 二维数组命名形式： \u003c类型标识符\u003e\u003c数组名\u003e[第1维长度][第2维长度] 这里的存储方式是先存储第1维下标为0的元素，再存第1维下标为1的元素。等同于先存第一行，再存第二行。(行为第1维，列维第2维) 访问二维数组形式： \u003c数组名\u003e[第1维下标][第2维下标] 二维数组的初始化形式： \u003c类型标识符\u003e\u003c数组名\u003e[第1维长度][第2维长度]={ {第0个第2维数组}, {第1个第2维数组}, ……, {第n个第2维数组} } 另一种形式： \u003c类型标识符\u003e\u003c数组名\u003e[第1维长度][第2维长度]={第0个元素值,第1个元素值,……,第n个元素值} 这里的注意事项与1维数组相同。 实例： #include\u003ciostream\u003e int main() { int nRow; //控制行变量 int nCol; //控制列变量 int nMatrix[6][6]={0}; //二维数组声明，且数组元素被赋值为0 //生成5×5方阵 for(nRow=0;nRow\u003c5;nRow++) { for(nCol=0;nCol\u003c5;nCol++) { if(nRow%2==0) nMatrix[nRow][nCol]=nRow*5+nCol+1; else nMatrix[nRow][4-nCol]=nRow*5+nCol+1; } } //输出方阵 cout\u003c\u003c\"生成方阵：\\n\"; for(nRow=0;nRow\u003c5;nRow++) { for(nCol=0;nCol\u003c5;nCol++) { cout\u003c\u003cnMatrix[nRow][nCol]; if(nMatrix[nRow][nCol]\u003c10) //控制输出1位数与2位数时的不同间隔 cout\u003c\u003c\"\"; else cout\u003c\u003c\"\"; } cout\u003c\u003cendl; //没输出一行后换行 } cout\u003c\u003cendl; //计算5×5方阵各行及左上右下对角线之和 for(nRow=0;nRow\u003c5;nRow++) { for(nCol=0;nCol\u003c5;nCol++) { nMatrix[nRow][5]+=nMatrix[nRow][nCol]; //计算各行之和 nMatrix[5][nRow]+=nMatrix[nCol][nRow]; //计算各列之和 } nMatrix[5][5]+=nMatrix[nRow][nRow]; cout\u003c\u003c\"第\"\u003c\u003cnRow+1\u003c\u003c\"行之和：\"\u003c\u003cnMatrix[nRow][5]\u003c\u003c\"\\t\\t\"; cout\u003c\u003c\"第\"\u003c\u003cnRow+1\u003c\u003c\"列之和\"\u003c\u003cnMatrix[5][nRow]\u003c\u003cendl; } cout\u003c\u003c\"\\n左上右下对角线之和：\"\u003c\u003cnMatrix[5][5]\u003c\u003cendl; return 0; } 这里的数组如果声明为静态的，未赋值的自动清零，若数组未声明为静态的，则不赋值时元素不确定。 ","date":"2021-01-28","objectID":"/20210128/:4:0","tags":["C++"],"title":"C++数组","uri":"/20210128/"},{"categories":["C++"],"content":"一维数组名作为参数 形式 形式1：\u003c类型标识符\u003e\u003c函数名\u003e(类型标识符 数组名[],int 长度) 形式2：\u003c类型标识符\u003e\u003c函数名\u003e(类型标识符 数组名[长度]) 实例： //计算成绩平均值，定义函数ave() #include\u003ciostream\u003e using namespace std; double ave(int a[],int n); int main() { const int N=20; int nScore[N]={90,88,45,92,76,59,89,93,60,51,91,65,82,74,92,35,66,78,62,91}; cout\u003c\u003c\"学生平均分数为：\"\u003c\u003cave(nScore,N)\u003c\u003cendl; return 0; } double ave(int a[],int n) { int i,nSum=0; for(i=0;i\u003cn;i++) nSum+=a[i]; return ((float)nSum/n); } 调试可发现主调函数里数组nScore和被调函数的形参数组a的起始地址一样，即数组nScore和形参数组a用同一段内存空间。 ","date":"2021-01-28","objectID":"/20210128/:5:0","tags":["C++"],"title":"C++数组","uri":"/20210128/"},{"categories":["C++"],"content":"二维数组的行地址作为参数 既然二维数组中的每一行相当一个一维数组，就可以把二维数组的行地址作为函数参数，实现传递这一行数据的目的。 #include\u003ciostream\u003e using namespace std; double grade(double fArray[],int n); //评分函数声明 int main() { double fScoreData[5][6]= { {9.31,9.20,9.00,9.40,9.35,9.20}, {9.71,9.52,9.50,9.66,9.49,9.57}, {8.89,8.80,9.10,9.25,8.90,9.00}, {9.38,9.50,9.40,9.20,9.90,8.90}, {9.30,8.84,9.40,9.45,9.10,8.89} }; cout.precision(3); //设置总的有效位数（不是设置小数点后的位数！） cout\u003c\u003c\"歌手的最后得分为：\"\u003c\u003cendl; for(int nRow=0;nRow\u003c5;nRow++) { cout\u003c\u003cnRow+1\u003c\u003c\" 号选手成绩为：\"; cout\u003c\u003cgrade(fScoreData[nRow],6)\u003c\u003cendl; } return 0; } double grade(double fArray[],int n) //评分函数定义，n作为行向量的长度 { double fMark,fMax,fMin; //定义记录成绩、最高分、最低分的变量 fMark=fMax=fMin=fArray[0]; for(int i=1;i\u003cn;i++) { if(fArray[i]\u003efMax) fMax=fArray[i]; if(fArray[i]\u003cfMin) fMin=fArray[i]; fMark+=fArray[i]; } return (fMark-fMax-fMin)/(n-2); //计算出平均分并返回调用函数 } ","date":"2021-01-28","objectID":"/20210128/:6:0","tags":["C++"],"title":"C++数组","uri":"/20210128/"},{"categories":["C++"],"content":"数组与字符串 在C++语言中没有字符串变量类型，为了表示字符串，可以使用字符型数组，字符型数组的每一个元素分别保存字符串中的每一个字符。 char \u003c数组名\u003e[]=\"字符串\" char \u003c数组名\u003e[]={'字符串'} 有问题的写法： char MyStrinq[]={'T','h','i','s',' ','i','s',' ','a',' ','c','o','m','p','u','t','e','r'}; //缺少字符串的结束标志，输出有问题！ cout\u003c\u003cMyStrinq\u003c\u003cendl; 正确写法： char MyStrinq[]=\"This is a computer\"; char MyStrinq[]={\"This is a computer\"}; //它们等同于： char MyStrinq[]={'T','h','i','s',' ','i','s',' ','a',' ','c','o','m','p','u','t','e','r','\\0'}; 说明： 1.转义字符\\0(即8进制的0)，表示的是字符串常量中字符串的结束标志。故：char a[4]={‘t’,‘h’,‘i’,‘s’};cout\u003c\u003ca\u003c\u003cendl; 缺少字符串的结束标志，输出有问题。 2.字符型数组也是数组，故赋初值时必须和字符数组的定义在一起。 char str1[]; str1[]=\"abcd\"; 错误！ 3.不能有：字符型数组名= “字符串”; 如: MyStrinq =\"abcd\";错误！ 4.字符型数组的长度在声明时就已经确定（字符串中字符个数+1），在使用的过程中不能更改。 const int N = 20;t[N] = \"uvwxyz\"; 转义字符：\\ddd:1到3位8进制符号；\\xhh:1到2位16进制符号 ","date":"2021-01-28","objectID":"/20210128/:7:0","tags":["C++"],"title":"C++数组","uri":"/20210128/"},{"categories":["C++"],"content":"字符串基本操作 在C++中要实现字符串的运算，例如：连接两个字符串，求字符串的长度等，可以： 编写程序对字符型数组进行操作：通常要借助于循环结构，通过判断当前字符是否为空字符’\\0’，来确定是否循环到底。 直接调用C++的库函数中提供的各种字符串运算的函数。 //求字符串的长度 char pString[] = \"abcd\"; int nSize=0; while(pString[nSize]!='\\0') //从第一个字符开始直到碰到'\\0'为止 nSize++; 注意： 字符型数组的长度:包括’\\0’的长度！ 字符串的长度:不包括’\\0’的长度！ //字符串的复制:将字符数组s中的字符依此赋给字符数组t，直到碰到字符数组s中的'\\0'为止 char s[] = \"abcd\",t[] = \"uvwxyz\"; int i=0; while(s[i]!='\\0') //从第一个字符开始直到碰到'\\0'为止 { t[i] = s[i]; i++; } t[i]='\\0'; //注意修改字符串t的结尾！ cout\u003c\u003ct\u003c\u003cendl; 注意： 字符数组t的长度要大于等于s的，否则t[i]访问越界错误！ 注意： 被连接的字符串t的初始化长度要大于字符串t目前的长度+字符串s的长度+1 //将字符串s连接到字符串t的尾部，要先找到字符串t中的‘\\0‘,或确定字符串t的长度，然后从t的尾部开始依此将字符串s中字符赋给t； const int N = 20; //N要足够大！N大于等于s和t的字符数之和+1 char s[] = \"abcd\",t[N] = \"uvwxyz\"; int i=0,nSize=0; while(t[nSize]!='\\0') nSize++; do{ t[nSize++]=s[i++]; }while(s[i]!='\\0'); t[nSize]='\\0'; //修改字符串t的结尾！ cout\u003c\u003ct\u003c\u003cendl; //通常采用while或do-while循环结构访问字符数组 ","date":"2021-01-28","objectID":"/20210128/:8:0","tags":["C++"],"title":"C++数组","uri":"/20210128/"},{"categories":["C++"],"content":"最后的实例 //求字符串长度，复制、连接字符串。 #include\u003ciostream\u003e using namespace std; int StringLength(char pS[]); void StringCopy(char pS[],char pD[]); void StringCat(char pTocat[],char pD[]); int main() { char str1[]=\"abcd\"; char str2[5]=\"\"; char str3[]=\"efg\"; cout\u003c\u003c\"str1：\"\u003c\u003cstr1\u003c\u003cendl; cout\u003c\u003c\"str2：\"\u003c\u003cstr2\u003c\u003cendl; cout\u003c\u003c\"str3：\"\u003c\u003cstr3\u003c\u003cendl; cout\u003c\u003c\"\\nstr1的长度：\" \u003c\u003cStringLength(str1)\u003c\u003cendl; cout\u003c\u003c\"\\nstr1字符串复制给str2后：\"; StringCopy(str1,str2); cout\u003c\u003cstr2\u003c\u003cendl; cout\u003c\u003c\"\\nstr3字符串连接到str1后：\"; StringCat(str3,str1); cout\u003c\u003cstr1\u003c\u003cendl; return 0; } //注意：一维字符数组作为函数参数时，函数的声明形式与普通一维数组的不同！不需要提供数组长度！ int StringLength(char pS[]) { int nSize=0; while(pS[nSize]!='\\0') nSize++; return nSize; } void StringCopy(char pS[],char pD[]) { int nIndex=0; while(pS[nIndex]!='\\0') pD[nIndex]=pS[nIndex++]; pD[nIndex]='\\0'; } void StringCat(char pTocat[],char pD[]) { int nSize=0,nIndex=0; while(pD[nSize]!=0) nSize++; do{ pD[nSize++]=pTocat[nIndex++]; }while(pTocat[nIndex]!='\\0'); pD[nSize]='\\0'; } ","date":"2021-01-28","objectID":"/20210128/:9:0","tags":["C++"],"title":"C++数组","uri":"/20210128/"},{"categories":["C++"],"content":"定义函数 \u003c类型标识符\u003e\u003c函数名\u003e(形式参数表) { 语句序列 } 实例： //求n! #include\u003ciostream\u003e using namespace std; int factorial(int m); //原型声明 int main() { int n; cout\u003c\u003c\"Input n:\"; cin\u003e\u003en; cout\u003c\u003cn\u003c\u003c\"!=\"\u003c\u003c\"factorial(n)\"\u003c\u003cendl; //函数调用作为表达式出现在语句中 return 0; } int factorial(int m) { int i,result=1; for(i=1;i\u003c=m;i++) result *=i; return result; } ","date":"2021-01-25","objectID":"/20210125/:1:0","tags":["C++"],"title":"C++函数","uri":"/20210125/"},{"categories":["C++"],"content":"函数返回值及其类型 函数头部的类型标识符规定函数返回值的类型，函数的返回值是返回给主调用函数的处理结果，由函数体中的return语句带回。 return后也可以是一个表达式，该表达式的结果必须是一个确定的值，且类型必须与函数的返回类型一致。 无返回值的函数不必有return语句，这时函数的类型标识符必须为void。 ","date":"2021-01-25","objectID":"/20210125/:2:0","tags":["C++"],"title":"C++函数","uri":"/20210125/"},{"categories":["C++"],"content":"形式参数 形式参数简称形参，作用是用来实现主调函数与被调函数之间数据联系的，通常将函数所处理的数据、影响函数功能的因素等作为形参。 函数头部分的形参表内容如下： 类型1形参名1,类型2形参名2,类型3形参名3……类型n形参名n ","date":"2021-01-25","objectID":"/20210125/:3:0","tags":["C++"],"title":"C++函数","uri":"/20210125/"},{"categories":["C++"],"content":"函数调用 1.函数原型声明： \u003c类型标识符\u003e\u003c函数名\u003e(形式参数表); 例如： int factorial(int m); 注意： (1)函数原型声明是一个独立的语句，其后要加分号; (2)声明时，形式参数表中可以省略形参名，即只有类型名 (3)如果是在所有函数之前声明了函数原型，那么该函数原型在本程序中的任何地方都有效。如果只在函数内部声明，就只能在内部用有效。 2.函数的调用形式 \u003c函数名\u003e(实参1,实参2……实参n) eg: cout\u003c\u003cn\u003c\u003c\"!=\"\u003c\u003cfactorial(n)\u003c\u003cendl; 3.函数调用及返回的过程 函数的定义是平行的，但是函数的调用允许嵌套。 ","date":"2021-01-25","objectID":"/20210125/:4:0","tags":["C++"],"title":"C++函数","uri":"/20210125/"},{"categories":["C++"],"content":"函数的参数传递 当函数未被调用时，C++编译系统并没有给函数的形参分配相应的内存空间，并且直接将实参的值复制给形参。 实参可以是常量变量或表达式，其类型必须与形参相符。 #include\u003ciostream\u003e using namespace std; void change(int a,int b); int main() { int x,y; cout\u003c\u003c\"Input x,y:\"; cin\u003e\u003ex\u003e\u003ey; cout\u003c\u003c\"Before change\"\u003c\u003cendl; cout\u003c\u003c\"x=\"\u003c\u003cx\u003c\u003c\" y=\"\u003c\u003cy\u003c\u003cendl; change(x,y); cout\u003c\u003c\"After change\"\u003c\u003cendl; return 0; } void change(int a,int b) { int t; t=a; a=b; b=t; } ","date":"2021-01-25","objectID":"/20210125/:5:0","tags":["C++"],"title":"C++函数","uri":"/20210125/"},{"categories":["C++"],"content":"引用传递 #include\u003ciostream\u003e using namespace std; void change(int \u0026a,int \u0026b); int main() { int x,y; cout\u003c\u003c\"Input x,y:\"; cin\u003e\u003ex\u003e\u003ey; cout\u003c\u003c\"Before change\"\u003c\u003cendl; cout\u003c\u003c\"x=\"\u003c\u003cx\u003c\u003c\" y=\"\u003c\u003cy\u003c\u003cendl; change(x,y); cout\u003c\u003c\"After change\"\u003c\u003cendl; return 0; } void change(int \u0026a,int \u0026b) { int t; t=a; a=b; b=t; } 程序分析： 现在子函数change()的两个参数都是引用，当被调用时，它们分别被初始化成为a和b的别名。因此，在子函数change()中将两个形参的值进行交换后，交换的结果可以影响实参x和y，实现两个数的真正交换。 ","date":"2021-01-25","objectID":"/20210125/:6:0","tags":["C++"],"title":"C++函数","uri":"/20210125/"},{"categories":["C++"],"content":"递归调用 //求n!的值 #include\u003ciostream\u003e using namespace int factorial(int n); int main() { int n; cout\u003c\u003c\"Input n:\"; cin\u003e\u003en; cout\u003c\u003cn\u003c\u003c\"!=\"\u003c\u003cfactorial(n)\u003c\u003cendl; return 0; } int factorial(int n) { int result; if(n==0) result =1; //递归结束条件 else result = n*factorial(n-1); //参数减1进行递归调用 return result; } 问题：5人坐在一起，问第1个人多少岁，他说比第2个人大2岁，问第2个人多少岁，他说比第3个人大2岁，……问最后一个人，他说是12岁。问第一个人多少岁。 #include\u003ciostream\u003e using namespace std; int age(int n); int main() { cout\u003c\u003c\"第一个人的年龄\"\u003c\u003cage(1)\u003c\u003c\"岁\"\u003c\u003cendl; return 0; } int age(int n) { int result; if(n==5) result = 12; //递归结束条件 else result = age(n+1)+2; //以参数加1的方式继续递归 return result; } ","date":"2021-01-25","objectID":"/20210125/:7:0","tags":["C++"],"title":"C++函数","uri":"/20210125/"},{"categories":["C++"],"content":"默认参数值的函数 这里和Python的定义与作用一样。 //求x的n次方 #include\u003ciostream\u003e using namespace std; int main() { int power(int x,int n=2); int x,n; cout\u003c\u003c\"Input x,n:\"; cin\u003e\u003ex\u003e\u003en; cout\u003c\u003cx\u003c\u003c\"^\"\u003c\u003cn\u003c\u003c\"=\"\u003c\u003cpower(x,n)\u003c\u003cendl; } int power(int x,int n=2) //第二个形参具有默认值 { if(n==0) return 1; else if(n==1) return x; else return (power(x,n-1)*x); } ","date":"2021-01-25","objectID":"/20210125/:8:0","tags":["C++"],"title":"C++函数","uri":"/20210125/"},{"categories":["C++"],"content":"内联函数 语法形式： 使用关键字inline \u003cinline\u003e\u003c类型标识符\u003e\u003c函数名\u003e(含类型说明的参数表) 编译程序在遇到这个命令时将记录下来，在处理内联函数的调用时，编译程序就1试图产生扩展码。 实际上就是函数调用时不再通过传参引用，而是在编译时将函数体嵌入到每一个调用语句处，节省了参数传递，系统栈的保护与恢复等的开销。 注意： 1.内联函数体内一般不含复杂的循环语句和switch语句。 2.内联函数声明和定义前必须加关键字inline。 3.内联函数不能进行异常接口声明。 如果违背上述注意事项，编译程序会无视inline的存在，像处理一般函数一样处理它，不产生扩展码。因此，只有使用频率很高的函数才被说明为内联函数，内联函数会扩大目标代码，使用需要谨慎。 //找最大值 #include\u003ciostream\u003e #include\u003ciomainip\u003e using namespace std; inline int max(int a,int b); int main() { int a,b,c,d,result; cout\u003c\u003c\"Input a,b,c:\"; cin\u003e\u003ea\u003e\u003eb\u003e\u003ec; d=max(a,b); //编译时两次调用处均被替换为max函数体语句 cout\u003c\u003c\"The biggest of\" \u003c\u003cstew(5)\u003c\u003ca \u003c\u003cstew(5)\u003c\u003cb \u003c\u003cstew(5)\u003c\u003cc\u003c\u003c\"is\"\u003c\u003cresult\u003c\u003cendl; return 0; } inline int max(int a,int b) { if(a\u003eb) return a; else return b; } ","date":"2021-01-25","objectID":"/20210125/:9:0","tags":["C++"],"title":"C++函数","uri":"/20210125/"},{"categories":["C++"],"content":"函数重载 函数重载又称为多态函数，C++编译系统运行为两个或两个以上的函数取相同的函数名，但形参的个数或者形参类型至少有1个不同，编译系统会根据实参和形参的类型和个数匹配最佳，自动确定调用哪个函数。 //使用函数重载实现两个数据或三个数据的相加 #include\u003ciostream\u003e using namespace std; int add(int x,int y) { return x+y; } int add(int x,int y,int z) { return x+y+z; } int main() { int x,y,z; cout\u003c\u003c\"Input x,y,z:\"; cin\u003e\u003ex\u003e\u003ey\u003e\u003ez; cout\u003c\u003c\"x+y=\"\u003c\u003cadd(x,y)\u003c\u003c\"\\nx+y+z=\"\u003c\u003cadd(x,y,z)\u003c\u003cendl; return 0; } 这里C++语言支持函数重载，C语言不支持。 ","date":"2021-01-25","objectID":"/20210125/:10:0","tags":["C++"],"title":"C++函数","uri":"/20210125/"},{"categories":["C++"],"content":"函数模板 对于算法来说，希望它可以处理多种数据类型，但即使这一算法被设计为重载函数也只是使用相同函数名，函数体需要分别定义。 形式： \u003ctemplate\u003e\u003cclass标识符\u003e \u003c类型标识符\u003e\u003c函数名\u003e(形式参数表) { …… } //任意类型两数相加 #include\u003ciostream\u003e using namespace std; template\u003ctypename T\u003e T add(T a,T b) { T sum; sum = a+b; return sum; } int main() { int x,y; double m,n; cout\u003c\u003c\"Input int x,y:\"; cin\u003e\u003ex\u003e\u003ey; cout\u003c\u003c\"x+y=\"\u003c\u003cadd(x,y)\u003c\u003cendl; cout\u003c\u003c\"Input double m,n:\"; cin\u003e\u003em\u003e\u003en; cout\u003c\u003c\"m+n=\"\u003c\u003cadd(m,n)\u003c\u003cendl; return 0; } 当调用函数add()时，编译系统从实参的类型推导出函数模板的类型参数T。意思是T的为各类型名随着实参的类型变化。 ","date":"2021-01-25","objectID":"/20210125/:11:0","tags":["C++"],"title":"C++函数","uri":"/20210125/"},{"categories":["电脑技巧"],"content":"C盘空间视图化显示软件 蓝奏云盘链接：点此跳转 ","date":"2021-01-23","objectID":"/20210123/:1:0","tags":["windows"],"title":"C盘清理视图化操作","uri":"/20210123/"},{"categories":["电脑技巧"],"content":"具体操作教程 视频教程点击这里跳转 ","date":"2021-01-23","objectID":"/20210123/:2:0","tags":["windows"],"title":"C盘清理视图化操作","uri":"/20210123/"},{"categories":["电脑技巧"],"content":"除了按照视频操作，如果你还发现什么占空间特别大的文件，欢迎评论区留言交流 ","date":"2021-01-23","objectID":"/20210123/:3:0","tags":["windows"],"title":"C盘清理视图化操作","uri":"/20210123/"},{"categories":["C++"],"content":"输入信息控制循环 输入信息控制循环通常控制的是无限循环(循环次数不确定的循环)。 通常使用while(或do while)语句构建无限循环。 统计输入的字符个数 #include\u003ciostream\u003e using namespace std; int main() { char ch; int count=0; cout\u003c\u003c\"输入字符串，以#结束：\"; while(true) { cin\u003e\u003ech; if(ch=='#') break; cout++; } cout\u003c\u003c\"共输入\"\u003c\u003ccount\u003c\u003c\"个字母。\"\u003c\u003cendl\u003c\u003cendl; return 0; } ","date":"2021-01-19","objectID":"/20210119/:1:0","tags":["C++"],"title":"C++循环结构补充","uri":"/20210119/"},{"categories":["C++"],"content":"循环嵌套 输出乘法九九表： 二维表，先从上到下输出行，再从左到右输出列。 需要构建两个循环，外循环控制行，内循环控制列。 #include\u003ciostream\u003e using namespace std; int main() { int i,j; for(i=1,i\u003c=9;i++) cout\u003c\u003ci\u003c\u003c\"\\t\" cout\u003c\u003c\"\\n-------------------------------\" \u003c\u003c\"----------------------------------------\\n\"; for(i=1;i\u003c=9;i++) { cout\u003c\u003ci\u003c\u003c\"\\t\"; for(j=1;j\u003c=9;j++) cout\u003c\u003ci*j\u003c\u003c\"\\t\"; cout\u003c\u003cendl; } return 0; } ","date":"2021-01-19","objectID":"/20210119/:2:0","tags":["C++"],"title":"C++循环结构补充","uri":"/20210119/"},{"categories":["C++"],"content":"其他控制语句 1.break语句 使用于循环中用于跳出或结束循环。 2.continue语句 使用于循环体中，作用是结束本次循环，然后判断循环条件，决定是否进行下一次循环。 实例： //运行这段程序可以多次输入学生百分制成绩，并分别对其进行成绩分级，直到输入-1结束程序。 #include\u003ciostream\u003e using namespace std; int main() { int score; char result; while(true) { cout\u003c\u003c\"请输入学生百分制成绩(0~100,输入-1结束):\"; cin\u003e\u003escore; if(score==-1) break; if(score\u003c0||score\u003e100) { cout\u003c\u003c\"输入学生百分制成绩有错，请重新输入！\"\u003c\u003cendl\u003c\u003cendl; continue; } switch(score/10) { case 10: case 9: result = 'A'; break; case 8: result = 'B'; case 7: result = 'C'; case 6: result = 'D'; default: result = 'E'; } cout\u003c\u003c\"百分制成绩\"\u003c\u003cscore\u003c\u003c\"对应的成绩等级为：\" \u003c\u003cresult\u003c\u003cendl\u003c\u003cendl; } return 0; } ","date":"2021-01-19","objectID":"/20210119/:3:0","tags":["C++"],"title":"C++循环结构补充","uri":"/20210119/"},{"categories":["C++"],"content":"goto语句 goto语句的作用是使程序的执行流程跳转到语句标号所指定的语句。语法格式如下 goto\u003c语句标号\u003e 上面实例中的continue可以用goto语句替代。 …… while(true) { a1: cout\u003c\u003c\"请输入学生百分制成绩(0~100,输入-1结束):\"; cin\u003e\u003escore; if(score==-1) break; if(score\u003c0||score\u003e100) { cout\u003c\u003c\"输入学生百分制成绩有错，请重新输入！\"\u003c\u003cendl\u003c\u003cendl; goto a1; } …… } …… 实例： //一元二次方程求解 #include\u003ciostream\u003e #include\u003cmath.h\u003e using namespace std; int main() { double a,b,c,d,x1,x2; cout\u003c\u003c\"一元二次方程：ax*x+bx+c=0\\n请输入系数a,b,c:\"; n1:cin\u003e\u003ea\u003e\u003eb\u003e\u003ec; if(a==0) { cout\u003c\u003c\"请重新输入系数a,b,c:\"; goto n1; } else { d=b*b-4*a*c; if(d\u003e=0) { x1=(-b+sqt(d))/(2*a); x2=(-b-sqt(d))/(2*a); cout\u003c\u003c\"x1=\"\u003c\u003cx1\u003c\u003cendl; cout\u003c\u003c\"x2=\"\u003c\u003cx2\u003c\u003cendl; } else cout\u003c\u003c\"此方程无解：\\n\"; } return 0; } 注意：goto语句的使用会破坏程序的结构，应该少用或不用。 ","date":"2021-01-19","objectID":"/20210119/:4:0","tags":["C++"],"title":"C++循环结构补充","uri":"/20210119/"},{"categories":["C++"],"content":"选择控制语句 if else 这里不像Python，每个分支语句后不需要加:，直接加 (Tab)后写分支语句，条件判断需要小加括号括起来，Python中是空格加条件，这点也不同。 if(x\u003e=0) cout\u003c\u003c\"y=\"\u003c\u003c1\u003c\u003cendl; else cout\u003c\u003c\"y=\"\u003c\u003c-1\u003c\u003cendl; 也可以省去else后的语句 if(x\u003e=0) cout\u003c\u003c\"y=\"\u003c\u003c1\u003c\u003cendl; 又到了经典的找最大值程序2333 #include\u003ciostream\u003e using namespace std; int main() { int a,b,max; cout\u003c\u003c\"Input a,b:\"; cin\u003e\u003ea\u003e\u003eb; if(a\u003eb) max=a; else max=b; cout\u003c\u003c\"The max is:\"\u003c\u003cmax\u003c\u003cendl; return 0; } ","date":"2021-01-18","objectID":"/20210118/:1:0","tags":["C++"],"title":"C++程序控制结构","uri":"/20210118/"},{"categories":["C++"],"content":"用条件运算符?:代替if else语句 max=a\u003eb?a:b; 代替 if(a\u003eb) max=a; else max=b; cout\u003c\u003c\"The max is:\"\u003c\u003cmax\u003c\u003cendl; 代替后的程序如下： #include\u003ciostream\u003e using namespace std; int main() { int a,b,max; cout\u003c\u003c\"Input a,b:\"; cin\u003e\u003ea\u003e\u003eb; /* if(a\u003eb) max=a; else max=b; if(c\u003emax) max=c; cout\u003c\u003c\"The max is:\"\u003c\u003cmax\u003c\u003cendl; */ //用？：运算符实现 max=(a\u003eb?a:b)\u003ec?(a\u003eb?a:b):c; cout\u003c\u003c\"The max is:\"\u003c\u003cmax\u003c\u003cendl; return 0; } 这里的if else语句缩减了格式，这是常用书写规范下需要合理选择的，花括号{}不能超过一屏等就是类似的常用书写规范。 ","date":"2021-01-18","objectID":"/20210118/:2:0","tags":["C++"],"title":"C++程序控制结构","uri":"/20210118/"},{"categories":["C++"],"content":"if else语句的嵌套 有两种形式嵌套if语句： if() if() else else if() else 或 if() else if() …… else if() else 无论是何种形式的if else嵌套，需要注意的是if和else的对应关系，有时候为了区分该层if的语句范围，用花括号{}括起来表示。 if() { if() 语句1} else 语句2 实例(考试成绩分级) #inclue\u003ciostream\u003e using namespace std; int main() { int score; char result; cout\u003c\u003c\"请输入学生百分制成绩(0~100):\"; cin\u003e\u003escore; if(score\u003e=90) result='A'; else if(score\u003e=80) result='B'; else if(score\u003e=70) result='C'; else if(score\u003e=60) result='D'; else result='E'; cout\u003c\u003c\"百分制成绩\"\u003c\u003cscore\u003c\u003c\"对应的成绩等级\"\u003c\u003cresult\u003c\u003cendl; return 0; } 这里成绩通过自上而下的方式筛选，实际也可以自下而上筛选。 ","date":"2021-01-18","objectID":"/20210118/:2:1","tags":["C++"],"title":"C++程序控制结构","uri":"/20210118/"},{"categories":["C++"],"content":"多路选择控制语句switch switch(测试表达式) { case 常量表达式1: 语句1 case 常量表达式2: 语句2 …… case 常量表达式n: 语句n default: 语句n+1 } 执行顺序： 1.执行测试表达式得到其值; 2.在case语句中找到值相等的常量表达式; 3.如果没有找到相等的常量表达式时，则从\"default:“开始执行。 注意： 1.switch后的括号()内只能是整型、字符型、枚举型; 2.各常量表达式的值不能相等，且次序不影响执行结果; 3.每个case语句只是一个入口标号，通常只需要执行一个case后的语句，所以每个case选择的最后应该加break语句，用来结束整个switch结构; 4.当若干选择需要执行相同操作时，可以使多个case选择共用一组语句。 用switch重做考试成绩分级： #include\u003ciostream\u003e using namespace std; int main() { int score; char result; cout\u003c\u003c\"请输入学生百分制的成绩(0~100):\"; cin\u003e\u003escore; switch(score/10) { case 10: // result='A'; case 9: result='A'; break; case 8: result='B'; break; case 7: result='C'; break; case 6: result='D'; break; default: result='E'; } cout\u003c\u003c\"百分制成绩\"\u003c\u003cscore\u003c\u003c\"对应的成绩等级为：\"\u003c\u003cresult\u003c\u003cendl; return 0; } ","date":"2021-01-18","objectID":"/20210118/:3:0","tags":["C++"],"title":"C++程序控制结构","uri":"/20210118/"},{"categories":["C++"],"content":"循环控制结构 ###1.while语句 while(测试表达式) 循环体 这里判断测试表达式为true时，执行循环体，一般这里的循环体会用花括号{}括起来，判断测试表达式为false时，循环结束。 求自然数1~100之和。 #include\u003ciostream\u003e using namespace std; int main() { int i=1,sum=0; while(i\u003c=100) { sum+=i; i++; } cout\u003c\u003c\"sum=\"\u003c\u003csum\u003c\u003cendl; return 0; } 程序运行情况： sum=5050 ","date":"2021-01-18","objectID":"/20210118/:4:0","tags":["C++"],"title":"C++程序控制结构","uri":"/20210118/"},{"categories":["C++"],"content":"do while语句 形式 do 循环体 while(测试表达式); 实例：求1~100之和 #include\u003ciostream\u003e using namespace std; int main() { int i=1,sum=0; do{ sum += i; i++; }while(i\u003c=100); cout\u003c\u003c\"sum=\"\u003c\u003csum\u003c\u003cendl; return 0; } 这里do while语句与while语句不同之处在于是测试表达式的判断先后。 有限次循环三要素: 1.循环控制变量初始化； 2.循环结束条件； 3.循环变量更新。 ","date":"2021-01-18","objectID":"/20210118/:5:0","tags":["C++"],"title":"C++程序控制结构","uri":"/20210118/"},{"categories":["C++"],"content":"for语句 形式 for(初始化表达式;测试表达式;更新表达式) 循环体 实例： #include\u003ciostream\u003e using namespace std; int main() { int i=1,sum=0; for(i\u003c1,i\u003c=100,i++) { sum +=i; } cout\u003c\u003c\"sum=\"\u003c\u003csum\u003c\u003cendl; return 0; } 程序段： int i=1,sum=0; for(i\u003c1,i\u003c=100;i++) { sum +=i } 可以缩写成 for(int i=1,sum=0;i\u003c=100;i++) sum+=i 如果省略初始化表达式和更新表达式，只有测试表达式，则完全等同于while语句。 for(;i\u003c=60;) sum+= i++; 等同于 while(i\u003c=60) sum+= i++; ","date":"2021-01-18","objectID":"/20210118/:6:0","tags":["C++"],"title":"C++程序控制结构","uri":"/20210118/"},{"categories":["C++"],"content":"赋值表达式 常规类似python，同样有赋值运算的简写形式，如 b += 2 //b = b + 2 x *= y + 3 //x = x*(y+3) x += x -= x*x //x = x + (x = x - x*x) ","date":"2021-01-15","objectID":"/20210115/:1:0","tags":["C++"],"title":"C++简单程序","uri":"/20210115/"},{"categories":["C++"],"content":"逗号表达式 在C++中，逗号也是一个运算符，使用形式为 \u003c表达式1\u003e,\u003c表达式2\u003e,……,\u003c表达式n\u003e 上述表达式的求解顺序为先求解表达式1，再求解表达式2，……，逗号表达式的最终结果为表达式n的值。 #include \u003ciostream\u003e using namespace std; int main( ) { //赋值 int a=1,c=2,n,m; n = 2-(a=3); // n=2-a = 3 //错误 n += m -= a*a; cout\u003c\u003c\"c+2=\"\u003c\u003cc+2\u003c\u003cendl; // cout\u003c\u003cn = m = a\u003c\u003cendl; //错误 a = (c=5,c+5,c/2); cout\u003c\u003c\"a=\"\u003c\u003ca\u003c\u003cendl; //a=2,注意c+5并没给c赋值 // cout\u003c\u003ca=(c=5,c+5,c/5)\u003c\u003cendl; //错误 // cout\u003c\u003ca-c+5\u003c\u003cendl; int i=12; i + = i =i * =i; cout\u003c\u003c\"i=\"\u003c\u003ci\u003c\u003cendl; n = m = a; cout\u003c\u003c\"n=\"\u003c\u003cn\u003c\u003c\",=\"\u003c\u003cm\u003c\u003cendl; return 0; } 程序运行情况: C+2=4 a=2 i=0 n=2,m=2 ","date":"2021-01-15","objectID":"/20210115/:2:0","tags":["C++"],"title":"C++简单程序","uri":"/20210115/"},{"categories":["C++"],"content":"关系表达式\u0026比较运算符 记住下面这段东西： // 优先级相同(较高) \u003c,\u003c=,\u003e,\u003e= //优先级相同(较低) ==,!= //以上运算符与Python一样 注意：==是两个等于号，表示判断左边是否等于右边，返回值是true或者false。这里与Python中的判断语句一样。 ","date":"2021-01-15","objectID":"/20210115/:3:0","tags":["C++"],"title":"C++简单程序","uri":"/20210115/"},{"categories":["C++"],"content":"逻辑表达式 !(非) \u0026\u0026(与) ||(或) 优先级为前高后低 !是一元运算符，作用是操作数取反 \u0026\u0026和||是二元运算符，作用是判断返回值为true或false。 ","date":"2021-01-15","objectID":"/20210115/:4:0","tags":["C++"],"title":"C++简单程序","uri":"/20210115/"},{"categories":["C++"],"content":"条件表达式 条件运算符?:是C++中唯一的三元运算符，作用是实现简单的选择功能，形式如下： \u003c测试表达式\u003e?\u003c表达式1\u003e:\u003c表达式2\u003e 其中，测试表达式通常是bool类型，表达式1和表达式2可以是任何类型。 执行顺序： 1.求解测试表达式，求解出值; 2.若值为true，执行表达式1，表达式1的结果就是该条件表达式结果; 3.若值为false，执行表达式2，表达式2的结果就是该条件表达式结果; 注意： 条件运算符的优先级高于赋值运算符，低于逻辑运算符，结合方向自右向左。 eg:将a与b中的最大值赋值给max max=(a\u003eb)?a:b; ","date":"2021-01-15","objectID":"/20210115/:5:0","tags":["C++"],"title":"C++简单程序","uri":"/20210115/"},{"categories":["C++"],"content":"sizeof运算符 计算某种数据类型在内存中所占字节数。 //XXX是类型名 sizeof(XXX) //或者XXX是表达式 sizeof(XXX) //注意，这里的表达式并不会求解，只会返回表达式结果的类型所占的字节数 ","date":"2021-01-15","objectID":"/20210115/:6:0","tags":["C++"],"title":"C++简单程序","uri":"/20210115/"},{"categories":["C++"],"content":"位运算 这是Python中所没有的，高级语言处理数据最小单位只能是字节，C++可以对数据按二进制位进行操作。 C++中有6个位运算符，只能对整型数据进行操作。 1.按位与(\u0026) 将两个操作数对应每一位分别进行逻辑与操作。 3 00000011 5(\u0026) 00000101 ------------------ 3\u00265 00000001 这里与0相与，清零该位；与1相与，维持不变。 最常用的使用方法是将操作数中的若干位清零，或者取操作数中的若干指定位。 (1)将char型变量a的最低位清零： a=a\u00260xfe (2)设变量c是char型变量，变量a是int变量，下列语句可取出a的低字节，并放置于c中： c=a\u00260337; 2.按位或(|) 将两个操作数的对应每一位分别进行逻辑或操作。 3 00000011 5(|) 00000101 ------------------ 3|5 00000111 常用于将操作数中若嘎巴位的值置为1(其他位保持不变)。 将int型变量a的低字节置为1： a=a|0xff 3.按位异或(^) 将两个操作数对应每一位进行异或操作(对应位相同为0，不同为1)。 071 00111001 051(^) 00101010 ------------------------ 071^051 00010011 常用于将操作数中的若干指定位取反。 与0异或，结果是该位原值；与1异或，结果是该位值取反。 4.按位取反(~) 按位取反是一个单目运算符，作用是对一个二进制数的每一位取反。 025 00010101 ~025 11101010 5.移位 C++中有两个移位运算符：左移位运算符(«)，右移位运算符(»)。它们都是二元运算符。 移位运算符左边是操作数，右边是需要移动的位数。 移位规则： 左移，低位补0，移出的高位舍弃。 右移，低位舍弃，无符号数高位补0，有符号数高位补符号位。 设 short a = 65 ，则a\u003e\u003e1的操作过程如下 移位前： 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 移位后： (0) 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 (1) 补1位0 舍弃低1位 设 2\u003c\u003c4的值为32 ，则2\u003c\u003c4的操作过程如下 移位前： 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 移位后： (0 0 0 0) 0 0 0 0 0 0 0 0 0 0 1 (0 0 0 0) 舍弃高4位 补4位0 注意：移位运算的结果是位运算表达式的值。移位后，左边的值不变，即a»1后，a还是原值65。 ","date":"2021-01-15","objectID":"/20210115/:7:0","tags":["C++"],"title":"C++简单程序","uri":"/20210115/"},{"categories":["C++"],"content":"数据类型转换 1.将一种类型值赋值给另一种类型的变量 #include\u003ciostream\u003e using namespace std; int main() { //整型和实型的赋值 int i = 3.56; //i赋值为3 int j = 1.8E12; //数值超出类型取值范围，j不能被正确赋值 float n = 5; //n被赋值为5.0 cout\u003c\u003c\" int i = \"\u003c\u003ci\u003c\u003cendl; cout\u003c\u003c\" int j = \"\u003c\u003cj\u003c\u003cendl; cout\u003c\u003c\" float n = \"\u003c\u003cn\u003c\u003c\" , n/2 =\"\u003c\u003cn/2\u003c\u003cendl; //bool类型的赋值 bool t1 = 19,t2 = 0; //t1被赋值为true，t2被赋值为false cout\u003c\u003c\" bool t1 = \"\u003c\u003ct1\u003c\u003c\" , bool t2 = \"\u003c\u003ct2\u003c\u003cendl; //取值范围不同类型的赋值 short s1 = 50; long l1 = s1; cout\u003c\u003c\" short s1 = \"\u003c\u003cs1\u003c\u003c\" , long l1 =\"\u003c\u003cl1\u003c\u003cendl; long l2 = 3500; short s2 = l2; //数值超过类型取值范围，s2不能被正确赋值 cout\u003c\u003c\" long l2 = \"\u003c\u003cl2\u003c\u003c\" , short s2 =\"\u003c\u003cs2\u003c\u003cendl; double d = 3.4E50; float f = d; //数值超出类型取值范围，f不能正确赋值 cout\u003c\u003c\" double d = \"\u003c\u003cd\u003c\u003c\" , float f =\"\u003c\u003cf\u003c\u003cendl; return 0 } 程序运行结果： int i = 3 int j = 408702976 float n = 5,n/2 = 2.5 bool t1 = 1,bool t2 = 0 short s1 = 50,long l1 = 50 long l2 = 3500,short s2 = -30536 double d = 3.4e+050,float = 1.#INF 小范围值可以赋值给大范围值，大范围值无法赋值给小范围值，此时会显示#INF表示不能正确赋值。 赋值运算要求左值与右值的类型相同，不同会自动进行类型转换，其转换的规则是将右值类型转换为左值的类型。 bool值赋值时，非0则赋值为true，0赋值为false。 ","date":"2021-01-15","objectID":"/20210115/:8:0","tags":["C++"],"title":"C++简单程序","uri":"/20210115/"},{"categories":["C++"],"content":"表达式的隐含转换 混合运算中二元运算符要求两边类型一致，若不一致，自动进行转换，由低到高。 大小关系如下 char short int unsigned long unsigned-long float double --------------------------------------------------------------------------------- 低 高 ","date":"2021-01-15","objectID":"/20210115/:9:0","tags":["C++"],"title":"C++简单程序","uri":"/20210115/"},{"categories":["C++"],"content":"强制类型转换\u0026显式转换 \u003c类型标识符\u003e(表达式) 或 (类型标识符)\u003c表达式\u003e 这里类似Python。 ","date":"2021-01-15","objectID":"/20210115/:10:0","tags":["C++"],"title":"C++简单程序","uri":"/20210115/"},{"categories":["C++"],"content":"输入与输出 1.cout cout\u003c\u003c\"\\\"This is a simple.\\\",he said.\\n\"; 输出结果为： “This is a simple.\",he said. 2.cin 程序需要键盘输入时，用提取操作符(»)从cin输入流中抽取字符，格式如下 cin\u003e\u003e变量名\u003e\u003e…… cin是预定义的流类对象，»是预定义的提取符，cin能自动识别输入的数据类型。 ","date":"2021-01-15","objectID":"/20210115/:11:0","tags":["C++"],"title":"C++简单程序","uri":"/20210115/"},{"categories":["C++"],"content":"I/O流控制符 包含在iomanip中 #include\u003ciomanip\u003e 头文件引入后可使用dec,hex,oct,ws,endl,ends,setprecision(int),setw(int) 其中较为常用的是设置宽域的setw()，插入换行符并刷新流的endl，插入空字符的ends。 cout\u003c\u003csetw(8)\u003c\u003c10\u003c\u003c20\u003c\u003cendl; 运行结果为 ------1020 例子： //用格式控制符控制输出 #include\u003ciostream\u003e #include\u003ciomainip\u003e using namespace std; int main() { int k; double n; cout\u003c\u003c\"输入十进制整数K和实数n的值：\"; cin\u003c\u003ck\u003c\u003cn; cout\u003c\u003c\"\\tDecimal:\"\u003c\u003cdec\u003c\u003ck\u003c\u003cendl \u003c\u003c\"\\tHexadecimal:\"\u003c\u003chex\u003c\u003ck\u003c\u003cendl \u003c\u003c\"\\t0ctal:\"\u003c\u003coct\u003c\u003ck\u003c\u003cendl; cout\u003c\u003c\"设置域宽setw(5):\\n\"\u003c\u003csetw(5)\u003c\u003cn\u003c\u003cendl; //5\u003c7 cout\u003c\u003c\"设置域宽setw(10):\\n\"\u003c\u003csetw(10)\u003c\u003cn\u003c\u003cendl; //10\u003e7 cout\u003c\u003c\"设置小数位数setprecision(4):\\n\"\u003c\u003csetprecision(4)\u003c\u003cn\u003c\u003cendl; return 0 } 程序运行情况： 输入十进制整数K和实数n的值：1001 3.14159 Decimal:1001 Hexadecimal:3e9 Octal:1751 设置域宽setw(5): 3.14159 设置域宽setw(10): 3.14159 设置小数位数setprecision(4): 2.142 ","date":"2021-01-15","objectID":"/20210115/:12:0","tags":["C++"],"title":"C++简单程序","uri":"/20210115/"},{"categories":["C++"],"content":"插入部分C语言控制符和函数 1.printf(“格式控制符”,输出列表)和scanf(“格式控制符”,地址列表) #include\u003ciostream\u003e using namespace std; int main() { int k; float n; char ch; printf(\"Input k,n,ch\") scanf(\"%d%f,%c\",\u0026k,\u0026n,\u0026ch); printf(\"k=%d,n=%f,ch=%c\\n\",k,n,ch); return 0 } 程序运行情况： Input k,n,ch:5 3.14,a k=5,n=3,ch=a printf(\"x=%dy=%f\\n\",x,y); 等同于 cout\u003c\u003c\"x=\"\u003c\u003cx\u003c\u003c\"y=\"\u003c\u003cy; 2.getchar()和putchar() #include\u003ciostream\u003e using namespace std; int main() { char ch; printf(\"Input ch:\"); //scanf()和printf() scanf(\"%c\",\u0026ch); printf(\"ch=5c\\n\",ch) //getchar()和putchar() // ch=getchar(); // putchar(ch); // putchar('\\n'); return 0; } 程序运行情况： Input ch:A ch=A ","date":"2021-01-15","objectID":"/20210115/:13:0","tags":["C++"],"title":"C++简单程序","uri":"/20210115/"},{"categories":["C++"],"content":"数据溢出 #include\u003ciostream\u003e using namespace std; int main() { short a=32767,b; cout\u003c\u003c\"Input b:\"; cin\u003e\u003eb; a = a+b; cout\u003c\u003c\"sizeof=\"\u003c\u003csizeof(short)\u003c\u003cendl; cout\u003c\u003c\"a=\"\u003c\u003ca\u003c\u003c\",b=\"\u003c\u003cb\u003c\u003cendl; return 0; } 测试用例： Input b:2 sizeof=2 a=-32767,b=2 ","date":"2021-01-15","objectID":"/20210115/:14:0","tags":["C++"],"title":"C++简单程序","uri":"/20210115/"},{"categories":["C++"],"content":"如果有Python的基础，学习c++会感觉很别扭2333 如果是用VS写c++程序，注意打开文件夹包含.vscode文件夹，否则会运行找不到路径。 (Python就没那么麻烦，不用整json配置) ","date":"2021-01-10","objectID":"/20210110/:0:0","tags":["C++"],"title":"C++入门","uri":"/20210110/"},{"categories":["C++"],"content":"注释 /* 这是C++的 多行注释方法*/ /*******************/ //这是c++的单行注释方法 注释约定俗成写在程序上方或右方 ","date":"2021-01-10","objectID":"/20210110/:1:0","tags":["C++"],"title":"C++入门","uri":"/20210110/"},{"categories":["C++"],"content":"头文件 #include\u003ciostream\u003e .cpp文件开头在编译前将iostream.h文件中的代码嵌入到程序中，作为程序的一部分。 ","date":"2021-01-10","objectID":"/20210110/:2:0","tags":["C++"],"title":"C++入门","uri":"/20210110/"},{"categories":["C++"],"content":"主函数 int main() { cout\u003c\u003c\"hellow!\"\u003c\u003cendl; cout\u003c\u003c\"I am student\"\u003c\u003cendl; return 0; } main()之前的int表示主函数返回值的类型是整数类型int,函数主体用了花括号{}括起来，每个语句由;作为结束符。 另外，C++程序都是由函数构成的，在C++程序中，有且只能有一个main()函数，c++程序从主函数main()开始执行。 cout是输出语句，return是函数返回语句。 ","date":"2021-01-10","objectID":"/20210110/:3:0","tags":["C++"],"title":"C++入门","uri":"/20210110/"},{"categories":["C++"],"content":"名称空间 using namespace std; 这里的std是名称空间，类似python在库中预定义的方法一样，避免自己使用的名称存在歧义(即自己命名的标识符和所使用的类库的标识符重合的情况)，python中通过前缀库名解决，c++通过开头声明名称空间来解决。 ","date":"2021-01-10","objectID":"/20210110/:4:0","tags":["C++"],"title":"C++入门","uri":"/20210110/"},{"categories":["C++"],"content":"第一个c++程序 /*第一个c++程序*/ #include\u003ciostream\u003e using namespace std; int main() { cout\u003c\u003c\"Hello world!\"\u003c\u003cendl; return 0; } ","date":"2021-01-10","objectID":"/20210110/:5:0","tags":["C++"],"title":"C++入门","uri":"/20210110/"},{"categories":["C++"],"content":"其他注意事项 1.编程预处理语句：#开头的行， 2.一个程序函数名可以很多，但是每个程序必须包含main()，程序总是从main()开始执行，不管main()处于程序哪个位置， 3.程序中符号都是英文符号，不是中文符号， 4.函数体由{}括起来，一般包含变量定义和程序功能实现部分，所有变量需要先定义再使用， 5.程序中标识符分大小写， 6.凡是空格符出现的地方都可以换行表示，运行结果一样。 ","date":"2021-01-10","objectID":"/20210110/:6:0","tags":["C++"],"title":"C++入门","uri":"/20210110/"},{"categories":["C++"],"content":"数据类型 测试数据类型字节数 #include \u003ciostream\u003e using namespace std; int main() { cout \u003c\u003c \"Size of char : \" \u003c\u003c sizeof(char) \u003c\u003c endl; cout \u003c\u003c \"Size of int : \" \u003c\u003c sizeof(int) \u003c\u003c endl; cout \u003c\u003c \"Size of short int : \" \u003c\u003c sizeof(short int) \u003c\u003c endl; cout \u003c\u003c \"Size of long int : \" \u003c\u003c sizeof(long int) \u003c\u003c endl; cout \u003c\u003c \"Size of float : \" \u003c\u003c sizeof(float) \u003c\u003c endl; cout \u003c\u003c \"Size of double : \" \u003c\u003c sizeof(double) \u003c\u003c endl; cout \u003c\u003c \"Size of wchar_t : \" \u003c\u003c sizeof(wchar_t) \u003c\u003c endl; return 0; } ","date":"2021-01-10","objectID":"/20210110/:7:0","tags":["C++"],"title":"C++入门","uri":"/20210110/"},{"categories":["C++"],"content":"转义字符\\ \\n 换行 \\t 横向跳格，输出位置跳到下一个制表位 \\b 退格，输出位置回退一个字符 \\r 回车，输出位置回退到本行开头 \\a 响铃 这里的\\类似Python中的r，作为转义字符使用 \\\\ 两个反斜杠实际表示一个反斜杠 ' 表示’ \" 表示\" \\ddd 表示1~3位的八进制数 \\xhh 表示1~2位的十六进制数 #include\u003ciostream\u003e using namespace std; int main() { //整型常量 int a=3; int b=023; int c=0x3a; int d=0x3A; cout\u003c\u003c\"整型常量：\\n赋值\\t\\t输出\\n\"; cout\u003c\u003c\"a=3,\\t\\ta=\"\u003c\u003ca\u003c\u003cendl; cout\u003c\u003c\"b=023,\\t\\tb=\"\u003c\u003cb\u003c\u003cendl; cout\u003c\u003c\"c=0x3a,\\tc=\"\u003c\u003cc\u003c\u003cendl; cout\u003c\u003c\"\\144=0x3A,\\t\\x64=\"\u003c\u003cd\u003c\u003cendl; //实型常量 double e=30000; //一般形式，大数 double f=0.00012; //一般形式，小数 double g=3.0E+4; //指数形式，大数 double h=0.12e-3; //指数形式，小数 cout\u003c\u003c\"\\xA实型常量：\\12赋值\\t\\t输出\\x0a\"; cout\u003c\u003c\"e=30000.0,\\te=\"\u003c\u003ce\u003c\u003cendl; cout\u003c\u003c\"f=0.0012\\tf=\"\u003c\u003cf\u003c\u003cendl; cout\u003c\u003c\"g=3.0E+4,\\tg=\"\u003c\u003cg\u003c\u003cendl; cout\u003c\u003c\"h=0.12e-3,\\th=\"\u003c\u003ch\u003c\u003cendl; } ","date":"2021-01-10","objectID":"/20210110/:8:0","tags":["C++"],"title":"C++入门","uri":"/20210110/"},{"categories":["C++"],"content":"变量声明与引用 声明形式如下 \u003c类型\u003e 变量名1,变量名2,……; 引用形式如下 \u003c类型\u003e \u0026引用名=目标名; eg： int r=10; //声明 int \u0026qr=r; //引用 实际qr=r=10,这里就是引用。 (这里如果是Python则直接用等号即可，c++需要在引用名前添加\u0026) ","date":"2021-01-10","objectID":"/20210110/:9:0","tags":["C++"],"title":"C++入门","uri":"/20210110/"},{"categories":["C++"],"content":"运算符 常规类似python，不同的如下。 1.单独使用自增自减运算符 int i=1,j=1; //前后置自增运算符单独执行 cout\u003c\u003c\"i=\"\u003c\u003ci\u003c\u003cendl; cout\u003c\u003c\"j=\"\u003c\u003cj\u003c\u003cendl; i++;++j; cout\u003c\u003c\"i=\"\u003c\u003ci\u003c\u003cendl; cout\u003c\u003c\"j=\"\u003c\u003cj\u003c\u003cendl; //运算后结果两者都为2 2.参与其他操作的自增自减运算符 int i=1,j=1; //参与其他操作的自增运算符 cout\u003c\u003c\"i=\"\u003c\u003ci\u003c\u003cendl; cout\u003c\u003c\"j=\"\u003c\u003cj\u003c\u003cendl; cout\u003c\u003c\"i++=\"\u003c\u003ci++\u003c\u003cendl; cout\u003c\u003c\"++j=\"\u003c\u003c++j\u003c\u003cendl; /* i=1 j=1 i++=1 ++j=2 */ 注意：自增自减运算符后置优先于前置。 ","date":"2021-01-10","objectID":"/20210110/:10:0","tags":["C++"],"title":"C++入门","uri":"/20210110/"},{"categories":["C++"],"content":"安装vscode 安装包 ","date":"2021-01-09","objectID":"/20210109/:1:0","tags":["C++"],"title":"C++环境安装","uri":"/20210109/"},{"categories":["C++"],"content":"教程安装C++用到的配置 压缩包解压后放到你装c++程序的文件夹里，里面的配置文件需要根据教程的第五步改。 压缩包链接 ","date":"2021-01-09","objectID":"/20210109/:2:0","tags":["C++"],"title":"C++环境安装","uri":"/20210109/"},{"categories":["C++"],"content":"安装教程 csdn链接 ","date":"2021-01-09","objectID":"/20210109/:3:0","tags":["C++"],"title":"C++环境安装","uri":"/20210109/"},{"categories":["C++"],"content":"暂时只安装c++环境，c环境有需要我再补充 ","date":"2021-01-09","objectID":"/20210109/:4:0","tags":["C++"],"title":"C++环境安装","uri":"/20210109/"},{"categories":["python","爬虫"],"content":"创建并使用多线程 print('主线程执行代码') # 从 threading 库中导入Thread类 from threading import Thread from time import sleep # 定义一个函数，作为新线程执行的入口函数 def threadFunc(arg1,arg2): print('子线程 开始') print(f'线程函数参数是：{arg1}, {arg2}') sleep(5) print('子线程 结束') # 创建 Thread 类的实例对象， 并且指定新线程的入口函数，此时并没有执行 thread = Thread(target=threadFunc, args=('参数1', '参数2') ) #target=threadFunc对应执行的函数threadFunc #args=('参数1', '参数2')这样新进程添加参数 # 执行start 方法，就会创建新线程， # 并且新线程会去执行入口函数里面的代码。 # 这时候这个进程有两个线程了。↓ thread.start() # 主线程的代码执行 子线程对象的join方法， # 就会等待子线程结束，才继续执行下面的代码 thread.join() print('主线程结束') 运行该程序，解释器执行到下面代码时 thread = Thread(target=threadFunc, args=('参数1', '参数2') ) 创建了一个Thread实例对象，其中，Thread类的初始化参数 有两个 target参数 是指定新线程的 入口函数， 新线程创建后就会 执行该入口函数里面的代码， args 指定了 传给 入口函数threadFunc 的参数。 线程入口函数 参数，必须放在一个元组里面，里面的元素依次作为入口函数的参数。 注意，上面的代码只是创建了一个Thread实例对象， 但这时，新的线程还没有创建。 要创建线程，必须要调用 Thread 实例对象的 start方法 。也就是执行完下面代码的时候 thread.start() 新的线程才创建成功，并开始执行 入口函数threadFunc 里面的代码。 有的时候， 一个线程需要等待其它的线程结束，比如需要根据其他线程运行结束后的结果进行处理。 这时可以使用 Thread对象的 join 方法 thread.join() 如果一个线程A的代码调用了 对应线程B的Thread对象的 join 方法，线程A就会停止继续执行代码，等待线程B结束。 线程B结束后，线程A才继续执行后续的代码。 就是等所一线程执行完毕才继续运行运行下面的程序 所以主线程在执行上面的代码时，就暂停在此处， 一直要等到 新线程执行完毕，退出后，才会继续执行后续的代码。 #错误示例！！！！ thread = Thread(target=threadFunc('参数1', '参数2')) ↑如果这样写无法创建新线程并执行，这样target传入不是函数，传入的是运行结果(null)，而且是在主线程运行完了，并不是在子线程里运行。 ","date":"2020-08-31","objectID":"/20200831/:0:1","tags":["python","爬虫"],"title":"创建新线程(通用)","uri":"/20200831/"},{"categories":["python","爬虫"],"content":"共享数据的访问控制 做多线程开发，经常遇到这样的情况：多个线程里面的代码需要访问同一个公共的数据对象。 这个公共的数据对象可以是任何类型， 比如一个列表、字典、或者自定义类的对象。 有的时候，程序需要防止线程的代码同时操作公共数据对象。否则，就有可能导致数据的访问互相冲突影响。 请看一个例子。 我们用一个简单的程序模拟一个银行系统，用户可以往自己的帐号上存钱。 对应代码如下： from threading import Thread from time import sleep bank = { 'byhy' : 0 } # 定义一个函数，作为新线程执行的入口函数 def deposit(theadidx,amount): balance = bank['byhy'] # 执行一些任务，耗费了0.1秒 sleep(0.1) bank['byhy'] = balance + amount print(f'子线程 {theadidx} 结束') theadlist = [] for idx in range(10): thread = Thread(target = deposit, args = (idx,1) ) thread.start() # 把线程对象都存储到 threadlist中 theadlist.append(thread) for thread in theadlist: thread.join() print('主线程结束') print(f'最后我们的账号余额为 {bank[\"byhy\"]}') 上面的代码中，一起执行 开始的时候， 该帐号的余额为0，随后我们启动了10个线程， 每个线程都deposit函数，往帐号byhy上存1元钱。 可以预期，执行完程序后，该帐号的余额应该为 10。 然而，我们运行程序后，发现结果如下 子线程 0 结束 子线程 3 结束 子线程 2 结束 子线程 4 结束 子线程 1 结束 子线程 7 结束 子线程 5 结束 子线程 9 结束 子线程 6 结束 子线程 8 结束 主线程结束 最后我们的账号余额为 1 为什么是 1 呢？ 而不是 10 呢？ 如果在我们程序代码中，只有一个线程，如下所示 from time import sleep bank = { 'byhy' : 0 } # 定义一个函数，作为新线程执行的入口函数 def deposit(theadidx,amount): balance = bank['byhy'] # 执行一些任务，耗费了0.1秒 sleep(0.1) bank['byhy'] = balance + amount for idx in range(10): deposit (idx,1) print(f'最后我们的账号余额为 {bank[\"byhy\"]}') 代码都是串行执行的。不存在多线程同时访问bank对象的问题，运行结果一切都是正常的。 现在我们程序代码中，有多个线程，并且在这个几个线程中都会去调用deposit，就有可能同时操作这个bank对象，就有可能出一个线程覆盖另外一个线程的结果的问题。 这时，可以使用threading库里面的锁对象Lock去保护。 我们修改多线程代码，如下： from threading import Thread,Lock from time import sleep bank = { 'byhy' : 0 } bankLock = Lock() # 定义一个函数，作为新线程执行的入口函数 def deposit(theadidx,amount): # 操作共享数据前，申请获取锁 bankLock.acquire() balance = bank['byhy'] # 执行一些任务，耗费了0.1秒 sleep(0.1) bank['byhy'] = balance + amount print(f'子线程 {theadidx} 结束') # 操作完共享数据后，申请释放锁 bankLock.release() theadlist = [] for idx in range(10): thread = Thread(target = deposit, args = (idx,1) ) thread.start() # 把线程对象都存储到 threadlist中 theadlist.append(thread) for thread in theadlist: thread.join() print('主线程结束') print(f'最后我们的账号余额为 {bank[\"byhy\"]}') 执行一下，结果如下 子线程 0 结束 子线程 1 结束 子线程 2 结束 子线程 3 结束 子线程 4 结束 子线程 5 结束 子线程 6 结束 子线程 7 结束 子线程 8 结束 子线程 9 结束 主线程结束 最后我们的账号余额为 10 正确了。 Lock对象的acquire方法是申请锁。 每个线程在操作共享数据对象之前，都应该申请获取操作权，也就是调用该共享数据对象对应的锁对象的acquire方法。 如果线程A执行如下代码，调用acquire方法的时候， bankLock.acquire() 别的线程B已经申请到了这个锁，并且还没有释放，那么线程A的代码就在此处等待线程B释放锁，不去执行后面的代码。 直到线程B执行了锁的release方法释放了这个锁，线程A才可以获取这个锁，就可以执行下面的代码了。 如果这时线程B又执行这个锁的acquire方法，就需要等待线程A执行该锁对象的release方法释放锁，否则也会等待，不去执行后面的代码。 ","date":"2020-08-31","objectID":"/20200831/:0:2","tags":["python","爬虫"],"title":"创建新线程(通用)","uri":"/20200831/"},{"categories":["python","爬虫"],"content":"daemon线程 from threading import Thread from time import sleep def threadFunc(): sleep(2) print('子线程 结束') thread = Thread(target=threadFunc) thread.start() print('主线程结束') 可以发现，主线程先结束，要过个2秒钟，等子线程运行完，整个程序才会结束退出。 因为： Python程序中当所有的 非daemon线程 结束了，整个程序才会结束 主线程是非daemon线程，启动的子线程缺省也是非daemon线程线程。 所以，要等到主线程和子线程都结束，程序才会结束。 我们可以在创建线程的时候，设置daemon参数值为True，如下 from threading import Thread from time import sleep def threadFunc(): sleep(2) print('子线程 结束') thread = Thread(target=threadFunc, daemon=True # 设置新线程为daemon线程 ) thread.start() print('主线程结束') 再次运行，可以发现，只要主线程结束了，整个程序就结束了。因为只有主线程是非daemon线程。 ","date":"2020-08-31","objectID":"/20200831/:0:3","tags":["python","爬虫"],"title":"创建新线程(通用)","uri":"/20200831/"},{"categories":["电脑技巧"],"content":"第三方词库资源 密码：QLHL 第三方词库下载链接 安装及使用视频 B站视频 ","date":"2020-07-27","objectID":"/20200727/:0:0","tags":["windows"],"title":"微软输入法进化类搜狗输入法","uri":"/20200727/"},{"categories":["matlab","数学建模"],"content":"通过下标引用矩阵元素 A(3,2)表示A矩阵第3行第2列的元素。\r如若超出限制行列维数，自动扩展，未赋值的默认为0 通过序号来引用矩阵元素 A(3)等同于A(1,2)\rA(i,j)的序号为(j-1)×m+i ps:A(:)可以将矩阵A的每一列元素堆叠起来，成为一个列向量。 运算 数值运算是矩阵运算的特殊形式 .点运算是矩阵各个元素对应作运算 判断运算： == 等于 ~= 不等于 当参与比较的量是两个同型的矩阵时，比较是对两矩阵相同位置的元素按标量关系运算规则逐个进行，最终的关系运算的结果是一个与原矩阵同型的矩阵，它的元素由0或1组成。 当参与比较的一个是标量，而另一个 是矩阵时，则把标量与矩阵的每一个元素按标量 关系运算规则逐个比较，最终的关系运算的结果是一个与原矩阵同型的矩阵，它的元素由0或1组成。 逻辑运算： 在算术运算、关系运算和逻辑运算中，算术运算的优先级最高，逻辑运算优先级最低，但逻辑非运算是单目运算，它的优先级比双目运算要高。 ps:双目运算是有两个数参与运算。单目运算是只有一个数参与运算。a\u0026b是双目运算。~a是单目运算 若参与逻辑运算的是两个同型矩阵，那么将对矩阵相同位置上的元素按标量规则逐个进行运算，最终运算结果是一个与原矩阵同型的矩阵，其元素由1或0组成。 若参与逻辑运算的一个是标量，一个是矩阵，那么将在标量与矩阵中的每个元素之间按标量规则逐个进行运算，最终运算结果是一个与原矩阵同型的矩阵，其元素由1或0组成。 字符串的表示 字符串是用单引号括起来的字符序列 字符串占一行，可通过(:)索引，类似Python切片操作，但区间是前包后闭 若字符串包含单引号，用两个单引号表示一个单引号 实战： 字符串的执行 矩阵处理 1.通用的特殊矩阵 2.魔方矩阵 3.范德蒙矩阵 4.希尔伯特矩阵 5.伴随矩阵 6.帕斯卡矩阵 7.函数 ","date":"2020-07-02","objectID":"/20200702/:0:0","tags":["matlab","数学建模"],"title":"Matlab02(矩阵运算)","uri":"/20200702/"},{"categories":["matlab","数学建模"],"content":"基础命令 1.打开文件夹 命令行窗口输入 cd 文件夹名\r这里推荐先在文件管理器先创建后打开 2.赋值变量会在工作区显示 可在命令行窗口输入whos 或 who 可以查看变量属性和具体参数 3.清空数据 clear\r4.设置文件搜索路径 5.数字类型转换 class()函数可得数字类型 class(数字)\r整型转换 int8() #转换成有符号的8位整型 uint8() #转换成无符号的8位整型 浮点型转换 数值数据默认为双精度型，可使用 single函数：single(数字)转换成单精度型 double函数：double(数字)转换成双精度型 复型 a+bi或a+bj real函数：取复型实部数据 image函数：取复型虚部数据 format命令格式 format long %输出长格式\rformat %输出短格式\rformat rat %输出有理数格式\r这个不影响数据存储，只是表达方式不同 ps:%是注释符号，按ctrl+R注释一行，ctrl+T取消一行注释 6.常见函数 三角函数及取整函数 实战及其他函数 rem(除数,被除数)函数取余数 isprime(n)函数判断n是否为素数，当n是素数时返回1，否则返回0 find()函数找寻数组中的序列号 7.预定义变量 简单矩阵的建立 1.直接输入法 A=[1,2,3;4,5,6;7,8,9]\r2.小矩阵拼接成大矩阵 A=[1,2,3;4,5,6;7,8,9] B=[-1,-2,3;-4,5,-6;-7,-8,-9] C=[A,B;B,A] 效果图： 3.用实部矩阵和虚部矩阵构成复数矩阵 B=[1,2,3;4,5,6] C=[6,7,8;9,10,11] A=B+i*C 效果图： 冒号表达式 结构矩阵和单元矩阵 ","date":"2020-07-01","objectID":"/20200701/:0:0","tags":["matlab","数学建模"],"title":"Matlab01(基础命令)","uri":"/20200701/"},{"categories":["python","数学建模"],"content":"前言 ","date":"2020-06-22","objectID":"/20200622/:1:0","tags":["python","数学建模"],"title":"Matplotlib","uri":"/20200622/"},{"categories":["python","数学建模"],"content":"本篇鸣谢 马川-燕大 的增删整理， 王圣元 ——原创文章，与原文不同之处包含我的学习记录。 匹配Jupyter Notebook的ipynb文档链接下载地址在资源页面里 ","date":"2020-06-22","objectID":"/20200622/:2:0","tags":["python","数学建模"],"title":"Matplotlib","uri":"/20200622/"},{"categories":["python","数学建模"],"content":"0 引言 Matplotlib 是 Python 中最基本的可视化工具，官网里 (https://matplotlib.org/) 好资料无数，可多多参考。 本章采用以下思路来讲解： 第一部分介绍 matplotlib 中的绘图逻辑，图包含的重要元素和他们之间的层级 (hierarchy) 第二部分只关注折线图 (line chart)，但是一步步从最初的烂图完善到最终的美图。这样可以把一种类型的图中的性质吃透，类比到其他类型的图一点也不难。 第三部分从画图的四大目的出发，即分布、联系、比较和构成，介绍了相对应的直方图 (historgram chart)，散点图 (scatter chart)，折线图 (line chart) 和饼状图 (pie chart)。这章偏向于用合适的图来实现不同的目的，没有在如何完善图的方面上下功夫，但在最后一节提到了如何画出使信息更有效的表达的图。 提纲： 和 NumPy, SciPy, Pandas 一样，要用 Matplotlib，首先引用其库。 import matplotlib 下面代码就是给 matplotlib 起了个别名 mpl，由于用 matplotlib.plot 比较多，也给它起了个别名 plt。 import matplotlib as mpl import matplotlib.pyplot as plt %matplotlib inline 而 %matplotlib inline 就是在 Jupyter notebook 里面内嵌画图的， 在画图中，个人偏好百度 Echarts 里面的一组颜色，因此将其 hex 颜色代码定义出来留在后面用。其中红色的 r_hex 和深青色的 dt_hex 是大爱。 r_hex = '#dc2624' # red, RGB = 220,38,36 dt_hex = '#2b4750' # dark teal, RGB = 43,71,80 tl_hex = '#45a0a2' # teal, RGB = 69,160,162 r1_hex = '#e87a59' # red, RGB = 232,122,89 tl1_hex = '#7dcaa9' # teal, RGB = 125,202,169 g_hex = '#649E7D' # green, RGB = 100,158,125 o_hex = '#dc8018' # orange, RGB = 220,128,24 tn_hex = '#C89F91' # tan, RGB = 200,159,145 g50_hex = '#6c6d6c' # grey-50, RGB = 108,109,108 bg_hex = '#4f6268' # blue grey, RGB = 79,98,104 g25_hex = '#c7cccf' # grey-25, RGB = 199,204,207 Hex Color RGB r_hex = ‘#dc2624’ # red RGB = 220,38,36 dt_hex = ‘#2b4750’ # dark teal RGB = 43,71,80 tl_hex = ‘#45a0a2’ # teal RGB = 69,160,162 r1_hex = ‘#e87a59’ # red RGB = 232,122,89 tl1_hex = ‘#7dcaa9’ # teal RGB = 125,202,169 g_hex = ‘#649E7D’ # green RGB = 100,158,125 o_hex = ‘#dc8018’ # orange RGB = 220,128,24 tn_hex = ‘#C89F91’ # tan RGB = 200,159,145 g50_hex = ‘#6c6d6c’ # grey-50 RGB = 108,109,108 bg_hex = ‘#4f6268’ # blue grey RGB = 79,98,104 g25_hex = ‘#c7cccf’ # grey-25 RGB = 199,204,207 ","date":"2020-06-22","objectID":"/20200622/:3:0","tags":["python","数学建模"],"title":"Matplotlib","uri":"/20200622/"},{"categories":["python","数学建模"],"content":"1 Matplotlib结构 ","date":"2020-06-22","objectID":"/20200622/:4:0","tags":["python","数学建模"],"title":"Matplotlib","uri":"/20200622/"},{"categories":["python","数学建模"],"content":"1.1 概览 Matplotlib 是一个巨无霸，乍一看无从下手，只能分解之后各点击破。总体来说，它包含两类元素： 基础 (primitives) 类：线 (line), 点 (marker), 文字 (text), 图例 (legend), 网格 (grid), 标题 (title), 图片 (image) 等。 容器 (containers) 类：图 (figure), 坐标系 (axes), 坐标轴 (axis) 和刻度 (tick) 基础类元素是程序员想画出的标准对象，而容器类元素是基础类元素的寄居处，它们也有层级结构。 图 → 坐标系 → 坐标轴 → 刻度 由上图看出： 图包含着坐标系 (多个) 坐标系由坐标轴组成 (横轴 xAxis 和纵轴 yAxis) 坐标轴上面有刻度 (主刻度 MajorTicks 和副刻度 MinorTicks) Python 中万物皆对象，Matplotlib 里这些元素也都是对象。下面代码打印出坐标系、坐标轴和刻度。 fig = plt.figure() ax = fig.add_subplot(1,1,1) plt.show() xax = ax.xaxis yax = ax.yaxis print( 'fig.axes:', fig.axes, '\\n') print( 'ax.xaxis:', xax ) print( 'ax.yaxis:', yax, '\\n' ) print( 'ax.xaxis.majorTicks:', xax.majorTicks, '\\n' ) print( 'ax.yaxis.majorTicks:', yax.majorTicks, '\\n') print( 'ax.xaxis.minorTicks:', xax.minorTicks ) print( 'ax.yaxis.minorTicks:', yax.minorTicks ) fig.axes: [\u003cmatplotlib.axes._subplots.AxesSubplot object at 0x000001C7E5D332B0\u003e] ax.xaxis: XAxis(54.0,36.0)\rax.yaxis: YAxis(54.0,36.0) ax.xaxis.majorTicks: [\u003cmatplotlib.axis.XTick object at 0x000001C7E5D54898\u003e, \u003cmatplotlib.axis.XTick object at 0x000001C7E5D54860\u003e, \u003cmatplotlib.axis.XTick object at 0x000001C7F8DB6B38\u003e, \u003cmatplotlib.axis.XTick object at 0x000001C7F8DB6D30\u003e, \u003cmatplotlib.axis.XTick object at 0x000001C7F8DCC470\u003e, \u003cmatplotlib.axis.XTick object at 0x000001C7F8DCC908\u003e] ax.yaxis.majorTicks: [\u003cmatplotlib.axis.YTick object at 0x000001C7E5D685C0\u003e, \u003cmatplotlib.axis.YTick object at 0x000001C7E5D54F60\u003e, \u003cmatplotlib.axis.YTick object at 0x000001C7F8DCCC88\u003e, \u003cmatplotlib.axis.YTick object at 0x000001C7F8DCC8D0\u003e, \u003cmatplotlib.axis.YTick object at 0x000001C7F8DD34E0\u003e, \u003cmatplotlib.axis.YTick object at 0x000001C7F8DD3668\u003e] ax.xaxis.minorTicks: [\u003cmatplotlib.axis.XTick object at 0x000001C7F8DA16A0\u003e]\rax.yaxis.minorTicks: [\u003cmatplotlib.axis.YTick object at 0x000001C7F8DAA940\u003e]\r从打印结果可看出坐标系、坐标轴和刻度都是对象。细看一下发现 xaxis 和 yaxis 上面都有 6 个主刻度 (majorTicks)。 此外，由坐标系和坐标轴指向同一个图 (侧面验证了图、坐标系和坐标轴的层级性)。 print( 'axes.figure:', ax.figure ) print( 'xaxis.figure:', xax.figure ) print( 'yaxis.figure:', yax.figure ) axes.figure: Figure(432x288)\rxaxis.figure: Figure(432x288)\ryaxis.figure: Figure(432x288)\r创造完以上四个容器元素后，可在上面添加各种基础元素，比如： 在坐标轴和刻度上添加标签 在坐标系中添加线、点、网格、图例和文字 在图中添加图例 如下图所示： 接下来四节分别介绍四大容器，首先从「图」开始。 ","date":"2020-06-22","objectID":"/20200622/:4:1","tags":["python","数学建模"],"title":"Matplotlib","uri":"/20200622/"},{"categories":["python","数学建模"],"content":"1.2 图 图是整个层级的顶部。 在图中可以添加基本元素「文字」。 plt.figure() plt.text( 0.5, 0.5, 'Figure', ha='center', va='center', size=20, alpha=0.5 ) plt.xticks([]), plt.yticks([]) plt.show() 用 plt.text() 函数，其参数解释如下： 第一、二个参数是指横轴和纵轴坐标 第三个参数字符是指要显示的内容 ha, va 是横向和纵向位置 size 设置字体大小 alpha 设置字体透明度 (0.5 是半透明) 在图中可以添加基本元素「图片」。 import numpy as np from PIL import Image plt.figure() plt.xticks([]), plt.yticks([]) im = np.array(Image.open('images/小白.jpg')) #im = plt.imread('images/小白.jpg') # Mc: 这种方式打开也可以 plt.imshow(im) plt.show() 用 Image.open() 将图片转成像素存在 ndarray 中，再用 plt.imshow() 展示。 在图中可以添加基本元素「折线」。 plt.figure() plt.plot( [0,1],[0,1] ) plt.show() plt.plot() 函数是用来画折线图的，前两个参数分别是 x 和 y，该函数会在第二节细讲。 当我们每次说画东西，看起来是在图 (Figure) 里面进行的，实际上是在坐标系 (Axes) 里面进行的。一幅图中可以有多个坐标系，因此在坐标系里画东西更方便 (有些设置使用起来也更灵活)。 下面来看看层级中排名第二的「坐标系」。 ","date":"2020-06-22","objectID":"/20200622/:4:2","tags":["python","数学建模"],"title":"Matplotlib","uri":"/20200622/"},{"categories":["python","数学建模"],"content":"1.3 坐标系 \u0026 子图 一幅图 (Figure) 中可以有多个坐标系 (Axes)，那不是说一幅图中有多幅子图 (Subplot)，因此坐标系和子图是不是同样的概念？ 在绝大多数情况下是的，两者有一点细微差别： 子图在母图中的网格结构一定是规则的 坐标系在母图中的网格结构可以是不规则的 由此可见，子图是坐标系的一个特例，来我们先研究特例。 子图 把图想成矩阵，那么子图就是矩阵中的元素，因此可像定义矩阵那样定义子图 - (子图行数、子图列数、第几个子图)。 subplot(rows, columns, i-th plots)\r文字解释起来有些晦涩，看代码和图就好懂了。 1×2 子图 plt.subplot(2,1,1) plt.xticks([]),plt.yticks([])#隐藏坐标 plt.text(0.5, 0.5, 'subplot(2,1,1)', ha='center', va='center', size=20, alpha=.5 ) plt.subplot(2,1,2) plt.xticks([]), plt.yticks([]) plt.text( 0.5, 0.5, 'subplot(2,1,2)', ha='center', va='center', size=20, alpha=.5 ) plt.show() 这两个子图类似于一个列向量 subplot(2,1,1) 是第一幅 subplot(2,1,2) 是第二幅 声明完子图后，下面所有代码就只在这幅子图上生效，直到声明下一幅子图。 2×1 子图 plt.subplot(1,2,1) plt.xticks([]),plt.yticks([]) plt.text(0.5, 0.5, 'subplot(1,2,1)', ha='center', va='center', size=20, alpha=.5 ) plt.subplot(1,2,2) plt.xticks([]), plt.yticks([]) plt.text( 0.5, 0.5, 'subplot(1,2,2)', ha='center', va='center', size=20, alpha=.5 ) plt.show() 这两个子图类似于一个行向量 subplot(1,2,1) 是第一幅 subplot(1,2,2) 是第二幅 创建包含subplot网格的figure是一个非常常见的任务，matplotlib有一个更为方便的方法plt.subplots，它可以创建一个新的Figure，并返回一个含有已创建的subplot对象的NumPy数组。这是非常实用的，因为可以轻松地对axes数组进行索引，就好像是一个二维数组一样，例如axes[0,1]。你还可以通过sharex和sharey指定subplot应该具有相同的X轴或Y轴。在比较相同范围的数据时，这也是非常实用的，否则，matplotlib会自动缩放各图表的界限。 2×2 子图 fig, axes = plt.subplots(nrows=2, ncols=2) # 可以轻松地对axes数组进行索引，就好像是一个二维数组一样 # axes[0,0].set( xticks=[], yticks=[] ) # s = 'My subplot' # axes[0,0].text( 0.5, 0.3, s, ha='center', va='center', size=20, alpha=.5 ) for i,ax in enumerate(axes.flat): #也可以axes.flatten()打平. flat将数组转换为1-D的迭代器,可以用for访问数组每一个元素;而flatten将数组的副本转换为一维(1-D)，并返回 ax.set( xticks=[], yticks=[] ) s = 'subplot(2,2,' + str(i) + ')' ax.text( 0.5, 0.5, s, ha='center', va='center', size=20, alpha=.5 ) plt.show() 这次我们用过坐标系来生成子图 (子图是坐标系的特例嘛)，第 1 行 fig, axes = plt.subplots(nrows=2, ncols=2)\r得到的 axes 是一个 2×2 的对象。在第 8行的 for 循环中用 axes.flat 将其打平，然后在每个 ax 上生成子图。 坐标系 坐标系比子图更通用，有两种生成方式 用 gridspec 包加上 subplot() gridspec用于生成一个标准的虚拟网格，后面可以对它进行切片处理生成不规则的图 用 plt.axes() 不规则网格 import matplotlib.gridspec as gridspec G = gridspec.GridSpec(3,3)#三行三列 ax1 = plt.subplot(G[0,:]) plt.xticks([]),plt.yticks([]) plt.text( 0.5, 0.5, 'Axes 1', ha='center', va='center', size=20, alpha=.5 ) ax2 = plt.subplot(G[1,:-1])#只有序号为1的行 plt.xticks([]),plt.yticks([]) plt.text( 0.5, 0.5, 'Axes 2', ha='center', va='center', size=20, alpha=.5 ) ax3 = plt.subplot(G[1:,-1])#序号为1以后的行 1: plt.xticks([]),plt.yticks([]) plt.text( 0.5, 0.5, 'Axes 3', ha='center', va='center', size=20, alpha=.5 ) ax4 = plt.subplot(G[-1,0]) plt.xticks([]),plt.yticks([]) plt.text( 0.5, 0.5, 'Axes 4', ha='center', va='center', size=20, alpha=.5 ) ax5 = plt.subplot(G[-1,-2]) plt.xticks([]),plt.yticks([]) plt.text( 0.5, 0.5, 'Axes 5', ha='center', va='center', size=20, alpha=.5 ) plt.show() 第 2 行将整幅图分成 3×3 份赋值给 G，第 4, 8, 12, 16, 20 行分别用 plt.subplot(G[]) 生成五个坐标系。G[] 里面的切片和 Numpy 数组用法一样： G[0, :] = 图的第一行 (Axes 1) G[1, :-1] = 图的第二行，第二三列 (Axes 2) G[1:, -1] = 图的第二三行，第三列 (Axes 3) G[-1, 0] = 图的第三行，第一列 (Axes 4) G[-1, -2] = 图的第三行，第二列 (Axes 5) 大图套小图 plt.axes([0.1,0.1,0.8,0.8]) plt.xticks([]),plt.yticks([]) plt.text( 0.6, 0.6, 'axes([0.1,0.1,0.8,0.8])', ha='center', va='center', size=20, alpha=.5 ) plt.axes([0.2,0.2,0.3,0.3]) plt.xticks([]),plt.yticks([]) plt.text( 0.5, 0.5, 'axes([0.2,0.2,0.3,0.3])', ha='center', va='center', size=20, alpha=.5 ) Text(0.5, 0.5, 'axes([0.2,0.2,0.3,0.3])')\r第 1 和 5 行分别用 plt.axes([l,b,w,h]) 其中 [l, b, w, h] 可以定义坐标系 l 代表坐标系左边到 Figure 左边的水平距离 b 代表坐标系底边到 Figure 底边的垂直距离 w 代表坐标系的宽度 h 代表坐标系的高度 如果 l, b, w, h 都小于 1，那它们是标准化 (normalized) 后的距离。比如 Figure 底边长度为 10， 坐标系底边到它的垂直距离是 2，那么 b = 2/10 = 0.2。 重叠图 plt.axes([0.1,0.1,0.5,0.5]) plt.xticks([]),plt.yticks([]) plt.text( 0.1, 0.1, 'axes([0.1,0.1,0.5,0.5])', ha='left', va='center', size=16, alpha=.5 ) plt.axes([0.2,0.2,0.5,0.5]) plt.xticks([]),plt.yticks([]) plt.text( 0.1, 0.1, 'axes([0.2,0.2,0.5,0.5])', ha='left', va='center', size=16, alpha=.5 ) plt.axes([0.3,0.3,0.5,0.5]) plt.xticks([]),plt.yticks([]) plt.text( 0.1, 0.1, 'axes([0.3,0.3,0.5,0.5])', ha='lef","date":"2020-06-22","objectID":"/20200622/:4:3","tags":["python","数学建模"],"title":"Matplotlib","uri":"/20200622/"},{"categories":["python","数学建模"],"content":"1.4 坐标轴 一个坐标系 (Axes)，通常是二维，有两条坐标轴 (Axis)： 横轴：XAxis 纵轴：YAxis 每个坐标轴都包含两个元素 容器类元素「刻度」，该对象里还包含刻度本身和刻度标签 基础类元素「标签」，该对象包含的是坐标轴标签 「刻度」和「标签」都是对象，下面代码通过改变它们一些属性值来进行可视化。 fig,ax = plt.subplots() ax.set_xlabel('Label on x-axis') ax.set_ylabel('Label on y-axis') for label in ax.xaxis.get_ticklabels():#设定刻度标签 #label is a Text instance label.set_color( dt_hex )#设定颜色 label.set_rotation(45)#设定字体逆时针旋转角度 label.set_fontsize(20)#设定字体大小 for line in ax.yaxis.get_ticklines():#设定对象的刻度本身 (即一条短线) #line is a Line2D instance line.set_color( r_hex ) line.set_markersize(500) line.set_markeredgewidth(30) plt.show() 第 2 和 3 行打印出 x 轴和 y 轴的标签。 第 5 到 9 行处理「刻度」对象里的刻度标签，将它颜色设定为深青色，字体大小为 20，旋转度 45 度。 第 11 到 15 行处理「标签」对象的刻度本身 (即一条短线)，将它颜色设定为红色，标记长度和宽度为 500 和 30 (夸张了些，但就为大家看清楚这条代表刻度的短线！)。 万物皆对象，坐标轴也不例外，下面代码打印出 x 轴的标签、刻度位置点、刻度标签、刻度线，刻度标签位置、主刻度。 print( ax.xaxis.get_label() )#x 轴的标签 print( ax.xaxis.get_ticklocs() )#x 轴的刻度位置点 print( ax.xaxis.get_ticklabels() )#x 轴的刻度标签 print( ax.xaxis.get_ticklines() )#x 刻度线 print( ax.xaxis.get_ticks_position() )#x 轴的刻度标签位置 print( ax.xaxis.get_major_ticks() )#x 轴的主刻度 Text(0.5,17.2,'Label on x-axis')\r[0. 0.2 0.4 0.6 0.8 1. ]\r\u003ca list of 6 Text major ticklabel objects\u003e\r\u003ca list of 12 Line2D ticklines objects\u003e\rbottom\r[\u003cmatplotlib.axis.XTick object at 0x000000000A5DDCF8\u003e, \u003cmatplotlib.axis.XTick object at 0x00000000087E5A58\u003e, \u003cmatplotlib.axis.XTick object at 0x0000000009C97F28\u003e, \u003cmatplotlib.axis.XTick object at 0x000000000A5FA6A0\u003e, \u003cmatplotlib.axis.XTick object at 0x000000000A5FACF8\u003e, \u003cmatplotlib.axis.XTick object at 0x000000000A600390\u003e]\r问题：其他都好懂，比如 6 个刻度标签，但为什么有 12 条刻度线？不应该是 6 条吗？ get_ticklines 返回12个对象是因为将左侧(tick1line)与右侧(tick2line)的tickline都返回了，如果右侧的label也是开启的，get_ticklabels也会返回12个。 下面来看看层级中排名第四也是最后的「刻度」。 ","date":"2020-06-22","objectID":"/20200622/:4:4","tags":["python","数学建模"],"title":"Matplotlib","uri":"/20200622/"},{"categories":["python","数学建模"],"content":"1.5 刻度 刻度 (Tick) 其实在坐标轴那节已经讲过了，它核心内容就是 一条短线 (刻度本身) 一串字符 (刻度标签) ","date":"2020-06-22","objectID":"/20200622/:4:5","tags":["python","数学建模"],"title":"Matplotlib","uri":"/20200622/"},{"categories":["python","数学建模"],"content":"1.6 基础元素 目前，我们已经介绍四个最重要的容器以及它们之间的层级 Figure → Axes → Axis → Ticks 图 → 坐标系 → 坐标轴 → 刻度 但要画出一幅有内容的图，还需要在容器里添加基础元素比如线 (line), 点 (marker), 文字 (text), 图例 (legend), 网格 (grid), 标题 (title), 图片 (image) 等，具体来说 画一条线，用 plt.plot() 或 ax.plot() 画个记号，用 plt.scatter() 或 ax.scatter() 添加文字，用 plt.text() 或 ax.text() 添加图例，用 plt.legend() 或 ax.legend() 添加图片，用 plt.imshow() 或 ax.imshow() 最后用 Matplotlib 官网的图来总结所有元素。 现在你基本理解了 Matplotlib 里面的绘图逻辑和元素，下两节分别从不同维度 (深度和广度) 研究如何画图： 第二节只研究一种类型的图「折线图」，但从头到尾不断根据需求添加元素完善它。深度研究做到完美！ 第三节研究四种类型的图 (展示数据的分布、联系、对比和组成)，却没在美感上下功夫，广度研究满足目的！ 但读完后两节后，你应该可以在各种类型的图上做到完美。 ","date":"2020-06-22","objectID":"/20200622/:4:6","tags":["python","数学建模"],"title":"Matplotlib","uri":"/20200622/"},{"categories":["python","数学建模"],"content":"2 画美感图 本节记录着老板让斯蒂文绘图不断提需求直到把他逼疯的一段对话。 ","date":"2020-06-22","objectID":"/20200622/:5:0","tags":["python","数学建模"],"title":"Matplotlib","uri":"/20200622/"},{"categories":["python","数学建模"],"content":"2.1 画第一幅图 首先用 pd.read_csv 函数从存好的 S\u0026P500.csv，截屏如下： 该函数中三个参数代表： index_col = 0 是说把第一列 Date 当成行标签 (index) parse_dates = True 是说把行标签转成 date 对象 dayFirst = True 是说日期是 DD/MM/YYYY 这样的格式 import pandas as pd data = pd.read_csv( 'data/S\u0026P500.csv', index_col=0, parse_dates=True, dayfirst=True ) data.head(3).append(data.tail(3)) Open\rHigh\rLow\rClose\rAdj Close\rVolume\rDate\r1950-01-03\r16.660000\r16.660000\r16.660000\r16.660000\r16.660000\r1260000\r1950-01-04\r16.850000\r16.850000\r16.850000\r16.850000\r16.850000\r1890000\r1950-01-05\r16.930000\r16.930000\r16.930000\r16.930000\r16.930000\r2550000\r2019-04-22\r2898.780029\r2909.510010\r2896.350098\r2907.969971\r2907.969971\r2997950000\r2019-04-23\r2909.989990\r2936.310059\r2908.530029\r2933.679932\r2933.679932\r3635030000\r2019-04-24\r2934.000000\r2936.830078\r2926.050049\r2927.250000\r2927.250000\r3448960000\rS\u0026P 500 的数据从 1950 年 1 月 3 号开始，老板只需要 2007 年 1 月 1 日到 2010 年 1 月 1 日的数据。做个切片即可，存储成 spx。 spx = data[['Adj Close']].loc['2007-01-01':'2010-01-01'] spx.head(3).append(spx.tail(3)) Adj Close\rDate\r2007-01-03\r1416.599976\r2007-01-04\r1418.339966\r2007-01-05\r1409.709961\r2009-12-29\r1126.199951\r2009-12-30\r1126.420044\r2009-12-31\r1115.099976\rspx 是个 DataFrame，将它的值一个个画出折线图只需用 plt.plot() 函数，展示在屏幕需用 plt.show()。 plt.plot( spx.values ) plt.show() 在 plot() 函数里面只有变量 y 时 (y = spx.values)，那么自变量就是默认赋值为 range(len(y))。 此外我们没有设置图的尺寸，像素、线的颜色宽度、坐标轴的刻度和标签、图例、标题等等，所有设置都用的是 matplotlib 的默认设置。 此图虽丑，但也满足了老板的需求，即标准普尔 500 指数在 2007-2010 的走势图。斯蒂文提交给了老板。 ","date":"2020-06-22","objectID":"/20200622/:5:1","tags":["python","数学建模"],"title":"Matplotlib","uri":"/20200622/"},{"categories":["python","数学建模"],"content":"2.2 图的默认设置 要修改图就必须知道它的属性，用 plt.rcParams 可查看上图的所有默认属性 (非常多的属性值)。 plt.rcParams RcParams({'_internal.classic_mode': False,\r'agg.path.chunksize': 0,\r'animation.avconv_args': [],\r'animation.avconv_path': 'avconv',\r'animation.bitrate': -1,\r'animation.codec': 'h264',\r'animation.convert_args': [],\r'animation.convert_path': 'convert',\r'animation.embed_limit': 20.0,\r'animation.ffmpeg_args': [],\r'animation.ffmpeg_path': 'ffmpeg',\r'animation.frame_format': 'png',\r'animation.html': 'none',\r'animation.html_args': [],\r'animation.mencoder_args': [],\r'animation.mencoder_path': 'mencoder',\r'animation.writer': 'ffmpeg',\r'axes.autolimit_mode': 'data',\r'axes.axisbelow': 'line',\r'axes.edgecolor': 'k',\r'axes.facecolor': 'w',\r'axes.formatter.limits': [-7, 7],\r'axes.formatter.min_exponent': 0,\r'axes.formatter.offset_threshold': 4,\r'axes.formatter.use_locale': False,\r'axes.formatter.use_mathtext': False,\r'axes.formatter.useoffset': True,\r'axes.grid': False,\r'axes.grid.axis': 'both',\r'axes.grid.which': 'major',\r'axes.hold': None,\r'axes.labelcolor': 'k',\r'axes.labelpad': 4.0,\r'axes.labelsize': 'medium',\r'axes.labelweight': 'normal',\r'axes.linewidth': 0.8,\r'axes.prop_cycle': cycler('color', ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']),\r'axes.spines.bottom': True,\r'axes.spines.left': True,\r'axes.spines.right': True,\r'axes.spines.top': True,\r'axes.titlepad': 6.0,\r'axes.titlesize': 'large',\r'axes.titleweight': 'normal',\r'axes.unicode_minus': True,\r'axes.xmargin': 0.05,\r'axes.ymargin': 0.05,\r'axes3d.grid': True,\r'backend': 'module://ipykernel.pylab.backend_inline',\r'backend.qt4': 'PyQt4',\r'backend.qt5': 'PyQt5',\r'backend_fallback': True,\r'boxplot.bootstrap': None,\r'boxplot.boxprops.color': 'k',\r'boxplot.boxprops.linestyle': '-',\r'boxplot.boxprops.linewidth': 1.0,\r'boxplot.capprops.color': 'k',\r'boxplot.capprops.linestyle': '-',\r'boxplot.capprops.linewidth': 1.0,\r'boxplot.flierprops.color': 'k',\r'boxplot.flierprops.linestyle': 'none',\r'boxplot.flierprops.linewidth': 1.0,\r'boxplot.flierprops.marker': 'o',\r'boxplot.flierprops.markeredgecolor': 'k',\r'boxplot.flierprops.markerfacecolor': 'none',\r'boxplot.flierprops.markersize': 6.0,\r'boxplot.meanline': False,\r'boxplot.meanprops.color': 'C2',\r'boxplot.meanprops.linestyle': '--',\r'boxplot.meanprops.linewidth': 1.0,\r'boxplot.meanprops.marker': '^',\r'boxplot.meanprops.markeredgecolor': 'C2',\r'boxplot.meanprops.markerfacecolor': 'C2',\r'boxplot.meanprops.markersize': 6.0,\r'boxplot.medianprops.color': 'C1',\r'boxplot.medianprops.linestyle': '-',\r'boxplot.medianprops.linewidth': 1.0,\r'boxplot.notch': False,\r'boxplot.patchartist': False,\r'boxplot.showbox': True,\r'boxplot.showcaps': True,\r'boxplot.showfliers': True,\r'boxplot.showmeans': False,\r'boxplot.vertical': True,\r'boxplot.whiskerprops.color': 'k',\r'boxplot.whiskerprops.linestyle': '-',\r'boxplot.whiskerprops.linewidth': 1.0,\r'boxplot.whiskers': 1.5,\r'contour.corner_mask': True,\r'contour.negative_linestyle': 'dashed',\r'datapath': 'G:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\matplotlib\\\\mpl-data',\r'date.autoformatter.day': '%Y-%m-%d',\r'date.autoformatter.hour': '%m-%d %H',\r'date.autoformatter.microsecond': '%M:%S.%f',\r'date.autoformatter.minute': '%d %H:%M',\r'date.autoformatter.month': '%Y-%m',\r'date.autoformatter.second': '%H:%M:%S',\r'date.autoformatter.year': '%Y',\r'docstring.hardcopy': False,\r'errorbar.capsize': 0.0,\r'examples.directory': '',\r'figure.autolayout': False,\r'figure.dpi': 72.0,\r'figure.edgecolor': (1, 1, 1, 0),\r'figure.facecolor': (1, 1, 1, 0),\r'figure.figsize': [6.0, 4.0],\r'figure.frameon': True,\r'figure.max_open_warning': 20,\r'figure.subplot.bottom': 0.125,\r'figure.subplot.hspace': 0.2,\r'figure.subplot.left': 0.125,\r'figure.subplot.right': 0.9,\r'figure.subplot.top': 0.88,\r'figure.subplot.wspace': 0.2,\r'figure.titlesize': 'large',\r'figure.titleweight': 'normal',\r'font.cursive': ['Apple Chancery',\r'Textile',\r'Zapf Chancery',\r'Sand',\r'Script MT',\r'Felipa',\r'cursive'],\r'font.family': ['san","date":"2020-06-22","objectID":"/20200622/:5:2","tags":["python","数学建模"],"title":"Matplotlib","uri":"/20200622/"},{"categories":["python","数学建模"],"content":"2.3 设置尺寸和 DPI 用 figsize 和 dpi 一起可以控制图的大小和像素。 函数 figsize(w,h) 决定图的宽和高 (单位是英寸)，而属性 dpi 全称 dots per inches，测量每英寸多少像素。两个属性一起用，那么得到的图的像素为 (wdpi, hdpi) 套用在下面代码中，我们其实将图的大小设置成 16×6 平方英寸，而像素设置成 (1600, 600)，因为 dpi = 100。 plt.figure( figsize=(16,6), dpi=100 ) plt.plot( spx.values ) plt.show() 运行代码生成大宽屏图！ ","date":"2020-06-22","objectID":"/20200622/:5:3","tags":["python","数学建模"],"title":"Matplotlib","uri":"/20200622/"},{"categories":["python","数学建模"],"content":"2.4 设置颜色-风格-宽度 在 plt.plot() 用 color，linewidth 和 linestyle 属性一起可以控制折线的颜色 (上面定义的深青色)、宽度 (2 像素) 和风格 (连续线)。 plt.figure( figsize=(16,6), dpi=100 ) plt.plot( spx.values, color=dt_hex, linewidth=2, linestyle='-' ) plt.show() 现在线条更明显了，而深青色看起来也比较有品位。 ","date":"2020-06-22","objectID":"/20200622/:5:4","tags":["python","数学建模"],"title":"Matplotlib","uri":"/20200622/"},{"categories":["python","数学建模"],"content":"2.5 设置边界 下面代码第 2 行在图中 (fig) 添加了一个坐标系 (ax)，然后所有操作都在 ax 里面完成，比如用 ax.plot() 来画折线 ax.set_xlim(), ax_set_ylim() 来设置横轴和纵轴的边界 fig = plt.figure( figsize=(16,6), dpi=100) ax = fig.add_subplot(1,1,1) x = spx.index y = spx.values ax.plot( x, y, color=dt_hex, linewidth=2, linestyle='-' ) #ax.set_xlim(['1/1/2007', '1/1/2010']) #ax.set_ylim( y.min()*0.8, y.max()*1.2 ); #加分号则不打印y.min()*0.8, y.max()*1.2 [\u003cmatplotlib.lines.Line2D at 0x1c7fc574fd0\u003e]\r第 3 行的 x 是日期 (回顾 spx 是一个 DataFrame，行标签是日期)。 第 6 行将横轴的上下边界设为 2007-01-01 和 2010-01-01，只好是整个时间序列的起始日和终止日。 第 7 行将纵轴的上下边界设为 spx 的最小值的 0.8 倍和最大值的 1.2 倍。 现在横轴的刻度标签都是日期，比数字刻度带来的信息多；而 spx 图离顶部也有空间，看起来没那么挤。 ","date":"2020-06-22","objectID":"/20200622/:5:5","tags":["python","数学建模"],"title":"Matplotlib","uri":"/20200622/"},{"categories":["python","数学建模"],"content":"2.6 设置刻度和标签 上图横轴的刻度个数 (老板说日期隔得有点开) 和标签显示 (老板说只有年月) 都是默认设置。为了满足老板的要求，斯蒂文只能手动设置，用以下两个函数： 先用 ax.set_ticks() 设置出数值刻度 再用 ax.set_xticklabels() 在对应的数值刻度上写标签 fig = plt.figure( figsize=(16,6), dpi=100) ax = fig.add_subplot(1,1,1) x = spx.index y = spx.values ax.plot( y, color=dt_hex, linewidth=2, linestyle='-' ) ax.set_xlim(-1, len(x)+1) ax.set_ylim( y.min()*0.8, y.max()*1.2 ) ax.set_xticks( range(0,len(x),40)) ax.set_xticklabels( [x[i].strftime('%Y-%m-%d') for i in ax.get_xticks()], rotation=90 ); 第 7 行设置横轴的边界，下界是 - 1，上界是 len(x) +1。 第 10 行先设置横轴「数值刻度」为 range(0,len(x), 40)，即 0, 40, 80, …. 第 11 行在这些「数值刻度」上写标签，即格式为 %Y-%m-%d 的日期。由于日期个数比较多，而且日期字符比较长，直接在图中显示出来会相互重叠非常难看。这里调节参数 rotation = 90 使得日期逆时针转了 90 度，看上图效果好多了。 现在横轴的刻度标签是带「年-月-日」的日期，而且标签的间隔刚刚好。 ","date":"2020-06-22","objectID":"/20200622/:5:6","tags":["python","数学建模"],"title":"Matplotlib","uri":"/20200622/"},{"categories":["python","数学建模"],"content":"2.7 添加图例 添加图例 (legend) 非常简单，只需要在 ax.plot() 里多设定一个参数 label，然后用 ax.legend() 其中 loc = 0 表示 matplotlib 自动安排一个最好位置显示图例，而 frameon = True 给图例加了外框。 fig = plt.figure( figsize=(16,6), dpi=100) ax = fig.add_subplot(1,1,1) x = spx.index y = spx.values ax.plot( y, color=dt_hex, linewidth=2, linestyle='-',label='S\u0026P500' ) ax.legend( loc=0, frameon=True ) ax.set_xlim(-1, len(x)+1) ax.set_ylim( y.min()*0.8, y.max()*1.2 ) ax.set_xticks( range(0,len(x),40)) ax.set_xticklabels( [x[i].strftime('%Y-%m-%d') for i in ax.get_xticks()], rotation=90 ); 注意图的右上角多了图例 S\u0026P500。 ","date":"2020-06-22","objectID":"/20200622/:5:7","tags":["python","数学建模"],"title":"Matplotlib","uri":"/20200622/"},{"categories":["python","数学建模"],"content":"2.8 添加第二幅图 在改进代码之前，先介绍一下 VIX 指数。 知识点 VIX 指数是芝加哥期权交易所 (CBOE) 市场波动率指数的交易代号，常见于衡量 S\u0026P500 指数期权的隐含波动性，通常被称为「恐慌指数」，它是了解市场对未来30天市场波动性预期的一种衡量方法。 由其定义可知，S\u0026P500 指数涨时，VIX 跌，而 S\u0026P500 指数暴跌时，VIX 暴涨。 和之前一样，首先用 pd.read_csv 函数从存好的 VIX.csv 读取数据存成 DataFrame。 data = pd.read_csv( 'data/VIX.csv', index_col=0, parse_dates=True, dayfirst=True ) vix = data[['Adj Close']].loc['2007-01-01':'2010-01-01'] vix.head(3).append(vix.tail(3)) Adj Close\rDate\r2007-01-03\r12.040000\r2007-01-04\r11.510000\r2007-01-05\r12.140000\r2009-12-29\r20.010000\r2009-12-30\r19.959999\r2009-12-31\r21.680000\r添加第二幅图也很简单，用两次 plt.plot() 或者 ax.plot() 即可。这里面用的是 plt 没用 ax，没有特殊原因，在本例中两者可以随意使用，但两者在使用「.methods」时有个小细节不知道大家注意到没有， plt.xlim plt.ylim plt.xticks ax.set_xlim ax.set_ylim ax_set_xticks fig = plt.figure( figsize=(16,6), dpi=100) x = spx.index y1 = spx.values y2 = vix.values plt.plot( y1, color=dt_hex, linewidth=2, linestyle='-',label='S\u0026P500' ) plt.plot( y2, color=r_hex, linewidth=2, linestyle='-',label='VIX' ) plt.legend( loc=0, frameon=True ) plt.xlim(-1, len(x)+1) plt.ylim( np.vstack([y1,y2]).min()*0.8, np.vstack([y1,y2]).max()*1.2 ) x_tick = range(0,len(x),40) x_label = [x[i].strftime('%Y-%m-%d') for i in x_tick] plt.xticks( x_tick, x_label, rotation=90 ) plt.show() 这图怎么成这样？？？VIX 怎么是一条平线？ ","date":"2020-06-22","objectID":"/20200622/:5:8","tags":["python","数学建模"],"title":"Matplotlib","uri":"/20200622/"},{"categories":["python","数学建模"],"content":"2.9 两个坐标系 \u0026 两幅子图 S\u0026P500 的量纲都是千位数，而 VIX 的量刚是两位数，两者放在一起，那可不是 VIX 就像一条水平线一样。两种改进方式： 用两个坐标系 (two axes) 用两幅子图 (two subplots) 两个坐标系 fig = plt.figure( figsize=(16,6), dpi=100) ax1 = fig.add_subplot(1,1,1) x = spx.index y1 = spx.values y2 = vix.values ax1.plot( y1, color=dt_hex, linewidth=2, linestyle='-',label='S\u0026P500' ) ax1.set_xlim(-1, len(x)+1) ax1.set_ylim( np.vstack([y1,y2]).min()*0.8, np.vstack([y1,y2]).max()*1.2 ) x_tick = range(0,len(x),40) x_label = [x[i].strftime('%Y-%m-%d') for i in x_tick] ax1.set_xticks( x_tick ) ax1.set_xticklabels( x_label, rotation=90 ) ax1.legend( loc='upper left', frameon=True ) #Add a second axes ax2 = ax1.twinx() ax2.plot( y2, color=r_hex, linewidth=2, linestyle='-',label='VIX' ) ax2.legend( loc='upper right', frameon=True ); 用 ax1 和 ax2 就能实现在两个坐标系上画图，代码核心部分是第 19 行的 ax2 = ax1.twinx() 在每个坐标系下画图以及各种设置前面都讲的很清楚了。 Mc：股市那两条曲线的legend分开放在两侧，怎么看怎么别扭，还是放在一块显示比较好。 实现方式有二： 仅使用一个轴的legend()函数 使用figure.legend() fig = plt.figure( figsize=(16,6), dpi=100) ax1 = fig.add_subplot(1,1,1) x = spx.index y1 = spx.values y2 = vix.values lns1 = ax1.plot( y1, color=dt_hex, linewidth=2, linestyle='-',label='S\u0026P500' ) ax1.set_xlim(-1, len(x)+1) ax1.set_ylim( np.vstack([y1,y2]).min()*0.8, np.vstack([y1,y2]).max()*1.2 ) x_tick = range(0,len(x),40) x_label = [x[i].strftime('%Y-%m-%d') for i in x_tick] ax1.set_xticks( x_tick ) ax1.set_xticklabels( x_label, rotation=90 ) # ax1.legend( loc='upper left', frameon=True ) #Add a second axes ax2 = ax1.twinx() lns2 = ax2.plot( y2, color=r_hex, linewidth=2, linestyle='-',label='VIX' ) # ax2.legend( loc='upper right', frameon=True ); # 方法一：仅使用一个轴的legend()函数 #lns = lns1+lns2 #labs = [l.get_label() for l in lns] #ax2.legend(lns, labs, loc=0) # 方法二：使用figure.legend() fig.legend(loc=1, bbox_to_anchor=(0.88,1.05), bbox_transform=ax.transAxes) \u003cmatplotlib.legend.Legend at 0x1c7fb007780\u003e\r两幅子图 plt.figure( figsize=(16,12), dpi=100) # subplot 1 plt.subplot(2,1,1) x = spx.index y1 = spx.values plt.plot( y1, color=dt_hex, linewidth=2, linestyle='-',label='S\u0026P500' ) plt.xlim(-1, len(x)+1) plt.ylim( y1.min()*0.8, y1.max()*1.2 ) x_tick = range(0,len(x),40) x_label = [x[i].strftime('%Y-%m-%d') for i in x_tick] plt.xticks( x_tick, x_label, rotation=45 ) plt.legend( loc='upper left', frameon=True ) # subplot 2 plt.subplot(2,1,2) y2 = vix.values plt.plot( y2, color=r_hex, linewidth=2, linestyle='-',label='VIX' ) plt.xlim(-1, len(x)+1) plt.ylim( y2.min()*0.8, y2.max()*1.2 ) plt.xticks( x_tick, x_label, rotation=45 ) plt.legend( loc='upper left', frameon=True ) plt.show() 定义 subplot(2,1,1) 和 subplot(2,1,2) 就能实现再两幅子图上画图。 在每幅子图上画图以及各种设置前面都讲的很清楚了。 这两种方法都可用，但在本例中，S\u0026P500 和 VIX 放在一起 (用两个坐标系) 更能看出它们之间的关系，比如 2008 年 9 月到 2009 年 3 月的金融危机期间，S\u0026P 500 在狂泻和 VIX 在飙升 。 ","date":"2020-06-22","objectID":"/20200622/:5:9","tags":["python","数学建模"],"title":"Matplotlib","uri":"/20200622/"},{"categories":["python","数学建模"],"content":"2.10 设置标注 在金融危机时期，市场发生了 5 件大事，分别是 2017-10-11: 牛市顶点 2008-03-12: 贝尔斯登倒闭 2008-09-15: 雷曼兄弟倒闭 2009-01-20: 苏格兰皇家银行股票抛售 2009-04-02: G20 峰会 加标注的代码略长，新内容为 第 3-7 行的定义危机事件，以元组的列表存储 第 26-34 行的事件标注，用到 annotate() 函数 from datetime import datetime fig = plt.figure( figsize=(16,6), dpi=100) crisis_data = [(datetime(2007, 10, 11), 'Peak of bull market'), (datetime(2008, 3, 12), 'Bear Stearns Fails'), (datetime(2008, 9, 15), 'Lehman Bankruptcy'), (datetime(2009, 1, 20), 'RBS Sell-off'), (datetime(2009, 4, 2), 'G20 Summit')] ax1 = fig.add_subplot(1,1,1) x = spx.index y1 = spx.values y2 = vix.values ax1.plot( y1, color=dt_hex, linewidth=2, linestyle='-',label='S\u0026P500' ) ax1.set_xlim(-1, len(x)+1) ax1.set_ylim( np.vstack([y1,y2]).min()*0.8, np.vstack([y1,y2]).max()*1.2 ) x_tick = range(0,len(x),40) x_label = [x[i].strftime('%Y-%m-%d') for i in x_tick] ax1.set_xticks( x_tick ) ax1.set_xticklabels( x_label, rotation=90 ) ax1.legend( loc='upper left', frameon=True ) for date, label in crisis_data: date = date.strftime('%Y-%m-%d') xi = x.get_loc(date) yi = spx.asof(date) ax1.scatter( xi, yi, 80, color=r_hex ) ax1.annotate( label, xy=(xi, yi + 60), xytext=(xi, yi+300), arrowprops=dict(facecolor='black',headwidth=4,width=1,headlength=6), horizontalalignment='left',verticalalignment='top' ) verticalalignment：垂直对齐方式 ，参数：[ ‘center’ | ‘top’ | ‘bottom’ | ‘baseline’ ] horizontalalignment：水平对齐方式 ，参数：[ ‘center’ | ‘right’ | ‘left’ ] #Add a second axes ax2 = ax1.twinx() ax2.plot( y2, color=r_hex, linewidth=2, linestyle='-',label='VIX' ) ax2.legend( loc='upper right', frameon=True ); 从第 26 行开始，用 for 循环读取 crisis_data 里面每个日期 date 和事件 label。 第 28 和 29 行是获取每一个 date 在整个日期数组中的索引 xi，以及对应的 spx 值 yi。 第 30 行用 scatter() 函数画出一个圆点，标注事件在 spx 折现上的位置。 第 31 和 34 行是重头戏，在 annotate() 函数里设置了事件，箭头坐标(距离圆点中心位置)，事件打印的坐标，箭头性质，以及对齐属性。 事件的确标注在图上了，但是效果像一坨~。 ","date":"2020-06-22","objectID":"/20200622/:5:10","tags":["python","数学建模"],"title":"Matplotlib","uri":"/20200622/"},{"categories":["python","数学建模"],"content":"2.11 设置透明度 为了把 VIX 折线弄得透明些，只用设置 ax2.plot() 里的 alpha 参数为 0.3，具体设什么值看你想要多透明，alpha 在 0 和 1 之间，0 是完全透明，1 是完全不透明。 fig = plt.figure( figsize=(16,6), dpi=100) crisis_data = [(datetime(2007, 10, 11), 'Peak of bull market'), (datetime(2008, 3, 12), 'Bear Stearns Fails'), (datetime(2008, 9, 15), 'Lehman Bankruptcy'), (datetime(2009, 1, 20), 'RBS Sell-off'), (datetime(2009, 4, 2), 'G20 Summit')] ax1 = fig.add_subplot(1,1,1) x = spx.index y1 = spx.values y2 = vix.values ax1.plot( y1, color=dt_hex, linewidth=2, linestyle='-',label='S\u0026P500' ) ax1.set_xlim(-1, len(x)+1) ax1.set_ylim( np.vstack([y1,y2]).min()*0.8, np.vstack([y1,y2]).max()*1.2 ) x_tick = range(0,len(x),40) x_label = [x[i].strftime('%Y-%m-%d') for i in x_tick] ax1.set_xticks( x_tick ) ax1.set_xticklabels( x_label, rotation=90 ) ax1.legend( loc='upper left', frameon=True ) for date, label in crisis_data: date = date.strftime('%Y-%m-%d') xi = x.get_loc(date) yi = spx.asof(date) ax1.scatter( xi, yi, 80, color=r_hex ) ax1.annotate( label, xy=(xi, yi + 60), xytext=(xi, yi+300), arrowprops=dict(facecolor='black',headwidth=4,width=1,headlength=6), horizontalalignment='left',verticalalignment='top' ) #Add a second axes ax2 = ax1.twinx() #设置透明度 ax2.plot( y2, color=r_hex, linewidth=2, linestyle='-', label='VIX', alpha=0.3 ) ax2.legend( loc='upper right', frameon=True ); 美如画！雷曼兄弟倒闭 (事件 3) 后 S\u0026P 暴跌最厉害，而同期的 VIX 也飙到天际。在 G20 峰会 (事件 5) 过后，大国领导者一起解决金融危机问题，从那个点开始，S\u0026P500 上涨 VIX 下跌。 经济总体平稳！风险总体可控！ ","date":"2020-06-22","objectID":"/20200622/:5:11","tags":["python","数学建模"],"title":"Matplotlib","uri":"/20200622/"},{"categories":["python","数学建模"],"content":"2.12 完善细节 既然老板关注这五个事件，而它们发生的日期可能没有落在横轴标签上，那老板不是在图上还是找不到他们发生的具体时间么？把它们加上去怎么样？ fig = plt.figure( figsize=(16,6), dpi=100) crisis_data = [(datetime(2007, 10, 11), 'Peak of bull market'), (datetime(2008, 3, 12), 'Bear Stearns Fails'), (datetime(2008, 9, 15), 'Lehman Bankruptcy'), (datetime(2009, 1, 20), 'RBS Sell-off'), (datetime(2009, 4, 2), 'G20 Summit')] ax1 = fig.add_subplot(1,1,1) x = spx.index y1 = spx.values y2 = vix.values ax1.plot( y1, color=dt_hex, linewidth=2, linestyle='-',label='S\u0026P500' ) ax1.set_xlim(-1, len(x)+1) ax1.set_ylim( np.vstack([y1,y2]).min()*0.8, np.vstack([y1,y2]).max()*1.2 ) ax1.legend( loc='upper left', frameon=True ) init_tick = list( range(0,len(x),40) ) impt_tick = [] impt_date = [] for date, label in crisis_data: date = date.strftime('%Y-%m-%d') impt_date.append(date) xi = x.get_loc(date) impt_tick.append(xi) yi = spx.asof(date) ax1.scatter( xi, yi, 80, color=r_hex ) ax1.annotate( label, xy=(xi, yi + 60), xytext=(xi, yi+300), arrowprops=dict(facecolor='black',headwidth=4,width=1,headlength=6), horizontalalignment='left',verticalalignment='top' ) x_tick = init_tick + impt_tick x_label = [x[i].strftime('%Y-%m-%d') for i in x_tick] ax1.set_xticks( x_tick ) ax1.set_xticklabels( x_label, rotation=90 ) for i, label in enumerate(ax1.get_xticklabels()): if i \u003e= len(init_tick): label.set_color(r_hex) label.set_fontweight('bold') else: label.set_fontsize(9) #Add a second axes ax2 = ax1.twinx() ax2.plot( y2, color=r_hex, linewidth=2, linestyle='-', label='VIX', alpha=0.3 ) ax2.legend( loc='upper right', frameon=True ); 新添加的代码在第 20-22 行和第 43-48 行。主要就是把日期分成两类： 常规日期标签 init_tick 五个事件日期标签 impt_tick ","date":"2020-06-22","objectID":"/20200622/:5:12","tags":["python","数学建模"],"title":"Matplotlib","uri":"/20200622/"},{"categories":["python","数学建模"],"content":"3 画有效图 ","date":"2020-06-22","objectID":"/20200622/:6:0","tags":["python","数学建模"],"title":"Matplotlib","uri":"/20200622/"},{"categories":["python","数学建模"],"content":"3.1 概览 在做图表设计时候经常面临着怎么选用合适的图表，图表展示的关系分为四大类 (点击下图放大)： 分布 (distribution) 联系 (relationship) 比较 (comparison) 构成 (composition) 在选用图表前首先要想清楚：你要表达什么样的数据关系。上面的图表分类太过繁多，接下来我们只讨论在量化金融中用的最多的几种类型，即 用直方图来展示股票价格和收益的分布 用散点图来展示两支股票之间的联系 用折线图来比较汇率在不同窗口的移动平均线 用饼状图来展示股票组合的构成成分 首先用 YahooFinancials API 来下载若干资产的一年历史数据 (安装该 API 用 pip install yahoofinancials)： 在 Anaconda 命令框(开始菜单的搜索框里搜ana,搜索到Anaconda Prompt并打开)里 pip install yahoofinancials 起始日：2018-04-29 终止日：2019-04-29 五只股票：英伟达、亚马逊、阿里巴巴、脸书、苹果 三个汇率：欧元美元、美元日元、美元人民币 下面代码就是从 API 获取数据，股票用的是股票代号 (stock code)，而货币用的该 API 要求的格式，比如「欧元美元」用 EURUSD=X，而不是市场常见的 EURUSD，而「美元日元」用 JPY=X 而不是 USDJPY。 from yahoofinancials import YahooFinancials start_date = '2018-04-29' end_date = '2019-04-29' stock_code = ['NVDA','AMZN','BABA','FB','AAPL' ] currency_code = ['EURUSD=X', 'JPY=X', 'CNY=X'] stock =YahooFinancials( stock_code ) currency = YahooFinancials( currency_code ) stock_daily = stock.get_historical_price_data( start_date, end_date, 'daily' ) currency_daily = currency.get_historical_price_data( start_date, end_date, 'daily' ) 该 API 返回结果 stock_daily 和 currency_daily 是「字典」格式，样子非常丑陋，感受一下。 stock_daily 展开查看\r{'AAPL': {'currency': 'USD',\r'eventsData': {'dividends': {'2018-05-11': {'amount': 0.73,\r'date': 1526045400,\r'formatted_date': '2018-05-11'},\r'2018-08-10': {'amount': 0.73,\r'date': 1533907800,\r'formatted_date': '2018-08-10'},\r'2018-11-08': {'amount': 0.73,\r'date': 1541687400,\r'formatted_date': '2018-11-08'},\r'2019-02-08': {'amount': 0.73,\r'date': 1549636200,\r'formatted_date': '2019-02-08'}}},\r'firstTradeDate': {'date': 345479400, 'formatted_date': '1980-12-12'},\r'instrumentType': 'EQUITY',\r'prices': [{'adjclose': 160.24440002441406,\r'close': 165.25999450683594,\r'date': 1525095000,\r'formatted_date': '2018-04-30',\r'high': 167.25999450683594,\r'low': 161.83999633789062,\r'open': 162.1300048828125,\r'volume': 42427400},\r{'adjclose': 163.96783447265625,\r'close': 169.10000610351562,\r'date': 1525181400,\r'formatted_date': '2018-05-01',\r'high': 169.1999969482422,\r'low': 165.27000427246094,\r'open': 166.41000366210938,\r'volume': 53569400},\r{'adjclose': 171.21115112304688,\r'close': 176.57000732421875,\r'date': 1525267800,\r'formatted_date': '2018-05-02',\r'high': 177.75,\r'low': 173.8000030517578,\r'open': 175.22999572753906,\r'volume': 66539400},\r{'adjclose': 171.52142333984375,\r'close': 176.88999938964844,\r'date': 1525354200,\r'formatted_date': '2018-05-03',\r'high': 177.5,\r'low': 174.44000244140625,\r'open': 175.8800048828125,\r'volume': 34068200},\r{'adjclose': 178.2508087158203,\r'close': 183.8300018310547,\r'date': 1525440600,\r'formatted_date': '2018-05-04',\r'high': 184.25,\r'low': 178.1699981689453,\r'open': 178.25,\r'volume': 56201300},\r{'adjclose': 179.54043579101562,\r'close': 185.16000366210938,\r'date': 1525699800,\r'formatted_date': '2018-05-07',\r'high': 187.6699981689453,\r'low': 184.75,\r'open': 185.17999267578125,\r'volume': 42451400},\r{'adjclose': 180.40342712402344,\r'close': 186.0500030517578,\r'date': 1525786200,\r'formatted_date': '2018-05-08',\r'high': 186.22000122070312,\r'low': 183.6699981689453,\r'open': 184.99000549316406,\r'volume': 28402800},\r{'adjclose': 181.67367553710938,\r'close': 187.36000061035156,\r'date': 1525872600,\r'formatted_date': '2018-05-09',\r'high': 187.39999389648438,\r'low': 185.22000122070312,\r'open': 186.5500030517578,\r'volume': 23211200},\r{'adjclose': 184.27232360839844,\r'close': 190.0399932861328,\r'date': 1525959000,\r'formatted_date': '2018-05-10',\r'high': 190.3699951171875,\r'low': 187.64999389648438,\r'open': 187.74000549316406,\r'volume': 27989300},\r{'adjclose': 183.5714874267578,\r'close': 188.58999633789062,\r'date': 1526045400,\r'formatted_date': '2018-05-11',\r'high': 190.05999755859375,\r'low': 187.4499969482422,\r'open': 189.49000549316406,\r'volume': 26212200},\r{'adjclose': 183.14320373535156,\r'close': 188.14999389648438,\r'date': 1526304600,\r'formatted_date': '2018-05-14',\r'high': 189.52999877929688,\r'low': 187.86000061035156,\r'open': 189.00999450683594,\r'volume': 20778800},\r{'adjclose': 181.47872924804688,\r'close': 186","date":"2020-06-22","objectID":"/20200622/:6:1","tags":["python","数学建模"],"title":"Matplotlib","uri":"/20200622/"},{"categories":["python","数学建模"],"content":"3.2 直方图 直方图 (histogram chart)，又称质量分布图，是一种统计报告图，由一系列高度不等的纵向条纹或线段表示数据分布的情况。 一般用横轴表示数据类型，纵轴表示分布情况。在 Matplotlib 里的语法是 plt.hist() ax.hist() 我们先看看英伟达 (NVDA) 的价格分布。 p_NVDA = NVDA['close'] fig = plt.figure( figsize=(8,4) ) plt.hist( p_NVDA, bins=30, color=dt_hex ) plt.xlabel('Nvidia Price') plt.ylabel('Number of Days Observed') plt.title('Frequency Distribution of Nvidia Prices, Apr-2018 to Apr-2019') plt.show() 在本例中函数 hist() 里的参数有 p_NVDA：Series，也可以是 list 或者 ndarray bins：分成多少堆 colors：用之前定义的深青色 从上图可看出，NVDA 的价格分布在有 220 划分的两个范围 (regime)。在 2018 年 11 月 16 日 (星期五)，英伟达第三季度的报表低于预期，那么股价暴跌 19%，在之后的星期一，又跌 12%，两个交易日股价一下子从原来的 220 左右跌到 150。 在研究股票价格序列中，由于收益率有些好的统计性质，我们对其更感兴趣，接下来再看看英伟达 (NVDA) 的对数收益 (log-return) 的分布。 date = p_NVDA.index price = p_NVDA.values r_NVDA = pd.Series( np.log(price[1:]/price[:-1]),index=date[1:] ) fig = plt.figure( figsize=(8,4) ) plt.hist( r_NVDA, bins=30, color=dt_hex ) plt.xlabel('Nvidia Daily Log-Return') plt.ylabel('Number of Days Observed') plt.title('Frequency Distribution of Nvidia Daily Log-Return, Apr-2018 to Apr-2019') plt.show() 首先对数收益的计算公式为 r(t) = ln(P(t)/P(t-1) 得到 r_NVDA。计算一天的收益率需要两天的价格，因此用 p_NVDA 计算 r_NVDA 时，会丢失最新一天的数据，因此我们用 date[1:] 作为 r_NVDA 的行标签 (index)。 不考虑在 -0.20 和 -0.15 那两个极端值，对数收益率的分布像一个正态分布 (人人都喜欢正态分布)。 ","date":"2020-06-22","objectID":"/20200622/:6:2","tags":["python","数学建模"],"title":"Matplotlib","uri":"/20200622/"},{"categories":["python","数学建模"],"content":"3.3 散点图 散点图 (scatter chart) 用两组数据构成多个坐标点，考察坐标点的分布，判断两变量之间是否存在某种联系的分布模式。在 Matplotlib 里的语法是 plt.scatter() ax.scatter() 我们看看中美两大电商亚马逊 (AMZN) 和阿里巴巴 (BABA) 之间的价格和对数收益率的联系。 首先计算价格和对数收益率。 AMZN = data_converter( stock_daily, 'AMZN', ' EQ' ) BABA = data_converter( stock_daily, 'BABA', ' EQ' ) p_AMZN = AMZN['close'] p_BABA = BABA['close'] date = p_AMZN.index price = p_AMZN.values r_AMZN = pd.Series( np.log(price[1:]/price[:-1]),index=date[1:] ) date = p_BABA.index price = p_BABA.values r_BABA = pd.Series( np.log(price[1:]/price[:-1]),index=date[1:] ) 用两个子图分别展示「价格」和「收益率」的散点图。 fig, axes = plt.subplots( nrows=1, ncols=2, figsize=(14,6) ) axes[0].scatter( p_AMZN, p_BABA, color=dt_hex ) axes[0].set_xlabel('Amazon Price') axes[0].set_ylabel('Alibaba Price') axes[0].set_title('Daily Price from Apr-2018 to Apr-2019') axes[1].scatter( r_AMZN, r_BABA, color=r_hex ) axes[1].set_xlabel('Amazon Log-Return') axes[1].set_ylabel('Alibaba Log-Return') axes[1].set_title('Daily Returns from Apr-2018 to Apr-2019') plt.show() 在本例中函数 scatter() 里的参数有 p_AMZN (r_AMZN)：Series，也可以是 list 或者 ndarray p_BABA (r_BABA)：Series，也可以是 list 或者 ndarray colors：用之前定义的深青色和红色 从右图来看，亚马逊和阿里巴巴在这段时期的表现正相关，如果做线性回归是一条斜率为正的线。 ","date":"2020-06-22","objectID":"/20200622/:6:3","tags":["python","数学建模"],"title":"Matplotlib","uri":"/20200622/"},{"categories":["python","数学建模"],"content":"3.4 折线图 折线图 (line chart) 显示随时间而变化的连续数据，因此非常适用于显示在相等时间间隔下数据的趋势。在 Matplotlib 里的语法是 plt.plot() ax.plot() 我们来看看如何画 EURUSD 的 20 天和 60 天移动平均 (moving average, MA) 线。 首先获取 EURUSD 的收盘价。 curr = 'EURUSD' EURUSD = data_converter( currency_daily, curr, 'FX' ) rate = EURUSD['close'] 用 Pandas 里面的 rolling() 函数来计算 MA，在画出收盘价，MA20 和 MA60 三条折线。 fig = plt.figure( figsize=(16,6) ) ax = fig.add_subplot(1,1,1) ax.set_title( curr + ' - Moving Average') ax.set_xticks( range(0,len(rate.index),10) ) ax.set_xticklabels( [rate.index[i] for i in ax.get_xticks()], rotation=90 ); ax.plot( rate, color=dt_hex, linewidth=2,label='Close' ) MA_20 = rate.rolling(20).mean() MA_60 = rate.rolling(60).mean() ax.plot(MA_20, color=r_hex, linewidth=2, label='MA20') ax.plot(MA_60, color=g_hex, linewidth=2, label='MA60') ax.legend(loc=0); 在本例中函数 plot() 里的参数有 rate, MA_20, MA_60：Series，也可以是 list 或者 ndarray colors：用之前定义的深青色，红色，绿色 linewidth：像素 2 label：用于显示图例 上面代码最关键的就是第 10 和 11 行，用 rolling(n) 函数对 rate 求 n 天移动均值。从图中注意到绿色的 MA60最短，红色的 MA20 其次。原因很简单，假如一年有 252 个交易日，那么第 1 个 MA60 值需要第 1 到 60 个汇率，第 2 个 MA60 值需要第 2 到 61 个汇率，第 193 个 MA60 值需要第 193 到 252 个汇率。最终只有 193 个 MA60。同理可得到只有 223 个 MA20。 双均线策略如下：MA60 和 MA20 必有交点，若 20 天平均线「上穿越」60 天均线，则为买入点；反之为卖出点。该策略基于不同天数均线的交叉点抓住股票的强势和弱势时刻进行交易。 ","date":"2020-06-22","objectID":"/20200622/:6:4","tags":["python","数学建模"],"title":"Matplotlib","uri":"/20200622/"},{"categories":["python","数学建模"],"content":"3.5 饼状图 饼状图 (pie chart) 是一个划分为几个扇形的圆形统计图表，用于描述量、频率或百分比之间的相对关系。 在饼状图中，每个扇区面积大小为其所表示的数量的比例。在 Matplotlib 里的语法是 plt.pie() ax.pie() 我们来看看如何画出一个股票投资组合在 2019 年 4 月 26 日的饼状图，假设组合里面有 100 股英伟达，20 股亚马逊，50 股阿里巴巴，30 股脸书和 40 股苹果 (一个科技股爱好者的组合 )。 首先计算组合里五支股票在 2019 年 4 月 26 日的市值 (market value, MV)。 stock_list = ['NVDA','AMZN','BABA','FB','AAPL' ] date = '2019-04-26' MV = [ data_converter(stock_daily, code, ' EQ')['close'][date] for code in stock_list ] MV = np.array(MV) * np.array([100,20,50,30,40]) 第 4 行用了列表解析式来获取 stock_list 每支股票的价格，第 5 行将价格乘上数量得到市值。 设定好五种颜色和百分数格式 %.0f%% (小数点后面保留 0 位)，画出饼状图。 fig = plt.figure( figsize=(7,7) ) ax = fig.add_subplot(1,1,1) ax.pie( MV, labels=stock_list, colors=[dt_hex,r_hex,g_hex,tn_hex,g25_hex], autopct='%.0f%%' ) plt.show() 在本例中函数 pie() 里的参数有 MV：股票组合市值，ndarray labels：标识，list colors：用之前定义的一组颜色，list autopct：显示百分数的格式，str 虽然画出了饼状图，但看起来有些别扭，且听下节分解如何改进。 ","date":"2020-06-22","objectID":"/20200622/:6:5","tags":["python","数学建模"],"title":"Matplotlib","uri":"/20200622/"},{"categories":["python","数学建模"],"content":"3.6 同理心 为用户习惯考虑 把饼当成钟，大多数人习惯顺时针的看里面的内容，因此把面积最大的那块的一条边 (见下图) 放在 12 点的位置最能突显其重要性，之后按面积从大到小顺时针排列。 在画饼状图前，我们需要额外做两件事： 按升序排列 5 只股票的市值 设定 pie() 的相关参数达到上述「最大块放 12 点位置」的效果 首先按市值大小按升序排序。 idx = MV.argsort()[::-1] MV = MV[idx] stock_list = [ stock_list[i] for i in idx ] print( MV ) print( stock_list ) [39012.60009766 17808.99963379 9354.49981689 8172.00012207\r5744.70016479]\r['AMZN', 'NVDA', 'BABA', 'AAPL', 'FB']\r设定参数 startangle = 90 是说第一片扇形 (AMZN 深青色那块) 的左边在 90 度位置 counterclock = False 是说顺时针拜访每块扇形 fig = plt.figure( figsize=(7,7) ) ax = fig.add_subplot(1,1,1) ax.pie( MV, labels=stock_list, colors=[dt_hex,r_hex,g_hex,tn_hex,g25_hex], \\ autopct='%.0f%%',startangle=90, counterclock=False ) plt.show() 和上节最后的图相比，现在这饼状图看上去是不是顺眼多了。你承不承认你第一眼就注意到 12 点那个位置的扇形？ 为图表信息考虑 当饼状图里面扇形多过 5 个时，面积相近的扇形大小并不容易一眼辨别出来，不信看上图的 BABA 和 APPL，没看到数字很难看出那个面积大。但绝大多数人是感官动物，图形和数字肯定先选择看图形，这个时候用柱状图 (bar chart) 来代替饼状图，每个市值成分大小一目了然 (好图就是能让用户能最快的抓住核心信息)。 用 ax.bar() 函数来画柱状图，为了和饼状图的信息一致，几个关键操作为 第 4 行计算出市值的百分数 pct_MV 第 8, 9 行设置横轴刻度 (0,1,2,3,4) 和标签 (stock_list) 第 12, 13 行在特定位置上 (x+0.04, y+0.05/100) 将 pct_MV 以 {0:.0%} 的格式 (不保留小数点) 写出来，这些位置试几次看图的效果就可以确定下来。 fig = plt.figure( figsize=(8,6) ) ax = fig.add_subplot(1,1,1) pct_MV = MV / np.sum(MV) index = np.arange(len(pct_MV)) ax.bar( index, pct_MV, facecolor=r_hex, edgecolor=dt_hex) ax.set_xticks( index ) ax.set_xticklabels( stock_list ) ax.set_ylim( 0, np.max(pct_MV)*1.1 ) for x,y in zip(index,pct_MV): ax.text(x+0.04,y+0.05/100,'{0:.0%}'.format(y), ha='center', va='bottom' ) plt.show() 在本例中函数 bar() 里的参数有 index：横轴刻度，ndarray pct_MV：股票组合市值比例，ndarray facecolor：柱状颜色，红色 edgecolor：柱边颜色，深青色 如果柱状很多时，或者标签名字很长时，用横向柱状图 (horizontal bar chart)，函数为 ax.barh()。代码和上面非常类似，就是把横轴和纵轴的调换了一下。 fig = plt.figure( figsize=(8,4) ) ax = fig.add_subplot(1,1,1) pct_MV = MV[::-1] / np.sum(MV) index = np.arange(len(pct_MV)) ax.barh( index, pct_MV, facecolor=r_hex, edgecolor=dt_hex ) ax.set_yticks( index ) ax.set_yticklabels( stock_list[::-1] ) ax.set_xlim( 0, np.max(pct_MV)*1.1 ) for x,y in zip(pct_MV,index): ax.text(x+0.04,y,'{0:.0%}'.format(x), ha='right', va='center' ) plt.show() 为色盲用户考虑 世界上有 1/12 的男人和 1/200 的女人都有不同程度的色盲症状。因此当你将结果展示给重要客户时，最好考虑到这一点，我相信对方会非常欣赏你这种「同理心」。 幸运的是，Matplotlib 里面有专门为色盲考虑的色彩风格，首先用下列语句看查看所有的色彩风格。 print(plt.style.available) ['bmh', 'classic', 'dark_background', 'fast', 'fivethirtyeight', 'ggplot', 'grayscale', 'seaborn-bright', 'seaborn-colorblind', 'seaborn-dark-palette', 'seaborn-dark', 'seaborn-darkgrid', 'seaborn-deep', 'seaborn-muted', 'seaborn-notebook', 'seaborn-paper', 'seaborn-pastel', 'seaborn-poster', 'seaborn-talk', 'seaborn-ticks', 'seaborn-white', 'seaborn-whitegrid', 'seaborn', 'Solarize_Light2', '_classic_test']\r不难发现 seaborn-colorblind就是我们所需要的。下面我们看看不同色彩风格下的「饼状图」和「柱状图」。 首先看从 R 中借用过来的大名鼎鼎的 ggplot 的效果。 plt.style.use('ggplot') fig, axes = plt.subplots( nrows=1, ncols=2, figsize=(14,7) ) axes[0].pie( MV, labels=stock_list,autopct='%.0f%%', \\ startangle=90, counterclock=False ) pct_MV = MV[::-1] / np.sum(MV) index = np.arange(len(pct_MV)) axes[1].barh( index, pct_MV ) axes[1].set_yticks( index ) axes[1].set_yticklabels( stock_list[::-1] ) axes[1].set_xlim( 0, np.max(pct_MV)*1.1 ) for x,y in zip(pct_MV,index): axes[1].text(x+0.04,y,'{0:.0%}'.format(x), ha='right', va='center' ) plt.tight_layout() plt.show() 再看 seaborn-colorblind 的效果(先执行下面代码，再重新执行上面代码)。 plt.style.use('seaborn-colorblind') ","date":"2020-06-22","objectID":"/20200622/:6:6","tags":["python","数学建模"],"title":"Matplotlib","uri":"/20200622/"},{"categories":["python","数学建模"],"content":"4 总结 本贴的思路非常清晰： 第一部分了解 Matplotlib 的绘图逻辑，以及里面包含的画图元素以及它们之间的层级。 第二部分深度学 Matplotlib，只研究折线图，通过研究它的属性，一步步改进图的尺寸、像素、线条颜色宽度风格、坐标轴边界、刻度标签、图例、多图、多坐标系、标注、透明度等等，画出了一幅美图。 第三部分广度学 Matplotlib，通过数据的分布、联系、比较和构成研究了直方图、散点图、折线图和饼状图，最后还为用户着想 (习惯、色盲等等) 画出更能有效表达信息的图。 基本绘图流程 我们现在处于一个大数据的时代，制图能力现在和写作能力一样重要。任何人现在都可以用各种制图工具或者编程语言来画图，但是很少人懂得画出好图。 好图不是指的绚烂的颜色 (fancy colors) 和复杂的层级 (complex layers)，当一张图里的信息能够以最清晰和有效的方式传递给使用者，那么这张图就是好图。 Stay Tuned! ","date":"2020-06-22","objectID":"/20200622/:7:0","tags":["python","数学建模"],"title":"Matplotlib","uri":"/20200622/"},{"categories":["python","数学建模"],"content":"前言 ","date":"2020-06-22","objectID":"/20200602/:1:0","tags":["python","数学建模"],"title":"Pandas (下)","uri":"/20200602/"},{"categories":["python","数学建模"],"content":"本篇鸣谢 马川-燕大 的增删整理， 王圣元 ——原创文章，与原文不同之处包含我的学习记录。 匹配Jupyter Notebook的ipynb文档链接下载地址在资源页面里 接着上篇继续后面三个章节 提纲 ","date":"2020-06-22","objectID":"/20200602/:2:0","tags":["python","数学建模"],"title":"Pandas (下)","uri":"/20200602/"},{"categories":["python","数学建模"],"content":"4 数据表的合并和连接 数据表可以按「键」合并，用 merge 函数；可以按「轴」来连接，用 concat 函数。 ","date":"2020-06-22","objectID":"/20200602/:3:0","tags":["python","数学建模"],"title":"Pandas (下)","uri":"/20200602/"},{"categories":["python","数学建模"],"content":"4.1 合并 合并用 merge 函数，语法如下： pd.merge( df1, df2, how=s, on=c ) c 是 df1 和 df2 共有的一栏，合并方式 (how=s) 有四种： 左连接 (left join)：合并之后显示 df1 的所有行 右连接 (right join)：合并之后显示 df2 的所有行 外连接 (outer join)：合并所有行 内连接 (inner join)：合并df1 和 df2 共有的所有行 (默认情况) 首先创建两个 DataFrame： df_price：4 天的价格 (2019-01-01 到 2019-01-04) df_volume：5 天的交易量 (2019-01-02 到 2019-01-06) import pandas as pd df_price = pd.DataFrame( {'Date': pd.date_range('2019-1-1', periods=4), 'Adj Close': [24.42, 25.00, 25.25, 25.64]}) df_price Date Adj Close 0 2019-01-01 24.42 1 2019-01-02 25.00 2 2019-01-03 25.25 3 2019-01-04 25.64 df_volume = pd.DataFrame( {'Date': pd.date_range('2019-1-2', periods=5), 'Volume' : [56081400, 99455500, 83028700, 100234000, 73829000]}) df_volume Date Volume 0 2019-01-02 56081400 1 2019-01-03 99455500 2 2019-01-04 83028700 3 2019-01-05 100234000 4 2019-01-06 73829000 接下来用 df_price 和 df_volume 展示四种合并。 left join pd.merge( df_price, df_volume, how='left' ) Date Adj Close Volume 0 2019-01-01 24.42 NaN 1 2019-01-02 25.00 56081400.0 2 2019-01-03 25.25 99455500.0 3 2019-01-04 25.64 83028700.0 按 df_price 里 Date 栏里的值来合并数据 df_volume 里 Date 栏里没有 2019-01-01，因此 Volume 为 NaN df_volume 里 Date 栏里的 2019-01-05 和 2019-01-06 不在 df_price 里 Date 栏，因此丢弃 right join pd.merge( df_price, df_volume, how='right' ) Date Adj Close Volume 0 2019-01-02 25.00 56081400 1 2019-01-03 25.25 99455500 2 2019-01-04 25.64 83028700 3 2019-01-05 NaN 100234000 4 2019-01-06 NaN 73829000 按 df_volume 里 Date 栏里的值来合并数据 df_price 里 Date 栏里没有 2019-01-05 和 2019-01-06，因此 Adj Close 为 NaN df_price 里 Date 栏里的 2019-01-01 不在 df_volume 里 Date 栏，因此丢弃 outer join pd.merge( df_price, df_volume, how='outer' ) Date Adj Close Volume 0 2019-01-01 24.42 NaN 1 2019-01-02 25.00 56081400.0 2 2019-01-03 25.25 99455500.0 3 2019-01-04 25.64 83028700.0 4 2019-01-05 NaN 100234000.0 5 2019-01-06 NaN 73829000.0 按 df_price 和 df_volume 里 Date 栏里的所有值来合并数据 df_price 里 Date 栏里没有 2019-01-05 和 2019-01-06，因此 Adj Close 为 NaN df_volume 里 Date 栏里没有 2019-01-01，因此 Volume 为 NaN inner join pd.merge( df_price, df_volume, how='inner' ) Date Adj Close Volume 0 2019-01-02 25.00 56081400 1 2019-01-03 25.25 99455500 2 2019-01-04 25.64 83028700 按 df_price 和 df_volume 里 Date 栏里的共有值来合并数据 df_price 里 Date 栏里的 2019-01-01 不在 df_volume 里 Date 栏，因此丢弃 df_volume 里 Date 栏里的 2019-01-05 和 2019-01-06 不在 df_price 里 Date 栏，因此丢弃 ","date":"2020-06-22","objectID":"/20200602/:3:1","tags":["python","数学建模"],"title":"Pandas (下)","uri":"/20200602/"},{"categories":["python","数学建模"],"content":"4.2 连接 Numpy 数组可相互连接，用 np.concat；同理，Series 和 DataFrame 也可相互连接，用 pd.concat。 连接 Series 在 concat 函数也可设定参数 axis， axis = 0 (默认)，沿着轴 0 (行) 连接，得到一个更长的 Series axis = 1，沿着轴 1 (列) 连接，得到一个 DataFrame 被连接的 Series 它们的 index 可以重复 (overlapping)，也可以不同。 non-overlapping index 先定义三个 Series，它们的 index 各不同。 s1 = pd.Series([0, 1], index=['a', 'b']) s2 = pd.Series([2, 3, 4], index=['c', 'd', 'e']) s3 = pd.Series([5, 6], index=['f', 'g']) print(s1) print(s2) print(s3) a 0 b 1 dtype: int64 c 2 d 3 e 4 dtype: int64 f 5 g 6 dtype: int64 沿着「轴 0」连接得到一个更长的 Series。 pd.concat([s1, s2, s3]) a 0 b 1 c 2 d 3 e 4 f 5 g 6 dtype: int64 沿着「轴 1」连接得到一个 DataFrame。 pd.concat([s1, s2, s3], axis=1) 0 1 2 a 0.0 NaN NaN b 1.0 NaN NaN c NaN 2.0 NaN d NaN 3.0 NaN e NaN 4.0 NaN f NaN NaN 5.0 g NaN NaN 6.0 overlapping index 将 s1 和 s3 沿「轴 0」连接来创建 s4，这样 s4 和 s1 的 index 是有重复的。 s4 = pd.concat([s1, s3]) print(s1) print(s4) a 0 b 1 dtype: int64 a 0 b 1 f 5 g 6 dtype: int64 将 s1 和 s4 沿「轴 1」内连接 (即只连接它们共有 index 对应的值) pd.concat([s1, s4], axis = 1, join='inner') 0 1 a 0 0 b 1 1 hierarchical index 最后还可以将 n 个 Series 沿「轴 0」连接起来，再赋予 3 个 keys 创建多层 Series。 pd.concat( [s1, s1, s3], keys=['one','two','three']) one a 0 b 1 two a 0 b 1 three f 5 g 6 dtype: int64 连接 DataFrame 连接 DataFrame 的逻辑和连接 Series 的一模一样。 沿着行连接 (axis = 0) 先创建两个 DataFrame，df1 和 df2。 import numpy as np df1 = pd.DataFrame( np.arange(12).reshape(3,4), columns=['a','b','c','d']) df1 a b c d 0 0 1 2 3 1 4 5 6 7 2 8 9 10 11 df2 = pd.DataFrame( np.arange(6).reshape(2,3), columns=['b','d','a']) df2 b d a 0 0 1 2 1 3 4 5 沿着行连接分两步 先把 df1 和 df2 列标签补齐 再把 df1 和 df2 纵向连起来 pd.concat( [df1, df2] ) a b c d 0 0 1 2.0 3 1 4 5 6.0 7 2 8 9 10.0 11 0 2 0 NaN 1 1 5 3 NaN 4 得到的 DataFrame 的 index = [0,1,2,0,1]，有重复值。如果 index 不包含重要信息 (如上例)，可以将 ignore_index 设置为 True，这样就得到默认的 index 值了。 pd.concat( [df1, df2], ignore_index=True ) a b c d 0 0 1 2.0 3 1 4 5 6.0 7 2 8 9 10.0 11 3 2 0 NaN 1 4 5 3 NaN 4 沿着列连接 (axis = 1) 先创建两个 DataFrame，df1 和 df2。 df1 = pd.DataFrame( np.arange(6).reshape(3,2), index=['a','b','c'], columns=['one','two'] ) df1 one two a 0 1 b 2 3 c 4 5 df2 = pd.DataFrame( 5 + np.arange(4).reshape(2,2), index=['a','c'], columns=['three','four']) df2 three four a 5 6 c 7 8 沿着列连接分两步 先把 df1 和 df2 行标签补齐 再把 df1 和 df2 横向连起来 pd.concat( [df1, df2], axis=1 ) one two three four a 0 1 5.0 6.0 b 2 3 NaN NaN c 4 5 7.0 8.0 ","date":"2020-06-22","objectID":"/20200602/:3:2","tags":["python","数学建模"],"title":"Pandas (下)","uri":"/20200602/"},{"categories":["python","数学建模"],"content":"5 数据表的重塑和透视 有许多用于重新排列表格型数据的基础运算。这些函数也称作重塑（reshape）或轴向旋转（pivot）运算。 重塑 (reshape) 和透视 (pivot) 两个操作只改变数据表的布局 (layout)： 重塑用 stack 和 unstack 函数 (互为逆转操作) 透视用 pivot 和 melt 函数 (互为逆转操作) ","date":"2020-06-22","objectID":"/20200602/:4:0","tags":["python","数学建模"],"title":"Pandas (下)","uri":"/20200602/"},{"categories":["python","数学建模"],"content":"5.1 重塑 重塑就是通过改变数据表里面的「行索引」和「列索引」来改变展示形式，从本质上说，就是重塑层次化索引(多层索引)。 行列旋转 列索引 → 行索引，用 stack 函数 行索引 → 列索引，用 unstack 函数 单层 DataFrame 创建 DataFrame df (1 层行索引，1 层列索引) symbol = ['JD', 'AAPL'] data = {'行业': ['电商', '科技'], '价格': [25.95, 172.97], '交易量': [27113291, 18913154]} df = pd.DataFrame( data, index=symbol ) df.columns.name = '特征' df.index.name = '代号' df 特征 行业 价格 交易量 代号 JD 电商 25.95 27113291 AAPL 科技 172.97 18913154 从上表中可知： 行索引 = [JD, AAPL]，名称是代号 列索引 = [行业, 价格, 交易量]，名称是特征 stack: 列索引 → 行索引 列索引 (特征) 变成了行索引，原来的 DataFrame df 变成了两层 Series (第一层索引是代号，第二层索引是特征)。 c2i_Series = df.stack() c2i_Series 代号 特征 JD 行业 电商 价格 25.95 交易量 27113291 AAPL 行业 科技 价格 172.97 交易量 18913154 dtype: object unstack: 行索引 → 列索引 行索引 (代号) 变成了列索引，原来的 DataFrame df 也变成了两层 Series (第一层索引是特征，第二层索引是代号)。 i2c_Series = df.unstack() i2c_Series 特征 代号 行业 JD 电商 AAPL 科技 价格 JD 25.95 AAPL 172.97 交易量 JD 27113291 AAPL 18913154 dtype: object 基于层和名称来 unstack 对于多层索引的 Series，unstack 哪一层有两种方法来确定： 基于层 (level-based) 基于名称 (name-based) 拿 c2i_Series 举例 (读者也可以尝试 i2c_Series)： 代号 特征 JD 交易量 27113291 价格 25.95 行业 电商 AAPL 交易量 18913154 价格 172.97 行业 科技 dtype: object 其索引列出如下： c2i_Series.index MultiIndex([( 'JD', '行业'), ( 'JD', '价格'), ( 'JD', '交易量'), ('AAPL', '行业'), ('AAPL', '价格'), ('AAPL', '交易量')], names=['代号', '特征']) 1.基于层来 unstack() 时，没有填层数，默认为最后一层。 c2i_Series.unstack() 特征 行业 价格 交易量 代号 JD 电商 25.95 27113291 AAPL 科技 172.97 18913154 c2i_Series 的最后一层 (看上面它的 MultiIndex) 就是 [交易量, 价格,行业 ]，从行索引转成列索引得到上面的 DataFrame。 2.基于层来 unstack() 时，选择第一层 (参数放 0) c2i_Series.unstack(0) 代号 JD AAPL 特征 行业 电商 科技 价格 25.95 172.97 交易量 27113291 18913154 c2i_Series 的第一层 (看上面它的 MultiIndex) 就是 [JD, AAPL]，从行索引转成列索引得到上面的 DataFrame。 3.基于名称来 unstack c2i_Series.unstack('代号') 代号 JD AAPL 特征 行业 电商 科技 价格 25.95 172.97 交易量 27113291 18913154 c2i_Series 的代号层 (看上面它的 MultiIndex) 就是 [JD, AAPL]，从行索引转成列索引得到上面的 DataFrame。 多层 DataFrame 创建 DataFrame df (2 层行索引，1 层列索引) data = [ ['电商', 101550, 176.92], ['电商', 175336, 25.95], ['金融', 60348, 41.79], ['金融', 36600, 196.00] ] midx = pd.MultiIndex( levels=[['中国','美国'], ['BABA', 'JD', 'GS', 'MS']], codes=[[0,0,1,1],[0,1,2,3]], names = ['地区', '代号']) mcol = pd.Index(['行业','雇员','价格'], name='特征') df = pd.DataFrame( data, index=midx, columns=mcol ) df 特征 行业 雇员 价格 地区 代号 中国 BABA 电商 101550 176.92 JD 电商 175336 25.95 美国 GS 金融 60348 41.79 MS 金融 36600 196.00 从上表中可知： 行索引第一层： r1 = [中国, 美国]，名称是地区 行索引第二层： r2 = [BABA, JD, GS, MS]，名称是代号 列索引： c = [行业, 雇员, 价格]，名称是特征 查看 df 的 index 和 columns 的信息 df.index, df.columns (MultiIndex([('中国', 'BABA'), ('中国', 'JD'), ('美国', 'GS'), ('美国', 'MS')], names=['地区', '代号']), Index(['行业', '雇员', '价格'], dtype='object', name='特征')) 那么 df 的行索引 = [r1, r2] df 的列索引 = c 1.基于层来 unstack() 时，选择第一层 (参数放 0) df.unstack(0) 特征 行业 雇员 价格 地区 中国 美国 中国 美国 中国 美国 代号 BABA 电商 NaN 101550.0 NaN 176.92 NaN JD 电商 NaN 175336.0 NaN 25.95 NaN GS NaN 金融 NaN 60348.0 NaN 41.79 MS NaN 金融 NaN 36600.0 NaN 196.00 df 被 unstack(0) 之后变成 (行 → 列) 行索引 = r2 列索引 = [c, r1] 重塑后的 DataFrame 这时行索引只有一层 (代号)，而列索引有两层，第一层是特征，第二层是地区。 2.基于层来 unstack() 时，选择第二层 (参数放 1) df.unstack(1) 特征 行业 雇员 价格 代号 BABA JD GS MS BABA JD GS MS BABA JD GS MS 地区 中国 电商 电商 NaN NaN 101550.0 175336.0 NaN NaN 176.92 25.95 NaN NaN 美国 NaN NaN 金融 金融 NaN NaN 60348.0 36600.0 NaN NaN 41.79 196.0 df 被 unstack(1) 之后变成 (行 → 列) 行索引 = r1 列索引 = [c, r2] 重塑后的 DataFrame 这时行索引只有一层 (地区)，而列索引有两层，第一层是地区，第二层是代号。 3.基于层先 unstack(0) 再 stack(0) df.unstack(0).stack(0) 地区 中国 美国 代号 特征 BABA 价格 176.92 NaN 行业 电商 NaN 雇员 101550 NaN JD 价格 25.95 NaN 行业 电商 NaN 雇员 175336 NaN GS 价格 NaN 41.79 行业 NaN 金融 雇员 NaN 60348 MS 价格 NaN 196 行业 NaN 金融 雇员 NaN 36600 df 被 unstack(0) 之后变成 (行 → 列) 行索引 = r2 列索引 = [c, r1] 再被 stack(0) 之后变成 (列 → 行) 行索引 = [r2, c] 列索引 = r1 重塑后的 DataFrame 这时行索引有两层，第一层是代号，第二层是特征，而列索引只有一层 (地区)。 4.基于层先 unstack(0) 再 stack(1) df.unstack(0).stack(1) 特征 行业 雇员 价格 代号 地区 BABA 中国 电商 101550.0 176.92 JD 中国 电商 175336.0 25.95 GS 美国 金融 60348.0 41.79 MS 美国 金融 36600.0 196.00 df 被 unstack(0) 之后变成 (行 → 列) 行索引 = r2 列索引 = [c, r1] 再被 stack(1) 之后变成 (列 → 行) 行索引 = [r2, r1] 列索引 = c 重塑后的 DataFrame 这时行索引有两层，第一层是代号，第二层是地区，而列索引只有一层 (特征)。 5.基于层先 unstack(1) 再 stac","date":"2020-06-22","objectID":"/20200602/:4:1","tags":["python","数学建模"],"title":"Pandas (下)","uri":"/20200602/"},{"categories":["python","数学建模"],"content":"5.2 透视 多个时间序列数据(在多个时间点观察或测量到的数据)通常是以所谓的**“长格式”（long）或“堆叠格式”（stacked）**存储在数据库和CSV中的。 因此，经常有重复值出现在各列下，因而导致源表不能传递有价值的信息。这时可用「透视」方法调整源表的布局用作更清晰的展示。 在 Pandas 里透视的方法有两种： 用 pivot 函数将「长格式」旋转为「宽格式」， 用 melt 函数将「宽格式」旋转为「长格式」， 本节使用的数据描述如下： 5 只股票：AAPL, JD, BABA, FB, GS 4 个交易日：从 2019-02-21 到 2019-02-26 data = pd.read_csv('data/Stock.csv', parse_dates=[0], dayfirst=True) data Date Symbol Open High Low Close Adj Close Volume 0 2019-02-21 AAPL 171.800003 172.369995 170.300003 171.059998 171.059998 17249700 1 2019-02-21 JD 24.820000 24.879999 24.010000 24.270000 24.270000 13542600 2 2019-02-21 BABA 171.000000 171.779999 169.800003 171.660004 171.660004 8434800 3 2019-02-21 GS 198.970001 199.449997 195.050003 196.360001 196.360001 2785900 4 2019-02-21 FB 161.929993 162.240005 159.589996 160.039993 160.039993 15607800 5 2019-02-22 AAPL 171.580002 173.000000 171.380005 172.970001 172.970001 18913200 6 2019-02-22 JD 24.549999 25.959999 24.480000 25.950001 25.950001 27113300 7 2019-02-22 BABA 172.800003 177.020004 172.520004 176.919998 176.919998 16175600 8 2019-02-22 GS 196.600006 197.750000 195.199997 196.000000 196.000000 2626600 9 2019-02-22 FB 160.580002 162.410004 160.309998 161.889999 161.889999 15858500 10 2019-02-25 AAPL 174.160004 175.869995 173.949997 174.229996 174.229996 21873400 11 2019-02-25 JD 27.110001 27.379999 26.040001 26.190001 26.190001 29338500 12 2019-02-25 BABA 181.259995 183.720001 180.729996 183.250000 183.250000 22831800 13 2019-02-25 GS 198.000000 201.500000 197.710007 198.649994 198.649994 3032200 14 2019-02-25 FB 163.070007 166.070007 162.899994 164.619995 164.619995 18737100 15 2019-02-26 AAPL 173.710007 175.300003 173.169998 174.330002 174.330002 17006000 16 2019-02-26 JD 25.980000 26.820000 25.660000 26.590000 26.590000 20264100 17 2019-02-26 BABA 179.789993 184.350006 179.369995 183.539993 183.539993 13857900 18 2019-02-26 GS 198.470001 200.559998 196.550003 198.899994 198.899994 2498000 19 2019-02-26 FB 164.339996 166.240005 163.800003 164.130005 164.130005 13645200 从上表看出有 20 行 (5 × 4) 和 8 列，在 Date 和 Symbol 那两列下就有重复值，4 个日期和 5 个股票在 20 行中分别出现了 5 次和 4 次。 这就是多个时间序列（或者其它带有两个或多个键的可观察数据，这里，我们的键是Date和Symbol）的长格式。表中的每行代表一次观察。 关系型数据库（如MySQL）中的数据经常都是这样存储的，因为固定架构（即列名和数据类型）有一个好处：随着表中数据的添加，Symbol列中的值的种类能够增加。在前面的例子中，Date和Symbol通常就是主键（关系型数据库中的术语，是表中的一个或多个字段，它的值用于唯一地标识表中的某一条记录），不仅提供了关系完整性，而且提供了更为简单的查询支持。有的情况下，使用这样的数据会很麻烦，你可能会更喜欢不同的Symbol值分别形成一列，Date列中的时间戳则用作索引。DataFrame的pivot方法完全可以实现这个转换： 从长到宽 (pivot) 当我们做数据分析时，只关注不同股票在不同日期下的 Adj Close data.iloc[:,[0,1,6]] Date Symbol Adj Close 0 2019-02-21 AAPL 171.059998 1 2019-02-21 JD 24.270000 2 2019-02-21 BABA 171.660004 3 2019-02-21 GS 196.360001 4 2019-02-21 FB 160.039993 5 2019-02-22 AAPL 172.970001 6 2019-02-22 JD 25.950001 7 2019-02-22 BABA 176.919998 8 2019-02-22 GS 196.000000 9 2019-02-22 FB 161.889999 10 2019-02-25 AAPL 174.229996 11 2019-02-25 JD 26.190001 12 2019-02-25 BABA 183.250000 13 2019-02-25 GS 198.649994 14 2019-02-25 FB 164.619995 15 2019-02-26 AAPL 174.330002 16 2019-02-26 JD 26.590000 17 2019-02-26 BABA 183.539993 18 2019-02-26 GS 198.899994 19 2019-02-26 FB 164.130005 那么可用 pivot 函数将原始 data「透视」成一个新的 DataFrame，起名 close_price。在 pivot 函数中 将 index 设置成 ‘Date’ 将 columns 设置成 ‘Symbol’ 将 values 设置 ‘Adj Close’ close_price 实际上把 data[‘Date’] 和 data[‘Symbol’] 的唯一值当成支点(pivot 就是支点的意思) 创建一个 DataFrame，其中 行标签 = 2019-02-21, 2019-02-22, 2019-02-25, 2019-02-26 列标签 = AAPL, JD, BABA, FB, GS 在把 data[‘Adj Close’] 的值放在以如上的行标签和列标签创建的 close_price 来展示。 代码如下： close_price = data.pivot( index='Date', columns='Symbol', values='Adj Close' ) close_price Symbol AAPL BABA FB GS JD Date 2019-02-21 171.059998 171.660004 160.039993 196.360001 24.270000 2019-02-22 172.970001 176.919998 161.889999 196.000000 25.950001 2019-02-25 174.229996 183.250000 164.619995 198.649994 26.190001 2019-02-26 174.330002 183.539993 164.130005 198.899994 26.590000 如果觉得 Adj Close 不够，还想加个 Volume 看看，这时支点还是 data[‘Date’] 和 data[‘Symbol’]，但是要透视的值增加到 data[[‘Adj Close’, ‘Volume’]] 了。pivot 函数返回的是两个透视表。 # data.pivot( index='Date', # columns","date":"2020-06-22","objectID":"/20200602/:4:2","tags":["python","数学建模"],"title":"Pandas (下)","uri":"/20200602/"},{"categories":["python","数学建模"],"content":"6 数据表的分组和聚合 DataFrame 中的数据可以根据某些规则分组，然后在每组的数据上计算出不同统计量。这种操作称之为 split-apply-combine（拆分－应用－合并）。 第一个阶段，pandas对象（无论是Series、DataFrame还是其他的）中的数据会根据你所提供的一个或多个键被拆分（split）为多组。拆分操作是在对象的特定轴上执行的。例如，DataFrame可以在其行（axis=0）或列（axis=1）上进行分组。然后，将一个函数应用（apply）到各个分组并产生一个新值。最后，所有这些函数的执行结果会被合并（combine）到最终的结果对象中。结果对象的形式一般取决于数据上所执行的操作。 该 split-apply-combine 过程有两步(apply-combine合为一步完成)： Step1 ：数据分组(split) groupby 方法 Step2 ：数据聚合(apply-combine) 使用内置函数——sum / mean / max / min / count等 使用自定义函数—— agg ( aggregate ) 方法 自定义更丰富的分组运算—— apply 方法 agg 方法将一个函数使用在一个数列上，然后返回一个标量的值。也就是说agg每次传入的是一列数据，对其聚合后返回标量。 apply 是一个更一般化的方法，会将当前分组后的数据一起传入，返回多维数据。 ","date":"2020-06-22","objectID":"/20200602/:5:0","tags":["python","数学建模"],"title":"Pandas (下)","uri":"/20200602/"},{"categories":["python","数学建模"],"content":"6.1 数据准备 本节使用数据：泰坦尼克数据集 PassengerId =\u003e 乘客编号 Survived =\u003e 获救情况（1为获救，0为未获救） Pclass =\u003e 乘客等级(1/2/3等舱位) Name =\u003e 乘客姓名 Sex =\u003e 性别 Age =\u003e 年龄 SibSp =\u003e 堂兄弟/妹个数 Parch =\u003e 父母与小孩个数 Ticket =\u003e 船票信息 Fare =\u003e 票价 Cabin =\u003e 客舱 Embarked =\u003e 登船港口 titanic = pd.read_csv(r'data\\Titanic.csv') titanic.head() PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked 0 1 0 3 Braund, Mr. Owen Harris male 22.0 1 0 A/5 21171 7.2500 NaN S 1 2 1 1 Cumings, Mrs. John Bradley (Florence Briggs Th... female 38.0 1 0 PC 17599 71.2833 C85 C 2 3 1 3 Heikkinen, Miss. Laina female 26.0 0 0 STON/O2. 3101282 7.9250 NaN S 3 4 1 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35.0 1 0 113803 53.1000 C123 S 4 5 0 3 Allen, Mr. William Henry male 35.0 0 0 373450 8.0500 NaN S 用前面所学透视一下数据： titanic.pivot_table(index='Sex',columns='Pclass',values='Survived') Pclass 1 2 3 Sex female 0.968085 0.921053 0.500000 male 0.368852 0.157407 0.135447 titanic.pivot_table(index='Sex',columns='Pclass',values='Survived',aggfunc='sum') Pclass 1 2 3 Sex female 91 70 72 male 45 17 47 titanic.pivot_table(index='Sex',columns='Pclass',aggfunc={'Survived':'sum','Age':'mean'}) Age Survived Pclass 1 2 3 1 2 3 Sex female 34.611765 28.722973 21.750000 91 70 72 male 41.281386 30.740707 26.507589 45 17 47 ","date":"2020-06-22","objectID":"/20200602/:5:1","tags":["python","数学建模"],"title":"Pandas (下)","uri":"/20200602/"},{"categories":["python","数学建模"],"content":"6.2 分组 (grouping) 用某一特定标签 (label) 将数据 (data) 分组的语法如下： data.groupBy( label ) 单标签分组 首先来按 Symbol 来分组： grouped = titanic.groupby('Sex') grouped \u003cpandas.core.groupby.generic.DataFrameGroupBy object at 0x00000278AE849CC0\u003e dir(grouped) ['Age', 'Cabin', 'Embarked', 'Fare', 'Name', 'Parch', 'PassengerId', 'Pclass', 'Sex', 'SibSp', 'Survived', 'Ticket', '__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_accessors', '_add_numeric_operations', '_agg_examples_doc', '_agg_see_also_doc', '_aggregate', '_aggregate_frame', '_aggregate_item_by_item', '_aggregate_multiple_funcs', '_apply_filter', '_apply_to_column_groupbys', '_apply_whitelist', '_assure_grouper', '_bool_agg', '_builtin_table', '_choose_path', '_concat_objects', '_constructor', '_cumcount_array', '_cython_agg_blocks', '_cython_agg_general', '_cython_table', '_cython_transform', '_define_paths', '_deprecations', '_dir_additions', '_dir_deletions', '_fill', '_get_cython_func', '_get_cythonized_result', '_get_data_to_aggregate', '_get_index', '_get_indices', '_gotitem', '_group_selection', '_insert_inaxis_grouper_inplace', '_internal_names', '_internal_names_set', '_is_builtin_func', '_iterate_column_groupbys', '_iterate_slices', '_make_wrapper', '_obj_with_exclusions', '_python_agg_general', '_python_apply_general', '_reindex_output', '_reset_cache', '_reset_group_selection', '_selected_obj', '_selection', '_selection_list', '_selection_name', '_set_group_selection', '_set_result_index_ordered', '_transform_fast', '_transform_general', '_transform_item_by_item', '_transform_should_cast', '_try_aggregate_string_function', '_try_cast', '_wrap_agged_blocks', '_wrap_aggregated_output', '_wrap_applied_output', '_wrap_frame_output', '_wrap_transformed_output', 'agg', 'aggregate', 'all', 'any', 'apply', 'backfill', 'bfill', 'boxplot', 'corr', 'corrwith', 'count', 'cov', 'cumcount', 'cummax', 'cummin', 'cumprod', 'cumsum', 'describe', 'diff', 'dtypes', 'expanding', 'ffill', 'fillna', 'filter', 'first', 'get_group', 'groups', 'head', 'hist', 'idxmax', 'idxmin', 'indices', 'last', 'mad', 'max', 'mean', 'median', 'min', 'ndim', 'ngroup', 'ngroups', 'nth', 'nunique', 'ohlc', 'pad', 'pct_change', 'pipe', 'plot', 'prod', 'quantile', 'rank', 'resample', 'rolling', 'sem', 'shift', 'size', 'skew', 'std', 'sum', 'tail', 'take', 'transform', 'tshift', 'var'] 又要提起那句说了无数遍的话「万物皆对象」了。这个 grouped 也不例外，当你对如果使用某个对象感到迷茫时，用 dir() 来查看它的「属性」和「内置方法」。以下几个属性和方法是学生感兴趣的： ngroups: 组的个数 (int) size(): 每组元素的个数 (Series) groups: 每组元素在原 DataFrame 中的索引信息 (dict) get_groups(label): 标签 label 对应的数据 (DataFrame) 下面看看这些属性和方法的产出结果。 数据里性别为male和female，因此有2组。 列索引变行索引，同项合并得到新运算结果 grouped.ngroups 2 每组的信息条数 grouped.size() Sex female 314 male 577 dtype: int64 女士 (female) 的索引 1, 2, 3, 8, 9, …，男士( male) 的索引0, 4, 5, 6, 7,… grouped.groups {'female': Int64Index([ 1, 2, 3, 8, 9, 10, 11, 14, 15, 18, ... 866, 871, 874, 875, 879, 880, 882, 885, 887, 888], dtype='int64', length=314), 'male': Int64Index([ 0, 4, 5, 6, 7, 12, 13, 16, 17, 20, ... 873, 876, 877, 878, 881, 883, 884, 886, 889, 890], dtype='int64', length=577)} 查查 ‘male’ 组里的数据的前五行。 grouped.get_group('male').head() PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked 0 1 0 3 Braund, Mr. Owen Harris male 22.0 1 0 A/5 21171 7.2500 NaN S 4 5 0 3 Allen, Mr. William Henry male 35.0 0 0 373450 8.0500 NaN S 5 6 0 3 Moran, Mr. James male NaN 0 0 330877 8.4583 NaN Q 6 7 0 1 McCarthy, Mr. Timothy J male 54.0 0 0 17463 51.8625 E46 S 7 8 0 3 Palsson, Master. Gosta Leonard male 2.0 3 1 349909 21.0750 NaN S 接下来定义个 print_groups 函数便于打印组的名字和前五行信息。 def print_groups( group_obj ): for name, group in group_obj: print( name ) ","date":"2020-06-22","objectID":"/20200602/:5:2","tags":["python","数学建模"],"title":"Pandas (下)","uri":"/20200602/"},{"categories":["python","数学建模"],"content":"6.3 聚合 (aggregating) 6.3.1 使用内置函数——sum / mean / max / min / count等 grouped.mean() # grouped.sum() # grouped.max() # grouped.min() # grouped.count() PassengerId Survived Pclass Age SibSp Parch Fare Sex female 431.028662 0.742038 2.159236 27.915709 0.694268 0.649682 44.479818 male 454.147314 0.188908 2.389948 30.726645 0.429809 0.235702 25.523893 6.3.2 使用自定义函数—— agg ( aggregate ) 方法 agg 方法将一个函数使用在一个数列上，然后返回一个标量的值。也就是说agg每次传入的是一列数据，对其聚合后返回标量。 # grouped['Survived'].agg(np.mean) grouped.agg(np.mean) PassengerId Survived Pclass Age SibSp Parch Fare Sex female 431.028662 0.742038 2.159236 27.915709 0.694268 0.649682 44.479818 male 454.147314 0.188908 2.389948 30.726645 0.429809 0.235702 25.523893 titanic.groupby(['Sex','Pclass'])['Survived'].agg(['mean','sum']) # 或者这样写 # titanic.groupby(['Sex','Pclass'])['Survived'].agg([np.mean,np.sum]) mean sum Sex Pclass female 1 0.968085 91 2 0.921053 70 3 0.500000 72 male 1 0.368852 45 2 0.157407 17 3 0.135447 47 将 np.mean 和 np.std 放进列表中，当成是高阶函数 agg() 的参数。上面代码按性别和乘客等级对获救情况求均值与和。 既然 agg() 是高阶函数，参数当然也可以是匿名函数 (lambda 函数)，下面先定义一个对 grouped2 里面每个标签下求最大值和最小值，再求差。注意 lambda 函数里面的 x 就是 grouped2。 grouped2.agg( lambda x: np.max(x)-np.min(x) ) PassengerId Survived Age SibSp Parch Fare Sex Pclass female 1 886 1 61.00 3 2 486.4000 2 871 1 55.00 3 3 54.5000 3 886 1 62.25 8 6 62.8000 male 1 883 1 79.08 3 4 512.3292 2 869 1 69.33 2 2 73.5000 3 890 1 73.58 8 5 69.5500 上面代码对每个分组在Age、Fare、Parch、PassengerId、SibSp和Survived上求「最大值」和「最小值」的差。真正有价值的信息在 Age、Parch 等栏，但是可以借此来验证agg使用自定义函数的用法。 6.3.3 自定义更丰富的分组运算—— apply 方法 apply 是一个更一般化的方法：将一个数据分拆-应用-汇总，会将当前分组后的数据一起传入，返回多维数据。 有时候返回的值不一定是一个标量的值，有可能是一个数组或是其他类型。此时，agg无法胜任，就需要使用apply了。 在看具体例子之前，先定一个 top 函数，返回 DataFrame 某一栏中 n 个最大值。 def top( df, n=5, column='Parch' ): return df.sort_values(by=column)[-n:] df.sort_values 根据column排序，上一代码中是升序 将 top 函数用到最原始的数据 (从 csv 中读取出来的) 上。 top( titanic ) PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked 13 14 0 3 Andersson, Mr. Anders Johan male 39.0 1 5 347082 31.2750 NaN S 25 26 1 3 Asplund, Mrs. Carl Oscar (Selma Augusta Emilia... female 38.0 1 5 347077 31.3875 NaN S 885 886 0 3 Rice, Mrs. William (Margaret Norton) female 39.0 0 5 382652 29.1250 NaN Q 638 639 0 3 Panula, Mrs. Juha (Maria Emilia Ojala) female 41.0 0 5 3101295 39.6875 NaN S 678 679 0 3 Goodwin, Mrs. Frederick (Augusta Tyler) female 43.0 1 6 CA 2144 46.9000 NaN S 上面的top函数中，df 代表你传递给它的DataFrame数据，n代表取它的前n行，在这里，n的默认值是5，也就是说在调用这个函数的时候，如果没有给n赋值，n值等于5。column是排序列，函数会先按column升序排序，然后返回最大的n行。在这个时候，agg的方法就不管用的，要是强行使用，就会出错。 来，演示一遍错误！ titanic.groupby('Sex').agg(top) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) D:\\Anaconda\\envs\\python32\\lib\\site-packages\\pandas\\core\\groupby\\generic.py in aggregate(self, func, *args, **kwargs) 947 try: --\u003e 948 result = self._aggregate_multiple_funcs([func], _axis=self.axis) 949 except ValueError as err: D:\\Anaconda\\envs\\python32\\lib\\site-packages\\pandas\\core\\base.py in _aggregate_multiple_funcs(self, arg, _axis) 541 if not len(results): --\u003e 542 raise ValueError(\"no results\") 543 ValueError: no results During handling of the above exception, another exception occurred: ValueError Traceback (most recent call last) D:\\Anaconda\\envs\\python32\\lib\\site-packages\\pandas\\core\\internals\\managers.py in create_block_manager_from_arrays(arrays, names, axes) 1670 blocks = form_blocks(arrays, names, axes) -\u003e 1671 mgr = BlockManager(blocks, axes) 1672 mgr._consolidate_inplace() D:\\Anaconda\\envs\\python32\\lib\\site-packages\\pandas\\core\\internals\\managers.py in __init__(self, blocks, axes, do_integrity_check) 138 if do_integrity_check: --\u003e 139 self._verify_integrity() 140 D:\\Anaconda\\envs\\python32\\lib\\site-packages\\pandas\\core\\internals\\managers.py in _verify_integrity(self) 333 if block._verify_integrity and block.shape[1:] != mgr_shape[1:]: --\u003e 334 construction_error(tot_items, block.shape[1:], self.axes) 335 if len(self.items) != tot_items: D:\\Anaconda\\envs\\python32\\lib\\site-","date":"2020-06-22","objectID":"/20200602/:5:3","tags":["python","数学建模"],"title":"Pandas (下)","uri":"/20200602/"},{"categories":["python","数学建模"],"content":"6.4 排序(Mc补充) 排序分为对索引排序 sort_index 和对 值排序 sort_values ascending：默认True升序排列；False降序排列 obj = pd.Series(range(4), index=['d','a','b','c']) print(obj) #索引排序 print('索引排序\\n',obj.sort_index()) #值排序 print('值排序\\n',obj.sort_values(ascending=False)) d 0 a 1 b 2 c 3 dtype: int64 索引排序 a 1 b 2 c 3 d 0 dtype: int64 值排序 c 3 b 2 a 1 d 0 dtype: int64 frame = pd.DataFrame(np.arange(8).reshape((2,4)),index=['three','one'], columns=['d','a','b','c']) print(frame) # 索引排序 print(frame.sort_index()) # frame.sort_index(axis=1) # 降序 # frame.sort_index(axis=1, ascending=False) # 值排序 # frame.sort_values(by='a',ascending=False) # frame.sort_values(by=['a','b'],ascending=False) # frame.sort_values(by='one',axis=1,ascending=False) d a b c three 0 1 2 3 one 4 5 6 7 d a b c one 4 5 6 7 three 0 1 2 3 c b a d three 3 2 1 0 one 7 6 5 4 ","date":"2020-06-22","objectID":"/20200602/:5:4","tags":["python","数学建模"],"title":"Pandas (下)","uri":"/20200602/"},{"categories":["python","数学建模"],"content":"7 总结 【合并数据表】用 merge 函数按数据表的共有列进行左/右/内/外合并。 【连接数据表】用 concat 函数对 Series 和 DataFrame 沿着不同轴连接。 【重塑数据表】用 stack 函数将「列索引」变成「行索引」，用 unstack 函数将「行索引」变成「列索引」。它们只是改变数据表的布局和展示方式而已。 【透视数据表】用 pivot 函数将「一张长表」变成「多张宽表」，用 melt 函数将「多张宽表」变成「一张长表」。它们只是改变数据表的布局和展示方式而已。 【分组数据表】用 groupBy 函数按不同「列索引」下的值分组。一个「列索引」或多个「列索引」就可以。 【聚合数据表】用 agg 函数对每个组做聚合而计算统计量。 【split-apply-combine】用 apply 函数做数据分析时美滋滋。 至此，可以说已经打好 Python Basics 的基础，能用 NumPy 做数组计算，能用 Pandas 做数据分析，现在已经搞很多事情了。现在我们唯一欠缺的是如何画图或可视化数据，下帖从最基础的可视化工具 Matplotlib 开始讲。Stay Tuned! ","date":"2020-06-22","objectID":"/20200602/:6:0","tags":["python","数学建模"],"title":"Pandas (下)","uri":"/20200602/"},{"categories":["C++","python"],"content":"尹成爬虫课件 蓝奏云链接 ","date":"2020-06-22","objectID":"/about/ziyuan/:0:1","tags":["windows"],"title":"博客相关资源","uri":"/about/ziyuan/"},{"categories":["C++","python"],"content":"电脑抓包工具fiddler fiddler百度云盘链接 提取码：qk5c fiddler蓝奏云盘链接 ","date":"2020-06-22","objectID":"/about/ziyuan/:0:2","tags":["windows"],"title":"博客相关资源","uri":"/about/ziyuan/"},{"categories":["C++","python"],"content":"爬虫headers伪装UserAgent集合 电脑端 pcUserAgent = { \"safari 5.1 – MAC\":\"User-Agent:Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_8; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50\", \"safari 5.1 – Windows\":\"User-Agent:Mozilla/5.0 (Windows; U; Windows NT 6.1; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50\", \"IE 9.0\":\"User-Agent:Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0);\", \"IE 8.0\":\"User-Agent:Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0)\", \"IE 7.0\":\"User-Agent:Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.0)\", \"IE 6.0\":\"User-Agent: Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1)\", \"Firefox 4.0.1 – MAC\":\"User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.6; rv:2.0.1) Gecko/20100101 Firefox/4.0.1\", \"Firefox 4.0.1 – Windows\":\"User-Agent:Mozilla/5.0 (Windows NT 6.1; rv:2.0.1) Gecko/20100101 Firefox/4.0.1\", \"Opera 11.11 – MAC\":\"User-Agent:Opera/9.80 (Macintosh; Intel Mac OS X 10.6.8; U; en) Presto/2.8.131 Version/11.11\", \"Opera 11.11 – Windows\":\"User-Agent:Opera/9.80 (Windows NT 6.1; U; en) Presto/2.8.131 Version/11.11\", \"Chrome 17.0 – MAC\":\"User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_0) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.56 Safari/535.11\", \"Maxthon\":\"User-Agent: Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; Maxthon 2.0)\", \"Tencent TT\":\"User-Agent: Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; TencentTraveler 4.0)\", \"The World 2.x\":\"User-Agent: Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)\", \"The World 3.x\":\"User-Agent: Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; The World)\", \"sogou 1.x\":\"User-Agent: Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; Trident/4.0; SE 2.X MetaSr 1.0; SE 2.X MetaSr 1.0; .NET CLR 2.0.50727; SE 2.X MetaSr 1.0)\", \"360\":\"User-Agent: Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; 360SE)\", \"Avant\":\"User-Agent: Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; Avant Browser)\", \"Green Browser\":\"User-Agent: Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)\" } 移动手机端 mobileUserAgent = { \"iOS 4.33 – iPhone\":\"User-Agent:Mozilla/5.0 (iPhone; U; CPU iPhone OS 4_3_3 like Mac OS X; en-us) AppleWebKit/533.17.9 (KHTML, like Gecko) Version/5.0.2 Mobile/8J2 Safari/6533.18.5\", \"iOS 4.33 – iPod Touch\":\"User-Agent:Mozilla/5.0 (iPod; U; CPU iPhone OS 4_3_3 like Mac OS X; en-us) AppleWebKit/533.17.9 (KHTML, like Gecko) Version/5.0.2 Mobile/8J2 Safari/6533.18.5\", \"iOS 4.33 – iPad\":\"User-Agent:Mozilla/5.0 (iPad; U; CPU OS 4_3_3 like Mac OS X; en-us) AppleWebKit/533.17.9 (KHTML, like Gecko) Version/5.0.2 Mobile/8J2 Safari/6533.18.5\", \"Android N1\":\"User-Agent: Mozilla/5.0 (Linux; U; Android 2.3.7; en-us; Nexus One Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1\", \"Android QQ\":\"User-Agent: MQQBrowser/26 Mozilla/5.0 (Linux; U; Android 2.3.7; zh-cn; MB200 Build/GRJ22; CyanogenMod-7) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1\", \"Android Opera \":\"User-Agent: Opera/9.80 (Android 2.3.4; Linux; Opera Mobi/build-1107180945; U; en-GB) Presto/2.8.149 Version/11.10\", \"Android Pad Moto Xoom\":\"User-Agent: Mozilla/5.0 (Linux; U; Android 3.0; en-us; Xoom Build/HRI39) AppleWebKit/534.13 (KHTML, like Gecko) Version/4.0 Safari/534.13\", \"BlackBerry\":\"User-Agent: Mozilla/5.0 (BlackBerry; U; BlackBerry 9800; en) AppleWebKit/534.1+ (KHTML, like Gecko) Version/6.0.0.337 Mobile Safari/534.1+\", \"WebOS HP Touchpad\":\"User-Agent: Mozilla/5.0 (hp-tablet; Linux; hpwOS/3.0.0; U; en-US) AppleWebKit/534.6 (KHTML, like Gecko) wOSBrowser/233.70 Safari/534.6 TouchPad/1.0\", \"Nokia N97\":\"User-Agent: Mozilla/5.0 (SymbianOS/9.4; Series60/5.0 NokiaN97-1/20.0.019; Profile/MIDP-2.1 Configuration/CLDC-1.1) AppleWebKit/525 (KHTML, like Gecko) BrowserNG/7.1.18124\", \"Windows Phone Mango\":\"User-Agent: Mozilla/5.0 (compatible; MSIE 9.0; Windows Phone OS 7.5; Trident/5.0; IEMobile/9.0; HTC; Titan)\", \"UC\":\"User-Agent: UCWEB7.0.2.37/28/999\", \"UC standard\":\"User-Agent: NOKIA5700","date":"2020-06-22","objectID":"/about/ziyuan/:0:3","tags":["windows"],"title":"博客相关资源","uri":"/about/ziyuan/"},{"categories":["C++","python"],"content":"Appium布置软件集合 链接: https://pan.baidu.com/s/126x-AgLKvM7qSJqdOzAAHA 提取码: h9b2 ","date":"2020-06-22","objectID":"/about/ziyuan/:0:4","tags":["windows"],"title":"博客相关资源","uri":"/about/ziyuan/"},{"categories":["C++","python"],"content":"go-cqhttp 下载链接：点我 ","date":"2020-06-22","objectID":"/about/ziyuan/:0:5","tags":["windows"],"title":"博客相关资源","uri":"/about/ziyuan/"},{"categories":["C++","python"],"content":"Numpy课件 源文档(上) 源文档(下) ","date":"2020-06-22","objectID":"/about/ziyuan/:0:6","tags":["windows"],"title":"博客相关资源","uri":"/about/ziyuan/"},{"categories":["C++","python"],"content":"Pandas课件 源文档及相关文件(上) 源文档及相关文件(下) ","date":"2020-06-22","objectID":"/about/ziyuan/:0:7","tags":["windows"],"title":"博客相关资源","uri":"/about/ziyuan/"},{"categories":["C++","python"],"content":"MySQL数据库下载链接(5.5版本) https://spiritlhl.lanzous.com/id5vt2f ","date":"2020-06-22","objectID":"/about/ziyuan/:0:8","tags":["windows"],"title":"博客相关资源","uri":"/about/ziyuan/"},{"categories":["C++","python"],"content":"MySQL图形界面客户端下载链接 https://spiritlhl.lanzous.com/id5vuji ","date":"2020-06-22","objectID":"/about/ziyuan/:0:9","tags":["windows"],"title":"博客相关资源","uri":"/about/ziyuan/"},{"categories":["C++","python"],"content":"Matplotlib课件 源文档及相关文件压缩包 ","date":"2020-06-22","objectID":"/about/ziyuan/:0:10","tags":["windows"],"title":"博客相关资源","uri":"/about/ziyuan/"},{"categories":["C++","python"],"content":"1Stopt安装包 点击跳转下载解压即可使用，记得看说明先 ","date":"2020-06-22","objectID":"/about/ziyuan/:0:11","tags":["windows"],"title":"博客相关资源","uri":"/about/ziyuan/"},{"categories":["C++","python"],"content":"代理加速网站 主站若下载慢请去镜像站 ","date":"2020-06-22","objectID":"/about/ziyuan/:0:12","tags":["windows"],"title":"博客相关资源","uri":"/about/ziyuan/"},{"categories":["C++","python"],"content":"反代理加速访问Github 将下面链接替换官方链接https://github.com即可国内直连加速访问，仅供访问查看。 https://git.spiritlhl.workers.dev ","date":"2020-06-22","objectID":"/about/ziyuan/:0:13","tags":["windows"],"title":"博客相关资源","uri":"/about/ziyuan/"},{"categories":["C++","python"],"content":"新冠疫情数据分析文件 https://github.com/spiritLHL/Cov2019Analysis 备用仓库 ","date":"2020-06-22","objectID":"/about/ziyuan/:0:14","tags":["windows"],"title":"博客相关资源","uri":"/about/ziyuan/"},{"categories":["C++","python"],"content":"常微分偏微分建模练习 python数据处理的所有文件 matlab建模的所有文件 ","date":"2020-06-22","objectID":"/about/ziyuan/:0:15","tags":["windows"],"title":"博客相关资源","uri":"/about/ziyuan/"},{"categories":["C++","python"],"content":"长三角数学建模B题 个人自己写的代码文件包，很乱没整理，1Stopt安装包在上面 matlab建模的所有文件 ","date":"2020-06-22","objectID":"/about/ziyuan/:0:16","tags":["windows"],"title":"博客相关资源","uri":"/about/ziyuan/"},{"categories":["数据库"],"content":"分组函数 功能：作统计使用，又称为聚合函数或统计函数或组函数 ","date":"2020-06-15","objectID":"/20200615/:0:0","tags":["MySQL"],"title":"MySQL数据库04(常见函数)","uri":"/20200615/"},{"categories":["数据库"],"content":"分类： sum 求和 avg 平均值 max 最大值 min 最小值 count 计算个数 ","date":"2020-06-15","objectID":"/20200615/:1:0","tags":["MySQL"],"title":"MySQL数据库04(常见函数)","uri":"/20200615/"},{"categories":["数据库"],"content":"特点： 1.sum，avg一般用于处理数值型，max，min，count可以处理任何类型 2.以上分组函数都忽略null值 3.可以和distinct搭配实现去重运算 4、count函数的单独介绍 一般使用count(*)用作统计行数 5、和分组函数一同查询的字段要求是group by后的字段 1.简单使用 select SUM(salary) from employees; select AVG(salary) from employees; select MIN(salary) from employees; select MAX(salary) from employees; select count(salary) from employees; (单行执行，一行一行的输出)\rselect SUM(salary) 和,AVG(salary) 平均,MAX(salary) 最高,MIN(salary) 最低,count(salary) 个数 from employees; (单行输出全部结果)\r2.参数支持哪些类型 select SUM(last_name) ,AVG(last_name) from employees;\r(即便不报错，也不支持字符串类型) select SUM(hiredate) ,AVG(hiredate) from employees; (不支持日期类型) select MAX(hiredate) ,MIN(hiredate) from employees; (数值型可用，日期型可用) select MAX(last_name) ,MIN(last_name) from employees; (可排序的都可用) select count(任意类型) from employees; (计算非空值的个数)\r3.和distinc搭配 select SUM(distinct salary) from employees; (去重后再求和)\rselect SUM(*) from employees; (数行数)\rselect SUM(1) from employees; (数开头为1的行)\r效率： MYISAM存储引擎下，count(*)的效率最高 INNODB存储引擎下，COUNT (*)和COUNT (1)的效牢差不多，比COUNT(字段)要高一些 6.和分组函数一同查询的字段有限制 SELECT AVG (salary) , employee_id FRCM employees; (后面的那个employee_id无法查询但不报错) ","date":"2020-06-15","objectID":"/20200615/:2:0","tags":["MySQL"],"title":"MySQL数据库04(常见函数)","uri":"/20200615/"},{"categories":["python","数学建模"],"content":"前言 ","date":"2020-06-02","objectID":"/20200526/:1:0","tags":["python","数学建模"],"title":"Pandas (上)","uri":"/20200526/"},{"categories":["python","数学建模"],"content":"本篇鸣谢 马川-燕大 的增删整理， 王圣元 ——原创文章，与原文不同之处包含我的学习记录。 匹配Jupyter Notebook的ipynb文档链接下载地址如下 源文档及相关文件 ","date":"2020-06-02","objectID":"/20200526/:2:0","tags":["python","数学建模"],"title":"Pandas (上)","uri":"/20200526/"},{"categories":["python","数学建模"],"content":"0 引言 Pandas 是 Python 为解决数据分析而创建的，详情看官网 https://pandas.pydata.org/。 在使用 pandas 之前，需要引进它，语法如下： import pandas 这样就可以用 pandas 里面所有的内置方法 (build-in methods) 了，比如创建一维的 Series 和二维的 DataFrame。 pandas.Series() pandas.DataFrame() 但是每次写 pandas 字数有点多，通常给 pandas 起个别名 pd，用以下语法，这样所有出现 pandas 的地方都可以用 pd 替代。 import pandas as pd#本篇使用的是0.25.1版本的pandas Pandas 里面的数据结构是「多维数据表」，学习它可以类比这 NumPy 里的「多维数组」。1/2 维的「多维数据表」分别叫做 Series (系列)和 DataFrame (数据帧)，与1/2 维的「多维数组」的类比关系如下。 由于「系列」、「数据帧」这些直译过来的中文名词听起来有些奇怪，在本帖还是直接用 Series和 DataFrame。 对比 NumPy (np) 和 Pandas (pd) 每个维度下的数据结构，不难看出 pd 多维数据表 = np 多维数组 + 描述 其中 Series = 1darray + index DataFrame = 2darray + index + columns 每个维度上的「索引」使得「多维数据表」比「多维数组」涵盖更多的信息，如下图，左边的 2d array 仅仅储存了一组数值 (具体代表什么意思却不知道)，而右边的 DataFrame 一看就知道这是平安银行和茅台从 2018-1-3 到 2019-1-3 的价格。 和学习 numpy 一样，学习 pandas 还是遵循的 Python 里「万物皆对象」的原则，既然把数据表当对象，就得按着数据表的创建、数据表的存载、数据表的获取、数据表的合并和连接、数据表的重塑和透视、和数据表的分组和整合来盘一盘 Pandas。 提纲： 由于篇幅原因，Pandas 系列分两贴，上贴讲前三节的内容，下帖讲后三节的内容。 ","date":"2020-06-02","objectID":"/20200526/:3:0","tags":["python","数学建模"],"title":"Pandas (上)","uri":"/20200526/"},{"categories":["python","数学建模"],"content":"1 数据表的创建 数据表有两大类型 Series: 一维数据，类似于 python 中的基本数据的 list 或 NumPy 中的 1D array。Pandas 里最基本的数据结构 DataFrame: 二维数据，类似于 R 中的 data.frame 或 Matlab 中的 Tables。DataFrame 是 Series 的容器 知识点 最常见的数据类型是二维的 DataFrame，其中 每行代表一个示例 (instance) 每列代表一个特征 (feature) DataFrame 可理解成是 Series 的容器，每一列都是一个 Series，或者 Series 是只有一列的 DataFrame。 接下来用代码来创建 pandas 数据表： 一维 Series 创建 Series 只需用下面一行代码 pd.Series( x, index=idx ) 其中 x 可以是 列表 (list) numpy 数组 (ndarray) 字典 (dict) 回顾Python编程基础中函数的定义，那么 x 是位置参数 index 是默认参数，默认值为 idx = range(0, len(x)) 用列表 s = pd.Series([27.2, 27.65, 27.70, 28]) s 0 27.20 1 27.65 2 27.70 3 28.00 dtype: float64 打印出来并不仅仅是列表里面的浮点数，每个浮点数前面还有一个索引，在本例中是 0, 1, 2, 3。 因此在创建 Series 时，如果不显性设定 index，那么 Python 给定一个默认从 0 到 N-1 的值，其中 N 是 x 的长度。 Series s 也是一个对象，用 dir(s) 可看出关于 Series 所有的属性和内置函数，其中最重要的是 用 s.values 打印 s 中的元素 用 s.index 打印 s 中的元素对应的索引 s.values array([27.2 , 27.65, 27.7 , 28. ]) s.index RangeIndex(start=0, stop=4, step=1) 不难发现，以上创建的 Series 和 numpy 数组比多了「索引」，但这种 0,1,2,3 的索引是在没有什么描述意义。实际上定义的 s 是海底捞在 2019 年 4 月 1 日到 2019 年 4 月 4 日的股价，那么用日期来当索引是不是更好些？ dates = pd.date_range('20190401',periods=4) s2 = pd.Series( [27.2, 27.65, 27.70, 28], index=dates ) s2 2019-04-01 27.20 2019-04-02 27.65 2019-04-03 27.70 2019-04-04 28.00 Freq: D, dtype: float64 pandas.date_range(start=None, end=None, periods=None, freq=‘D’, tz=None, normalize=False, name=None, closed=None, **kwargs) 该函数主要用于生成一个固定频率的时间索引，在调用构造方法时，必须指定start、end、periods中的两个参数值，否则报错。 主要参数说明： periods：固定时期，取值为整数或None freq：日期偏移量，取值为string或DateOffset，默认为’D’ normalize：若参数为True表示将start、end参数值正则化到午夜时间戳 name：生成时间索引对象的名称，取值为string或None closed：可以理解成在closed=None情况下返回的结果中，若closed=‘left’表示在返回的结果基础上，再取左开右闭的结果，若closed=‘right’表示在返回的结果基础上，再取做闭右开的结果 显然，s2 比 s 包含的信息更多，这是 s2 的索引是一组日期对象，数据类型是 datetime64，频率是 D (天)。 s2.index DatetimeIndex(['2019-04-01', '2019-04-02', '2019-04-03', '2019-04-04'], dtype='datetime64[ns]', freq='D') 甚至还可以给 s2 命名，就叫海底捞股价如何？ s2.name = '海底捞股价' s2 2019-04-01 27.20 2019-04-02 27.65 2019-04-03 27.70 2019-04-04 28.00 Freq: D, Name: 海底捞股价, dtype: float64 用 numpy 数组 除了用列表，还可以用 numpy 数组来生成 Series。在下例中，加入缺失值 np.nan，并分析一下 Series 中另外 5 个属性或内置函数的用法： len: s 里的元素个数 shape: s 的形状 (用元组表示) count: s 里不含 nan 的元素个数 unique: 返回 s 里不重复的元素 value_counts: 统计 s 里非 nan 元素的出现次数 对照上面函数的用法，下面的输出一看就懂了吧。 空值的产生只有np.nan() 总结一下： np.nan不是一个“空”对象，用 i is None判断是False； 对某个值是否为空值进行判断，只能用np.isnan(i)函数，万万不可用 i == np.nan()来做，否则你会死的很惨的，因为空值并不能用判断相等的“==”正确识别（上例前两条）； np.nan非空对象，其类型为基本数据类型float（是不是很神奇，我也不知道为什么要这样设计） import numpy as np s = pd.Series( np.array([27.2, 27.65, 27.70, 28, 28, np.nan]) ) print( 'The length is', len(s) ) print( 'The shape is', s.shape ) print( 'The count is', s.count() ) The length is 6 The shape is (6,) The count is 5 s.unique() array([27.2 , 27.65, 27.7 , 28. , nan]) s.value_counts() 28.00 2 27.70 1 27.65 1 27.20 1 dtype: int64 用字典 创建 Series 还可以用字典。字典的「键值对」的「键」自动变成了 Series 的索引 (index)，而「值」自动变成了Series 的值 (values)。代码如下 (下列用 name 参数来对 s3 命名) data_dict = { 'BABA': 187.07, 'PDD': 21.83, 'JD': 30.79, 'BIDU': 184.77 } s3 = pd.Series(data_dict, name='中概股') s3.index.name = '股票代号' s3 股票代号 BABA 187.07 PDD 21.83 JD 30.79 BIDU 184.77 Name: 中概股, dtype: float64 给 s3 起名中概股是因为阿里巴巴 (BABA)、拼多多 (PDD)、京东 (JD) 和百度 (BIDU) 都是中国公司但在美国上市的。此外还可以给 index 命名为 ‘股票代号’。 现在假设这里的股票代号为 stock = ['FB', 'BABA', 'PDD', 'JD'] s4 = pd.Series( s3, index=stock ) s4 FB NaN BABA 187.07 PDD 21.83 JD 30.79 Name: 中概股, dtype: float64 代号里多加了脸书 (FB)，而 sdata 字典中没有 FB 这个键，因此生成的 s4 在 FB 索引下对应的值为 NaN。再者，代号里没有百度 (BIDU)，因此 s4 里面没有 BIDU 对应的值 (即便 sdata 里面有)。 当两个 Series 进行某种操作时，比如相加，Python 会自动对齐不同 Series 的 index，如下面代码所示： s3 + s4 BABA 374.14 BIDU NaN FB NaN JD 61.58 PDD 43.66 Name: 中概股, dtype: float64 Series 是 Pandas 里面最基本的数据结构，但是对应每个索引只有一个元素 (比如一个日期对应一个股价)，因此 Series 处理不了每个索引对应多个元素 (比如一个日期对应一个开盘价、收盘价、交易量等等)。而 DataFrame 可以解决这个问题。 二维 DataFrame 创建 DataFrame 只需用下面一行代码 pd.DataFrame( x, index=idx, columns=col ) 其中 x 可以是 二维列表 (list) 二维 numpy 数组 (ndarray) 字典 (dict)，其值是一维列表、numpy 数组或 Series 另外一个 DataFrame 回顾Python编程基础中函数的定义，那么 x 是位置参数 index 是默认参数，默认值为 idx = range(0, x.shape[0]),行索引 columns 是默认参数，","date":"2020-06-02","objectID":"/20200526/:4:0","tags":["python","数学建模"],"title":"Pandas (上)","uri":"/20200526/"},{"categories":["python","数学建模"],"content":"2 数据表的存载 本节讲数据表的「保存」和「加载」，在 NumPy 一贴已经提到过，数据的存载没什么技术含量 保存只是为了下次再用处理好的 DataFrame 加载可以不用重新再定义 DataFrame DataFrame 可以被保存为 Excel, csv, SQL 和 HDF5 格式，其语句一看就懂，用 to_数据格式，具体如下： to_excel() to_csv() to_sql() to_hdf() 如果要加载某种格式的数据到 DataFrame 里，用 read_数据格式，具体如下： read_excel() read_csv() read_sql() read_hdf() 这里只用 excel 和 csv 格式举例。 Excel 格式 用 pd.to_excel 函数将 DataFrame 保存为 .xlsx 格式，并保存到 ‘Sheet1’ 中，具体写法如下： pd.to_excel( ‘文件名’，‘表名’ ) df = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6]])) df.to_excel('pd_excel.xlsx', sheet_name='Sheet2')#sheet_name :字符串,默认“Sheet1”，将包含DataFrame的表的名称。 df 0 1 2 0 1 2 3 1 4 5 6 用 pd.read_excel( ‘文件名’，‘表名’ ) 即可加载该文件并存成 DataFrame 形式 df1 = pd.read_excel('pd_excel.xlsx', sheet_name='Sheet2') df1 Unnamed: 0 0 1 2 0 0 1 2 3 1 1 4 5 6 csv 格式 用 pd.to_csv 函数将 DataFrame 保存为 .csv 格式，注意如果 index 没有特意设定，最后不要把 index 值存到 csv 文件中。具体写法如下： pd.to_csv( ‘文件名’，index=False ) data = {'Code': ['BABA', '00700.HK', 'AAPL', '600519.SH'], 'Name': ['阿里巴巴', '腾讯', '苹果', '茅台'], 'Market': ['US', 'HK', 'US', 'SH'], 'Price': [185.35, 380.2, 197, 900.2], 'Currency': ['USD', 'HKD', 'USD', 'CNY']} df = pd.DataFrame(data) df.to_csv('pd_csv.csv', index=False) 用 pd.read_csv( ‘文件名’ ) 即可加载该文件并存成 DataFrame 形式 df2 = pd.read_csv('pd_csv.csv') df2 Code Name Market Price Currency 0 BABA 阿里巴巴 US 185.35 USD 1 00700.HK 腾讯 HK 380.20 HKD 2 AAPL 苹果 US 197.00 USD 3 600519.SH 茅台 SH 900.20 CNY 如果一开始储存 df 的时候用 index=True，会发现加载完后的 df2 是以下的样子。 df2 里面第一栏是 df 的 index，由于没有具体的 columns 名称，系统给它一个 “Unamed: 0”。因此在存储 df 的时候，如果 df.index 没有特意设定，记住要在 to_csv() 中把 index 设置为 False。 ","date":"2020-06-02","objectID":"/20200526/:5:0","tags":["python","数学建模"],"title":"Pandas (上)","uri":"/20200526/"},{"categories":["python","数学建模"],"content":"3 数据表的索引和切片 由于索引/切片 Series 跟 numpy 数组很类似，因此本节只专注于对 DataFrame 做索引和切片。本节以下面 df 为例做展示。 symbol = ['BABA', 'JD', 'AAPL', 'MS', 'GS', 'WMT'] data = {'行业': ['电商', '电商', '科技', '金融', '金融', '零售'], '价格': [176.92, 25.95, 172.97, 41.79, 196.00, 99.55], '交易量': [16175610, 27113291, 18913154, 10132145, 2626634, 8086946], '雇员': [101550, 175336, 100000, 60348, 36600, 2200000]} df = pd.DataFrame( data, index=symbol ) df.name='美股' df.index.name = '代号' df 行业 价格 交易量 雇员 代号 BABA 电商 176.92 16175610 101550 JD 电商 25.95 27113291 175336 AAPL 科技 172.97 18913154 100000 MS 金融 41.79 10132145 60348 GS 金融 196.00 2626634 36600 WMT 零售 99.55 8086946 2200000 用不同颜色标注了 df 的 index, columns 和 values，可视图如下： DataFrame 的索引或切片可以基于标签 (label-based) ，也可以基于位置 (position-based)，不像 numpy 数组的索引或切片只基于位置。 DataFrame 的索引或切片有四大类： 索引单元素： 基于标签的 at 基于位置的 iat 切片 columns： 用 . 来切片单列 用 [] 来切片单列或多列 基于标签的 loc 基于位置的 iloc 切片 index： 用 [] 来切片单行或多行 基于标签的 loc 基于位置的 iloc 切片 index 和 columns： 基于标签的 loc 基于位置的 iloc 总体规律，基于标签就用 at 和 loc，基于位置就用 iat 和 iloc。下面来一类类分析： ","date":"2020-06-02","objectID":"/20200526/:6:0","tags":["python","数学建模"],"title":"Pandas (上)","uri":"/20200526/"},{"categories":["python","数学建模"],"content":"3.1 索引单元素 两种方法来索引单元素，情况 1 基于标签 at，情况 2 基于位置 iat。 情况 1 - df.at[‘idx_i’, ‘attr_j’] 情况 2 - df.iat[i, j] Python 里的中括号 [] 会代表很多意思，比如单元素索引，多元素切片，布尔索引等等，因此让 Python 猜你用的 [] 意图会很低效。如果想索引单元素，明明白白的用 at 和 iat 效率最高。 情况 1 df.at['AAPL','价格'] 172.97 用 at 获取「行标签」为 ‘AAPL’ 和「列标签」为 ‘价格’ 对应的元素。 情况 2 df.iat[2,1] 172.97 用 iat 获取第 3 行第 2 列对应的元素。 索引单元素的总结图： ","date":"2020-06-02","objectID":"/20200526/:6:1","tags":["python","数学建模"],"title":"Pandas (上)","uri":"/20200526/"},{"categories":["python","数学建模"],"content":"3.2 切片 columns 切片单个 columns 切片单个 columns 会返回一个 Series，有以下四种情况。情况 1 用点 .；情况 2 用中括号 []；情况 3 基于标签 loc，情况 4 基于位置 iloc。 情况 1 - df.attr_i 情况 2 - df[‘attr_i’] 情况 3 - df.loc[:, ‘attr_i’] 情况 4 - df.iloc[:, i] 情况 1 记住就可以了，没什么可说的。 情况 2 非常像二维 numpy 数组 arr 的切片，用 arr[i] 就能获取 arr 在「轴 0」上的第 i 个元素 (一个 1darray)，同理 df[‘attr_i’] 也能获取 df 的第 i 个 Series。 情况 3 和 4 的 loc 和 iloc 可类比于上面的 at 和 iat。带 i 的基于位置 (位置用整数表示，i 也泛指整数)，不带 i 的基于标签。里面的冒号 : 代表所有的 index (和 numpy 数组里的冒号意思相同)。 个人建议，如果追求简洁和方便，用 . 和 []；如果追求一致和清晰，用 loc 和 iloc。 情况 1 df.价格 代号 BABA 176.92 JD 25.95 AAPL 172.97 MS 41.79 GS 196.00 WMT 99.55 Name: 价格, dtype: float64 用 . 获取「价格」那一栏下的 Series。 情况 2 df['价格'] 代号 BABA 176.92 JD 25.95 AAPL 172.97 MS 41.79 GS 196.00 WMT 99.55 Name: 价格, dtype: float64 用 [] 获取「价格」属性下的 Series。 情况 3 df.loc[:, '交易量'] 代号 BABA 16175610 JD 27113291 AAPL 18913154 MS 10132145 GS 2626634 WMT 8086946 Name: 交易量, dtype: int64 用 loc 获取「交易量」属性下的 Series。 情况 4 df.iloc[:, 0] 代号 BABA 电商 JD 电商 AAPL 科技 MS 金融 GS 金融 WMT 零售 Name: 行业, dtype: object 用 iloc 获取第 1 列下的 Series。 切片单个 columns 的总结图： 切片多个 columns 切片多个 columns 会返回一个 sub-DataFrame (原 DataFrame 的子集)，有以下三种情况。情况 1 用中括号 []；情况 2 基于标签 loc，情况 3 基于位置 iloc。 情况 1 - df[[‘attr_i’, ‘attr_j’]] 情况 2 - df.loc[:, ‘attr_i’:‘attr_j’] 情况 3 - df.iloc[:, i:j] 和切片单个 columns 相比： 情况 1 用一个列表来储存一组属性 ‘attr_i’, ‘attr_j’，然后在放进中括号 [] 里获取它们 情况 2 用 ‘attr_i’:‘attr_j’ 来获取从属性 i 到属性 j 的 sub-DataFrame 情况 3 用 i:j 来获取从列 i+1 到列 j 的 sub-DataFrame 个人建议，如果追求简洁和方便，用 []；如果追求一致和清晰，用 loc 和 iloc。 情况 1 df[ ['雇员', '价格'] ]#两个中括号 雇员 价格 代号 BABA 101550 176.92 JD 175336 25.95 AAPL 100000 172.97 MS 60348 41.79 GS 36600 196.00 WMT 2200000 99.55 用 [] 获取「雇员」和「价格」两个属性下的 sub-DataFrame。 情况 2 df.loc[:, '行业':'交易量'] 行业 价格 交易量 代号 BABA 电商 176.92 16175610 JD 电商 25.95 27113291 AAPL 科技 172.97 18913154 MS 金融 41.79 10132145 GS 金融 196.00 2626634 WMT 零售 99.55 8086946 用 loc 获取从属性 ‘行业’ 到 ‘交易量‘ 的 sub-DataFrame。 情况 3 df.iloc[:, 0:2] 行业 价格 代号 BABA 电商 176.92 JD 电商 25.95 AAPL 科技 172.97 MS 金融 41.79 GS 金融 196.00 WMT 零售 99.55 用 iloc 获取第 1 和 2 列下的 sub-DataFrame。 切片多个 columns 的总结图： ","date":"2020-06-02","objectID":"/20200526/:6:2","tags":["python","数学建模"],"title":"Pandas (上)","uri":"/20200526/"},{"categories":["python","数学建模"],"content":"3.3 切片 index 切片单个 index 切片单个 index 有时会返回一个 Series，有以下两种情况。情况 1 基于标签 loc，情况 2 基于位置 iloc。 情况 1 - df.loc[‘idx_i’, :] 情况 2 - df.iloc[i, :] 切片单个 index 有时会返回一个只有一行的 DataFrame，有以下两种情况。情况 3 用中括号 [] 加「位置」，情况 4 用中括号 [] 加「标签」。 情况 3 - df[i:i+1] 情况 4 - df[‘idx_i’:‘idx_i’] 情况 1 和 2 的 loc 和 iloc 可类比于上面的 at 和 iat。带 i 的基于位置 (位置用整数表示，i 也泛指整数)，不带 i 的基于标签。里面的冒号 : 代表所有的 columns (和 numpy 数组里的冒号意思相同)。 情况 3 用中括号 [] 加「位置」，位置 i:i+1 有前闭后开的性质。如果要获取第 i+1 行，需要用 i:i+1。 情况 4 用中括号 [] 加「标签」，标签没有前闭后开的性质。如果要获取标签 i，只需要用 ‘idx_i’:‘idx_i’。为什么不能只用 ‘idx_i’ 呢？原因是 Python 会把 df[‘idx_i’] 当成切片 columns，然后发现属性中没有 ‘idx_i’ 这一个字符，会报错的。 个人建议，只用 loc 和 iloc。情况 3 太麻烦，获取一行还要用 i:i+1。情况 4 的 df[‘idx_i’] 很容易和切片 columns 中的语句 df[‘attr_j’] 混淆。 情况 1 df.loc[ 'GS', : ] 行业 金融 价格 196 交易量 2626634 雇员 36600 Name: GS, dtype: object 用 loc 获取标签为 ‘GS‘ 的 Series。(GS = Goldman Sachs = 高盛) 情况 2 df.iloc[ 3, : ] 行业 金融 价格 41.79 交易量 10132145 雇员 60348 Name: MS, dtype: object 用 iloc 获取第 4 行下的 Series。(MS = Morgan Stanley = 摩根斯坦利) 情况 3 df[1:2] 行业 价格 交易量 雇员 代号 JD 电商 25.95 27113291 175336 用 [1:2] 获取第 2 行的 sub-DataFrame (只有一行)。 情况 4 df['JD':'JD']#一个头一个尾 行业 价格 交易量 雇员 代号 JD 电商 25.95 27113291 175336 df['JD':'MS'] 行业 价格 交易量 雇员 代号 JD 电商 25.95 27113291 175336 AAPL 科技 172.97 18913154 100000 MS 金融 41.79 10132145 60348 用 [‘JD’:‘JD’] 获取标签为 ‘JD’ 的 sub-DataFrame (只有一行)。 切片单个 index 的总结图： 切片多个 index 切片多个 index 会返回一个 sub-DataFrame，有以下四种情况。情况 1 用中括号 [] 加「位置」，情况 2 用中括号 [] 加「标签」，情况 3 基于标签 loc，情况 4 基于位置 iloc。 情况 1 - df[i:j] 情况 2 - df[‘idx_i’:‘idx_j’] 情况 3 - df.loc[‘idx_i’:‘idx_j’, :] 情况 4 - df.iloc[i:j, :] 和切片单个 index 相比： 情况 1 用 [i:j] 来获取行 i+1 到行 j 的 sub-DataFrame 情况 2 用 [‘idx_i’:‘idx_j’] 来获取标签 i 到标签 j 的 sub-DataFrame 情况 3 用 loc 加 ‘idx_i’:‘idx_j’ 来获取从标签 i 到标签 j 的 sub-DataFrame 情况 4 用 iloc 加 i:j 来获取从行 i+1 到行 j 的 sub-DataFrame 个人建议，只用 loc 和 iloc。情况 1 和 2 的 df[] 很容易混淆中括号 [] 里的到底是切片 index 还是 columns。 情况 1 df[ 1:4 ] 行业 价格 交易量 雇员 代号 JD 电商 25.95 27113291 175336 AAPL 科技 172.97 18913154 100000 MS 金融 41.79 10132145 60348 用 [1:4] 获取第 2 到 4 行的 sub-DataFrame。 情况 2 df[ 'GS':'WMT' ] 行业 价格 交易量 雇员 代号 GS 金融 196.00 2626634 36600 WMT 零售 99.55 8086946 2200000 用 [‘GS’:‘WMT’] 获取标签从’GS’ 到 ‘WMT’ 的 sub-DataFrame。(WMT = Walmart = 沃尔玛) 情况 3 df.loc[ 'MS':'GS', : ] 行业 价格 交易量 雇员 代号 MS 金融 41.79 10132145 60348 GS 金融 196.00 2626634 36600 用 loc 获取标签从 ‘MS‘ 到 ‘GS’ 的 sub-DataFrame。注意 ‘MS’:’GS’ 要按着 index 里面元素的顺序，要不然会返回一个空的 DataFrame，比如： df.loc[ 'MS':'JD', : ] 行业 价格 交易量 雇员 代号 情况 4 df.iloc[ 1:3, : ] 行业 价格 交易量 雇员 代号 JD 电商 25.95 27113291 175336 AAPL 科技 172.97 18913154 100000 用 iloc 获取第 2 到 3 行的 sub-DataFrame。 切片多个 index 的总结图： ","date":"2020-06-02","objectID":"/20200526/:6:3","tags":["python","数学建模"],"title":"Pandas (上)","uri":"/20200526/"},{"categories":["python","数学建模"],"content":"3.4 切片 index 和 columns 切片多个 index 和 columns 会返回一个 sub-DataFrame，有以下两种情况。情况 1 基于标签 loc，情况 2 基于位置 iloc。 情况 1 - df.loc[‘idx_i’:‘idx_j’, ‘attr_k’:‘attr_l’] 情况 2 - df.iloc[i:j, k:l] 清清楚楚，明明白白，用 loc 和 iloc。 情况 1 df.loc[ 'GS':'WMT', '价格': ] 价格 交易量 雇员 代号 GS 196.00 2626634 36600 WMT 99.55 8086946 2200000 用 loc 获取行标签从 ‘GS‘ 到 ‘WMT’，列标签从’价格’到最后的 sub-DataFrame。 情况 2 df.iloc[ :2, 1:3 ] 价格 交易量 代号 BABA 176.92 16175610 JD 25.95 27113291 用 iloc 获取第 1 到 2 行，第 1 到 2 列的 sub-DataFrame。 切片 index 和 columns 的总结图： ","date":"2020-06-02","objectID":"/20200526/:6:4","tags":["python","数学建模"],"title":"Pandas (上)","uri":"/20200526/"},{"categories":["python","数学建模"],"content":"3.5 高级索引 高级索引 (advanced indexing) 可以用布尔索引 (boolean indexing) 和调用函数 (callable function) 来实现，两种方法都返回一组“正确”的索引，而且可以和 loc , iloc , [] 一起套用，具体形式有以下常见几种： df.loc[布尔索引, :] df.iloc[布尔索引, :] df[布尔索引] df.loc[调用函数, :] df.iloc[调用函数, :] df[调用函数] 还有以下罕见几种： df.loc[:, 布尔索引] df.iloc[:, 布尔索引] df.loc[:, 调用函数] df.iloc[:, 调用函数] 读者可以想一想为什么第一组形式「常见」而第二组形式「罕见」呢？(Hint: 看看两组里冒号 : 在不同位置，再想想 DataFrame 每一行和每一列中数据的特点) 布尔索引 在〖数组计算之 NumPy (上)〗提过，布尔索引就是用一个由布尔类型值组成的数组来选择元素的方法。 当要过滤掉雇员小于 100,000 人的公司，可以用 loc 加上布尔索引。 print( df.雇员 \u003e= 100000 ) df.loc[ df.雇员 \u003e= 100000, : ] 代号 BABA True JD True AAPL True MS False GS False WMT True Name: 雇员, dtype: bool 行业 价格 交易量 雇员 代号 BABA 电商 176.92 16175610 101550 JD 电商 25.95 27113291 175336 AAPL 科技 172.97 18913154 100000 WMT 零售 99.55 8086946 2200000 一种更简便的表达形式是用 df[]，但是个人不喜欢 []，总觉得会引起「到底在切片 index 还是 columns」的歧义。 df[ df.雇员 \u003e= 100000 ] 行业 价格 交易量 雇员 代号 BABA 电商 176.92 16175610 101550 JD 电商 25.95 27113291 175336 AAPL 科技 172.97 18913154 100000 WMT 零售 99.55 8086946 2200000 现在来看一个「罕见」例子，假如想找到所有值为整数型的 columns print( df.dtypes == 'int64' ) df.loc[ :, df.dtypes == 'int64' ] 行业 False 价格 False 交易量 True 雇员 True dtype: bool 交易量 雇员 代号 BABA 16175610 101550 JD 27113291 175336 AAPL 18913154 100000 MS 10132145 60348 GS 2626634 36600 WMT 8086946 2200000 调用函数 调用函数是只能有一个参数 (DataFrame, Series) 并返回一组索引的函数。因为调用函数定义在 loc , iloc , [] 里面，因此它就像在〖Python编程基础〗提过的匿名函数。 当要找出交易量大于平均交易量的所有公司，可以用 loc 加上匿名函数 (这里 x 代表 df)。 df.loc[ lambda x: x.交易量 \u003e x.交易量.mean() , : ] 行业 价格 交易量 雇员 代号 BABA 电商 176.92 16175610 101550 JD 电商 25.95 27113291 175336 AAPL 科技 172.97 18913154 100000 在上面基础上再加一个条件 – 价格要在 100 之上 (这里 x 还是代表 df) df.loc[ lambda x: (x.交易量 \u003e x.交易量.mean()) \u0026 (x.价格 \u003e 100), : ] 行业 价格 交易量 雇员 代号 BABA 电商 176.92 16175610 101550 AAPL 科技 172.97 18913154 100000 最后来看看价格大于 100 的股票 (注意这里 x 代表 df.价格) df.价格.loc[ lambda x: x \u003e 100 ] 代号 BABA 176.92 AAPL 172.97 GS 196.00 Name: 价格, dtype: float64 ","date":"2020-06-02","objectID":"/20200526/:6:5","tags":["python","数学建模"],"title":"Pandas (上)","uri":"/20200526/"},{"categories":["python","数学建模"],"content":"3.6 多层索引 层次化索引（hierarchical indexing）也叫多层索引，是pandas的一项重要功能，它使你能在一个轴上拥有多个（两个以上）索引级别。多层索引可以将「低维数据」升维到「高维数据」。抽象点说，它使你能以低维度形式处理高维度数据。 多层索引 Series 首先定义一个 Series，注意它的 index 是一个二维列表，列表第一行 dates 作为第一层索引，第二行 codes 作为第二层索引。 price = [190,32,196,192,200,189,31,30,199] dates = ['2019-04-01']*3 + ['2019-04-02']*2+['2019-04-03']*2 + ['2019-04-04']*2 codes = ['BABA','JD','GS','BABA','GS','BABA','JD','JD','GS'] data = pd.Series( price, index=[ dates, codes ]) data 2019-04-01 BABA 190 JD 32 GS 196 2019-04-02 BABA 192 GS 200 2019-04-03 BABA 189 JD 31 2019-04-04 JD 30 GS 199 dtype: int64 这个 Series 存储了四天里若干股票的价格，2019-04-01 储存了阿里巴巴、京东和高盛的股价，2019-04-04 只储存了京东和高盛的股价。试想，如果不用多层索引的 Series，则需要用一个 DataFrame 来存储在这样的数据，把 index 设置成 dates，把 colums 设置成 codes。 来看看 Series 的多层 index 是如何表示的 data.index MultiIndex([('2019-04-01', 'BABA'), ('2019-04-01', 'JD'), ('2019-04-01', 'GS'), ('2019-04-02', 'BABA'), ('2019-04-02', 'GS'), ('2019-04-03', 'BABA'), ('2019-04-03', 'JD'), ('2019-04-04', 'JD'), ('2019-04-04', 'GS')], ) 输出是一个 MultiIndex 的对象，里面有 levels 和 labels 二类信息。 知识点 索引既然分多层，那么肯定分「内层」和「外层」把，levels 就是描述层的先后的。levels 是一个二维列表，每一行只存储着「唯一」的索引信息： dates 是第一层索引，有 4 个「唯一」元素 codes 是第二层索引，有 3 个「唯一」元素 但是 data 里面有九行啊，4 个 dates 和 3 个 codes 怎么能描述这九行信息呢？这就需要 labels 了。labels 也是一个二维列表： 第一行储存 dates 每个元素在 data 里的位置索引 第二行储存 codes 每个元素在 data 里的位置索引 用 [] 加第一层索引可以获取第一层信息。 data['2019-04-02'] BABA 192 GS 200 dtype: int64 同理，用 loc 加第一层索引也可以切片获取第一层信息。 data.loc['2019-04-02':'2019-04-04'] 2019-04-02 BABA 192 GS 200 2019-04-03 BABA 189 JD 31 2019-04-04 JD 30 GS 199 dtype: int64 此外，切片还可以在不同层上进行，下面 loc 中的冒号 : 表示第一层所有元素，‘GS’ 表示第二层标签为 ‘GS’。 data.loc[ :, 'GS' ]#[第一层索引，第二层索引] 2019-04-01 196 2019-04-02 200 2019-04-04 199 dtype: int64 多层索引 DataFrame Series 只有 index，上面刚介绍完多层 index，DataFrame 有 index 和 columns，它们可以设置成多层吗？下面代码用 MultiIndex 函数创建「多层 index 」midx 和「多层columns」mcol。 midx 和 mcol 都是对象，各种都有 levels, labels, names 等性质。 data = [ ['电商', 101550, 176.92, 16175610], ['电商', 175336, 25.95, 27113291], ['金融', 60348, 41.79, 10132145], ['金融', 36600, 196.00, 2626634] ] midx = pd.MultiIndex( levels=[['中国','美国'], ['BABA', 'JD', 'GS', 'MS']], codes=[[0,0,1,1],[0,1,2,3]], names=['地区', '代号']) #codes是levals的排序 mcol = pd.MultiIndex( levels=[['公司数据','交易数据'], ['行业','雇员','价格','交易量']], codes=[[0,0,1,1],[0,1,2,3]], names=['概括','细分']) df = pd.DataFrame(data, index=midx, columns=mcol) df 概括 公司数据 交易数据 细分 行业 雇员 价格 交易量 地区 代号 中国 BABA 电商 101550 176.92 16175610 JD 电商 175336 25.95 27113291 美国 GS 金融 60348 41.79 10132145 MS 金融 36600 196.00 2626634 这个 DataFrame 的 index 和 columns 都有两层，严格来说是个四维数据。下面看看如何进行「多层索引」的操作吧。 在第一层 columns 的 ‘公司数据’ 和第二层 columns 的 ‘行业’ 做索引，得到一个含两层 index 的 Series。 # 1st level-1 column, 2nd level-2 column df['公司数据','行业'] 地区 代号 中国 BABA 电商 JD 电商 美国 GS 金融 MS 金融 Name: (公司数据, 行业), dtype: object 在第一层 index 的 ‘中国’ 做切片，得到一个含两层 columns 的 DataFrame。 df.loc['中国'].loc['BABA':'JD'] 概括 公司数据 交易数据 细分 行业 雇员 价格 交易量 代号 BABA 电商 101550 176.92 16175610 JD 电商 175336 25.95 27113291 调位 level 如果不喜欢 index level 的顺序，可用 swaplevel 将它们调位。 df.swaplevel('地区', '代号') 概括 公司数据 交易数据 细分 行业 雇员 价格 交易量 代号 地区 BABA 中国 电商 101550 176.92 16175610 JD 中国 电商 175336 25.95 27113291 GS 美国 金融 60348 41.79 10132145 MS 美国 金融 36600 196.00 2626634 df 概括 公司数据 交易数据 细分 行业 雇员 价格 交易量 地区 代号 中国 BABA 电商 101550 176.92 16175610 JD 电商 175336 25.95 27113291 美国 GS 金融 60348 41.79 10132145 MS 金融 36600 196.00 2626634 如果不喜欢 columns level 的顺序，也可用 swaplevel 将它们调位。 df.columns = df.columns.swaplevel(0,1) df 细分 行业 雇员 价格 交易量 概括 公司数据 公司数据 交易数据 交易数据 地区 代号 中国 BABA 电商 101550 176.92 16175610 JD 电商 175336 25.95 27113291 美国 GS 金融 60348 41.79 10132145 MS 金融 36600 196.00 2626634 重设 index 有时候，一个 DataFrame 的一个或者多个 columns 适合做 index，这时可用 set_index 将它们设置为 index，如果要将 index 还原成 columns，那么用 reset_index 。 看下面这个例子。 data = {'地区': ['中国', '中国', '美国', '美国'], '代号': ['BABA', 'JD', 'MS', 'GS'], '行业': ['电商', '电商', '金融', '金融'], '价格': [176.92, 25.95, 41.79, 196.00], '交易量': [16175610, 27113291, 10132145, 2626634], '雇员': [101550, 175336, 60348, 36600] } df = pd.DataFrame( data ) df 地区 代号 行业 价格 交易量 雇员 0 中国 BABA 电商 176.92 16175610 1","date":"2020-06-02","objectID":"/20200526/:6:6","tags":["python","数学建模"],"title":"Pandas (上)","uri":"/20200526/"},{"categories":["python","数学建模"],"content":"4 总结 Pandas 里面的数据结构是多维数据表，细化为一维的 Series，二维的 DataFrame。 pd 多维数据表 = np 多维数组 + 描述 其中 Series = 1darray + index DataFrame = 2darray + index + columns pd 多维数据表和 np 多维数组之间的类比关系如下图所示。 【创建数据表】创建 Series, DataFrame 用下面语句 pd.Series(x, index=idx) pd.DataFrame(x, index=idx, columns=col) DataFrame 由多个 Series 组成，而 Series 非常类似于一维的 DataFrame，因此学 Pandas 把注意力放在 DataFrame 上即可。 【索引和切片数据表】在索引或切片 DataFrame，有很多种方法。最好记的而不易出错的是用基于位置的 at 和 loc，和基于标签的 iat 和 iloc，具体来说，索引用 at 和 iat，切片用 loc 和 iloc。带 i 的基于位置，不带 i 的基于标签。 用 MultiIndex 可以创建多层索引的对象，获取 DataFrame df 的信息可用 df.loc[1st].loc[2nd] df.loc[1st].iloc[2nd] df.iloc[1st].loc[2nd] df.iloc[1st].iloc[2nd] 要调换 level 可用 df.index.swaplevel(0,1) df.columns.swaplevel(0,1) 要设置和重设 index 可用 df.set_index( columns ) df.reset_index 下篇讨论 Pandas 系列的后三节，分别是 「数据表的合并和连接」 「数据表的重塑和透视」 「数据表的分组和整合」 Stay Tuned! ","date":"2020-06-02","objectID":"/20200526/:7:0","tags":["python","数学建模"],"title":"Pandas (上)","uri":"/20200526/"},{"categories":["数据库"],"content":"函数 概念:类似于java的方法，将-组逻辑语句封装在方法体中，对外暴露方法名 好处: 1、隐藏了实现细节 2、 提高代码的重用性 调用: select 函数名(实参列表) [ from 表] ; 特点: 1.叫什么(函数名) 2.干什么(函数功能) 分类: 1、单行函数 如concat、 length、 ifnull等 2、分组函数 功能:做统计使用，又称为统计函数、聚合函数、组函数 ","date":"2020-05-31","objectID":"/20200531/:0:0","tags":["MySQL"],"title":"MySQL数据库03(常见函数)","uri":"/20200531/"},{"categories":["数据库"],"content":"length获取参数值的字节个数 SELECT LENGTH('john') ; SELECT LENGTH(' 张三丰hahaha') ; SHOW VARIABLES LIKE '%char%'\r","date":"2020-05-31","objectID":"/20200531/:0:1","tags":["MySQL"],"title":"MySQL数据库03(常见函数)","uri":"/20200531/"},{"categories":["数据库"],"content":"concat拼接字符串 SELECT CONCAT (last_ name, '_ ' , first_ name) 姓名 FROM employees;\r","date":"2020-05-31","objectID":"/20200531/:0:2","tags":["MySQL"],"title":"MySQL数据库03(常见函数)","uri":"/20200531/"},{"categories":["数据库"],"content":"upper、lower SELECT UPPER('john') ; SELECT LOWER( 'joHn') ; 示例:将姓变大写，名变小写，然后拼接 SELECT CONCAT (UPPER(last_ name) , LOWER(first_ name) )姓名 FROM employees; ","date":"2020-05-31","objectID":"/20200531/:0:3","tags":["MySQL"],"title":"MySQL数据库03(常见函数)","uri":"/20200531/"},{"categories":["数据库"],"content":"substr、substring 注意:索引从1开始 #截取从指定索引处后面所有字符 SELECT SUBSTR('欢迎来到二叉树的博客',7)out_put; #截取从指定索引处指定字符长度的字符 SELECT SUBSTR('欢迎来到二叉树的博客',5,7) out_put; 案例:姓名中首字符大写，其他字符小写然后用_拼接，显示出来 SELECT CONCAT (UPPER (SUBSTR(last_ name,1,1)) ,'_ ' , LOWER (SUBSTR(last_ name,2)) ) out_put FROM employees ;\r","date":"2020-05-31","objectID":"/20200531/:0:4","tags":["MySQL"],"title":"MySQL数据库03(常见函数)","uri":"/20200531/"},{"categories":["数据库"],"content":"instr 返回子串第一次出现的索引，如果找不到返回0 SELECT INSTR('欢迎来到二叉树的博客', '二叉树') AS out_ put;\r","date":"2020-05-31","objectID":"/20200531/:0:5","tags":["MySQL"],"title":"MySQL数据库03(常见函数)","uri":"/20200531/"},{"categories":["数据库"],"content":"trim SELECT LENGTH (TRIM('二叉树')) AS out_put;\rSELECT TRIM('aa' FROM 'aaaaaaaa二aaaaaaaaaaa叉树aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa ')\rAS out_put;\r","date":"2020-05-31","objectID":"/20200531/:0:6","tags":["MySQL"],"title":"MySQL数据库03(常见函数)","uri":"/20200531/"},{"categories":["数据库"],"content":"lpad 用指定的字符实现左填充指定长度 SELECT LPAD('二叉树',2, 1*1) AS out_ put;\r","date":"2020-05-31","objectID":"/20200531/:0:7","tags":["MySQL"],"title":"MySQL数据库03(常见函数)","uri":"/20200531/"},{"categories":["数据库"],"content":"rpad 用指定的字符实现右填充指定长度 SELECT RPAD('二叉树',12, 'ab') AS out_ put;\r","date":"2020-05-31","objectID":"/20200531/:0:8","tags":["MySQL"],"title":"MySQL数据库03(常见函数)","uri":"/20200531/"},{"categories":["数据库"],"content":"replace 替换 SELECT REPLACE('欢迎你来到二叉树的博客', '你'，'大家') AS out_ put;\r数学函数 ","date":"2020-05-31","objectID":"/20200531/:0:9","tags":["MySQL"],"title":"MySQL数据库03(常见函数)","uri":"/20200531/"},{"categories":["数据库"],"content":"round 四舍五入 SELECT ROUND(-1.55) ; SELECT ROUND(1.567,2) ; ","date":"2020-05-31","objectID":"/20200531/:0:10","tags":["MySQL"],"title":"MySQL数据库03(常见函数)","uri":"/20200531/"},{"categories":["数据库"],"content":"ceil 向上取整,返回\u003e=该参数的最小整数 SELECT CEIL(-1.02) ;\r","date":"2020-05-31","objectID":"/20200531/:0:11","tags":["MySQL"],"title":"MySQL数据库03(常见函数)","uri":"/20200531/"},{"categories":["数据库"],"content":"floor 向下取整，返回\u003c=该参数的最大整数 SELECT FLOOR(-9.99) ;\r","date":"2020-05-31","objectID":"/20200531/:0:12","tags":["MySQL"],"title":"MySQL数据库03(常见函数)","uri":"/20200531/"},{"categories":["数据库"],"content":"truncate 截断 SELECT TRUNCATE (1.69999,1) ;\r","date":"2020-05-31","objectID":"/20200531/:0:13","tags":["MySQL"],"title":"MySQL数据库03(常见函数)","uri":"/20200531/"},{"categories":["数据库"],"content":"mod 取余 /* mod(a,b) ; a-a/b*b\rmod(-10,-3) :-10- (-10)/ (-3)* (-3) =-1\r*/ SELECT MOD(10,-3) ; SELECT 10号3; 日期函数 ","date":"2020-05-31","objectID":"/20200531/:0:14","tags":["MySQL"],"title":"MySQL数据库03(常见函数)","uri":"/20200531/"},{"categories":["数据库"],"content":"now 返回当前系统日期+时间 SELECT NOW() ; ","date":"2020-05-31","objectID":"/20200531/:0:15","tags":["MySQL"],"title":"MySQL数据库03(常见函数)","uri":"/20200531/"},{"categories":["数据库"],"content":"curdate 返回当前系统日期，不包含时间 SELECT CURDATE() ;\r","date":"2020-05-31","objectID":"/20200531/:0:16","tags":["MySQL"],"title":"MySQL数据库03(常见函数)","uri":"/20200531/"},{"categories":["数据库"],"content":"curtime 返回当前时间，不包含日期 SELECT CURTIME () ;\r","date":"2020-05-31","objectID":"/20200531/:0:17","tags":["MySQL"],"title":"MySQL数据库03(常见函数)","uri":"/20200531/"},{"categories":["数据库"],"content":"可以获取指定的部分年、月、日、小时、分钟、秒 SELECT YEAR (NOW())年; SELECT YEAR('1998-1-1') 年; SELECT YEAR (hiredate)年FROM employees; SELECT MONTH (NOW())月; SELECT MONTHNAME (NOW())月; ","date":"2020-05-31","objectID":"/20200531/:0:18","tags":["MySQL"],"title":"MySQL数据库03(常见函数)","uri":"/20200531/"},{"categories":["数据库"],"content":"补充 now:获取当前日期 str_to_date: 将日期格式的字符转换成指定格式的日期\r示例：STR_TO_DATE('9-13-1999','%m-%d-%Y')\r结果：1999-09-13\rdate_ format:将日期转换成字符 DATE_ FORMAT('2018/6/6','%Y年%m月 %d日)\r结果：2018年06月06日\r对照图： (https://pic./2020/06/02/71c8a64dc5fee.png) 流程控制函数 ","date":"2020-05-31","objectID":"/20200531/:0:19","tags":["MySQL"],"title":"MySQL数据库03(常见函数)","uri":"/20200531/"},{"categories":["数据库"],"content":"if函数: if else的效果 SELECT IF(10\u003c5, '大', '小'); SELECT last_ name, commission_ _pct, IF (commission_ pct Is NULL, '没奖金', '有奖金')备注 FROM employees; ","date":"2020-05-31","objectID":"/20200531/:0:20","tags":["MySQL"],"title":"MySQL数据库03(常见函数)","uri":"/20200531/"},{"categories":["数据库"],"content":"case when条件1 then 要显示的值1或语句1 when条件2 then 要显示的值2或语句2 else要显示的值n或语句n end 案例:查询员工的工资的情况 如果工资\u003e20000,显示A级别 如果工资\u003e15000,显示B级别 如果工资\u003e10000，显示c级别 SELECT salary, CASE WHEN salary\u003e20000 THEN 'A' WHEN salary\u003e15000 THEN 'B' WHEN salary\u003e10000 THEN 'C' ELSE 'D' END AS 工资级别 FROM employees ; ","date":"2020-05-31","objectID":"/20200531/:0:21","tags":["MySQL"],"title":"MySQL数据库03(常见函数)","uri":"/20200531/"},{"categories":["数据库"],"content":"前言 图形界面客户端下载链接 https://spiritlhl.lanzous.com/id5vuji 客户端安装 1.配置证书 2.新建用户配置 3.启用 4.询问(navaicate)窗口是命令行窗口 5.ctrl+s保存指令 6.ctrl+鼠标滚动轴调整字体大小 7.指令末尾加分号 DQL语言(Data Query Language) ","date":"2020-05-30","objectID":"/20200530/:0:0","tags":["MySQL"],"title":"MySQL数据库02(图形界面客户端基本运行指令)","uri":"/20200530/"},{"categories":["数据库"],"content":"基础查询 ues 上级表名; (打开你要查询的上级表/库名) (这里点击查询的库也能进入，但不推荐使用这种方法，尽量用SQL命令执行) select 查询列表 from 表名; (查询列表可以是表中字段，常量值，表达式，函数) (查询结果是一个虚拟表格) 查询表中字段 1.查询单个字段 select xxx from 上级表名;\r2.查询多个字段 select 字段1,字段2,字段3 from 表名; (这里的顺序与表内顺序无关，只是显示顺序) 3.查询表中所有字段 select (双击表名，此处会显示`所选表名`) from 上级表名; (这里的表名顺序无要求，是展示的顺序) (格式切换是选中所有指令后按Fn+F12，格式化) select * from 上级表名; (这种方式选中的表顺序与源顺序一样) (这里的`是着重号不是单引号，着重号主要用于区分表名为保留字，其他时候可有可无) (执行命令选中指令按Fn+F9或者按栏目里的执行按钮) 查询常量值 select 数字常量; select 字段常量;\r查询表达式 select 100*333; (数字运算)\r查询函数 select version();\r","date":"2020-05-30","objectID":"/20200530/:0:1","tags":["MySQL"],"title":"MySQL数据库02(图形界面客户端基本运行指令)","uri":"/20200530/"},{"categories":["数据库"],"content":"为字段起别名 方式一 使用as select 100*333 as 结果;\rselect last_name as 姓,first_name as 名 from 上级表名;\rselect xxx as yyy, kkk from 上级表名\r好处： 1.便于理解 2.如果要查询的字段有重名，使用别名区分开来 3.别名在表头显示\r方式二 使用空格 select last_name 姓,first_name 名 from 上级表名;\r这里建议别名与保留字重复时用双引号或单引号括起来 ","date":"2020-05-30","objectID":"/20200530/:0:2","tags":["MySQL"],"title":"MySQL数据库02(图形界面客户端基本运行指令)","uri":"/20200530/"},{"categories":["数据库"],"content":"去重 select distinct 表中字段 from 上级表名;\r","date":"2020-05-30","objectID":"/20200530/:0:3","tags":["MySQL"],"title":"MySQL数据库02(图形界面客户端基本运行指令)","uri":"/20200530/"},{"categories":["数据库"],"content":"+号作用 仅仅表示运算符 select 100+90; 两个操作数都为数值型，则做加法运算 select '123'+90; 其中一方为字符型，试图将字符型数值转换成数值型 select 'john'+90; 如果转换成功，则继续做加法运算，如果转换失败，则将字符型数值转换成0 select nu11+10; 只要其中一方为nu11，则结果肯定为nu11 ","date":"2020-05-30","objectID":"/20200530/:0:4","tags":["MySQL"],"title":"MySQL数据库02(图形界面客户端基本运行指令)","uri":"/20200530/"},{"categories":["数据库"],"content":"拼接 调用concat函数 select concat('a','b','c')\r","date":"2020-05-30","objectID":"/20200530/:0:5","tags":["MySQL"],"title":"MySQL数据库02(图形界面客户端基本运行指令)","uri":"/20200530/"},{"categories":["数据库"],"content":"判断是否为空 select ifnull(表名,返回值)\r","date":"2020-05-30","objectID":"/20200530/:0:6","tags":["MySQL"],"title":"MySQL数据库02(图形界面客户端基本运行指令)","uri":"/20200530/"},{"categories":["数据库"],"content":"条件查询 语法 select\r查询列表\rfrom\r表名\rwhere\r筛选条件\r分类 1.按条件表达式筛选 条件运算符: \u003e \u003c = \u003c= \u003e= != \u003c\u003e (最后一个是不等号) 2.按逻辑表达式筛选 逻辑运算符： \u0026与 ||或 !非 and or not 3.模糊查询\rlike between and in is null 按条件表达式筛选 案例1:查询收入大于10000的人员信息 指令如下 select\r*\rfrom\remployees\rwhere\rsalary\u003e10000;\r案例2:查询部门编号不等于90的员工名称 指令如下 select\rlast_name,\rdepartment_id\rfrom\remployees\rwhere\rdepartment_id != 90;\r按逻辑表达式筛选 \u0026\u0026和and:两个条件都为true,结果为true，反之为false ||或or: 只要有一个条件为true,结果为true, 反之为false |或not:_如果连按的条件本身为false, 结果为true,反之为falsd 案例3：查询工资z在10000到20000之.间的员工名、工资以及奖金 SELECT\rlast_ name ,\rsalary,\rcommission_ pct\rFROM\remployees\rWHERE\rsalary\u003e=10000 AND salary\u003c=2 0000;\r案例4:查询部门编号不是在90到110之间，或者工资高于15000的员工信息 SELECT\r*\rFROM\remployees\rWHERE\rNOT (department_ id\u003e=90 AND department_ id\u003c=110) OR salary\u003e15000;\r","date":"2020-05-30","objectID":"/20200530/:0:7","tags":["MySQL"],"title":"MySQL数据库02(图形界面客户端基本运行指令)","uri":"/20200530/"},{"categories":["数据库"],"content":"模糊查询 like 特点: 一般和通配符搭配使用 通配符: % 任意多个字符,包含0个字符 _ 任意单个字符 案例5:查询员工名中包含字符a的员工信息 SELECT\r*\rFROM\remployees\rWHERE\rlast_ name LIKE '%a%' ;#abc\r案例6:查询员工名中第三个字符为e，第五个字符为a的员工名和工资 SELECT\rlast_ name,\rsalary\rFROM\remployees\rWHERE\rlast_ name LIKE '__n_l%';|\r案例7:查询员工名中第二个字符为_的员工名 SELECT\rlast_ name\rFROM\remployees\rWHERE\rlast_ name LIKE '_ $_%' ESCAPE '$' ;\r或者 '_\\_%'也能转义_\rbetween and I 案例3:查询员工编号在100到120之间的员工信息 SELECT\r*\rFROM\remployees\rWHERE\remployee_ _id \u003e= 100 AND employee_ id\u003c=120;\r#———————-等同于 SELECT\r*\rFROM\remployees\rWHERE\remployee_ id BETWEEN 100 AND 120; .\r这里的 employee_ id BETWEEN 大于等于的值 AND 小于等于的值;\rin 含义:判断某字段的值是否属于in列表中的某一项 特点: 1.使用in提高语句简洁度\r2.in列表的值类型必须一致或兼容\r3.不能和通配符混用\r案例8:查询员工的工种编号是IT_PROG、 AD_VP、 AD_PRES中的一个员工名和工种编号 SELECT\rlast_ name,\rjob_ id\rFROM\remployees\rWHERE\rjob_ id = 'IT_ PROT' OR job_ id = 'AD_ VP' OR JOB_ ID ='AD_ PRES' ;\r这里的 job_id = 'IT_ PROT' OR job_id = 'AD_ VP' OR JOB_ID ='AD_ PRES' ;\r等同于 job_id IN('T_PROT','AD_ VP', 'AD_ PRES');\ris null =或\u003c\u003e不能用于判断null值 is null或is not null 可以判断null值 案例9：查询没有奖金的员工名和奖金率 SELECT\rlast_ name，.\rcommission_pct\rFROM\remployees\rWHERE\rcommission_pct IS NULL;\r如果是查询有奖金的，写is not null 安全等于 \u003c==\u003e \u003c==\u003e可以判断null值也可以判断一般数值 Is NULL: 仅仅可以判断NULL值，可读性较高，建议使用 \u003c=\u003e: 既可以判断NULL值，又可以判断普通的数值，可读性较低 排序查询 引入: select * from employees ;\r语法: select 查询列表\rfrom 表\r[where筛选条件]\rorder by 排序列表 [asc|desc]\r案例:查询员工信息，要求工资从高到低排序 SELECT * FROM employees ORDER BY salary DESC;\r案例:查询员工信息，要求工资从低到高排序 SELECT * FROM employees ORDER BY salary ASC; 特点: 1.asc代表的是升序，desc代表的是降序 2.如果不写，默认是升序 3.支持按表达式，别名，函数排序 4.order by子句一般是放在查询语句的最后面，limit子句除外 案例:按姓名的长度显示员工的姓名和工资[按函数排序] SELECT LENGTH(last_ name) 字节长度,last_ name, salary\rFROM employees\rORDER BY LENGTH (last_ name) DESC;\r案例:查询员工信息，要求先按工资升序，再按员工编号降序[按多个字段排序] SELECT * FROM employees ORDER BY salary ASC, employee_ _id DESC; ","date":"2020-05-30","objectID":"/20200530/:0:8","tags":["MySQL"],"title":"MySQL数据库02(图形界面客户端基本运行指令)","uri":"/20200530/"},{"categories":["数据库"],"content":"前言 MySQL数据库下载链接(5.5版本) https://spiritlhl.lanzous.com/id5vt2f 常用指令 1.查看当前所有的数据库 show dat abases; 2.打开指定的库 use 库名; 3.查看当前库的所有表 show_ tables; 4.查看其它库的所有表 show tables from 库名; 5.创建表 create table 表名( 列名 列类型， 列名 列类型， ... ) 6.查看表结构 desc表名; 启动与退出 #cmder 管理员模式下 C:\\Users\\祈LHL\\Desktop $ net stop mysql MySQL 服务正在停止. MySQL 服务已成功停止。 C:\\Users\\祈LHL\\Desktop $ net start mysql MySQL 服务正在启动 . MySQL 服务已经启动成功。 或者直接打开控制面板，搜索服务在服务中找到MySQL右键属性选择手动或开机自启，右键选择打开或关闭服务 登录与退出登录 #cmder 管理员模式下 C:\\Users\\祈LHL\\Desktop $ mysql -h localhost -P3306 -u root -p Enter password: 你的root账号密码 #这里的【-h主机名 -P端口号】在本地客户端里可以不输入， -u用户名 -p密码 Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 2 Server version: 5.5.62 MySQL Community Server (GPL) Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql\u003e exit Bye 或直接在左下角开始图标里找到MySQL 5.5 Command Line Client点击打开输入root密码，退出输入exit或ctrl+c 显示存在的目录 mysql\u003e show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | test | +--------------------+ 4 rows in set (0.01 sec) mysql\u003e use test;#进入test库 Database changed mysql\u003e show tables;#展示表 Empty set (0.01 sec) mysql\u003e show tables from mysql; #这里还在test库，只是去查看mysql库，没有离开test库 +---------------------------+ | Tables_in_mysql | +---------------------------+ | columns_priv | | db | | event | | func | | general_log | | help_category | | help_keyword | | help_relation | | help_topic | | host | | ndb_binlog_index | | plugin | | proc | | procs_priv | | proxies_priv | | servers | | slow_log | | tables_priv | | time_zone | | time_zone_leap_second | | time_zone_name | | time_zone_transition | | time_zone_transition_type | | user | +---------------------------+ 24 rows in set (0.00 sec) mysql\u003e select database(); #查看在哪个库 +------------+ | database() | +------------+ | NULL | +------------+ 1 row in set (0.00 sec) 创建表 mysql\u003e create table stuinfo( -\u003e id int, -\u003e name varchar(20)); Query OK, 0 rows affected (0.02 sec) 查看表 # desc 加 空格 加 表名 mysql\u003e desc stuinfo; +-------+-------------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +-------+-------------+------+-----+---------+-------+ | id | int(11) | YES | | NULL | | | name | varchar(20) | YES | | NULL | | +-------+-------------+------+-----+---------+-------+ 2 rows in set (0.02 sec) 查看表内数据 select * from stuinfo; 小技巧 如果你之前输入过相同命令且与你的输入行接近，按键盘上下键可以切换你输入过的命令，可以避免重复输入相同命令消耗时间，cmder下可以选中命令后右键点击，自动复制该命令到输入的行 查看数据库版本 #已经登陆时输入(SQL指令) mysql\u003e select version(); +-----------+ | version() | +-----------+ | 5.5.62 | +-----------+ 1 row in set (0.01 sec) #未登录时输入(windows指令) $ mysql --version mysql Ver 14.14 Distrib 5.5.62, for Win64 (AMD64) #或者输入(windows指令) mysql -V mysql Ver 14.14 Distrib 5.5.62, for Win64 (AMD64) ","date":"2020-05-29","objectID":"/20200529/:0:0","tags":["MySQL"],"title":"MySQL数据库01(cmder基本运行指令)","uri":"/20200529/"},{"categories":["python","爬虫"],"content":"前言 最好有Selenium的Web自动化的实际经验 运行基础：client库(0.52版本)，Appium Server，安卓SDK(含JDK环境)，USB调试模式下的手机(开发者模式) 所用apk包(wv.apk)链接： https://spiritlhl.lanzous.com/icxhm7g 界面操作和adb命令 ","date":"2020-05-25","objectID":"/20200525/:0:0","tags":["python","爬虫"],"title":"Appium自动化操作03(界面操作和adb命令)","uri":"/20200525/"},{"categories":["python","爬虫"],"content":"click点击 最常见的操作之一，使用WebElement对象的click方法。 ","date":"2020-05-25","objectID":"/20200525/:0:1","tags":["python","爬虫"],"title":"Appium自动化操作03(界面操作和adb命令)","uri":"/20200525/"},{"categories":["python","爬虫"],"content":"tap点按 WebElement对象的tap方法和click类似，都是点击界面。 但是最大的区别是，tap是针对坐标而不是针对找到的元素。 为了保证自动化代码在所有分辨率的手机上都能正常执行，我们通常应该使用click方法。 但有的时候，我们难以用通常的方法定位元素，可以用这个tap方法，根据坐标来点击 用inspect查看该元素的属性中，有一个bounds属性吗？ 它就是表示元素的左上角，右下角坐标的坐标。 我们还可以使用UIAutomatorviewer直接十字光标移动，看右边的属性提示。 tap方法可以像这样进行调用 driver.tap([(1100,1080),],700) 它有两个参数： 第一个参数是个列表，表示点击的坐标。 注意最多可以有5个元素，代表5根手指点击5个坐标。所以是list类型。 如果我们只要模拟一根手指点击屏幕，list中只要一个元素就可以了 第二个参数表示tap点按屏幕后停留的时间（毫秒）。 如果点按时间过长，就变成了长按操作了。 ","date":"2020-05-25","objectID":"/20200525/:0:2","tags":["python","爬虫"],"title":"Appium自动化操作03(界面操作和adb命令)","uri":"/20200525/"},{"categories":["python","爬虫"],"content":"输入 最常见的操作之一，使用WebElement对象的send_keys方法。 ","date":"2020-05-25","objectID":"/20200525/:0:3","tags":["python","爬虫"],"title":"Appium自动化操作03(界面操作和adb命令)","uri":"/20200525/"},{"categories":["python","爬虫"],"content":"获取界面文本信息 可以通过WebElement对象的.text属性获取该对象的文本信息。 ","date":"2020-05-25","objectID":"/20200525/:0:4","tags":["python","爬虫"],"title":"Appium自动化操作03(界面操作和adb命令)","uri":"/20200525/"},{"categories":["python","爬虫"],"content":"滑动 做移动app测试的时候，经常需要滑动界面。 这需要使用WebDriver对象的swipe方法。 driver.swipe(start_x=x, start_y=y1, end_x=x, end_y=y2, duration=800) 前面4个参数是滑动起点和终点的x、y坐标。 第5个参数duration是滑动从起点到终点坐标所耗费的时间（毫秒）。 注意这个时间非常重要，在屏幕上滑动同样的距离，如果时间设置的很短，就是快速的滑动。 例如：一个翻动新闻的界面，快速的滑动，就会是扫动的动作，会导致内容随惯性滚动很多。 ","date":"2020-05-25","objectID":"/20200525/:0:5","tags":["python","爬虫"],"title":"Appium自动化操作03(界面操作和adb命令)","uri":"/20200525/"},{"categories":["python","爬虫"],"content":"按键 调用press_keycode方法，就能模拟按键动作，包括安卓手机的实体按键和键盘按钮。 具体代码如下： from appium.webdriver.extensions.android.nativekey import AndroidKey # 输入回车键，确定搜索 driver.press_keycode(AndroidKey.ENTER) 按键的定义，可以参考这篇文档https://github.com/appium/python-client/blob/master/appium/webdriver/extensions/android/nativekey.py ","date":"2020-05-25","objectID":"/20200525/:0:6","tags":["python","爬虫"],"title":"Appium自动化操作03(界面操作和adb命令)","uri":"/20200525/"},{"categories":["python","爬虫"],"content":"长按、双击、移动 Appium的TouchAction类提供了更多的手机操作方法，如：长按、双击、移动 参考源代码中的注释https://github.com/appium/python-client/blob/master/appium/webdriver/common/touch_action.py 下面有一个长按的例子 from appium.webdriver.common.touch_action import TouchAction actions = TouchAction(driver) actions.long_press(element) actions.perform() ","date":"2020-05-25","objectID":"/20200525/:0:7","tags":["python","爬虫"],"title":"Appium自动化操作03(界面操作和adb命令)","uri":"/20200525/"},{"categories":["python","爬虫"],"content":"打开通知栏 安卓手机，查看通知栏的动作可以是从屏幕顶端下滑来查看通知。 也可以使用如下代码，直接打开通知栏 driver.open_notifications() 通知栏里面的元素，自动化的方法和前面介绍的App界面元素自动化是一样的。 ","date":"2020-05-25","objectID":"/20200525/:0:8","tags":["python","爬虫"],"title":"Appium自动化操作03(界面操作和adb命令)","uri":"/20200525/"},{"categories":["python","爬虫"],"content":"收起通知栏 收起通知栏，可以使用前面介绍的模拟按键，发出返回按键的方法。 ","date":"2020-05-25","objectID":"/20200525/:0:9","tags":["python","爬虫"],"title":"Appium自动化操作03(界面操作和adb命令)","uri":"/20200525/"},{"categories":["python","爬虫"],"content":"adb 命令 android sdk里面有一个命令行工具adb。 adb全称Android Debug Bridge，这个adb使用非常广泛。 它可以与Android手机设备进行通信，它可进行各种设备操作。 如：安装应用和调试应用，传输文件，甚至登录到手机设备上shell的进行访问，就像远程登录一样 这个adb在sdk的platform-tools目录下面，请大家确保路径在Path环境变量中。 Appium对anroid的自动化非常依赖这个adb工具。执行自动化过程中，有很多内部操作，比如获取设备信息，传送文件到手机，安装apk，启动某些程序等，都是通常这个adb实现的。 adb命令既然是个命令，就可以使用Python的os.system()或者subprocess来自动化调用它，完成我们的各种自动化需求。 而自动化过程中，可能需要截屏手机，并且下载到指定目录中，可以在Python程序中这样写 import os os.system('adb shell screencap /sdcard/screen3.png \u0026\u0026 adb pull /sdcard/screen3.png') 特别的，还可以通过adb使用am(activity manager)和pm(package manager)两个工具，可以启动Activity、强行停止进程、广播intent、修改设备屏幕属性、列出应用、卸载应用等。 adb命令的官方文档：https://developer.android.google.cn/studio/command-line/adb.html#devicestatus 一些常见的adb命令： 查看连接的设备 adb devices -l\r查看文件目录 adb shell ls /sdcard\r上传文件 adb push wv.apk /sdcard/wv.apk\r下载文件 adb pull /sdcard/new.txt\r截屏 adb shell screencap /sdcard/screen.png\r截屏后的文件存在手机上，可以使用adb pull下载下来 ","date":"2020-05-25","objectID":"/20200525/:0:10","tags":["python","爬虫"],"title":"Appium自动化操作03(界面操作和adb命令)","uri":"/20200525/"},{"categories":["python","爬虫"],"content":"shell 登录到手机设备上shell的进行访问，就像远程登录一样，可用来在连接的设备上运行各种命令。 输入adb shell然后执行各种安卓支持的Linux命令，比如ps、netstat、netstat -an|grep 4724、pwd、ls、cd、rm等。 执行quit退出shell ","date":"2020-05-25","objectID":"/20200525/:0:11","tags":["python","爬虫"],"title":"Appium自动化操作03(界面操作和adb命令)","uri":"/20200525/"},{"categories":["python","爬虫"],"content":"前言 最好有Selenium的Web自动化的实际经验 运行基础：client库(0.52版本)，Appium Server，安卓SDK(含JDK环境)，USB调试模式下的手机(开发者模式) 定位元素 从示例代码就可以发现，和Selenium Web自动化一样，要操作界面元素，必须先定位(选择)元素。 Appium是基于Selenium的，所以和Selenium代码定位元素的基本规则相同： find_element_by_XXX方法，返回符合条件的第一个元素，找不到抛出异常 find_elements_by_XXX方法，返回符合条件的所有元素的列表，找不到返回空列表 通过WebDriver对象调用这样的方法，查找范围是整个界面 通过WebElement对象调用这样的方法，查找范围是该节点的子节点 界面元素查看工具 做Selenium Web自动化的时候，要找到元素，我们是通过浏览器的开发者工具栏来查看元素的特性，根据这些特性（属性和位置），来定位元素 Appium要自动化手机应用，同样需要工具查看界面元素的特征。 常用的查看工具： Android Sdk中的uiautomateviewer Appium Desktop中的Appium Inspector ","date":"2020-05-24","objectID":"/20200527/:0:0","tags":["python","爬虫"],"title":"Appium自动化操作02(元素定位及查看工具)","uri":"/20200527/"},{"categories":["python","爬虫"],"content":"uiautomateviewer 安卓查看APP界面元素，最常用的就是Android SDK中的工具uiautomateviewer，它在SDK目录目录的tools\\bin目录中 和Selenium一样，我们要定位选择元素，也是根据元素的特征，包括: 元素的属性\r元素的相对位置（相对父元素、兄弟元素等）\r具体细节，参考视频里面的讲解。\r","date":"2020-05-24","objectID":"/20200527/:1:0","tags":["python","爬虫"],"title":"Appium自动化操作02(元素定位及查看工具)","uri":"/20200527/"},{"categories":["python","爬虫"],"content":"Appium Inspector Appium Desktop中的Appium Inspector也可以查看元素。 它的一个优点是可以直接验证选择表达式是否能定位到元素 ","date":"2020-05-24","objectID":"/20200527/:2:0","tags":["python","爬虫"],"title":"Appium自动化操作02(元素定位及查看工具)","uri":"/20200527/"},{"categories":["python","爬虫"],"content":"定位元素的方法 1.根据ID 在Selenium Web自动化里，如果能根据ID选择定位元素，最好根据ID，因为通常来说ID是唯一的，所以根据ID选择 效率高。 在安卓应用自动化的时候，同样可以根据ID查找。 但是这个ID，是安卓应用元素的resource-id属性 具体代码： driver.find_element_by_id('') 2.根据CLASS NAME 安卓界面元素的class属性其实就是根据元素的类型，类似web里面的tagname， 所以通常不是唯一的。 通常，我们根据class属性来选择元素，是要选择多个而不是一个。 当然如果你确定要查找的界面元素的类型 在当前界面中只有一个，就可以根据class来唯一选择。 具体代码： driver.find_elements_by_class_name('') 3.根据ACCESSIBILITY ID 元素的content-desc属性是用来描述该元素的作用的。 如果要查询的界面元素有content-desc属性，我们可以通过它来定位选择元素。 具体代码： driver.find_element_by_accessibility_id('') 4.Xpath Appium也支持通过Xpath选择元素。 但是其可靠性和性能不如Selenium Web自动化。因为Web自动化对Xpath的支持是由浏览器实现的，而Appium Xpath的支持是Appium Server实现的。 毕竟，浏览器产品的成熟度比Appium要高很多。 当然，Xpath是标准语法，所以这里表达式的语法规则和Selenium里面Xpath的语法是一样的，比如 driver.find_element_by_xpath('//ele0/ele1[@attr=\"value\"]') 注意： selenium自动化中，xpath表达式中每个节点名是html的tagname。 但是在appium中，xpath表达式中每个节点名是元素的class属性值。 比如：要选择所有的文本节点，就用如下代码: driver.find_element_by_xpath('//android.widget.TextView') ","date":"2020-05-24","objectID":"/20200527/:3:0","tags":["python","爬虫"],"title":"Appium自动化操作02(元素定位及查看工具)","uri":"/20200527/"},{"categories":["python","爬虫"],"content":"参考文档 根据id，classname， accessibilityid，xpath这些方法选择元素，其实底层都是利用了安卓uiautomator框架的API功能实现的。 这里是谷歌安卓官方文档介绍： https://developer.android.google.cn/training/testing/ui-automator 也就是说，程序的这些定位请求，被Appium server转发给手机自动化代理程序，就转化为为uiautomator里面相应的定位函数调用。 其实，自动化程序，可以直接告诉手机上的自动化代理程序，让它调用UI Automator API的java代码，实现最为直接的自动化控制。 主要是通过UiSelector这个类里面的方法实现元素定位的，比如 code = 'new UiSelector().text(\"热门\").className(\"android.widget.TextView\")' ele = driver.find_element_by_android_uiautomator(code) ele.click() 就是通过text属性和className的属性两个条件来定位元素。 UiSelector里面有些元素选择的方法可以解决前面解决不了的问题。 比如 text方法 可以根据元素的文本属性查找元素\rtextContains 根据文本包含什么字符串\rtextStartsWith 根据文本以什么字符串开头\rtextmartch方法 可以使用正则表达式选择一些元素，如下\r```python\rcode = 'new UiSelector().textMatches(\"^我的.*\")'\r```\rUiSelector的instance和index也可以用来定位元素，都是从0开始计数，他们的区别： instance是匹配的结果所有元素里面 的第几个元素\rindex则是其父元素的几个节点，类似xpath里面的*[n]\rUiSelector的childSelector可以选择后代元素，比如 code = 'new UiSelector().resourceId(\"tv.danmaku.bili:id/recycler_view\").childSelector(new UiSelector().className(\"android.widget.TextView\"))' ele = driver.find_element_by_android_uiautomator(code) 注意：childSelector后面的引号要框住整个uiSelector的表达式 ","date":"2020-05-24","objectID":"/20200527/:4:0","tags":["python","爬虫"],"title":"Appium自动化操作02(元素定位及查看工具)","uri":"/20200527/"},{"categories":["python","爬虫"],"content":"前言 最好有Selenium的Web自动化的实际经验 本篇用到的相关软件链接： 链接: https://pan.baidu.com/s/126x-AgLKvM7qSJqdOzAAHA 提取码: h9b2 Appium 基础知识 Appium 用途和特点 Appium 是一个移动 App （手机应用）自动化工具。 手机APP自动化有什么用？ 自动化完成一些重复性的任务\r比如 微信客服机器人\r爬虫\r自动化测试\r爬虫就是通过手机自动化爬取信息。 为什么不通过网页、HTTP 爬取呢？ 有的系统没有网页，也不方便通过HTTP爬取\r自动化测试 很多软件开发里面有这样的需求\rAppium 自动化方案的特点： 开源免费\r支持多个平台\riOS （苹果）、安卓 App 的自动化都支持。\r支持多种类型的自动化\r支持 苹果、安卓 应用 原生界面 的自动化\r支持 应用 内嵌 WebView 的自动化\r支持 手机浏览器 中的 web网站自动化\r支持 flutter 应用的自动化\r支持多种编程语言\r像 Selenium 一样，Appium可以用多种编程语言调用它开发自动化程序。 自动化原理 Appium自动化的原理图: 它和Selenium原理图很像。因为Appium自动化架构借鉴了Selenium。 它包含了3个主体部分：自动化程序、Appium Server、移动设备 自动化程序 自动化程序是由我们来开发的，实现具体的手机自动化功能。 要发出具体的指令控制手机，也需要使用客户端库。 和Selenium一样，Appium 组织也提供了多种编程语言的客户端库，包括 java，python，js， ruby等，方便不同编程语言的开发者使用。 首先需要安装好客户端库，调用这些库，就可以发出自动化指令给手机。 Appium Server Appium Server 是 Appium 组织开发的程序，它负责管理手机自动化环境，并且转发自动化程序的控制指令给手机，并且转发手机给自动化程序的响应消息。 手机设备 这里说的手机设备，其实不仅仅是手机，包括所有苹果、安卓的移动设备，比如：手机、平板、智能手表等。 为了直观方便的讲解，这里我们简称：手机 当然手机上也包含了我们要自动化控制的手机应用APP。 手机设备为什么能接收并且处理自动化指令呢？ 因为，Appium Server 会在手机上安装一个自动化代理程序，代理程序会等待自动化指令，并且执行自动化指令 PS:这里使用手机端的自动化代理后你的键盘会无法弹出，只能接受电脑控制输入，手机键盘输入与电脑输入不能并存 比如：要模拟用户点击界面按钮，Appium自动化系统的流程是这样的： 自动化程序调用客户端库相应的函数，发送点击元素的指令（封装在HTTP消息里）给Appium Server Appium Server再转发这个指令给手机上的自动化代理 手机上的自动化代理接收到指令后，调用手机平台的自动化库，执行点击操作，返回点击成功的结果给 Appium Server Appium Server转发给自动化程序 自动化程序了解到本操作成功后，继续后面的自动化流程 其中，自动化代理控制，使用的什么库来实现自动化的呢？ 如果测试的是苹果手机， 用的是苹果的 XCUITest 框架 （IOS9.3版本以后） 如果测试的是安卓手机，用的是安卓的 UIAutomator 框架 (Android4.2以后) 这些自动化框架提供了在手机设备上运行的库，可以让程序调用这些库，像人一样自动化操控设备和APP，比如：点击、滑动，模拟各种按键消息等。 自动化环境搭建 这里以安卓APP的自动化为例。 环境搭建需要下载安装不少软件，而且还有不少是国外网站下载的。 这些软件安装包都放在前言的百度网盘链接中了，请自行下载。 1.安装client第三方库 首先需要在开发环境下下载appium-python-client库，也可以用pip安装，如下(pip默认下载最新库，要指定特殊版本，要在后面加上==特殊版本名) PS:这里的appium-python-client库有特殊版本要求，需要安装的是0.52版本，不是1.0版本以上，否则会报错，建议使用Pycharm环境 pip install appium-python-client==0.52 2.安装Appium Server Appium Server 是用 nodejs 运行的，基于js开发出来的。 Appium组织为了方便软件安装使用，制作了一个可执行程序 Appium Desktop，把nodejs 运行环境、Appium Server 和一些工具打包在里面了，只需要简单的下载安装就可以了。 可以从前言给出的百度网盘里下载安装： Appium-windows-1.15.1.exe Appium Desktop官方下载链接： https://github.com/appium/appium-desktop/releases/tag/v1.15.1 3.安装JDK 安卓APP的自动化，必须要安装安卓SDK(后面会提到)，而安卓SDK需要JDK环境。 可以从前言给出的百度网盘里下载安装： jdk-8u211-windows-x64.exe 安装好之后，还需要添加一个环境变量JAVA_HOME，指定值为jdk安装目录，比如 JAVA_HOME D:\\Javajdk 实际情况如下： 4.安装Android SDK 对于安卓APP的自动化，Appium Server是需要Android SDK的。 因为要用到里面的一些工具，比如要执行命令设置手机、传送文件、安装应用、查看手机界面等。 可以从前言给出的百度网盘里下载Android SDK文件包： androidsdk.zip，并且解压，即可。 解压完成后，需要配置一下添加一个环境变量 ANDROID_HOME，设置值为sdk包解压目录，比如 D:\\androidsdk添加步骤参照第三步的图 另外，还推荐大家配置环境变量PATH，加入adb所在目录， D:\\安卓dk\\androidsdk\\androidsdk\\platform-tools\\ 实际情况如下： 注意：是添加该目录到环境变量PATH中，不是替换!否则会导致系统命令都找不到的严重后果，双击2处使用新建添加！。 5.连接手机 上述的软件环境都准备好以后，要自动化手机APP，需要： 在你运行程序的电脑上用USB线连接上你的安卓手机 进入手机设置 -\u003e 关于手机，不断点击版本号菜单（大概7次以上）进入开发者模式 退出到上级菜单，在设置首页里点系统与更新，在系统与更新的开发者模式中，启动USB调试 如果手机连接USB线后，手机界面弹出是否选择允许USB调试，请选择是。 注意： 有的手机系统，可能需要一些额外的选项需要设置好。 比如，有的手机，开发者选项里需要打开允许通过USB安装应用等。 总之，给USB开发调试尽可能方便的控制手机。 连接好以后，打开命令行窗口，执行adb devices -l命令来列出连接在电脑上的安卓设备。 如果输出类似如下的内容： List of devices attached MGFNW19731015276 device product:HLK-AL00 model:HLK_AL00 device:HWHLK-H transport_id:1 表示电脑上可以查看到连接的设备，就可以运行自动化程序了。 第一个例子 运行代码前，首先得运行Appium Desktop from appium import webdriver from appium.webdriver.extensions.android.nativekey import AndroidKey desired_caps = { 'platformName': 'Android', # 被测手机是安卓 'platformVersion': '10', # 手机安卓版本，这个需要在设置里的关于手机里查找，注意是Android版本，不是MIUI等系统版本 'deviceName': 'HLK-AL00', # 设备名，安卓手机可以随意填写 'appPackage': 'tv.danmaku.bili', # 启动APP Package名称 'appActivity': '.ui.splash.SplashActivity', # 启动Activity名称 'unicodeKeyboard': True, # 使用自带输入法，输入中文时填True 'resetKeyboard': True, # 执行完程序恢复原来输入法 'noReset': True, # 不要重置App 'newCommandTimeout': 6000, #服务自动断开时间 'automationName' : 'UiAutomator2'#服务协议 } # 连接Appium Server，初始化自动化环境 driver = webdriver.Remote('http://localhost:4723/wd/hub', desired_caps) # 设置等待时间 driver.implicitly_wait(5) # 如果有`青少年保护`界面，点击`我知道了` iknow = driver.find_elements_by_id(\"text3\") if iknow: iknow.click() # 根据id定位搜索位置框，点击 driver.find_element_by_id(\"expand_search\").click() # 根据id定位搜索输入框，点击 sbox = ","date":"2020-05-23","objectID":"/20200523/:0:0","tags":["python","爬虫"],"title":"Appium自动化操作01(环境安装与初始结构)","uri":"/20200523/"},{"categories":["python","数学建模"],"content":"前言 ","date":"2020-05-22","objectID":"/20200522/:0:0","tags":["python","数学建模"],"title":"NumPy (下)","uri":"/20200522/"},{"categories":["python","数学建模"],"content":"本篇鸣谢 马川-燕大 的增删整理， 王圣元 ——原创文章，与原文不同之处包含我的学习记录。 匹配Jupyter Notebook的ipynb文档链接下载地址如下 源文档 接着上篇继续后面两个章节，数组变形和数组计算。 提纲： ","date":"2020-05-22","objectID":"/20200522/:0:1","tags":["python","数学建模"],"title":"NumPy (下)","uri":"/20200522/"},{"categories":["python","数学建模"],"content":"4 数组的变形 本节介绍四大类数组层面上的操作，具体有 重塑 (reshape) 和打平 (ravel, flatten) 合并 (concatenate, stack) 和分裂 (split) 重复 (repeat) 和拼接 (tile) 其他操作 (sort, insert, delete, copy) ","date":"2020-05-22","objectID":"/20200522/:1:0","tags":["python","数学建模"],"title":"NumPy (下)","uri":"/20200522/"},{"categories":["python","数学建模"],"content":"4.1 重塑和打平 重塑 (reshape) 和打平 (ravel, flatten) 这两个操作仅仅只改变数组的维度 重塑是从低维到高维 打平是从高维到低维 重塑 用reshape()函数将一维数组 arr 重塑成二维数组。 import numpy as np arr = np.arange(12) print( arr ) print( arr.reshape(4,3) ) [ 0 1 2 3 4 5 6 7 8 9 10 11] [[ 0 1 2] [ 3 4 5] [ 6 7 8] [ 9 10 11]] 思考：为什么重塑后的数组不是 [[ 0 4 8] [ 1 5 9] [ 2 6 10] [ 3 7 11]] 当你重塑高维矩阵时，不想花时间算某一维度的元素个数时，可以用「-1」取代，程序会自动帮你计算出来。比如把 12 个元素重塑成 (2, 6)，你可以写成 (2,-1) 或者 (-1, 6)。 print( arr.reshape((2,-1)) ) print( arr.reshape((-1,6)) ) [[ 0 1 2 3 4 5] [ 6 7 8 9 10 11]] [[ 0 1 2 3 4 5] [ 6 7 8 9 10 11]] 打平 用 ravel() 或flatten() 函数将二维数组 arr 打平成一维数组。 arr = np.arange(12).reshape((4,3)) print( arr ) ravel_arr = arr.ravel() print( ravel_arr ) flatten_arr = arr.flatten() print( flatten_arr ) [[ 0 1 2] [ 3 4 5] [ 6 7 8] [ 9 10 11]] [ 0 1 2 3 4 5 6 7 8 9 10 11] [ 0 1 2 3 4 5 6 7 8 9 10 11] 思考：为什么打平后的数组不是 [ 0 3 6 9 1 4 7 10 2 5 8 11] 要回答本节两个问题，需要了解 numpy 数组在内存块的存储方式。 行主序和列主序 行主序 (row-major order) 指每行的元素在内存块中彼此相邻，而列主序 (column-major order) 指每列的元素在内存块中彼此相邻。 在众多计算机语言中， 默认行主序的有 C 语言(下图 order=‘C’ 等价于行主序) 默认列主序的有 Fortran 语言(下图 order=‘F’ 等价于列主序) 在 numpy 数组中，默认的是行主序，即 order =‘C’。现在可以回答本节那两个问题了。 如果你真的想在「重塑」和「打平」时用列主序，只用把 order 设为 ‘F’，以重塑举例： print( np.arange(12).reshape((4,3), order='F') ) [[ 0 4 8] [ 1 5 9] [ 2 6 10] [ 3 7 11]] 细心的读者可能已经发现为什么「打平」需要两个函数 ravel() 或 flatten()？它们的区别在哪里？ 知识点 函数 ravel() 或 flatten() 的不同之处是 1. ravel() 按「行主序」打平时没有复制原数组，按「列主序」在打平时复制了原数组 2. flatten() 在打平时复制了原数组 用代码验证一下，首先看 flatten()，将打平后的数组 flatten 第一个元素更新为 10000，并没有对原数组 arr 产生任何影响 (证明 flatten() 是复制了原数组) arr = np.arange(6).reshape(2,3) print( arr ) flatten = arr.flatten() print( flatten ) flatten_arr[0] = 10000 print( arr ) [[0 1 2] [3 4 5]] [0 1 2 3 4 5] [[0 1 2] [3 4 5]] 再看 ravel() 在「列主序」打平，将打平后的数组 ravel_F 第一个元素更新为 10000，并没有对原数组 arr 产生任何影响 (证明 ravel(order=‘F’) 是复制了原数组) ravel_F = arr.ravel( order='F' ) ravel_F[0] = 10000 print( ravel_F ) print( arr ) [10000 3 1 4 2 5] [[0 1 2] [3 4 5]] 最后看 ravel() 在「行主序」打平，将打平后的数组 ravel_C 第一个元素更新为 10000，原数组 arr[0][0] 也变成了 10000 (证明 ravel() 没有复制原数组) ravel_C = arr.ravel() ravel_C[0] = 10000 print( ravel_C ) print( arr ) [10000 1 2 3 4 5] [[10000 1 2] [ 3 4 5]] ","date":"2020-05-22","objectID":"/20200522/:1:1","tags":["python","数学建模"],"title":"NumPy (下)","uri":"/20200522/"},{"categories":["python","数学建模"],"content":"4.2 合并和分裂 合并 (concatenate, stack) 和分裂 (split) 这两个操作仅仅只改变数组的分合 合并是多合一 分裂是一分多 合并 使用「合并」函数有两种选择 有通用的 concatenate 有专门的 vstack, hstack, dstack 用下面两个数组来举例： arr1 = np.array([[1, 2, 3], [4, 5, 6]]) arr2 = np.array([[7, 8, 9], [10, 11, 12]]) concatenate np.concatenate([arr1, arr2], axis=0) array([[ 1, 2, 3], [ 4, 5, 6], [ 7, 8, 9], [10, 11, 12]]) np.concatenate([arr1, arr2], axis=1) array([[ 1, 2, 3, 7, 8, 9], [ 4, 5, 6, 10, 11, 12]]) 在 concatenate() 函数里通过设定轴，来对数组进行竖直方向合并 (轴 0) 和水平方向合并 (轴 1)。 vstack, hstack, dstack 通用的东西是好，但是可能效率不高，NumPy 里还有专门合并的函数 vstack：v 代表 vertical，竖直合并，等价于 concatenate(axis=0) hstack：h 代表 horizontal，水平合并，等价于 concatenate(axis=1) dstack：d 代表 depth-wise，按深度合并，深度有点像彩色照片的 RGB 通道 一图胜千言： 用代码验证一下： print( np.vstack((arr1, arr2)) ) print( np.hstack((arr1, arr2)) ) print( np.dstack((arr1, arr2)) ) [[ 1 2 3] [ 4 5 6] [ 7 8 9] [10 11 12]] [[ 1 2 3 7 8 9] [ 4 5 6 10 11 12]] [[[ 1 7] [ 2 8] [ 3 9]] [[ 4 10] [ 5 11] [ 6 12]]] 和 vstack, hstack 不同，dstack 将原数组的维度增加了一维。 np.dstack((arr1, arr2)).shape (2, 3, 2) 分裂 使用「分裂」函数有两种选择 有通用的 split 有专门的 hsplit, vsplit 用下面数组来举例： arr = np.arange(25).reshape((5,5)) print( arr ) [[ 0 1 2 3 4] [ 5 6 7 8 9] [10 11 12 13 14] [15 16 17 18 19] [20 21 22 23 24]] split 和 concatenate() 函数一样，我们可以在 split() 函数里通过设定轴，来对数组沿着竖直方向分裂 (轴 0) 和沿着水平方向分裂 (轴 1)。 first, second, third = np.split(arr,[1,3]) print( 'The first split is', first ) print( 'The second split is', second ) print( 'The third split is', third ) The first split is [[0 1 2 3 4]] The second split is [[ 5 6 7 8 9] [10 11 12 13 14]] The third split is [[15 16 17 18 19] [20 21 22 23 24]] split() 默认沿着轴 0 分裂，其第二个参数 [1, 3] 相当于是个切片操作，将数组分成三部分： 第一部分 - :1 (即第 1 行) 第二部分 - 1:3 (即第 2 到 3 行) 第二部分 - 3: (即第 4 到 5 行) hsplit, vsplit vsplit() 和 split(axis=0) 等价，hsplit() 和 split(axis=1) 等价。一图胜千言： 为了和上面不重复，我们只看 hsplit。 first, second, third = np.hsplit(arr,[1,3]) print( 'The first split is', first ) print( 'The second split is', second ) print( 'The third split is', third ) The first split is [[ 0] [ 5] [10] [15] [20]] The second split is [[ 1 2] [ 6 7] [11 12] [16 17] [21 22]] The third split is [[ 3 4] [ 8 9] [13 14] [18 19] [23 24]] ","date":"2020-05-22","objectID":"/20200522/:1:2","tags":["python","数学建模"],"title":"NumPy (下)","uri":"/20200522/"},{"categories":["python","数学建模"],"content":"4.3 重复和拼接 重复 (repeat) 和拼接 (tile) 这两个操作本质都是复制 重复是在元素层面复制 拼接是在数组层面复制 重复 函数 repeat() 复制的是数组的每一个元素，参数有几种设定方法： 一维数组：用标量和列表来复制元素的个数 多维数组：用标量和列表来复制元素的个数，用轴来控制复制的行和列 标量 arr = np.arange(3) print( arr ) print( arr.repeat(3) ) [0 1 2] [0 0 0 1 1 1 2 2 2] 标量参数 3 - 数组 arr 中每个元素复制 3 遍。 列表 print( arr.repeat([2,3,4]) ) [0 0 1 1 1 2 2 2 2] 列表参数 [2,3,4] - 数组 arr 中每个元素分别复制 2, 3, 4 遍。 标量和轴 arr2d = np.arange(6).reshape((2,3)) print( arr2d ) print( arr2d.repeat(2, axis=0) ) [[0 1 2] [3 4 5]] [[0 1 2] [0 1 2] [3 4 5] [3 4 5]] 标量参数 2 和轴 0 - 数组 arr2d 中每个元素沿着轴 0 复制 2 遍。 列表和轴 print( arr2d.repeat([2,3,4], axis=1) ) [[0 0 1 1 1 2 2 2 2] [3 3 4 4 4 5 5 5 5]] 列表参数 [2,3,4] 和轴 1 - 数组 arr2d 中每个元素沿着轴 1 分别复制 2, 3, 4 遍。 拼接 函数 tile() 复制的是数组本身，参数有几种设定方法： 标量：把数组当成一个元素，一列一列复制 形状：把数组当成一个元素，按形状复制 标量 arr2d = np.arange(6).reshape((2,3)) print( arr2d ) print( np.tile(arr2d,2) ) [[0 1 2] [3 4 5]] [[0 1 2 0 1 2] [3 4 5 3 4 5]] 标量参数 2 - 数组 arr 按列复制 2 遍。 形状 tile 是瓷砖的意思，顾名思义，这个函数就是把数组像瓷砖一样铺展开来。 arr2d2 = np.array([[1,2], [3, 4]]) print( arr2d2 ) [[1 2] [3 4]] 横向 np.tile(arr2d2, (1,4)) # 与 np.tile(arr2d2, 4) 等价 array([[1, 2, 1, 2, 1, 2, 1, 2], [3, 4, 3, 4, 3, 4, 3, 4]]) 纵向 np.tile(arr2d2, (3,1)) array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]]) 横向+纵向 print( np.tile(arr2d2, (3,4)) ) [[1 2 1 2 1 2 1 2] [3 4 3 4 3 4 3 4] [1 2 1 2 1 2 1 2] [3 4 3 4 3 4 3 4] [1 2 1 2 1 2 1 2] [3 4 3 4 3 4 3 4]] 形状参数 (3,4) - 数组 arr 按形状复制 12 (3×4) 遍，并以 (3,4) 的形式展现。 ","date":"2020-05-22","objectID":"/20200522/:1:3","tags":["python","数学建模"],"title":"NumPy (下)","uri":"/20200522/"},{"categories":["python","数学建模"],"content":"4.4 其他操作 本节讨论数组的其他操作，包括排序 (sort)，插入 (insert)，删除 (delete) 和复制 (copy)。 排序 排序包括直接排序 (direct sort) 和间接排序 (indirect sort)。 直接排序 arr = np.array([5,3,2,6,1,4]) print( 'Before sorting', arr ) arr.sort() print( 'After sorting', arr ) Before sorting [5 3 2 6 1 4] After sorting [1 2 3 4 5 6] sort()函数是按升序 (ascending order) 排列的，该函数里没有参数可以控制 order，因此你想要按降序排列的数组，只需 print( arr[::-1] ) [6 5 4 3 2 1] 现在让人困惑的地方来了。 知识点 用来排序 numpy 用两种方式： arr.sort()#原址排序 np.sort( arr )#副本排序 第一种 sort 会改变 arr，第二种 sort 在排序时创建了 arr 的一个复制品，不会改变 arr。看下面代码，用一个形状是 (3, 4) 的「二维随机整数」数组来举例，用整数是为了便于读者好观察排序前后的变化： arr = np.random.randint( 40, size=(3,4) ) print( arr ) [[10 3 38 38] [27 32 14 11] [11 5 11 0]] 第一种 arr.sort()，对第一列排序，发现 arr 的元素改变了。 arr[:, 0].sort() print( arr ) [[10 3 38 38] [11 32 14 11] [27 5 11 0]] 第二种 np.sort(arr)，对第二列排序，但是 arr 的元素不变。 np.sort(arr[:,1]) array([ 3, 5, 32]) print( arr ) [[10 3 38 38] [11 32 14 11] [27 5 11 0]] 此外也可以在不同的轴上排序，对于二维数组，在「轴 0」上排序是「跨行」排序，在「轴 1」上排序是「跨列」排序。 arr.sort(axis=1) print( arr ) [[ 3 10 38 38] [11 11 14 32] [ 0 5 11 27]] 间接排序 有时候我们不仅仅只想排序数组，还想在排序过程中提取每个元素在原数组对应的索引(index)，这时 argsort() 就派上用场了。以排列下面五个学生的数学分数为例： score = np.array([100, 60, 99, 80, 91]) idx = score.argsort()#得到排序索引 print( idx ) [1 3 4 2 0] 这个 idx = [1 3 4 2 0] 怎么理解呢？很简单，排序完之后分数应该是 [60 80 91 99 100]， 60，即 score[1] 排在第0位， 因此 idx[0] =1 80，即 score[3] 排在第1 位， 因此 idx[1] =3 91，即 score[4] 排在第2 位， 因此 idx[2] =4 99，即 score[2] 排在第3 位， 因此 idx[3] =2 100，即 score[0] 排在第4 位， 因此 idx[4] =0 用这个 idx 对 score 做一个「花式索引」得到 (还记得上贴的内容吗？) print( score[idx] ) [ 60 80 91 99 100] 再看一个二维数组的例子。 arr = np.random.randint( 40, size=(3,4) ) print( arr ) [[38 14 23 19] [15 8 38 37] [ 4 0 21 23]] 对其第一行 arr[0] 排序，获取索引，在应用到所用行上。 arr[:, arr[0].argsort()] array([[14, 19, 23, 38], [ 8, 37, 38, 15], [ 0, 23, 21, 4]]) 这不就是「花式索引」吗？来我们分解一下以上代码，先看看索引。传入[索引] print( arr[0].argsort() ) [1 3 2 0] 「花式索引」来了，结果和上面一样的。 arr[:, [2, 0, 3, 1]] array([[23, 38, 19, 14], [38, 15, 37, 8], [21, 4, 23, 0]]) 插入和删除 和列表一样，我们可以给 numpy 数组 用insert()函数在某个特定位置之前插入元素 用delete()函数删除某些特定元素 a = np.arange(6) print( a ) print( np.insert(a, 1, 100) ) print( np.delete(a, [1,3]) ) [0 1 2 3 4 5] [ 0 100 1 2 3 4 5] [0 2 4 5] 复制 用copy()函数来复制数组 a 得到 a_copy，很明显，改变 a_copy 里面的元素不会改变 a。 a = np.arange(6) a_copy = a.copy() print( 'Before changing value, a is', a ) print( 'Before changing value, a_copy is', a_copy ) a_copy[-1] = 99 print( 'After changing value, a_copy is', a_copy ) print( 'After changing value, a is', a ) Before changing value, a is [0 1 2 3 4 5] Before changing value, a_copy is [0 1 2 3 4 5] After changing value, a_copy is [ 0 1 2 3 4 99] After changing value, a is [0 1 2 3 4 5] ","date":"2020-05-22","objectID":"/20200522/:1:4","tags":["python","数学建模"],"title":"NumPy (下)","uri":"/20200522/"},{"categories":["python","数学建模"],"content":"5数组的计算 本节介绍两大类数组计算，具体有 元素层面 (element-wise) 计算 广播机制 (broadcasting) 计算 ","date":"2020-05-22","objectID":"/20200522/:2:0","tags":["python","数学建模"],"title":"NumPy (下)","uri":"/20200522/"},{"categories":["python","数学建模"],"content":"5.1 元素层面计算 Numpy 数组元素层面计算包括： 二元运算 (binary operation)：加减乘除 数学函数：倒数、平方、指数、对数 比较运算 (comparison) 先定义两个数组 arr1 和 arr2。 arr1 = np.array([[1., 2., 3.], [4., 5., 6.]]) arr2 = np.ones((2,3)) * 2 print( arr1 ) print( arr2 ) [[1. 2. 3.] [4. 5. 6.]] [[2. 2. 2.] [2. 2. 2.]] 加、减、乘、除 print( arr1 + arr2 + 1 ) print( arr1 - arr2 ) print( arr1 * arr2 ) print( arr1 / arr2 ) [[4. 5. 6.] [7. 8. 9.]] [[-1. 0. 1.] [ 2. 3. 4.]] [[ 2. 4. 6.] [ 8. 10. 12.]] [[0.5 1. 1.5] [2. 2.5 3. ]] 倒数、平方、指数、对数 print( 1 / arr1 ) print( arr1 ** 2 ) print( np.exp(arr1) ) print( np.log(arr1) ) [[1. 0.5 0.33333333] [0.25 0.2 0.16666667]] [[ 1. 4. 9.] [16. 25. 36.]] [[ 2.71828183 7.3890561 20.08553692] [ 54.59815003 148.4131591 403.42879349]] [[0. 0.69314718 1.09861229] [1.38629436 1.60943791 1.79175947]] 比较 arr1 \u003e arr2 arr1 \u003e 3 array([[False, False, False], [ True, True, True]]) 从上面结果可知 「数组和数组间的二元运算」都是在元素层面上进行的 「作用在数组上的数学函数」都是作用在数组的元素层面上的。 「数组和数组间的比较」都是在元素层面上进行的 但是在「数组和标量间的比较」时，python 好像先把 3 复制了和 arr1 形状一样的数组 [[3,3,3], [3,3,3]]，然后再在元素层面上作比较。上述这个复制标量的操作叫做「广播机制」，是 NumPy 里最重要的一个特点，在下一节会详细讲到。 ","date":"2020-05-22","objectID":"/20200522/:2:1","tags":["python","数学建模"],"title":"NumPy (下)","uri":"/20200522/"},{"categories":["python","数学建模"],"content":"5.2 广播机制计算 广播的引出 当两个数组的形状并不相同的时候，我们可以通过扩展数组的方法来实现相加、相减、相乘等操作，这种机制叫做广播（broadcasting）。 比如，一个二维数组减去列平均值，来对数组的每一列进行距平化处理： arr = np.random.randn(4,3) #shape(4,3) arr_mean = arr.mean(0) #shape(3,) demeaned = arr -arr_mean print(arr) print(arr_mean) print(demeaned) [[ 0.48226402 1.20876697 -0.67351982] [ 0.65606798 -1.16182488 -1.68726346] [-0.92629614 0.49865982 -0.07100581] [ 0.73134776 -0.28327924 0.14857151]] [ 0.23584591 0.06558067 -0.5708044 ] [[ 0.24641812 1.1431863 -0.10271542] [ 0.42022208 -1.22740555 -1.11645907] [-1.16214204 0.43307915 0.49979858] [ 0.49550185 -0.34885991 0.71937591]] 很明显上式arr和arr_mean维度并不形同，但是它们可以进行相减操作，这就是通过广播机制来实现的。 广播的原则 如果两个数组的后缘维度（trailing dimension，即从末尾开始算起的维度）的轴长度相符，或其中的一方的长度为1，则认为它们是广播兼容的。广播会在缺失和（或）长度为1的维度上进行。 这句话乃是理解广播的核心。广播主要发生在两种情况，一种是两个数组的维数不相等，但是它们的后缘维度的轴长相符，另外一种是有一方的长度为1。 数组维度不同，后缘维度的轴长相符 我们来看一个例子： import numpy as np arr1 = np.array([[0, 0, 0],[1, 1, 1],[2, 2, 2], [3, 3, 3]]) #arr1.shape = (4,3) arr2 = np.array([1, 2, 3]) #arr2.shape = (3,) arr_sum = arr1 + arr2 print(arr_sum) [[1 2 3] [2 3 4] [3 4 5] [4 5 6]] 上例中arr1的shape为（4,3），arr2的shape为（3，）。可以说前者是二维的，而后者是一维的。但是它们的后缘维度相等，arr1的第二维长度为3，和arr2的维度相同。arr1和arr2的shape并不一样，但是它们可以执行相加操作，这就是通过广播完成的，在这个例子当中是将arr2沿着0轴进行扩展。 上面程序当中的广播如下图所示(一维数据在轴0上的广播): 同样的例子还有(三维数据在轴0上的广播)： 从上面的图可以看到，（3,4,2）和（4,2）的维度是不相同的，前者为3维，后者为2维。但是它们后缘维度的轴长相同，都为（4,2），所以可以沿着0轴进行广播。 同样，还有一些例子：（4,2,3）和（2,3）是兼容的，（4,2,3）还和（3）是兼容的，后者需要在两个轴上面进行扩展。 数组维度相同，其中有个轴为1 我们来看下面的例子： import numpy as np arr1 = np.array([[0, 0, 0],[1, 1, 1],[2, 2, 2], [3, 3, 3]]) #arr1.shape = (4,3) arr2 = np.array([[1],[2],[3],[4]]) #arr2.shape = (4, 1) arr_sum = arr1 + arr2 print(arr_sum) [[1 1 1] [3 3 3] [5 5 5] [7 7 7]] arr1的shape为（4,3），arr2的shape为（4,1），它们都是二维的，但是第二个数组在1轴上的长度为1，所以，可以在1轴上面进行广播，如下图所示(二维数组在轴1上的广播)： 在这种情况下，两个数组的维度要保证相等，其中有一个轴的长度为1，这样就会沿着长度为1的轴进行扩展。这样的例子还有：（4,6）和（1,6） 。（3,5,6）和（1,5,6）、（3,1,6）、（3,5,1），后面三个分别会沿着0轴，1轴，2轴进行广播。 人们经常需要通过算术运算过程将较低维度的数组在除0轴以外的其他轴向上广播。根据广播的原则，较小数组的“广播维”必须为1。 对于三维的情况，在三维中的任何一维上广播其实也就是将数据重塑为兼容的形状而已。下图说明了要在三维数组各维度上广播的形状需求(能在该三维数组上广播的二维数组的形状)。 ","date":"2020-05-22","objectID":"/20200522/:2:2","tags":["python","数学建模"],"title":"NumPy (下)","uri":"/20200522/"},{"categories":["python","数学建模"],"content":"6 总结 NumPy 篇终于完结！即上贴讨论过的数组创建、数组存载和数组获取，本贴讨论了数组变形、数组计算。 数组变形有以下重要操作： 改变维度的重塑和打平 改变分合的合并和分裂 复制本质的重复和拼接 其他排序插入删除复制 数组计算有以下重要操作： 元素层面：四则运算、函数，比较 广播机制：太重要了，大量用于科学计算和机器学习中！ ","date":"2020-05-22","objectID":"/20200522/:3:0","tags":["python","数学建模"],"title":"NumPy (下)","uri":"/20200522/"},{"categories":["python","爬虫"],"content":"前言 需要下载Chrome或Firefox的driver，Chrome内核81.440与Firefox内核74.0下载链接如下： Firefox Chrome 其他版本请在搜索引擎查找，本篇使用该版本，注意，driver下载后需要配置对应内核的游览器，电脑本身需要有该内核的游览器。 ","date":"2020-05-17","objectID":"/20200517/:1:0","tags":["python","爬虫"],"title":"Selenium的web自动化操作03(语法补充)","uri":"/20200517/"},{"categories":["python","爬虫"],"content":"正文 ","date":"2020-05-17","objectID":"/20200517/:2:0","tags":["python","爬虫"],"title":"Selenium的web自动化操作03(语法补充)","uri":"/20200517/"},{"categories":["python","爬虫"],"content":"Xpath语法简介 可以发现CSS选择元素非常灵活、强大。 还有一种灵活、强大的选择元素的方式，就是使用Xpath表达式。 XPath (XML Path Language) 是由国际标准化组织W3C指定的，用来在XML和HTML文档中选择节点的语言。 目前主流浏览器 (chrome、firefox，edge，safari) 都支持XPath语法，xpath有 1 和 2 两个版本，目前浏览器支持的是 xpath 1的语法。 既然已经有了CSS，为什么还要学习Xpath呢？因为 有些场景用css选择web元素很麻烦，而xpath却比较方便。 另外Xpath还有其他领域会使用到，比如爬虫框架Scrapy，手机App框架Appium。 测试网址：http://cdn1.python3.vip/files/selenium/test1.html 按F12打开调试窗口，点击Elements标签。 要验证Xpath语法是否能成功选择元素，也可以像验证CSS语法那样，按组合键Ctrl + F就会出现搜索框 xpath语法中，整个HTML文档根节点用’/‘表示，如果我们想选择的是根节点下面的html节点，则可以在搜索框输入 /html 如果输入下面的表达式 /html/body/div 这个表达式表示选择html下面的body下面的div元素。 注意/有点像CSS中的\u003e,表示直接子节点关系。 ","date":"2020-05-17","objectID":"/20200517/:3:0","tags":["python","爬虫"],"title":"Selenium的web自动化操作03(语法补充)","uri":"/20200517/"},{"categories":["python","爬虫"],"content":"绝对路径选择 从根节点开始的，到某个节点，每层都依次写下来，每层之间用/分隔的表达式，就是某元素的绝对路径 上面的xpath表达式/html/body/div，就是一个绝对路径的xpath表达式，等价于css表达式html\u003ebody\u003ediv 自动化程序要使用Xpath来选择web元素，应该调用WebDriver对象的方法find_element_by_xpath或者find_elements_by_xpath，像这样： elements = driver.find_elements_by_xpath(\"/html/body/div\") ","date":"2020-05-17","objectID":"/20200517/:3:1","tags":["python","爬虫"],"title":"Selenium的web自动化操作03(语法补充)","uri":"/20200517/"},{"categories":["python","爬虫"],"content":"相对路径选择 有的时候，我们需要选择网页中某个元素，不管它在什么位置 。 比如，选择示例页面的所有标签名为div的元素，如果使用css表达式，直接写一个div就行了。 那xpath怎么实现同样的功能呢？xpath需要前面加//, 表示从当前节点往下寻找所有的后代元素,不管它在什么位置。 所以xpath表达式，应该这样写：//div ‘//’ 符号也可以继续加在后面,比如，要选择所有的div元素里面的所有的p元素 ，不管div在什么位置，也不管p元素在div下面的什么位置，则可以这样写//div//p 对应的自动化程序如下 elements = driver.find_elements_by_xpath(\"//div//p\") 如果使用CSS选择器，对应代码如下 elements = driver.find_elements_by_css_selector(\"div p\") 如果，要选择所有的div元素里面的直接子节点p，xpath就应该这样写了//div/p 如果使用CSS选择器，则为div \u003e p ","date":"2020-05-17","objectID":"/20200517/:3:2","tags":["python","爬虫"],"title":"Selenium的web自动化操作03(语法补充)","uri":"/20200517/"},{"categories":["python","爬虫"],"content":"通配符 如果要选择所有div节点的所有直接子节点，可以使用表达式//div/* *是一个通配符，对应任意节点名的元素，等价于CSS选择器div \u003e * 代码如下： elements = driver.find_elements_by_xpath(\"//div/*\") for element in elements: print(element.get_attribute('outerHTML')) ","date":"2020-05-17","objectID":"/20200517/:3:3","tags":["python","爬虫"],"title":"Selenium的web自动化操作03(语法补充)","uri":"/20200517/"},{"categories":["python","爬虫"],"content":"根据属性选择 Xpath 可以根据属性来选择元素。 根据属性来选择元素是通过这种格式来的[@属性名='属性值'] 注意： 属性名注意前面有个@ 属性值一定要用引号，可以是单引号，也可以是双引号 根据id属性选择 选择id为west的元素，可以这样//*[@id='west'] 根据class属性选择 选择所有select元素中class为single_choice的元素，可以这样//select[@class='single_choice'] 如果一个元素class有多个，比如 \u003cp id=\"beijing\" class='capital huge-city'\u003e 北京 \u003c/p\u003e 如果要选它，对应的xpath就应该是//p[@class=\"capital huge-city\"] 不能只写一个属性，像这样//p[@class=\"capital\"]则不行 根据其他属性 同样的道理，我们也可以利用其它的属性选择 比如选择具有multiple属性的所有页面元素，可以这样//*[@multiple] 属性值包含字符串 要选择style属性值包含color字符串的页面元素，可以这样//*[contains(@style,'color')] 要选择style属性值以color字符串开头的页面元素，可以这样//*[starts-with(@style,'color')] style属性值以某个字符串结尾的页面元素，大家可以推测是//*[ends-with(@style,'color')]，但是很遗憾，这是xpath 2.0 的语法，目前浏览器都不支持。 按次序选择 前面学过css表达式可以根据元素在父节点中的次序选择，非常实用。 xpath也可以根据次序选择元素。语法比css更简洁，直接在方括号中使用数字表示次序 比如 某类型第几个子元素 比如 要选择p类型第2个的子元素，就是 //p[2] 注意，选择的是p类型第2个的子元素，不是第2个子元素，并且是p类型 。 再比如，要选取父元素为div中的p类型第2个子元素 //div/p[2] ","date":"2020-05-17","objectID":"/20200517/:3:4","tags":["python","爬虫"],"title":"Selenium的web自动化操作03(语法补充)","uri":"/20200517/"},{"categories":["python","爬虫"],"content":"第几个子元素 也可以选择第2个子元素，不管是什么类型，采用通配符 比如 选择父元素为div的第2个子元素，不管是什么类型 //div/*[2] ","date":"2020-05-17","objectID":"/20200517/:3:5","tags":["python","爬虫"],"title":"Selenium的web自动化操作03(语法补充)","uri":"/20200517/"},{"categories":["python","爬虫"],"content":"某类型倒数第几个子元素 当然也可以选取倒数第几个子元素 比如： 选取p类型倒数第1个子元素 —\u003e //p[last()] 选取p类型倒数第2个子元素 —\u003e //p[last()-1] 选择父元素为div中p类型倒数第3个子元素 —\u003e//div/p[last()-2] ","date":"2020-05-17","objectID":"/20200517/:3:6","tags":["python","爬虫"],"title":"Selenium的web自动化操作03(语法补充)","uri":"/20200517/"},{"categories":["python","爬虫"],"content":"范围选择 xpath还可以选择子元素的次序范围。 比如， 选取option类型第1到2个子元素 //option[position()\u003c=2] 或者 //option[position()\u003c3] 选择class属性为multi_choice的前3个子元素 //*[@class='multi_choice']/*[position()\u003c=3] 选择class属性为multi_choice的后3个子元素 //*[@class='multi_choice']/*[position()\u003e=last()-2] 为什么不是 last()-3 呢？因为 last()本身代表最后一个元素 last()-1本身代表倒数第2个元素 last()-2本身代表倒数第3个元素 ","date":"2020-05-17","objectID":"/20200517/:3:7","tags":["python","爬虫"],"title":"Selenium的web自动化操作03(语法补充)","uri":"/20200517/"},{"categories":["python","爬虫"],"content":"组选择、父节点、兄弟节点 组选择 css有组选择，可以同时使用多个表达式，多个表达式选择的结果都是要选择的元素 css组选择，表达式之间用逗号隔开 xpath也有组选择，是用竖线隔开多个表达式 比如，要选所有的option元素和所有的h4元素，可以使用 #xpath //option | //h4 等同于CSS选择器 #css option , h4 再比如，要选所有的class为single_choice和class为multi_choice的元素，可以使用 #xpath //*[@class='single_choice'] | //*[@class='multi_choice'] 等同于CSS选择器 #css .single_choice , .multi_choice ","date":"2020-05-17","objectID":"/20200517/:3:8","tags":["python","爬虫"],"title":"Selenium的web自动化操作03(语法补充)","uri":"/20200517/"},{"categories":["python","爬虫"],"content":"选择父节点 xpath可以选择父节点，这是css做不到的。 某个元素的父节点用/..表示 比如，要选择id为china的节点的父节点，可以这样写//*[@id='china']/.. 。 当某个元素没有特征可以直接选择，但是它有子节点有特征， 就可以采用这种方法，先选择子节点，再指定父节点。 还可以继续找上层父节点，比如//*[@id='china']/../../.. ","date":"2020-05-17","objectID":"/20200517/:3:9","tags":["python","爬虫"],"title":"Selenium的web自动化操作03(语法补充)","uri":"/20200517/"},{"categories":["python","爬虫"],"content":"兄弟节点选择 前面学过css选择器，要选择某个节点的后续兄弟节点，用波浪线 xpath也可以选择后续兄弟节点，用这样的语法following-sibling:: 比如，要选择class为single_choice的元素的所有后续兄弟节点//*[@class='single_choice']/following-sibling::* 等同于CSS选择器.single_choice ~ * 如果，要选择后续节点中的div节点，就应该这样写//*[@class='single_choice']/following-sibling::div xpath还可以选择前面的兄弟节点，用这样的语法preceding-sibling:: 比如，要选择class为single_choice的元素的所有前面的兄弟节点//*[@class='single_choice']/preceding-sibling::* 而CSS选择器目前还没有方法选择前面的兄弟节点 要了解更多Xpath选择语法，可以点击这里，打开Xpath选择器参考手册 ","date":"2020-05-17","objectID":"/20200517/:3:10","tags":["python","爬虫"],"title":"Selenium的web自动化操作03(语法补充)","uri":"/20200517/"},{"categories":["python","爬虫"],"content":"selenium 注意点 原代码： 先选择示例网页中，id是china的元素\r然后通过这个元素的WebElement对象，使用find_elements_by_xpath，选择里面的p元素，\r# 先寻找id是china的元素 china = wd.find_element_by_id('china') # 再选择该元素内部的p元素 elements = china.find_elements_by_xpath('//p') # 打印结果 for element in elements: print('----------------') print(element.get_attribute('outerHTML')) 运行发现，打印的不仅仅是china内部的p元素，而是所有的p元素。 要在某个元素内部使用xpath选择元素，需要在xpath表达式最前面加个点。 像这样 elements = china.find_elements_by_xpath('.//p') ","date":"2020-05-17","objectID":"/20200517/:3:11","tags":["python","爬虫"],"title":"Selenium的web自动化操作03(语法补充)","uri":"/20200517/"},{"categories":["python","数学建模"],"content":"前言 ","date":"2020-05-12","objectID":"/20200512/:0:0","tags":["python","数学建模"],"title":"NumPy (上)","uri":"/20200512/"},{"categories":["python","数学建模"],"content":"本篇鸣谢 马川——燕大 增删整理，王圣元——原创文章，与原文不同之处包含我的学习记录。 匹配Jupyter Notebook的ipynb文档链接下载地址如下 源文档 ","date":"2020-05-12","objectID":"/20200512/:0:1","tags":["python","数学建模"],"title":"NumPy (上)","uri":"/20200512/"},{"categories":["python","数学建模"],"content":"0 引言 Numpy 是 Python 专门处理高维数组 (high dimensional array) 的计算的包，每次使用它遇到问题都会它的官网 (www.numpy.org). 去找答案。 在使用 numpy 之前，需要引进它，语法如下： import numpy 这样你就可以用 numpy 里面所有的内置方法 (build-in methods) 了，比如求和与均值。 numpy.sum() numpy.mean() 但是每次写 numpy 字数有点多，通常我们给 numpy 起个别名 np，用以下语法，这样所有出现 numpy 的地方都可以用 np 替代。 import numpy as np 为什么要专门学习数组呢？看下面「numpy 数组」和「列表」之间的计算效率对比：两个大小都是 1000000，把每个元素翻倍，运行 10 次用 %time 记时。 my_arr = np.arange(1000000) my_list = list(range(1000000)) %time for _ in range(10): my_arr2 = my_arr * 2 Wall time: 34.3 ms %time for _ in range(10): my_list2 = [x * 2 for x in my_list] Wall time: 1.8 s 「numpy 数组」效率是「列表」效率的10到100倍（甚至更快），并且使用的内存更少。如果元素全是数值型变量 (numerical variable)，那么 numpy 数组明显是个很好的数据结构。 学习 numpy 还是遵循的 Python 里「万物皆对象」的原则，既然把数组当对象，我们就按着数组的创建、数组的存载、数组的获取、数组的变形、和数组的计算来盘一盘 NumPy，目录如下： 由于篇幅原因，NumPy 系列分两贴，上贴讲前三节的内容，下帖讲后两节的内容。 ","date":"2020-05-12","objectID":"/20200512/:1:0","tags":["python","数学建模"],"title":"NumPy (上)","uri":"/20200512/"},{"categories":["python","数学建模"],"content":"1 数组的创建 ","date":"2020-05-12","objectID":"/20200512/:2:0","tags":["python","数学建模"],"title":"NumPy (上)","uri":"/20200512/"},{"categories":["python","数学建模"],"content":"1.1 初次印象 数组 (array) 是相同类型的元素 (element) 的集合所组成数据结构 (data structure)。numpy 数组中的元素用的最多是「数值型」元素，平时我们说的一维、二维、三维数组长下面这个样子 (对应着线、面、体)。四维数组很难被可视化。 注意一个关键字 axis，中文叫「轴」，一个数组是多少维度就有多少根轴。由于 Python 计数都是从 0 开始的，那么 第 1 维度 = axis 0 第 2 维度 = axis 1 第 3 维度 = axis 2 但这些数组只可能在平面上打印出来，那么它们 (高于二维的数组) 的表现形式稍微有些不同。 分析上图各个数组的在不同维度上的元素： 一维数组：轴 0 有 3 个元素 二维数组：轴 0 有 2 个元素，轴 1 有 3 个元素 三维数组：轴 0有 2 个元素 (2 块)，轴 1 有 2 个元素，轴 2 有 3 个元素 四维数组：轴 0 有 2 个元素 (2 块)，轴 1 有 2 个元素 (2 块)，轴 2 有 2 个元素，轴 3 有 3 个元素 ","date":"2020-05-12","objectID":"/20200512/:2:1","tags":["python","数学建模"],"title":"NumPy (上)","uri":"/20200512/"},{"categories":["python","数学建模"],"content":"1.2 创建数组 带着上面这个对轴的认识，接下来我们用代码来创建 numpy 数组，有三种方式： 按步就班的 np.array() 用在列表和元组上 定隔定点的 np.arange() 和 np.linspace() 一步登天的 np.ones(), np.zeros(), np.eye() 和 np.random.random() ","date":"2020-05-12","objectID":"/20200512/:2:2","tags":["python","数学建模"],"title":"NumPy (上)","uri":"/20200512/"},{"categories":["python","数学建模"],"content":"按步就班法 给了「列表」和「元组」原材料，用 np.array() 包装一下便得到 numpy 数组。 l = [3.5, 5, 2, 8, 4.2] np.array(l) array([3.5, 5. , 2. , 8. , 4.2]) t = (3.5, 5, 2, 8, 4.2) np.array(t) array([3.5, 5. , 2. , 8. , 4.2]) 注意，numpy 数组的输出都带有 array() 的字样，里面的元素用「中括号 []」框住。 ","date":"2020-05-12","objectID":"/20200512/:2:3","tags":["python","数学建模"],"title":"NumPy (上)","uri":"/20200512/"},{"categories":["python","数学建模"],"content":"定隔定点法 更常见的两种创建 numpy 数组方法： 定隔的 arange：固定元素大小间隔 定点的 linspace：固定元素个数 先看 arange 例子： print( np.arange(8) ) print( np.arange(2,8) ) print( np.arange(2,8,2)) [0 1 2 3 4 5 6 7] [2 3 4 5 6 7] [2 4 6] 函数 arange 的参数为起点 , 终点 , 间隔 arange(start , stop , step) 其中 stop 必须要有，start 为 0和 step 没有的话默认为 1。对着这个规则看看上面各种情况的输出。 注：用函数 print 打印 numpy 数组就没有 array() 的字样了，只用其内容，而且元素之间的「逗号」也没有了。 再看 linspace 的例子：第三个参数输入，等分段落 print( np.linspace(2,6,3) ) print( np.linspace(3,8,11,endpoint) ) #linescape里面有一个参数endpoint=False,意思是最后一个数字不取到，默认取到最后一个数字。 [2. 4. 6.] [3. 3.5 4. 4.5 5. 5.5 6. 6.5 7. 7.5 8. ] 函数 linspace 的参数为起点 , 终点 , 点数 (左右区间都是闭合的) linspace (start , stop , num) 其中 start 和 stop 必须要有，num 没有的话默认为 50。对着这个规则看看上面各种情况的输出。 ","date":"2020-05-12","objectID":"/20200512/:2:4","tags":["python","数学建模"],"title":"NumPy (上)","uri":"/20200512/"},{"categories":["python","数学建模"],"content":"一步登天法 NumPy 还提供一次性 用 zeros(n) 创建全是 0 的 n 维数组 用 ones(n) 创建全是 1 的 n 维数组 用 random(n,行数,列数) 创建随机 n 维数组 用 eye() 创建对角矩阵 (二维数组) 对于前三种，由于输出是 n 为数组，它们的参数是一个「标量」或「元组类型的形状」，下面三个例子一看就懂了： print( np.zeros(5) ) # 标量5代表形状(5,) print( np.ones((2,3)) ) print( np.random.random((2,3,4)) ) [0. 0. 0. 0. 0.] [[1. 1. 1.] [1. 1. 1.]] [[[0.14428606 0.18096881 0.62007296 0.6772929 ] [0.1455759 0.8892189 0.62079121 0.11571584] [0.35057464 0.15843398 0.95314951 0.00487452]] [[0.2036554 0.77356948 0.70228873 0.62647952] [0.97942093 0.16552439 0.37465336 0.11141434] [0.75365885 0.20963809 0.87369812 0.47554261]]] 对于函数 eye()，它的参数就是一个标量，控制矩阵的行数或列数： np.eye(4) array([[1., 0., 0., 0.], [0., 1., 0., 0.], [0., 0., 1., 0.], [0., 0., 0., 1.]]) 此外还可以设定 eye() 里面的参数 k 默认设置 k = 0 代表 1 落在对角线上 k = 1 代表 1 落在对角线右上方 k = -1 代表 1 落在对角线左下方 np.eye(4, k=1) array([[0., 1., 0., 0.], [0., 0., 1., 0.], [0., 0., 0., 1.], [0., 0., 0., 0.]]) ","date":"2020-05-12","objectID":"/20200512/:2:5","tags":["python","数学建模"],"title":"NumPy (上)","uri":"/20200512/"},{"categories":["python","数学建模"],"content":"1.3 数组性质 还记得 Python 里面「万物皆对象」么？numpy 数组也不例外，那么我们来看看数组有什么属性 (attributes) 和方法 (methods)。 ","date":"2020-05-12","objectID":"/20200512/:2:6","tags":["python","数学建模"],"title":"NumPy (上)","uri":"/20200512/"},{"categories":["python","数学建模"],"content":"一维数组 用按步就班的 np.array() 带列表生成数组 arr arr = np.array([3.5, 5, 2, 8, 4.2]) arr array([3.5, 5. , 2. , 8. , 4.2]) 现在你应该会用 dir(arr) 来查看数组的属性了吧，看完之后我们对 type, ndim, len(), size, shape, stride, dtype 几个感兴趣，打印出来看看： print( 'The type is', type(arr) ) print( 'The dimension is', arr.ndim ) print( 'The length of array is', len(arr) ) print( 'The number of elements is', arr.size ) print( 'The shape of array is', arr.shape ) print( 'The stride of array is', arr.strides ) print( 'The type of elements is', arr.dtype ) The type is \u003cclass 'numpy.ndarray'\u003e The dimension is 1 The length of array is 5 The number of elements is 5 The shape of array is (5,) The stride of array is (8,) The type of elements is float64 根据结果我们来看看上面属性到底是啥： type：数组类型，当然是 numpy.ndarray ndim：维度个数是 1 len()：数组长度为 5 (注意这个说法只对一维数组有意义) size：数组元素个数为 5 shape：数组形状，即每个维度的元素个数 (用元组来表示)，只有一维，元素个数为 5，写成元组形式是 (5,) strides：跨度，即在某一维度下为了获取到下一个元素需要「跨过」的字节数 (用元组来表示)，float64 是 8 个字节数 (bytes)，因此跨度为 8 dtype：数组元素类型，是双精度浮点 (注意和 type 区分) 注意 strides，这个概念对于解决引言的「转置高维数组」问题很重要。一图胜千言。 咦，为什么有个 Python View 和 Memory Block 啊？这两个不是一样的么？对一维数组来说，「Python 视图」看它和「内存块」存储它的形式是一样的，但对二维数组甚至高维数组呢？ ","date":"2020-05-12","objectID":"/20200512/:2:7","tags":["python","数学建模"],"title":"NumPy (上)","uri":"/20200512/"},{"categories":["python","数学建模"],"content":"二维数组 还是用按步就班的 np.array() 带二维列表生成二维数组 arr2d l2 = [[1, 2, 3], [4, 5, 6]] arr2d = np.array(l2) arr2d array([[1, 2, 3], [4, 5, 6]]) 打印属性出来看看： print( 'The type is', type(arr2d) ) print( 'The dimension is', arr2d.ndim ) print( 'The length of array is', len(arr2d) ) print( 'The number of elements is', arr2d.size ) print( 'The shape of array is', arr2d.shape ) print( 'The stride of array is', arr2d.strides ) print( 'The type of elements is', arr2d.dtype ) The type is \u003cclass 'numpy.ndarray'\u003e The dimension is 2 The length of array is 2 The number of elements is 6 The shape of array is (2, 3) The stride of array is (12, 4) The type of elements is int32 同样，我们来分析一下上面属性： $\\color{red}{type}$：数组类型 numpy.ndarray $\\color{red}{ndim}$：维度个数是 2 $\\color{red}{len()}$：数组长度为 2 (严格定义 len 是数组在「轴 0」的元素个数) $\\color{red}{size}$：数组元素个数为 6 $\\color{red}{shape}$：数组形状 (2, 3） $\\color{red}{strides}$：跨度 (12, 4) 看完下图再解释 $\\color{red}{dtype}$：数组元素类型 int32 对于二维数组，「Python 视图」看它和「内存块」存储它的形式是不一样的，如下图所示： 在 numpy 数组中，默认的是行主序 (row-major order)，意思就是每行的元素在内存块中彼此相邻，而列主序 (column-major order) 就是每列的元素在内存块中彼此相邻。 回顾跨度 (stride) 的定义，即在某一维度下为了获取到下一个元素需要「跨过」的字节数。注：每一个 int32 元素是 4 个字节数。对着上图： 第一维度(轴0)：沿着它获取下一个元素需要跨过 3 个元素，即 12 = 3×4 个字节 第二维度 (轴 1)：沿着它获取下一个元素需要跨过 1 个元素，即 4 = 1×4 个字节 因此该二维数组的跨度为 (12, 4)。 ","date":"2020-05-12","objectID":"/20200512/:2:8","tags":["python","数学建模"],"title":"NumPy (上)","uri":"/20200512/"},{"categories":["python","数学建模"],"content":"n 维数组 用 np.random.random() 来生成一个多维数组： arr4d = np.random.random( (2,2,2,3) ) print(arr4d) [[[[0.3655641 0.14651352 0.05611382] [0.09145433 0.66341311 0.93410998]] [[0.32589061 0.21609648 0.65855021] [0.01984889 0.29624348 0.38033199]]] [[[0.57298013 0.5646688 0.80097287] [0.00362119 0.59812186 0.9974391 ]] [[0.726032 0.29853497 0.66405837] [0.83010788 0.95585422 0.13115111]]]] 里面具体元素是什么不重要，arr4d 的属性比较重要： print( 'The type is', type(arr4d) ) print( 'The dimension is', arr4d.ndim ) print( 'The length of array is', len(arr4d) ) print( 'The number of elements is', arr4d.size ) print( 'The shape of array is', arr4d.shape ) print( 'The stride of array is', arr4d.strides ) print( 'The type of elements is', arr4d.dtype ) The type is \u003cclass 'numpy.ndarray'\u003e The dimension is 4 The length of array is 2 The number of elements is 24 The shape of array is (2, 2, 2, 3) The stride of array is (96, 48, 24, 8) The type of elements is float64 除了 stride，都好理解，请根据下图好好想想为什么 stride 是 (96, 48, 24, 8)？[Hint: 一个 float64 的元素占 8 个字节] 算了还是分析一下吧 (免得掉粉 )。回顾跨度 (stride) 的定义，即在某一维度下为了获取到下一个元素需要「跨过」的字节数。注：每一个 float64 元素是 8 个字节数 第一维度 (轴 0)：沿着它获取下一个元素需要跨过 12 个元素，即 96 = 12×8 个字节 第二维度 (轴 1)：沿着它获取下一个元素需要跨过 6 个元素，即 48 = 6×8 个字节 第三维度 (轴 2)：沿着它获取下一个元素需要跨过 3 个元素，即 24 = 3×8 个字节 第四维度 (轴 3)：沿着它获取下一个元素需要跨过 1 个元素，即 8 = 1×8 个字节 因此该四维数组的跨度为 (96, 48, 24, 8)。 留一道思考题，strides 和 shape 有什么关系？ strides = (96, 48, 24, 8) shape = (2, 2, 2, 3) 总不能每个高维数组都用可视化的方法来算 strides 吧。 3*8 3*2*8 3*2*2*8 3*2*2*2*8 ","date":"2020-05-12","objectID":"/20200512/:2:9","tags":["python","数学建模"],"title":"NumPy (上)","uri":"/20200512/"},{"categories":["python","数学建模"],"content":"2 数组的存载 本节讲数组的「保存」和「加载」，我知道它们没什么技术含量，但是很重要。假设你已经训练完一个深度神经网络，该网络就是用无数参数来表示的。比如权重都是 numpy 数组，为了下次不用训练而重复使用，将其保存成 .npy 格式或者 .csv 格式是非常重要的。 ","date":"2020-05-12","objectID":"/20200512/:3:0","tags":["python","数学建模"],"title":"NumPy (上)","uri":"/20200512/"},{"categories":["python","数学建模"],"content":"numpy 自身的 .npy 格式 用 np.save 函数将 numpy 数组保存为 .npy 格式，具体写法如下： np.save(\"文件名\"，数组 ) arr_disk = np.arange(8) np.save(\"arr_disk\", arr_disk) arr_disk array([0, 1, 2, 3, 4, 5, 6, 7]) arr_disk.npy 保存在 Jupyter Notebook 所在的根目录下。要加载它也很简单，用 np.load( “文件名” ) 即可： np.load(\"arr_disk.npy\") array([0, 1, 2, 3, 4, 5, 6, 7]) ","date":"2020-05-12","objectID":"/20200512/:3:1","tags":["python","数学建模"],"title":"NumPy (上)","uri":"/20200512/"},{"categories":["python","数学建模"],"content":"文本 .txt 格式 用 np.savetxt 函数将 numpy 数组保存为 .txt 格式，具体写法如下： np.savetxt(“文件名”,数组 ) arr_text = np.array([[1., 2., 3.], [4., 5., 6.]]) np.savetxt(\"arr_from_text.txt\", arr_text) arr_from_text.txt 保存在 Jupyter Notebook 所在的根目录下，用 Notepad 打开看里面确实存储着 [[1,2,3], [4,5,6]]。 用 np.loadtxt( “文件名” ) 即可加载该文件 np.loadtxt(\"arr_from_text.txt\") array([[1., 2., 3.], [4., 5., 6.]]) ","date":"2020-05-12","objectID":"/20200512/:3:2","tags":["python","数学建模"],"title":"NumPy (上)","uri":"/20200512/"},{"categories":["python","数学建模"],"content":"文本 .csv 格式 另外，假设我们已经在 arr_from_csv 的 csv 文件里写进去了 [[1,2,3], [4,5,6]]，每行的元素是由「分号 ;」来分隔的，展示如下： 用 np.genfromtxt( “文件名” ) 即可加载该文件 np.genfromtxt(\"arr_from_csv.csv\") array([nan, nan]) 奇怪的是数组里面都是 nan，原因是没有设定好「分隔符 ;」，那么函数 genfromtxt 读取的两个元素是 1;2;3 4;5;6 它们当然不是数字拉，Numpy 只能用两个 nan (Not a Number) 来代表上面的四不像了。 带上「分隔符 ;」再用 np.genfromtxt( “文件名”，分隔符 ) 即可加载该文件 np.genfromtxt(\"arr_from_csv.csv\", delimiter=\";\") array([[1., 2., 3.], [4., 5., 6.]]) ","date":"2020-05-12","objectID":"/20200512/:3:3","tags":["python","数学建模"],"title":"NumPy (上)","uri":"/20200512/"},{"categories":["python","数学建模"],"content":"3 数组的获取 获取数组是通过索引 (indexing) 和切片 (slicing) 来完成的， 切片是获取一段特定位置的元素 索引是获取一个特定位置的元素 索引和切片的方式和列表一模一样。对于一维数组 arr, 切片写法是 arr[start : stop : step] 索引写法是 arr[index] 因此，切片的操作是可以用索引操作来实现的 (一个一个总能凑成一段)，只是没必要罢了。为了简化，我们在本章三节标题里把切片和索引都叫做索引。 索引数组有三种形式，正规索引 (normal indexing)、布尔索引 (boolean indexing) 和花式索引 (fancy indexing)。 ","date":"2020-05-12","objectID":"/20200512/:4:0","tags":["python","数学建模"],"title":"NumPy (上)","uri":"/20200512/"},{"categories":["python","数学建模"],"content":"3.1 正规索引 虽然切片操作可以由多次索引操作替代，但两者最大的区别在于 切片得到的是原数组的一个视图 (view) ，修改切片中的内容会改变原数组 索引得到的是原数组的一个复制 (copy)，修改索引中的内容不会改变原数组 请看下面一维数组的例子来说明上述两者的不同。 一维数组 arr = np.arange(10) arr array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) 用 arr[6] 索引第 7 个元素 (记住 Python 是从 0 开始记录位置的) arr[6] 6 把它赋给变量 a，并重新给 a 赋值 1000，但是元数组 arr 第 7 个元素的值还是 6，并没有改成 1000。 a = arr[6] a = 1000 arr array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) 用 arr[5:8] 切片第 6 到 8 元素 (记住 Python 切片包头不包尾) arr[5:8] array([5, 6, 7]) 把它赋给变量 b，并重新给 b 的第二个元素赋值 12，再看发现元数组 arr 第 7 个元素的值已经变成 12 了。 b = arr[5:8] b[1] = 12 arr array([ 0, 1, 2, 3, 4, 5, 12, 7, 8, 9]) 这就证实了切片得到原数组的视图 (view)，更改切片数据会更改原数组，而索引得到原数组的复制 (copy)， 更改索引数据不会更改原数组。希望用下面一张图可以明晰 view 和 copy 的关系。 了解完一维数组的切片和索引，类比到二维和多维数组上非常简单。 二维数组 arr2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) arr2d array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) 索引 情况一：用 arr2d[2] 来索引第三行，更严格的说法是索引「轴 0」上的第三个元素。 arr2d[2] array([7, 8, 9]) 情况二：用 arr2d[0][2] 来索引第一行第三列 arr2d[0][2] 3 索引二维数组打了两个中括号好麻烦，索引五维数组不是要打了五个中括号？还有一个简易方法，用 arr2d[0, 2] 也可以索引第一行第三列 arr2d[0,2] 3 切片 情况一：用 arr2d[:2] 切片前两行，更严格的说法是索引「轴 0」上的前两个元素。 arr2d[:2] array([[1, 2, 3], [4, 5, 6]]) 情况二：用 arr2d[:, [0,2]] 切片第一列和第三列 arr2d[:,[0,2]] array([[1, 3], [4, 6], [7, 9]]) 情况三：用 arr2d[1, :2] 切片第二行的前两个元素 arr2d[1, :2] array([4, 5]) 情况四：用 arr2d[:2, 2] 切片第三列的前两个元素 arr2d[:2, 2] array([3, 6]) ","date":"2020-05-12","objectID":"/20200512/:4:1","tags":["python","数学建模"],"title":"NumPy (上)","uri":"/20200512/"},{"categories":["python","数学建模"],"content":"3.2 布尔索引 布尔索引，就是用一个由布尔 (boolean) 类型值组成的数组来选择元素的方法。 假设我们有阿里巴巴 (BABA)，脸书 (FB) 和京东 (JD) 的 股票代码 code 数组 股票价格 price 数组：每行记录一天开盘，最高和收盘价格。 code = np.array(['BABA', 'FB', 'JD', 'BABA', 'JD', 'FB']) price = np.array([[170,177,169],[150,159,153], [24,27,26],[165,170,167], [22,23,20],[155,116,157]]) price array([[170, 177, 169], [150, 159, 153], [ 24, 27, 26], [165, 170, 167], [ 22, 23, 20], [155, 116, 157]]) 假设我们想找出 BABA 对应的股价，首先找到 code 里面是 ‘BABA’ 对应的索引 (布尔索引)，即一个值为 True 和 False 的布尔数组。 code == 'BABA' array([ True, False, False, True, False, False]) 用该索引可以获取 BABA 的股价： price[ code == 'BABA' ] array([[170, 177, 169], [165, 170, 167]]) 用该索引还可以获取 BABA 的最高和收盘价格： price[ code == 'BABA', 1: ] array([[177, 169], [170, 167]]) 再试试获取 JD 和 FB 的股价： price[ (code == 'FB')|(code == 'JD') ] array([[150, 159, 153], [ 24, 27, 26], [ 22, 23, 20], [155, 116, 157]]) 虽然下面操作没有实际意义，试试把股价小于 25 的清零。 price[ price \u003c 25 ] = 0 price array([[170, 177, 169], [150, 159, 153], [ 0, 27, 26], [165, 170, 167], [ 0, 0, 0], [155, 116, 157]]) 注：这种布尔索引的操作在 Pandas 更常用也更方便，看完 pandas 那帖后就可以忽略这一节了。 ","date":"2020-05-12","objectID":"/20200512/:4:2","tags":["python","数学建模"],"title":"NumPy (上)","uri":"/20200512/"},{"categories":["python","数学建模"],"content":"3.3 花式索引 花式索引是获取数组中想要的特定元素的有效方法。考虑下面数组： arr = np.arange(32).reshape(8,4) arr array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]]) 假设你想按特定顺序来获取第 5, 4 和 7 行时，用 arr[ [4,3,6] ] arr[ [4,3,6] ] array([[16, 17, 18, 19], [12, 13, 14, 15], [24, 25, 26, 27]]) 假设你想按特定顺序来获取倒数第 4, 3 和 6 行时 (即正数第 4, 5 和 2 行)，用 arr[ [-4,-3,-6] ] arr[ [-4,-3,-6] ] array([[16, 17, 18, 19], [20, 21, 22, 23], [ 8, 9, 10, 11]]) 此外，你还能更灵活的设定「行」和「列」中不同的索引，如下 arr[ [1,5,7,2], [0,3,1,2] ] array([ 4, 23, 29, 10]) 检查一下，上行代码获取的分别是第二行第一列、第六行第四列、第八行第二列、第三行第三列的元素，它们确实是 4, 23, 29 和 10。如果不用花式索引，就要写下面繁琐但等价的代码： np.array( [ arr[1,0], arr[5,3], arr[7,1], arr[2,2] ] ) array([ 4, 23, 29, 10]) 最后，我们可以把交换列，把原先的 [0,1,2,3] 的列换成 [0,3,1,2]。 arr[:,[0,3,1,2]] array([[ 0, 3, 1, 2], [ 4, 7, 5, 6], [ 8, 11, 9, 10], [12, 15, 13, 14], [16, 19, 17, 18], [20, 23, 21, 22], [24, 27, 25, 26], [28, 31, 29, 30]]) ","date":"2020-05-12","objectID":"/20200512/:4:3","tags":["python","数学建模"],"title":"NumPy (上)","uri":"/20200512/"},{"categories":["python","数学建模"],"content":"4 总结 本帖讨论了 NumPy 的前三节，数组创建、数组存载和数组获取。同样把 numpy 数组当成一个对象，要学习它，无非就是学习怎么 创建它：按步就班法、定隔定点法、一步登天法 存载它：保存成 .npy, .txt 和 .csv 格式，下次加载即用 获取它：一段用切片，一个用索引；有正规法、布尔法、花式法 等等，你好像还没教什么 numpy 数组硬核的东西呢，下帖讨论 NumPy 的后两节就教怎么 变形它：重塑和打平，合并和分裂，元素重复和数组重复 计算它：元素层面计算，线性代数计算，广播机制计算 欧了！下篇讨论 NumPy 系列的「数组的变形」和「数组的计算」。Stay Tuned! ","date":"2020-05-12","objectID":"/20200512/:5:0","tags":["python","数学建模"],"title":"NumPy (上)","uri":"/20200512/"},{"categories":["python","爬虫"],"content":"前言 需要下载Chrome或Firefox的driver，Chrome内核81.440与Firefox内核74.0下载链接如下： Firefox Chrome 其他版本请在搜索引擎查找，本篇使用该版本，注意，driver下载后需要配置对应内核的游览器，电脑本身需要有该内核的游览器。 ","date":"2020-05-10","objectID":"/20200510/:0:1","tags":["python","爬虫"],"title":"Selenium的web自动化操作01(环境布置与标准流程)","uri":"/20200510/"},{"categories":["python","爬虫"],"content":"web自动化操作流程 from selenium import webdriver import time wd = webdriver.Chrome(r'C:\\chromedriver.exe') ''' wd.get('https://www.baidu.com') #webdriver类选择的是整个页面 element = wd.find_element_by_id(\"kw\") #class，name，id(id比较精确) #通过webelement对象进行操作 element.send_keys('csdn')#输入 如果输入csdn\\n可以模拟回车键 element = wd.find_element_by_id('su')#点击搜索 element.click()#点击 ''' wd.get('https://blog.csdn.net/spiritLHL/article/details/105252792?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522158864611119724848300006%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.57677%2522%257D\u0026request_id=158864611119724848300006\u0026biz_id=0\u0026utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~rank_v25-1') #elements = wd.find_element_by_class_name(\"blog-content-box\") #time.sleep(2)#模拟点击等待的时间(找不找得到都会等待) wd.implicitly_wait(5)#更方便的等待时间(找不到元素才会等待) elements = wd.find_elements_by_tag_name(\"p\") for e in elements: print(e.text) #print(elements.get_attribute('href')) wd.close()#关闭游览器 ","date":"2020-05-10","objectID":"/20200510/:0:2","tags":["python","爬虫"],"title":"Selenium的web自动化操作01(环境布置与标准流程)","uri":"/20200510/"},{"categories":["python","爬虫"],"content":"find_element和find_elements的区别 使用find_elements选择的是符合条件的所有元素，如果没有符合条件的元素，回空列表 使用find_element选择的是符合条件的第一个元素，如果没有符合条件的元素，抛出异常 获取属性值—\u003e element.get_attribute('href') 获取整个元素对应html—\u003e elements.get_attribute('outerHTML') 获取某元素内所有html文本内容—\u003e elements.get_attribute('innerHTML') 获取输入框内的文本内容—\u003e elements.get_attribute('value') 获取元素文本内容 通过WebElement对象的text属性，可以获取元素展示在界面上的文本内容。 但是，有时候，元素的文本内容没有展示在界面上，或者没有完全完全展示在界面上。这时用WebElement的text属性,获取文本内容，就会有问题。 出现这种情况，可以尝试使用 element.get_attribute('innerText') 或者 element.get_attribute('textContent') ","date":"2020-05-10","objectID":"/20200510/:0:3","tags":["python","爬虫"],"title":"Selenium的web自动化操作01(环境布置与标准流程)","uri":"/20200510/"},{"categories":["python","爬虫"],"content":"css选择器 wd.find_element_by_css_selector() CSS Selector同样可以根据tag名、id 属性和class属性来选择元素`。 根据tag名选择元素的CSS Selector语法非常简单，直接写上tag名即可。 比如要选择所有的tag名为div的元素,就可以是这样 elements = wd.find_elements_by_css_selector('div') 等价于 elements = wd.find_elements_by_tag_name('div') ","date":"2020-05-10","objectID":"/20200510/:1:0","tags":["python","爬虫"],"title":"Selenium的web自动化操作01(环境布置与标准流程)","uri":"/20200510/"},{"categories":["python","爬虫"],"content":"根据属性值定位 element = wd.find_element_by_css_selector('[href=\"http://ww.miitbeian.gov.cn\"]') ","date":"2020-05-10","objectID":"/20200510/:1:1","tags":["python","爬虫"],"title":"Selenium的web自动化操作01(环境布置与标准流程)","uri":"/20200510/"},{"categories":["python","爬虫"],"content":"验证所找元素是否正确书写格式 在开发者工具中按ctrl+f，输入所写格式，若存在着会高亮显示 css选择某个class的所有，写 .class0 (表示选中名为class0的所有标签) css选择两个不同名class(都选中)(中间写英文逗号）写 .class1 , .class2 逗号左右的属性类型可以不同 ","date":"2020-05-10","objectID":"/20200510/:1:2","tags":["python","爬虫"],"title":"Selenium的web自动化操作01(环境布置与标准流程)","uri":"/20200510/"},{"categories":["python","爬虫"],"content":"父元素 父元素的第几个某类型的子节点 我们可以指定选择的元素是父元素的第几个某类型的子节点(要选择元素的上一层级为父节点) 使用 nth-of-type 比如，我们要选择class1和class2的第几个元素， 可以像上面那样思考：选择的是第2个子元素，并且是span类型 所以这样可以这样写 span:nth-child(2) 还可以这样思考，选择的是第1个span类型的子元素 所以也可以这样写 span:nth-of-type(1) 父元素的倒数第几个某类型的子节点 当然也可以反过来，选择父元素的倒数第几个某类型的子节点 使用 nth-last-of-type 像这样 p:nth-last-of-type(2) 相邻兄弟节点选择 上面的例子里面，我们要选择我们要选择class1和class2的第几个元素， 还有一种思考方法，就是选择h3后面紧跟着的兄弟节点span。 这就是一种相邻兄弟关系，可以这样写h3 + span 表示元素紧跟关系的是加号 后续所有兄弟节点选择 如果要选择是选择 h3 后面所有的兄弟节点span可以这样写 h3 ~ span ","date":"2020-05-10","objectID":"/20200510/:1:3","tags":["python","爬虫"],"title":"Selenium的web自动化操作01(环境布置与标准流程)","uri":"/20200510/"},{"categories":["python","爬虫"],"content":"内嵌 内嵌html页面的，使用wd.switch_to.frame(frame_reference)切换到内嵌 页面进行操作。 其中，frame_reference可以是frame元素的属性name或者ID。 比如这里，就可以填写iframe元素的id'frame1' 或者name属性值'innerFrame'。 像这样 wd.switch_to.frame('frame1') 或者 wd.switch_to.frame('innerFrame') 也可以填写frame所对应的WebElement对象。 我们可以根据frame的元素位置或者属性特性，使用find系列的方法，选择到该元素，得到对应的WebElement对象 比如，这里就可以写 wd.switch_to.frame(wd.find_element_by_tag_name(\"iframe\")) 然后，就可以进行后续操作frame里面的元素了。 上面的例子的正确代码如下 from selenium import webdriver wd = webdriver.Chrome(r'd:\\webdrivers\\chromedriver.exe') wd.get('http://cdn1.python3.vip/files/selenium/sample2.html') # 先根据name属性值 'innerFrame'，切换到iframe中 wd.switch_to.frame('innerFrame') # 根据 class name 选择元素，返回的是 一个列表 elements = wd.find_elements_by_class_name('plant') for element in elements: print(element.text) #如果我们已经切换到某个iframe里面进行操作了，那么后续选择和操作界面元素 就都是在这个frame里面进行的。 #这时候，如果我们又需要操作主html（我们把最外部的html称之为主html）里面的元素了呢？ #怎么切换回原来的主html呢？ #很简单，写如下代码即可 wd.switch_to.default_content() #例如，在上面 代码 操作完 frame里面的元素后， 需要 点击 主html 里面的按钮，就可以这样写 from selenium import webdriver wd = webdriver.Chrome(r'd:\\webdrivers\\chromedriver.exe') wd.get('http://cdn1.python3.vip/files/selenium/sample2.html') # 先根据name属性值 'innerFrame'，切换到iframe中 wd.switch_to.frame('innerFrame') # 根据 class name 选择元素，返回的是 一个列表 elements = wd.find_elements_by_class_name('plant') for element in elements: print(element.text) # 切换回 最外部的 HTML 中 wd.switch_to.default_content() # 然后再 选择操作 外部的 HTML 中 的元素 wd.find_element_by_id('outerbutton').click() wd.quit() 如果我们要到新的窗口里面操作，该怎么做呢？ 可以使用Webdriver对象的switch_to属性的window方法，如下所示： wd.switch_to.window(handle) 其中，参数handle需要传入什么呢？ WebDriver对象有window_handles属性，这是一个列表对象，里面包括了当前浏览器里面所有的窗口句柄。 所谓句柄，大家可以想象成对应网页窗口的一个ID， 那么我们就可以通过类似下面的代码， for handle in wd.window_handles: # 先切换到该窗口 wd.switch_to.window(handle) # 得到该窗口的标题栏字符串，判断是不是我们要操作的那个窗口 if 'Bing' in wd.title: # 如果是，那么这时候WebDriver对象就是对应的该该窗口，正好，跳出循环， break 上面代码的用意就是： 我们依次获取wd.window_handles里面的所有句柄对象，并且调用wd.switch_to.window(handle)方法，切入到每个窗口，然后检查里面该窗口对象的属性(可以是标题栏，地址栏)判断是不是我们要操作的那个窗口，如果是，就跳出循环。 同样的，如果我们在新窗口操作结束后， 还要回到原来的窗口，该怎么办？ 我们可以仍然使用上面的方法，依次切入窗口，然后根据标题栏之类的属性值判断。 还有更省事的方法: 因为我们一开始就在原来的窗口里面，我们知道进入新窗口操作完后，还要回来，可以事先保存该老窗口的句柄，使用如下方法 (mainWindow变量保存当前窗口的句柄) mainWindow = wd.current_window_handle 切换到新窗口操作完后，就可以直接像下面这样，将driver对应的对象返回到原来的窗口 (通过前面保存的老窗口的句柄，自己切换到老窗口) wd.switch_to.window(mainWindow) ","date":"2020-05-10","objectID":"/20200510/:1:4","tags":["python","爬虫"],"title":"Selenium的web自动化操作01(环境布置与标准流程)","uri":"/20200510/"},{"categories":["python","数学建模"],"content":"前言 本篇鸣谢 燕大——马川 的整理 匹配Jupyter Notebook的ipynb文档链接下载地址如下 源文档 Python编程基础 by 马川 燕大 代码胜于雄辩 Talks is cheap. Show me the code. —-Linus Torvalds(Linux操作系统的奠基者) 对于任何一种计算机语言，最重要的就是： 数据类型 控制结构 函数 这三方面一定要打牢基础。 此外 Python 非常简洁，具有很多**高级特性**，使得一行代码 (one-liner) 就能做很多事情，我们将重点介绍各种「解析式」和「高阶函数」。 shirft + Tab 看Jupyter Notebook解释文档 ","date":"2020-05-09","objectID":"/20200509/:0:0","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"00 Python概览 #直接在当前文件里运行时会调用main，但是在其他文件里import这个文件，就不会执行这个文件的main（上图解释） ","date":"2020-05-09","objectID":"/20200509/:1:0","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"Python程序实例解析 温度转换程序 根据华氏和摄氏温度定义，转换公式如下： C = ( F – 32 ) / 1.8\rF = C * 1.8 + 32\r其中，C表示摄氏温度，F表示华氏温度 #e1.1TempConvert.py TempStr = input(\"请输入带有符号的温度值: \") if TempStr[-1] in ['F','f']: C = (eval(TempStr[0:-1]) - 32)/1.8 print(\"转换后的温度是{:.2f}C\".format(C)) elif TempStr[-1] in ['C','c']: F = 1.8*eval(TempStr[0:-1]) + 32 print(\"转换后的温度是{:.2f}F\".format(F)) else: print(\"输入格式错误\") ","date":"2020-05-09","objectID":"/20200509/:1:1","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"Python语法元素分析 格式框架、注释、变量、表达式、语句函数 ","date":"2020-05-09","objectID":"/20200509/:1:2","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"缩进 1个缩进 = 4个空格 (1)用以在Python中标明代码的层次关系 (2)缩进是Python语言中表明程序框架的唯一手段 ","date":"2020-05-09","objectID":"/20200509/:1:3","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"注释 单行注释以#开头 print(\"Hello world\") #打印显示 多行注释以 ‘‘‘开头和结尾 ‘‘‘python This is a multiline comment used in Python ’’’ ","date":"2020-05-09","objectID":"/20200509/:1:4","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"命名与保留字 常量： 程序中值不发生改变的元素 变量：程序中值发生改变或者可以发生改变的元素 Python语言允许采用大写字母、小写字母、数字、下划线(_)和汉字等字符及其组合给变量命名，但名字的首字符不能是数字，中间不能出现空格，长度没有限制 注意：标识符对大小写敏感，python和Python是两个不同的名字 ","date":"2020-05-09","objectID":"/20200509/:1:5","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"字符串 Python语言中，字符串是用两个双引号“ ”或者单引号‘ ’括起来的一个或多个字符。 Python字符串的两种序号体系 str = \"Hello World\" print(str[0:-1]) ","date":"2020-05-09","objectID":"/20200509/:1:6","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"赋值语句 Python语言中，= 表示“赋值”，即将等号右侧的值计算后将结果值赋给左侧变量，包含等号（=）的语句称为“赋值语句” 同步赋值 x=5 y=10 x,y=y,x print(x,y) x,y,z=1,4,5 print(x,y,z) ","date":"2020-05-09","objectID":"/20200509/:1:7","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"input()函数 获得用户输入之前，input()函数可以包含一些提示性文字 \u003c变量\u003e = input(\u003c提示性文字\u003e) 字符型\rinput(\"请输入: \") ","date":"2020-05-09","objectID":"/20200509/:1:8","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"eval() 函数 eval(\u003c字符串\u003e)函数是Python语言中一个十分重要的函数，它去掉字符串最外侧的引号并以Python表达式的方式解析并执行去掉引号后的字符串内容，将返回结果输出(会进行数值运算) tmp=\"102C\" print(eval(\"tmp\")) print(eval(tmp[0:-1])) value=eval(input(\"输入数值\")) print(value*2) s = \"11+5in\" print(eval(s[1:-2])) ","date":"2020-05-09","objectID":"/20200509/:1:9","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"输出函数 #print()函数用来输出字符信息，或以字符形式输出变量。 F=10.258 print(F) print(\"转换后的温度是{:.2f}\".format(F)) ","date":"2020-05-09","objectID":"/20200509/:1:10","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"Python 库的引入与调用 ","date":"2020-05-09","objectID":"/20200509/:1:11","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"import关键字 import是一个关键字，用来引入一些外部库 引入方式1 import numpy print(numpy.arange(0,10)) 引入方式2 from numpy import * print(arange(0,10)) 引入方式3 import numpy as np print(np.arange(0,10)) ","date":"2020-05-09","objectID":"/20200509/:1:12","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"01 数据 在 Python 中数据可分两大类： 基本数据类型(元素型)：整数、浮点数、复数、布尔型 组合数据类型(容器型)：字符串、元组、列表、字典、集合 ","date":"2020-05-09","objectID":"/20200509/:2:0","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"1.1 基本数据类型（元素型） Python 里面有自己的内置数据类型 (build-in data type)，本节介绍四种数字类型(Numbers): 整型 (int) 浮点型 (float) 复数 (complex) 布尔型 (bool) 思维导图(图中左侧部分的字符串属于组合数据类型) ","date":"2020-05-09","objectID":"/20200509/:2:1","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"数字类型 print( 1, type(1) ) print( 1., type(1.) ) print( 1 + 2j, type(1 + 2j) ) print( True, type( True )) 布尔型 (boolean) 布尔 (boolean) 型变量只能取两个值，True 和 False。当把布尔变量用在数字运算中，用 1 和 0 代表 True 和 False。 T = True F = False print( T + 2 ) print( F - 8 ) ","date":"2020-05-09","objectID":"/20200509/:2:2","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"数字类型的转换 int(4.5) # = 4 ，直接去掉小数部分 float(4) # = 4.0，增加小数部分 complex(4) # = 4 + 0j bool(4.5) bool(x) 若x为基本数据类型，则只要x不是整型 0、浮点型 0.0，bool(x) 就是 True，其余就是 False。 若x为组合数据类型，则只要x不是空的变量，bool(x) 就是 True，其余就是 False。 ","date":"2020-05-09","objectID":"/20200509/:2:3","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"类型的判断 type() 函数：type(x)，返回x的类型，适用于所有类型的判断 print(type(4+2j)) ","date":"2020-05-09","objectID":"/20200509/:2:4","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"dir和help函数 dir() dir()用来查询一个类或者对象的所有属性 dir(list) help() help()函数帮助我们了解模块、类型、对象、方法、属性的详细信息 1.帮助查看类型详细信息，包含类的创建方式、属性、方法 help(list) 2.帮助查看方法的详细使用信息（使用时要注意输入完整路径，使用模块帮助时，需要先导入模块） import math help(math.sqrt) ","date":"2020-05-09","objectID":"/20200509/:2:5","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"字符串类型及其操作 字符串是用双引号“”或者单引号‘’ 或’’’括起来的一个或多个字符。 字符串可以保存在变量中，也可以单独存在。 可以用type()函数测试一个字符串的类型 print('单引号表示可以使用\"双引号\"作为内容') print(\"双引号表示可以使用'单引号'作为内容\") print('''三引号表示可以使用\"双引号\" 单引号'作为内容'，还可以换行 ''') ","date":"2020-05-09","objectID":"/20200509/:3:0","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"常用的字符串处理函数 ","date":"2020-05-09","objectID":"/20200509/:3:1","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"len len()函数返回一个字符串的长度 print(len(\"天行健，君子以自强不息\")) ","date":"2020-05-09","objectID":"/20200509/:3:2","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"str 大多数数据类型都可以通过str()函数转换为字符串 str(123.456) str(123e+10) ","date":"2020-05-09","objectID":"/20200509/:3:3","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"遍历字符串 可以通过 for 和 in 组成的循环来遍历字符串中每个字符 mystr=\"地势坤，君子以厚德载物\" for s in mystr: print(s) ","date":"2020-05-09","objectID":"/20200509/:3:4","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"split 按指定字符分割字符串为数组 mystr=\"敕勒川，阴山下，天似穹庐，笼盖四野\" print(mystr.split(\"，\")) ","date":"2020-05-09","objectID":"/20200509/:3:5","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"join 连接两个字符串序列 mystr = \"@\" ls = [\"天苍苍\",\"野茫茫\",\"风吹草低见牛羊\"] print(mystr.join(ls)) ","date":"2020-05-09","objectID":"/20200509/:3:6","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"replace 字符串替换 myOldStr=\"今夕何夕溪，搴舟中流。今日何日溪，得与王子同舟。\" myNewStr=myOldStr.replace(\"溪\",\"兮\") print(myNewStr) ","date":"2020-05-09","objectID":"/20200509/:3:7","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"format方法的基本使用 hero=\"乔峰\" department=\"丐帮\" skill=\"降龙十八掌\" print(\"{}大侠，{}人士，成名绝技{},此前已刻苦练功{}个时辰\".format(hero,department,skill,1234.5678)) #\"{0:*^30}大侠，{1}人士，成名绝技{2},此前已刻苦练功{3:,.2f}个时辰\".format(hero,department,skill,1234.5678) ","date":"2020-05-09","objectID":"/20200509/:3:8","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"1.2 组合数据类型(容器型) ","date":"2020-05-09","objectID":"/20200509/:3:9","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"思维导图 ","date":"2020-05-09","objectID":"/20200509/:3:10","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"序列 序列是一组有顺序的元素向量，通过序号访问，元素之间不排他。 ","date":"2020-05-09","objectID":"/20200509/:4:0","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"1. 字符串(具体细节见“基本数据类型”思维导图左侧部分) mystr=\"Hello world\" mystr[0:3] mystr[0:-1] print(\"Hello world\"[0:3]) ","date":"2020-05-09","objectID":"/20200509/:4:1","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"2. 元组 creature = \"cat\", \"dog\", \"tiger\", \"human\" color = (\"red\", 0x001100, \"blue\", creature) color[2] color[-1][2]#索引可以索引两重 应用场景 def func(x): #函数多返回值 return x, x**3 a, b = 'dog', 'tiger' #多变量同步赋值 a, b = (b, a) #多变量同步赋值，括号可省略 func(3) import math for x, y in ((1,0), (2,5), (3,8)): #循环遍历 print(math.hypot(x,y)) #求多个坐标值到原点的距离 ","date":"2020-05-09","objectID":"/20200509/:4:2","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"3. 列表 ls = [425, \"BIT\", [10, \"CS\"], 425] ls[2][-1][0]#多重索引 list((425, \"BIT\", [10, \"CS\"], 425)) list(\"中国是一个伟大的国家\") list() print(ls[2][-1][0]) ls = [425, \"BIT\", 1024] #用数据赋值产生列表ls lt = ls #lt是ls所对应数据的引用，lt并不包含真实数据 #lt = ls[:] #ls通过分片操作将列表ls的元素全部拷贝给lt ls[0] = 0 print(id(ls),id(lt)) vlist = list(range(5)) len(vlist[2:]) #计算从第3个位置开始到结尾的子串长度 2 in vlist #判断2是否在列表vlist中 vlist[3]=\"python\" #修改序号3的元素值和类型 vlist[1:3]=[\"bit\", \"computer\"] print(vlist) 多增少减 vlist[1:3]=[\"new_bit\", \"new_computer\", 123] vlist #vlist[1:3]=[\"fewer\"] print(vlist) #以k为步数 ls = [425, \"BIT\", [10, \"CS\"], 123, \"Hello Ysu\", 23 , (10,29)] lt=[\"1st\",\"2nd\",\"3rd\"] ls[0:5:2] = lt print(ls) del ls[0:5:2]#删去了024号元素 print(ls) ls = [\"1st\",\"2nd\",\"3rd\"] lt = [425, \"BIT\", [10, \"CS\"], 425, \"Hello Ysu\", 23, 425, (10,29)] #在列表ls最后增加一个元素x ls.append(\"4th\") print(ls) #删除ls中所有元素 ls.clear() print(ls) #生成一个新列表，复制lt中所有元素 ls = lt.copy() print(ls) #在列表ls第i位置增加元素x ls.insert(1,\"ysu\") print(ls) #将列表ls中第i项元素取出并删除该元素BIT ls.pop(2) #将列表中出现的第一个元素x删除 ls.remove(425) print(ls) #列表ls中元素反转 ls.reverse() print(ls) for e in vlist: print(e, end=\" \")#不换行显示 ","date":"2020-05-09","objectID":"/20200509/:4:3","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"4. 集合 集合类型是一个元素集合，元素之间无序，相同元素在集合中唯一存在。 #元素类型只能是固定数据类型，例如：整数、浮点数、字符串、元组等 S = {425, \"BIT\", (10, \"CS\"), 424} T = {425, \"BIT\", (10, \"CS\"), 424, 425, \"BIT\"} #列表、字典和集合类型本身都是可变数据类型，不能作为集合的元素出现。 X = {425, \"BIT\", [10, \"CS\"], {\"蜀\":\"诸葛亮\"}, {234,(10,\"haha\")}} #set(x)函数可以用于生成集合 W = set('apple') V = set((\"cat\", \"dog\", \"tiger\", \"human\")) print(V) 应用场景 \"BIT\" in {\"PYTHON\", \"BIT\", 123, \"GOOD\"} #成员关系测试 tup = (\"PYTHON\", \"BIT\", 123, \"GOOD\", 123) tup1 = set(tup)#元素去重 newtup = tuple(set(tup)-{'PYTHON'}) # 去重同时删除数据项 print(tup1) 集合类型的4种基本操作，交集（\u0026）、并集（|）、差集（-）、补集（^），操作逻辑与数学定义相同 A = {425, \"BIT\", (10, \"CS\"), 424, 125, \"This is A\"} B = {425, \"BIT\", (10, \"CS\"), 424, 425, \"BIT\",\"This is B\"} print(A | B) print(A - B) print(A \u0026 B) print(A ^ B) s = [123,(45,\"Hello world\"),\"set\"] t = [123,(45,\"Hello world\"),\"set\",\"haha\"] print(s \u003c= t) print(s \u003e= t) ","date":"2020-05-09","objectID":"/20200509/:4:4","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"5. 映射 映射类型是“键-值”数据项的组合，每个元素是一个键值对，表示为(key, value) 字典是集合类型的延续，各个元素并没有顺序之分 Dcountry={\"中国\":\"北京\", \"美国\":\"华盛顿\", \"法国\":\"巴黎\"} print(Dcountry) #访问 Dcountry[\"中国\"] #修改 Dcountry[\"中国\"]='大北京' print(Dcountry) #增加新元素 Dcountry={\"中国\":\"北京\", \"美国\":\"华盛顿\", \"法国\":\"巴黎\"} Dcountry[\"英国\"]=\"伦敦\" print(Dcountry) #直接使用大括号（{}）可以创建一个空的字典，并通过中括号（[]）向其增加元素 Dp={} Dp['2^10']=1024 print(Dp) 字典类型的操作 Dcountry={\"中国\":\"北京\", \"美国\":\"华盛顿\", \"法国\":\"巴黎\"} Dcountry.keys() list(Dcountry.values()) Dcountry.items() '中国' in Dcountry #只对键进行判断 Dcountry.get('美国', '悉尼') #'美国'在字典中存在 Dcountry.get('澳大利亚', '悉尼') #'澳大利亚'在字典中不存在 for key in Dcountry: print(key) ","date":"2020-05-09","objectID":"/20200509/:4:5","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"02 程序的控制结构 ","date":"2020-05-09","objectID":"/20200509/:5:0","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"思维导图 ","date":"2020-05-09","objectID":"/20200509/:5:1","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"分支结构 #求两个数的最大值 x=int(input(\"请输入x:\")) y=int(input(\"请输入y:\")) if x\u003ey: print(x) else: print(y) #条件判断从左到右执行，并且在and或or两侧的条件会有\"短路\"现象 a = 5 b = 7 c = 8 d = 6 if a\u003cb or c\u003ed: print(\"True\") def suma(y): global a a=a+y return a if suma(2) or suma(3): print(\"a={}\".format(a)) 身体质量指数BMI #多分支 height, weight = eval(input(\"请输入身高(米)和体重(公斤)[逗号隔开]: \")) bmi = weight / pow(height, 2) print(\"BMI数值为：{:.2f}\".format(bmi)) wto, dom = \"\", \"\" if bmi \u003c 18.5: wto, dom = \"偏瘦\", \"偏瘦\" elif 18.5 \u003c= bmi \u003c 24: wto, dom = \"正常\", \"正常\" elif 24 \u003c= bmi \u003c 25: wto, dom = \"正常\", \"偏胖\" elif 25 \u003c= bmi \u003c 28: wto, dom = \"偏胖\", \"偏胖\" elif 28 \u003c= bmi \u003c 30: wto, dom = \"偏胖\", \"肥胖\" else: wto, dom = \"肥胖\", \"肥胖\" print(\"BMI指标为:国际'{0}', 国内'{1}'\".format(wto, dom)) ","date":"2020-05-09","objectID":"/20200509/:5:2","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"循环结构 遍历循环：for语句 循环次数确定，循环次数采用遍历结构中元素的个数来体现 #判断一个数是否为素数 integer=int(input(\"请输入一个整数:\")) flag=False for i in range(2,integer):#从2到输入的整数求余数，若都为0就是素数 if integer%i==0: break else: # if i==integer-1 flag=True print(\"问：整数{}是素数吗？\\n答：{}\".format(integer,flag)) continue vs break for i in range(4): for j in range(4): if j==i: print('-',end='\\t') break # 试试continue print('*',end='\\t') print() 无限循环：while语句 循环次数不确定。无限循环一直保持循环操作，直到特定循环条件不被满足才结束 #猜密码 guess=0 #输入的数字 secret=7 #预设的数字 while guess!=secret: #条件 也可用True/barek构造无限循环 guess=int(input(\"@数字区间0-9，请输入你猜的数字:\")) if guess==secret: print(\"你猜对了，真厉害！\") else: print(\"很遗憾，猜错了！\") print(\"游戏结束\") #猜密码 secret=7 #预设的数字 while True: # 用True/barek构造无限循环 guess=int(input(\"@数字区间0-9，请输入你猜的数字:\")) if guess==secret: print(\"你猜对了，真厉害！\") break else: print(\"很遗憾，猜错了！\") print(\"游戏结束\") ","date":"2020-05-09","objectID":"/20200509/:5:3","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"03 函数 ","date":"2020-05-09","objectID":"/20200509/:6:0","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"思维导图 def - 使用def关键字定义函数 function_name - 函数名，起名应有意义，见名知意 arg1 - 位置参数 ，这些参数在调用函数 (call function) 时位置要固定 arg2 = v - 默认参数 = 默认值，调用函数的时候，默认参数已经有值，可省略 *args - 可变参数，可以是从零个到任意个，自动组装成元组 ：- 冒号，在第一行最后要加个冒号，表示后面内容为函数体部分 “““docstring””” - 函数说明，用于介绍该函数，可省略，但写函数说明是一个好习惯，可使你写的代码可读性更好 statement - 函数体部分(函数内容) ","date":"2020-05-09","objectID":"/20200509/:6:1","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"函数的参数传递 默认值 def dup(str, times = 2): print(str*times) dup(\"knock~\") dup(\"knock~\",4) 可选参数 def func(x1,y1,z1,x2,y2,z2): return (x1,y1,z1,x2,y2,z2) # 按位置给参数赋值 result = func(1,2,3,4,5,6) # 按参数名给参数赋值 result = func(x2=4, y2=5, z2=6, x1=1, y1=2, z1=3) 可变参数 def vfunc(a, *b): print(type(b)) for n in b: a += n return a vfunc(1,2,3,4,5) 注意： 在 Python 中定义函数时，若定义了位置参数、默认参数、可变参数，参数定义的顺序必须是： 位置参数、默认参数、可变参数 否则，程序会报错。 函数的返回值 def func(a, b): return a*b s = func(\"knock~\", 2) print(s) def func(a, b): return b,a s = func(\"knock~\", 2) #print(s, type(s)) 全局变量与局部变量 n = 1 #n是全局变量 def func(a, b): c = a * b #c是局部变量，a和b作为函数参数也是局部变量 return c s = func(\"knock~\", 2) print(c) print(s) n = 1 #n是全局变量 def func(a, b): n = b #这个n是在函数内存中新生成的局部变量 return a*b s = func(\"knock~\", 2) print(s, n) n = 1 #n是全局变量 def func(a, b): global n n = b #将局部变量b赋值给全局变量n return a*b s = func(\"knock~\", 2) print(s, n) ls = [] #建立ls全局列表变量 def func(a, b): ls.append(b) #将局部变量b增加到全局列表变量ls中 return a*b s = func(\"knock~\", 2) print(s, ls) #测试一下ls值是否改变 ls = [] #ls是全局列表变量 def func(a, b): ls = [] #创建了名称为ls的局部列表变量列 ls.append(b) #将局部变量b增加到局部列表变量ls中 return a*b s = func(\"knock~\", 3) print(s, ls) #测试一下ls值是否改变 ","date":"2020-05-09","objectID":"/20200509/:6:2","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"函数的递归 def fact(n): if n == 0: return 1 else: return n * fact(n-1) num = eval(input(\"请输入一个整数: \")) print(fact(abs(int(num)))) def reverse(s): if s==\"\": return s else: return reverse(s[1:]) + s[0] lambda函数(匿名函数) lambda - 定义匿名函数的关键字 argument_list - 函数参数，可以是位置参数、默认参数、可变参数等，和正规函数里的参数类型一样 ：- 冒号，在函数参数和表达式中间要加个冒号 expression - 函数表达式，输入函数参数，输出一些值 注意 lambda 函数没有所谓的函数名，所以也叫匿名函数。下面是一些 lambda 函数示例： lambda所表示的匿名函数的内容应该是很简单的，如果复杂的话，干脆就重新定义一个函数了，使用lambda就有点过于执拗了。 # 输入 x 和 y，输出其积 x*y func = lambda x, y: x*y func(2, 3) 和下面的正规函数等价： def func(x,y): return x*y func(2,3) # 输入任意个数的参数，输出其和 func = lambda *args: sum(args) func( 1, 2, 3, 4, 5 ) 和下面的正规函数等价： def func(*args): return sum(args) func( 1, 2, 3, 4, 5 ) ","date":"2020-05-09","objectID":"/20200509/:6:3","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"04 高级特性 在Python中，代码不是越多越好，而是越少越好。代码不是越复杂越好，而是越简单越好。 因此，Python中有许多高级特性，这里仅介绍推导式和高阶函数。 ","date":"2020-05-09","objectID":"/20200509/:7:0","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"推导式 推导式comprehensions（又称生成式、解析式），是Python的一种独有特性。推导式是可以从一个数据序列构建另一个新的数据序列的结构体。 共有三种推导，在Python2和3中都有支持： 列表(list)推导式 字典(dict)推导式 集合(set)推导式 基本格式 variable = [out_exp_res for out_exp in input_list if out_exp == 2] [要添加的元素 for循环 if判断条件] out_exp_res:　列表生成元素表达式，可以是有返回值的函数。 for out_exp in input_list：　迭代input_list将out_exp传入out_exp_res表达式中。 if out_exp == 2：　根据条件过滤哪些值可以。 问题： 如何从一个含整数列表中把奇数 (odd number) 挑出来？ lst = [1, 2, 3, 4, 5] odds = [] for n in lst: if n % 2 == 1: odds.append(n * 2) odds 任务完成了，但不够简洁，看看下面这一行代码： odds = [n * 2 for n in lst if n % 2 == 1] odds 乍一看从「for 循环」到「解析式」不直观，我来用不同颜色把这个过程可视化一下，如下图： 现在你可能会说上面「for 循环」只有一层，如果两层怎么转换「列表解析式」？具体来说怎么解决下面这个问题。 问题： 如何用「列表解析式」将一个二维列表中的元素按行一个个展平？ 没思路？先用「for 循环」试试？ lst = [[1, 2, 3], [4, 5, 6], [7, 8, 9]] flattened = [] for row in lst: for n in row: flattened.append(n) flattened 套用一维「列表解析式」的做法 两点需要注意： 该例没有「if 条件」条件，或者认为有，写成「if True」。如果有「if 条件」那么直接加在「内 for 循环」后面。 「外 for 循环」写在「内 for 循环」前面。 lst = [[1, 2, 3], [4, 5, 6], [7, 8, 9]] flattened = [n for row in lst for n in row] flattened 我们把「列表解析式」那一套举一反三的用到其他解析式上，用下面两图理解一下「字典解析式」和「集合解析式」。 再看一些例子： #列表生成式 #两层循环 [m + n for m in 'ABC' for n in 'XYZ'] #字典生成式 #大小写key合并 mcase = {'a': 10, 'b': 34, 'A': 7, 'Z': 3} mcase_frequency = {v: k for k, v in mcase.items()} print(mcase_frequency) #集合生成式 squared = {x**2 for x in [1, 1, 2]} print(squared) ","date":"2020-05-09","objectID":"/20200509/:7:1","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"高阶函数 高阶函数 (high-order function) 在函数化编程 (functional programming) 很常见，主要有两种形式： 参数是函数 (map, filter, reduce) 返回值是函数 (closure, partial, currying) 这里只介绍第一种。 Map, Filter, Reduce Python 里面的 map, filter 和 reduce 属于第一种高阶函数，参数是函数。这时候是不是很自然的就想起了 lambda 函数？ 作为内嵌在别的函数里的参数，lambda 函数就像微信小程序一样，即用即丢，非常轻便。 首先看看 map, filter 和 reduce 的语法： map(函数 f, 序列 x)： 对序列 x 中每个元素依次执行函数 f，将 f(x) 组成一个「map 对象」返回 (可以将其转换成 list 或 set) filter(函数 f, 序列 x)： 对序列 x 中每个元素依次执行函数 f，将 f(x) 为 True 的结果组成一个「filter 对象」返回 (可以将其转换成 list 或 set) f(x)是一个判断函数，取值为正的时候返回对象 reduce(函数 f, 序列 x)： 对序列 x 的第一个和第二个元素执行函数 f，得到的结果和序列 x 的下一个元素执行函数 f，一直遍历完的序列 x 所有元素。 map() 函数接收两个参数，一个是函数，一个是 Iterable (可迭代对象，如列表、元组、字典、字符串等可以用for遍历的数据结构)，map 将传入的函数依次作用到序列的每个元素，并把结果作为新的Iterator(可以将其转换成 list 或 set)返回。 看个具体的平方示例，用 map 函数对列表每个元素平方。 lst = [1, 2, 3, 4, 5, 6, 7, 8, 9] map_iter = map( lambda x: x**2, lst ) print( map_iter ) print( list(map_iter) ) 接着再看看 filter 函数，顾名思义就是筛选函数，那么我们把刚才列表中的计数筛选出来吧。 filter_iter = filter(lambda n: n % 2 == 1, lst) print( filter_iter ) print( list(filter_iter) ) 在 filter 函数中 第一个参数是一个识别奇数的「匿名函数」 第二个参数是列表，即该「匿名函数」作用的对象 同样，filter_iter 作为 filter 函数的返回对象，也是一个迭代器，想要将其内容显示出来，需要用 list 将其转换成「列表」形式。 最后来看看 reduce 函数，顾名思义就是累积函数，把一组数减少 (reduce) 到一个数。 from functools import reduce reduce( lambda x,y: x+y, lst ) 在 reduce 函数中 第一个参数是一个求和相邻两个元素的「匿名函数」 第二个参数是列表，即该「匿名函数」作用的对象 在 reduce 函数的第三个参数还可以赋予一个初始值 reduce( lambda x,y: x+y, lst, 100 ) ","date":"2020-05-09","objectID":"/20200509/:7:2","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"05 综合示例 ","date":"2020-05-09","objectID":"/20200509/:8:0","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"Jieba库的使用 #jieba库的安装 #pip install jieba import jieba jieba.lcut(\"中国是一个伟大的国家\") 精确模式：将句子最精确地切开，适合文本分析 jieba.lcut(\"中华人民共和国是一个伟大的国家\") 全模式：把句中所有可以成词的词语都扫描出来，速度快，但不能解决歧义 jieba.lcut(\"中华人民共和国是一个伟大的国家\", cut_all=True) 搜索引擎模式：在精确模式的基础上，对长词再次切分，适合搜索引擎分词 jieba.lcut_for_search(\"中华人民共和国是一个伟大的国家\") ","date":"2020-05-09","objectID":"/20200509/:9:0","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"《三国演义》人物出场统计 import jieba excludes = {\"将军\",\"却说\",\"荆州\",\"二人\",\"不可\",\"不能\",\"如此\"} txt = open(\"三国演义.txt\", \"r\", encoding='utf-8').read() words = jieba.lcut(txt) counts = {} for word in words: if len(word) == 1: continue elif word == \"诸葛亮\" or word == \"孔明曰\": rword = \"孔明\" elif word == \"关公\" or word == \"云长\": rword = \"关羽\" elif word == \"玄德\" or word == \"玄德曰\": rword = \"刘备\" elif word == \"孟德\" or word == \"丞相\": rword = \"曹操\" else: rword = word counts[rword] = counts.get(rword,0) + 1 for word in excludes: del(counts[word]) items = list(counts.items()) items.sort(key=lambda x:x[1], reverse=True) for i in range(10): word, count = items[i] print (\"{0:\u003c10}{1:\u003e5}\".format(word, count)) ","date":"2020-05-09","objectID":"/20200509/:10:0","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python","数学建模"],"content":"Sort函数 列表有自己的sort方法，其对列表进行原址排序 x = [4, 6, 2, 1, 7, 9] x.sort() print(x) sort和sorted方法还有两个可选参数：key和reverse key接受一个函数，这个函数只接受一个元素，这个函数用于从每个元素中提取一个用于比较的关键字,默认为None x = ['mmm', 'mm', 'mm', 'm' ] x.sort(key = len) #指定key=len，就是比较len()之后的结果 print(x) reverse是一个布尔值。如果设置为True，列表元素将被倒序排列，默认为False y = [3, 2, 8 ,0 , 1] y.sort(reverse = False) print(y) ","date":"2020-05-09","objectID":"/20200509/:10:1","tags":["python","数学建模"],"title":"Python数据分析快速入门","uri":"/20200509/"},{"categories":["python"],"content":"直接放代码 from selenium import webdriver import time driver = webdriver.Chrome(r'C:\\chromedriver.exe') urllist = [ 'https://www.bilibili.com/video/BV15f4y1m7xH?from=search\u0026seid=9788956603997309480', 'https://www.bilibili.com/video/BV1WA411h76h?from=search\u0026seid=9738279009337231611', 'https://www.bilibili.com/video/BV13c411h7k7?from=search\u0026seid=9738279009337231611', 'https://www.bilibili.com/video/BV1x541147u8?from=search\u0026seid=9738279009337231611', 'https://www.bilibili.com/video/BV17p4y1C78w?from=search\u0026seid=9738279009337231611' ] #视频链接 timelist=[ 311, 598, 669, 568, 507, ] #放入自己各个视频的时长 t = 0 for url in urllist: try: driver.set_page_load_timeout(5) driver.get(url) time.sleep(10) except Exception : print(\"timeout\") element = driver.find_element_by_xpath('//*[@id=\"bilibiliPlayer\"]/div[1]/div[1]/div[10]/div[2]/div[2]/div[1]/div[1]/button[1]')#xpath抓取播放控件 time.sleep(5) print('控件抓取成功') driver.find_element_by_xpath('//*[@id=\"bilibiliPlayer\"]/div[1]/div[1]/div[10]/div[2]/div[2]/div[1]/div[1]/button[1]').click()#xpath定位成功后点击播放 print('播放成功') time.sleep(timelist[t]) print('下一个视频') t = t + 1 因为页面加载需要时间，抓取控件也需要时间，设计sleep时长看你的页面加载速度以及网速进行调整 链接https://b23.tv/D0a1BX是我完善后的源码效果视频，视频评论区里有完善后的源码链接，视频点赞自取。 ","date":"2020-05-05","objectID":"/20200505/:1:0","tags":["python"],"title":"比较简单的selenium自动化操作播放bilibili(b站)视频2020","uri":"/20200505/"},{"categories":["python","爬虫"],"content":"前言 re库的实用实例如下 import requests import re import os a = True while a: #创建一个文件夹，保存所有图片 if not os.path.exists('./tupianLibs'): os.mkdir('./tupianLibs') headers = { 'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.122 Safari/537.36' } url = \"https://www.pexels.com/\" #使用通用爬虫对整张页面进行爬取 page_text = requests.get(url=url, headers=headers).text #使用聚焦爬虫将页面中所有的图片进行解析/提取 #正则.*?表示一切内容 #re.S单行匹配 ex = '\u003ca class=\"js-photo-link photo-item__link\" style.*? \u003e.*?\u003cimg srcset=\"(.*?)\" class.*?\u003e\u003c/div\u003e' image_src_list = re.findall(ex, page_text, re.S ) for src in image_src_list: src = 'https:'+ src #拼接出一个完整的图片url image_data = requests.get(url=src, headers=headers).content #请求到了图片的二进制数据 image_name = src.split('/')[-1] #生成图片名称 imgPath = './tupianlbs/' + image_name #图片最终存储的路径 with open(imgPath, 'W') as fp: fp.write(image_data) print('下载成功') a = False ","date":"2020-05-05","objectID":"/20200506/:0:1","tags":["python","爬虫"],"title":"爬虫流程及方法14(正则表达式篇)","uri":"/20200506/"},{"categories":["python","爬虫"],"content":"正则表达式详情 raw string类型区别于原生字符串类型（不包含转义字符） r'[1-9]\\d{5}' re.search(pattern, string, flags=0) 在一个字符串中搜索匹配正则表达式的第一个位置，返回match对象。 pattern:正则表达式的字符串或原生字符串表示 string:待匹配字符串 flags:正则表达式使用时的控制标记 re.split(pattern, string, maxsplit=0, flags=0) 将一个字符串按照正则表达式匹配结果进行分割,返回列表类型。 pattern:正则表达式的字符串或原生字符串表示 string:待匹配字符串 maxsplit:最大分割数，剩余部分作为最后一个元素输出 flags:正则表达式使用时的控制标记 re.finditer(pattern, string, flags=0) 搜索字符串，返回一个匹配结果的迭代类型，每个迭代元素是match对象。 pattern:正则表达式的字符串或原生字符串表示 string:待匹配字符串 flags:正则表达式使用时的控制标记 re.sub(pattern, repl, string, count=0, flags=0) 在一个字符串中替换所有匹配正则表达式的子串，返回替换后的字符串。 pattern:正则表达式的字符串或原生字符串表示 repl:替换匹配字符串的字符串 string:待匹配字符串 flags:正则表达式使用时的控制标记 regex = re.compile(pattern, flags=0) 将正则表达式的字符串形式编译成正则表达式对象 pattern:正则表达式的字符串或原生字符串表示 flags:正则表达式使用时的控制标记 Match:对象的属性 match = re.search(r'PY.*N',' PYANBNCNDN' ) match.group(0) Re库默认采用贪婪匹配，即输出匹配最长的子串。 输出’PYANBNCNDN' match = re.search(r'PY. *?N', ' PYANBNCNDN') match group(0) 输出’PYAN ' import re restr=\"\u003ctd data-v-80203e10=\"\"\u003e（\\\\d+）\u003c/td\u003e\"#括号表示只取数据（数字） regex=re.compile(restr,re.IGNORECASE) mylist=regex.findall(province) ","date":"2020-05-05","objectID":"/20200506/:0:2","tags":["python","爬虫"],"title":"爬虫流程及方法14(正则表达式篇)","uri":"/20200506/"},{"categories":["python","爬虫"],"content":"前言 xpath解析原理: 1.实例化一个etree的对象，且需要将被解析的页面源码数据加载到该对象中。 2.调用et ree对象中的xpath方法结合着xpath表达式实现标签的定位和内容的捕获。 环境的安装: pip install Lxml 如何实例化一个etree对象: from Lxml import etree 1.将本地的html文档中的源码数据加载到etree对象中: etree.parse(fiLePath) 2.可以将从互联网上获取的源码数据加裁到该对象中 etree.HTML( 'page_ text' ) xpath('xpath表达式') #3.7版本后引入etree模块如下，3.5版本以下可以直接从lxml中引入 from lxml import html etree = html.etree parser = etree.HTMLParser(encoding=\"utf-8\") #实例化好了一个etree对象，且将被解析的源码加载到了该对象中 tree = etree.parse('bs4练习.html', parser=parser) # r = tree.xpath('/html/body/div') # r = tree.xpath('/html//div') # r = tree.xpath('//div') /表示的是从根节点开始定位，一个/x/表示一个层级，//表示跨越多个层级,可以表示从任意位置开始定位 r = tree.xpath('//div[@class=\"song\"]') 属性定位： //div[@class=\"song\"] tag[@attrName=\"attrValue\"] r = tree.xpath('//div[@class=\"song\"]/p[3]') 索引定位： '//div[@class=\"song\"]/p[3]' #这里索引以1开始 r = tree.xpath('//div[@class=\"tang\"]//li[5]/a/text()')[0] 取文本： /text() #获取的是标签中直系的文本内容 //text() #获取标签中非直系文本内容（所有文本内容） ```python r = tree.xpath('//div[@class=\"tang\"]/text()') 取属性： /@attrName ==\u003eimg/src r = tree.xpath('//div[@class=\"song\"]/img/@src') 实际案例： #3.7版本后引入etree模块如下，3.5版本以下可以直接从lxml中引入 from lxml import html import requests etree = html.etree a = True while a: #爬取页面源码数据 url = 'https://mm.58.com/ershoufang/' headers = { 'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.122 Safari/537.36' } page_text = requests.get(url=url, headers=headers).text #数据解析 tree = etree.HTML(page_text) li_list = tree.xpath('//ul[@class=\"house-list-wrap\"]/li') fp = open('58.txt', 'w', encoding='utf-8') for li in li_list: #页面数据局部解析 title = li.xpath('./div[2]/h2/a/text()')[0]#./表示从前面的li开始（局部开始） print(title) fp.write(title+'\\n') a = False ","date":"2020-05-04","objectID":"/20200504/:0:1","tags":["python","爬虫"],"title":"爬虫流程及方法13(xpath解析页面)","uri":"/20200504/"},{"categories":["python","爬虫"],"content":"前言 目的:在爬虫中使用异步实现高性能的数据爬取操作。 异步爬虫的方式: –多线程，多进程(不建议): 好处:可以为相关阻塞的操作单独开启线程或者进程，阻塞操作就可以异步执行。 弊端:无法无限制的开启多线程或者多进程。 ps:get方法与post方法是阻塞的方法 –线程池、进程池(适当的使用)： 好处:我们可以降低系统对进程或者线程创建和销毁的一个频率，从而很好的降低系统的开销。 弊端:池中线程或进程的数量是有上限。| ","date":"2020-05-01","objectID":"/20200501/:0:1","tags":["python","爬虫"],"title":"爬虫流程及方法12(高性能异步爬虫)","uri":"/20200501/"},{"categories":["python","爬虫"],"content":"模拟多线程操作 单线程模拟： import time #使用单线程串行方式执行 def get_page(str): print(\"正在下载: \", str) time.sleep(2) print('下载成功: ', str) name_list = ['xiaozi', 'aa','bb','cc'] start_time = time.time() for i in range(len(name_list)): get_page(name_list[i]) end_time = time.time() print('%d second' % (end_time-start_time)) 结果:8s 线程池模拟： import time #导入线程池模块对应的类 from multiprocessing.dummy import Pool #使用线程池方式进行 #导入线程池所对应的pool start_time = time.time()#程序开始时计时 def get_page(str): print(\"正在下载: \", str) time.sleep(2) print('下载成功: ', str) name_list = ['xiaozi', 'aa','bb','cc']#可迭代对象 #实例化一个线程对象 pool = Pool(4)#线程池开启4个线程 #将列表中每一个列表元素传递给get_page进行处理 pool.map(get_page, name_list)#若有返回值返回的是列表，因为多次传入到map end_time = time.time()#程序结束时结束计时 print(end_time-start_time) 结果:2s ","date":"2020-05-01","objectID":"/20200501/:0:2","tags":["python","爬虫"],"title":"爬虫流程及方法12(高性能异步爬虫)","uri":"/20200501/"},{"categories":["python","爬虫"],"content":"实际案例 提取js动态加载内容，使用re正则匹配 js源码 var contId=\"1671755\",liveStatusUrl=\"liveStatus.jsp\",liveSta=\"\",playSta=\"1\",autoPlay=!1,isLiving=!1,isVrVideo=!1,hdflvUrl=\"\",sdflvUrl=\"\",hdUrl=\"\",sdUrl=\"\",ldUrl=\"\",srcUrl=\"https://video.pearvideo.com/mp4/third/20200429/cont-1671755-11742488-084919-hd.mp4\",vdoUrl=srcUrl,skinRes=\"//www.pearvideo.com/domain/skin\",videoCDN=\"//video.pearvideo.com\" 正则匹配 ex = ‘srcUrL=\"( .*? )”,vdoUrl’ 分组操作提取链接 import requests from bs4 import BeautifulSoup import re from multiprocessing import Pool def get_video_data(dic): headers = { 'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.122 Safari/537.36\" } #使用线程池对视频数据进行请求（较为耗时的堵塞操作） url = dic['url'] print(dic['name'], '正在下载') data = requests.get(url=url, headers=headers, timeout=0.5).content #持久化存储操作 with open(dic['name'], 'wb') as fp: fp.write(data) print(dic['name'], '下载成功') if __name__ == '__main__': headers = { 'User-Agent':\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.122 Safari/537.36\" } url = 'https://www.pearvideo.com/category_5' page_text = requests.get(url=url, headers=headers).text soup = BeautifulSoup(page_text, 'lxml') li_urls = soup.select('.vervideo-bd') urls = []#存储所有视频的链接和名字 i = 1 for li in li_urls: try: i = i + 1 detail_url = 'https://www.pearvideo.com/' + li.a['href'] name = soup.select('.vervideo-title')[i].text+'.mp4' detail_page_text = requests.get(url=detail_url, headers=headers, timeout=0.5).text ex = 'srcUrl=\"(.*?)\",vdoUrl' video_url = re.findall(ex, detail_page_text)[0] dic = { 'name': name, 'url': video_url } urls.append(dic) except: continue pool = Pool(4) pool.map(get_video_data, urls) pool.close() pool.join() 总结： 1.windows环境下需要将主函数放在以下代码下方 if __name__ == '__main__': mac环境下不需要此操作 2.下载时下载二进制数据，使用’wb’而不是’w’。 3.如果下载视频过多(爬取大量数据)，网站要求验证证书，大量爬取需要使用其他方法应对ssl反爬策略。 ps：感谢csdn学院提供的案例支持 ","date":"2020-05-01","objectID":"/20200501/:0:3","tags":["python","爬虫"],"title":"爬虫流程及方法12(高性能异步爬虫)","uri":"/20200501/"},{"categories":["python","爬虫"],"content":"原网页链接萌新论坛 ","date":"2020-04-29","objectID":"/20200429/:0:0","tags":["python","爬虫"],"title":"爬虫流程及方法10(爬虫伪装专题篇)","uri":"/20200429/"},{"categories":["python","爬虫"],"content":"requests 伪装 headers 发送请求 headers中空着的可能有也可能无，user-agent基本得有 在chrome中找到网页的请求头，图片如下 headers = { \"Accept\": \" \", \"Accept-Encoding\": \" \", \"Accept-Language\": \" \", \"Host\": \" \", 'user-agent':'粘贴1处' } #在页面中点击右键选择检查，调出网页自带的抓包工具，打开Network后刷新当前页面抓包找到user-agent的项复制粘贴1 cookie的三种传参方法 headers = {\"User_Agent\":\"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.186 Safari/537.36\", \"Cookie\" : \" \", \"Refer\" : \" 从哪个网页来的(url)\" } #三种Cookie请求方式 '''第一种：cookie放在headers中''' headers = {\"User_Agent\":\"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.186 Safari/537.36\", \"Cookie\" : \" \" } '''第二种：cookie字典传给cookies参数''' '''第三种 先发送post请求，获取cookie，带上cookie请求登陆之后的页面''' # 如果没有的就要抓包了Network -\u003e preserve log -\u003e login包 -\u003erequesy seesion = requests.seesion() # 用户名作为键， 真正的密码作为值 模拟登陆 post_data = {\"email\":\"xxxx\", \"password\":\"xxxx\"} seesion.post(url=url, data=post_data, headers=headers) # 服务器设置在本地的cookie会保存在本地 seesion.get(url) # 会带上之前保存在seesion中的cookie，能够请求成功 ","date":"2020-04-29","objectID":"/20200429/:0:1","tags":["python","爬虫"],"title":"爬虫流程及方法10(爬虫伪装专题篇)","uri":"/20200429/"},{"categories":["python","爬虫"],"content":"requests 伪装 params 传输数据 params = { '某名字':'某值', '粘贴2': '黏贴2' } #在页面中点击右键选择检查，调出网页自带的抓包工具，打开Network后刷新当前页面抓包找到Query String Parameters的项复制粘贴2（记得加符号'粘贴2'） User-Agent：这里面存放浏览器的信息。可以看到上面的参数值，它表示我是通过Windows的Chrome浏览器，访问的这个服务器。如果我们不设置这个参数，用Python程序直接发送GET请求，服务器接受到的User-Agent信息就会是一个包含python字样的User-Agent。如果后台设计者验证这个User-Agent参数是否合法，不让带Python字样的User-Agent访问，这样就起到了反爬虫的作用。这是一个最简单的，最常用的反爬虫手段。 Referer：这个参数也可以用于反爬虫，它表示这个请求是从哪发出的。可以看到我们通过浏览器访问网站，这个请求是从哪个页面来的(那个页面包含该链接)，这个地址发出的。如果后台设计者，验证这个参数，对于不是从这个地址跳转过来的请求一律禁止访问，这样就也起到了反爬虫的作用。 ps: authorization：这个参数是基于AAA模型中的身份验证信息允许访问一种资源的行为。在我们用浏览器访问的时候，服务器会为访问者分配这个用户ID。如果后台设计者，验证这个参数，对于没有用户ID的请求一律禁止访问，这样就又起到了反爬虫的作用。 UserAgent伪装集合详见资源页面 ","date":"2020-04-29","objectID":"/20200429/:0:2","tags":["python","爬虫"],"title":"爬虫流程及方法10(爬虫伪装专题篇)","uri":"/20200429/"},{"categories":["python","爬虫"],"content":"selenium 模拟使用浏览器伪装 headers 使用自动化测试工具 selenium 可以模拟使用浏览器访问网站。使用的selenium版本大都支持 Chrome 和 Firefox 浏览器。要使用该库浏览器需要下载对应版本到电脑上。 使用 webdriver 访问本身自带浏览器的 headers。 import selenium import selenium.webdriver import ssl def get_url_text(url): driver = selenium.webdriver.Chrome()#模拟调用谷歌游览器（模拟你电脑有的游览器操作） driver.get(url)#访问链接 pagesource=driver.page_source#抓取网页源代码 #你要执行的预处理写这里 driver.close() return #返回值 ","date":"2020-04-29","objectID":"/20200429/:0:3","tags":["python","爬虫"],"title":"爬虫流程及方法10(爬虫伪装专题篇)","uri":"/20200429/"},{"categories":["python","爬虫"],"content":"ssl处理(仅针对使用urllib与urllib3) urllib库爬虫 import ssl context = ssl._create_unverified_context() #忽略安全 requests库爬虫 忽略ssl验证使得网页访问得以顺利通过 verify=False 代表不做证书验证 import requests from requests.packages import urllib3 urllib3.disable_warnings() #关闭警告 respone=requests.get('https://www.12306.cn',verify=False) print(respone.status_code) 不做证书验证的情况，在某些情况下是行不通的的，这需要其他处理方式 ","date":"2020-04-29","objectID":"/20200429/:0:4","tags":["python","爬虫"],"title":"爬虫流程及方法10(爬虫伪装专题篇)","uri":"/20200429/"},{"categories":["python","爬虫"],"content":"requests 使用 ip 代理发送请求 查询自己的ip，网址https://httpbin.org/ip import requests a = True while a: try: url = 'https://httpbin.org/ip' response = requests.get(url) print(response.text) except: print(\"爬取失败\") a = False 使用代理ip与伪装headers的方式相似,只需要传入proxies参数。 比如现在我有一个代理ip:111.164.20.86:8111，使用如下： import requests a = True while a: url = 'https://httpbin.org/ip' proxy = { 'http': '111.164.20.86:8111', } #或者填入https请求的'https': ' ' response = requests.get(url=url, proxies=proxy) print(response.text) #返回值是代理ip地址，更换url即可使用代理ip爬虫 a = False 支持socks代理,安装输入： pip install requests[socks] 实例： import requests proxies = { 'http': 'socks5://user:pass@host:port', 'https': 'socks5://user:pass@host:port' } respone=requests.get('https://www.12306.cn', proxies=proxies) print(respone.status_code) 如果没考虑好用http/https，建议两个都写入字典proxy里面，就不会报错 代理免费ip可能会时不时中断，建议淘宝购买(支持验证那种)，当然如果购买阿里云端口也是可以的 ","date":"2020-04-29","objectID":"/20200429/:0:5","tags":["python","爬虫"],"title":"爬虫流程及方法10(爬虫伪装专题篇)","uri":"/20200429/"},{"categories":["python","爬虫"],"content":"重复执行报错处理 import requests from retrying import retry #@retry(stop_max_attempt_number = 10) '''让被装饰的函数反复执行10次，10次全部报错才会报错， 中间有一次正常就继续往下走''' url = \"http://www.baidu.com\" response = requests.get(url,timeout=0.01)#timeout=0.01 代表请求+接收服务端数据的总时间 #如果想明确控制链接与等待接收服务端数据的时间则写 timeout=(1,2) #timeout=(1,2)---\u003e1代表链接超时时间 2代表接收数据的超时时间 print(response.content.decode()) headers = {\"User_Agent\":\"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.186 Safari/537.36\", } ","date":"2020-04-29","objectID":"/20200429/:0:6","tags":["python","爬虫"],"title":"爬虫流程及方法10(爬虫伪装专题篇)","uri":"/20200429/"},{"categories":["python","爬虫"],"content":"前言 本篇鸣谢 清华——尹成 的整理收集 PyQuery文档https://www.osgeo.cn/pyquery/index.html PyQuery库也是一个非常强大又灵活的网页解析库，如果你有前端开发经验的，都应该接触过jQuery,那么PyQuery就是你非常绝佳的选择，PyQuery 是 Python 仿照 jQuery 的严格实现。语法与 jQuery 几乎完全相同，所以不用再去费心去记一些奇怪的方法了。 官网地址:http://pyquery.readthedocs.io/en/latest/ jQuery参考文档:http://jquery.cuishifeng.cn/ ","date":"2020-04-28","objectID":"/20200428/:1:0","tags":["python","爬虫"],"title":"爬虫流程及方法11(PyQuery解析网页篇)(全)","uri":"/20200428/"},{"categories":["python","爬虫"],"content":"初始化 初始化的时候一般有三种传入方式：传入字符串，传入url,传入文件 字符串初始化 html = ''' \u003cdiv\u003e \u003cul\u003e \u003cli class=\"item-0\"\u003efirst item\u003c/li\u003e \u003cli class=\"item-1\"\u003e\u003ca href=\"link2.html\"\u003esecond item\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-0 active\"\u003e\u003ca href=\"link3.html\"\u003e\u003cspan class=\"bold\"\u003ethird item\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-1 active\"\u003e\u003ca href=\"link4.html\"\u003efourth item\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-0\"\u003e\u003ca href=\"link5.html\"\u003efifth item\u003c/a\u003e\u003c/li\u003e \u003c/ul\u003e \u003c/div\u003e ''' from pyquery import PyQuery as pq doc = pq(html) print(doc) print(type(doc)) print(doc('li')) 结果如下： 由于PyQuery写起来比较麻烦，所以我们导入的时候都会添加别名： from pyquery import PyQuery as pq 这里我们可以知道上述代码中的doc其实就是一个pyquery对象，我们可以通过doc可以进行元素的选择，其实这里就是一个css选择器，所以CSS选择器的规则都可以用，直接doc(标签名)就可以获取所有的该标签的内容，如果想要获取class 则doc(’.class_name’),如果是id则doc(’#id_name’)…. URL初始化 from pyquery import PyQuery as pq doc = pq(url=\"http://www.baidu.com\",encoding='utf-8') print(doc('head')) 文件初始化 我们在pq()这里可以传入url参数也可以传入文件参数，当然这里的文件通常是一个html文件。 例如：pq(filename=‘index.html’) ","date":"2020-04-28","objectID":"/20200428/:1:1","tags":["python","爬虫"],"title":"爬虫流程及方法11(PyQuery解析网页篇)(全)","uri":"/20200428/"},{"categories":["python","爬虫"],"content":"基本的CSS选择器 html = ''' \u003cdiv id=\"container\"\u003e \u003cul class=\"list\"\u003e \u003cli class=\"item-0\"\u003efirst item\u003c/li\u003e \u003cli class=\"item-1\"\u003e\u003ca href=\"link2.html\"\u003esecond item\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-0 active\"\u003e\u003ca href=\"link3.html\"\u003e\u003cspan class=\"bold\"\u003ethird item\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-1 active\"\u003e\u003ca href=\"link4.html\"\u003efourth item\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-0\"\u003e\u003ca href=\"link5.html\"\u003efifth item\u003c/a\u003e\u003c/li\u003e \u003c/ul\u003e \u003c/div\u003e ''' from pyquery import PyQuery as pq doc = pq(html) print(doc('#container .list li')) 这里我们需要注意的一个地方是doc(’#container .list li’)，这里的三者之间的并不是必须要挨着，只要是层级关系就可以,下面是常用的CSS选择器方法： ","date":"2020-04-28","objectID":"/20200428/:1:2","tags":["python","爬虫"],"title":"爬虫流程及方法11(PyQuery解析网页篇)(全)","uri":"/20200428/"},{"categories":["python","爬虫"],"content":"查找元素 子元素 children,find 代码例子： html = ''' \u003cdiv id=\"container\"\u003e \u003cul class=\"list\"\u003e \u003cli class=\"item-0\"\u003efirst item\u003c/li\u003e \u003cli class=\"item-1\"\u003e\u003ca href=\"link2.html\"\u003esecond item\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-0 active\"\u003e\u003ca href=\"link3.html\"\u003e\u003cspan class=\"bold\"\u003ethird item\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-1 active\"\u003e\u003ca href=\"link4.html\"\u003efourth item\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-0\"\u003e\u003ca href=\"link5.html\"\u003efifth item\u003c/a\u003e\u003c/li\u003e \u003c/ul\u003e \u003c/div\u003e ''' from pyquery import PyQuery as pq doc = pq(html) items = doc('.list') print(type(items)) print(items) lis = items.find('li') print(type(lis)) print(lis) 运行结果如下 从结果里我们也可以看出通过pyquery找到结果其实还是一个pyquery对象，可以继续查找，上述中的代码中的items.find(’li’) 则表示查找ul里的所有的li标签 当然这里通过children可以实现同样的效果,并且通过.children方法得到的结果也是一个pyquery对象 li = items.children() print(type(li)) print(li) 同时在children里也可以用CSS选择器 li2 = items.children(’.active’) print(li2) 父元素 parent,parents方法 通过.parent就可以找到父元素的内容，例子如下： html = ''' \u003cdiv id=\"container\"\u003e \u003cul class=\"list\"\u003e \u003cli class=\"item-0\"\u003efirst item\u003c/li\u003e \u003cli class=\"item-1\"\u003e\u003ca href=\"link2.html\"\u003esecond item\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-0 active\"\u003e\u003ca href=\"link3.html\"\u003e\u003cspan class=\"bold\"\u003ethird item\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-1 active\"\u003e\u003ca href=\"link4.html\"\u003efourth item\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-0\"\u003e\u003ca href=\"link5.html\"\u003efifth item\u003c/a\u003e\u003c/li\u003e \u003c/ul\u003e \u003c/div\u003e ''' from pyquery import PyQuery as pq doc = pq(html) items = doc('.list') container = items.parent() print(type(container)) print(container) 通过.parents就可以找到祖先节点的内容，例子如下： html = ''' \u003cdiv class=\"wrap\"\u003e \u003cdiv id=\"container\"\u003e \u003cul class=\"list\"\u003e \u003cli class=\"item-0\"\u003efirst item\u003c/li\u003e \u003cli class=\"item-1\"\u003e\u003ca href=\"link2.html\"\u003esecond item\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-0 active\"\u003e\u003ca href=\"link3.html\"\u003e\u003cspan class=\"bold\"\u003ethird item\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-1 active\"\u003e\u003ca href=\"link4.html\"\u003efourth item\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-0\"\u003e\u003ca href=\"link5.html\"\u003efifth item\u003c/a\u003e\u003c/li\u003e \u003c/ul\u003e \u003c/div\u003e \u003c/div\u003e ''' from pyquery import PyQuery as pq doc = pq(html) items = doc('.list') parents = items.parents() print(type(parents)) print(parents) 结果如下： 从结果我们可以看出返回了两部分内容，一个是的父节点的信息，一个是父节点的父节点的信息即祖先节点的信息 同样我们通过.parents查找的时候也可以添加css选择器来进行内容的筛选 兄弟元素 siblings html = ''' \u003cdiv class=\"wrap\"\u003e \u003cdiv id=\"container\"\u003e \u003cul class=\"list\"\u003e \u003cli class=\"item-0\"\u003efirst item\u003c/li\u003e \u003cli class=\"item-1\"\u003e\u003ca href=\"link2.html\"\u003esecond item\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-0 active\"\u003e\u003ca href=\"link3.html\"\u003e\u003cspan class=\"bold\"\u003ethird item\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-1 active\"\u003e\u003ca href=\"link4.html\"\u003efourth item\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-0\"\u003e\u003ca href=\"link5.html\"\u003efifth item\u003c/a\u003e\u003c/li\u003e \u003c/ul\u003e \u003c/div\u003e \u003c/div\u003e ''' from pyquery import PyQuery as pq doc = pq(html) li = doc('.list .item-0.active') print(li.siblings()) 代码中doc(’.list .item-0.active’) 中的.tem-0和.active是紧挨着的，所以表示是并的关系，这样满足条件的就剩下一个了：thired item的那个标签了 这样在通过.siblings就可以获取所有的兄弟标签，当然这里是不包括自己的 同样的在.siblings()里也是可以通过CSS选择器进行筛选 遍历 单个元素 html = ''' \u003cdiv class=\"wrap\"\u003e \u003cdiv id=\"container\"\u003e \u003cul class=\"list\"\u003e \u003cli class=\"item-0\"\u003efirst item\u003c/li\u003e \u003cli class=\"item-1\"\u003e\u003ca href=\"link2.html\"\u003esecond item\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-0 active\"\u003e\u003ca href=\"link3.html\"\u003e\u003cspan class=\"bold\"\u003ethird item\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-1 active\"\u003e\u003ca href=\"link4.html\"\u003efourth item\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-0\"\u003e\u003ca href=\"link5.html\"\u003efifth item\u003c/a\u003e\u003c/li\u003e \u003c/ul\u003e \u003c/div\u003e \u003c/div\u003e ''' from pyquery import PyQuery as pq doc = pq(html) li = doc('.item-0.active') print(li) lis = doc('li').items() print(type(lis)) for li in lis: print(type(li)) print(li) 运行结果如下： 从结果中我们可以看出通过items()可以得到一个生成器，并且我们通过for循环得到的每个元素依然是一个pyquery对象。 ","date":"2020-04-28","objectID":"/20200428/:1:3","tags":["python","爬虫"],"title":"爬虫流程及方法11(PyQuery解析网页篇)(全)","uri":"/20200428/"},{"categories":["python","爬虫"],"content":"获取信息 获取属性 pyquery对象.attr(属性名) pyquery对象.attr.属性名 html = ''' \u003cdiv class=\"wrap\"\u003e \u003cdiv id=\"container\"\u003e \u003cul class=\"list\"\u003e \u003cli class=\"item-0\"\u003efirst item\u003c/li\u003e \u003cli class=\"item-1\"\u003e\u003ca href=\"link2.html\"\u003esecond item\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-0 active\"\u003e\u003ca href=\"link3.html\"\u003e\u003cspan class=\"bold\"\u003ethird item\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-1 active\"\u003e\u003ca href=\"link4.html\"\u003efourth item\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-0\"\u003e\u003ca href=\"link5.html\"\u003efifth item\u003c/a\u003e\u003c/li\u003e \u003c/ul\u003e \u003c/div\u003e \u003c/div\u003e ''' from pyquery import PyQuery as pq doc = pq(html) a = doc('.item-0.active a') print(a) print(a.attr('href')) print(a.attr.href) 所以这里我们也可以知道获得属性值的时候可以直接a.attr(属性名)或者a.attr.属性名 获取文本 在很多时候我们是需要获取被html标签包含的文本信息,通过.text()就可以获取文本信息 html = ''' \u003cdiv class=\"wrap\"\u003e \u003cdiv id=\"container\"\u003e \u003cul class=\"list\"\u003e \u003cli class=\"item-0\"\u003efirst item\u003c/li\u003e \u003cli class=\"item-1\"\u003e\u003ca href=\"link2.html\"\u003esecond item\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-0 active\"\u003e\u003ca href=\"link3.html\"\u003e\u003cspan class=\"bold\"\u003ethird item\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-1 active\"\u003e\u003ca href=\"link4.html\"\u003efourth item\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-0\"\u003e\u003ca href=\"link5.html\"\u003efifth item\u003c/a\u003e\u003c/li\u003e \u003c/ul\u003e \u003c/div\u003e \u003c/div\u003e ''' from pyquery import PyQuery as pq doc = pq(html) a = doc('.item-0.active a') print(a) print(a.text()) 结果如下： 获取html 我们通过.html()的方式可以获取当前标签所包含的html信息，例子如下 html = ''' \u003cdiv class=\"wrap\"\u003e \u003cdiv id=\"container\"\u003e \u003cul class=\"list\"\u003e \u003cli class=\"item-0\"\u003efirst item\u003c/li\u003e \u003cli class=\"item-1\"\u003e\u003ca href=\"link2.html\"\u003esecond item\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-0 active\"\u003e\u003ca href=\"link3.html\"\u003e\u003cspan class=\"bold\"\u003ethird item\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-1 active\"\u003e\u003ca href=\"link4.html\"\u003efourth item\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-0\"\u003e\u003ca href=\"link5.html\"\u003efifth item\u003c/a\u003e\u003c/li\u003e \u003c/ul\u003e \u003c/div\u003e \u003c/div\u003e ''' from pyquery import PyQuery as pq doc = pq(html) li = doc('.item-0.active') print(li) print(li.html()) 结果如下： ","date":"2020-04-28","objectID":"/20200428/:1:4","tags":["python","爬虫"],"title":"爬虫流程及方法11(PyQuery解析网页篇)(全)","uri":"/20200428/"},{"categories":["python","爬虫"],"content":"DOM操作 addClass、removeClass 熟悉前端操作的话，通过这两个操作可以添加和删除属性 html = ''' \u003cdiv class=\"wrap\"\u003e \u003cdiv id=\"container\"\u003e \u003cul class=\"list\"\u003e \u003cli class=\"item-0\"\u003efirst item\u003c/li\u003e \u003cli class=\"item-1\"\u003e\u003ca href=\"link2.html\"\u003esecond item\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-0 active\"\u003e\u003ca href=\"link3.html\"\u003e\u003cspan class=\"bold\"\u003ethird item\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-1 active\"\u003e\u003ca href=\"link4.html\"\u003efourth item\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-0\"\u003e\u003ca href=\"link5.html\"\u003efifth item\u003c/a\u003e\u003c/li\u003e \u003c/ul\u003e \u003c/div\u003e \u003c/div\u003e ''' from pyquery import PyQuery as pq doc = pq(html) li = doc('.item-0.active') print(li) li.removeClass('active') print(li) li.addClass('active') print(li) attr,css 同样的我们可以通过attr给标签添加和修改属性， 如果之前没有该属性则是添加，如果有则是修改 我们也可以通过css添加一些css属性，这个时候，标签的属性里会多一个style属性 html = ''' \u003cdiv class=\"wrap\"\u003e \u003cdiv id=\"container\"\u003e \u003cul class=\"list\"\u003e \u003cli class=\"item-0\"\u003efirst item\u003c/li\u003e \u003cli class=\"item-1\"\u003e\u003ca href=\"link2.html\"\u003esecond item\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-0 active\"\u003e\u003ca href=\"link3.html\"\u003e\u003cspan class=\"bold\"\u003ethird item\u003c/span\u003e\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-1 active\"\u003e\u003ca href=\"link4.html\"\u003efourth item\u003c/a\u003e\u003c/li\u003e \u003cli class=\"item-0\"\u003e\u003ca href=\"link5.html\"\u003efifth item\u003c/a\u003e\u003c/li\u003e \u003c/ul\u003e \u003c/div\u003e \u003c/div\u003e ''' from pyquery import PyQuery as pq doc = pq(html) li = doc('.item-0.active') print(li) li.attr('name', 'link') print(li) li.css('font-size', '14px') print(li) 结果如下 remove 有时候我们获取文本信息的时候可能并列的会有一些其他标签干扰，这个时候通过remove就可以将无用的或者干扰的标签直接删除，从而方便操作 html = ''' \u003cdiv class=\"wrap\"\u003e Hello, World \u003cp\u003eThis is a paragraph.\u003c/p\u003e \u003c/div\u003e ''' from pyquery import PyQuery as pq doc = pq(html) wrap = doc('.wrap') print(wrap.text()) wrap.find('p').remove() print(wrap.text()) 结果如下： ","date":"2020-04-28","objectID":"/20200428/:1:5","tags":["python","爬虫"],"title":"爬虫流程及方法11(PyQuery解析网页篇)(全)","uri":"/20200428/"},{"categories":["python","爬虫"],"content":" import requests from bs4 import BeautifulSoup a = True while a: headers = { 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.122 Safari/537.36' } params = { '_v': '5.12.0' } fp = open('./萌新论坛爬虫.text', 'w', encoding='utf-8') urls = 'http://www.lolichan.vip/' response = requests.get(url=urls, params=params, headers=headers).text soup = BeautifulSoup(response, 'lxml') class_list= soup.select('.node-title') for li in class_list: try: detail_url = 'http://www.lolichan.vip/' + li.a['href'] detail_page_text = requests.get(url=detail_url, params=params, headers=headers).text detail_soup = BeautifulSoup(detail_page_text, 'lxml') page_list = detail_soup.select('.structItem-title') print('抓取页面成功') except: page_list = '-----' for i in page_list: try: page_title = i.a.string page_url = 'http://www.lolichan.vip/' + i.a['href'] page_text = requests.get(url=page_url, headers=headers).text detail_soup = BeautifulSoup(page_text, 'lxml') div_tag = detail_soup.find('div', class_='bbWrapper') content = div_tag.text fp.write(page_title + ':' + content + '\\n') print('爬取页面成功') except: continue a = False ajax请求请参考爬虫流程及方法09(动态加载页面)(ajax请求)(Json实例) ","date":"2020-04-26","objectID":"/20200426/:0:0","tags":["python","爬虫"],"title":"爬虫流程及方法08(BeautifulSoup实例)(非ajax请求)","uri":"/20200426/"},{"categories":["python","爬虫"],"content":"动态加载数据ajax ","date":"2020-04-26","objectID":"/20200427/:0:0","tags":["python","爬虫"],"title":"爬虫流程及方法09(动态加载页面)(ajax请求)(Json实例)","uri":"/20200427/"},{"categories":["python","爬虫"],"content":"首页中对应企业数据通过ajax请求得到 详情页url只有id不同其余相同 id从json中获取，域名与id拼接新url 详情页的数据也是动态加载出来的 详情页的url也是相同的只有id不同 爬取的原网站药妆局 推荐使用chrome网页抓包工具查看请求类型 首页与详情页都使用post请求传输json数据包，需要json解析 import requests import json a = True while a: headers = { \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.122 Safari/537.36\" } #批量获取企业详情页对应id url = \"http://125.35.6.84:81/xk/itownet/portalAction.do?method=getXkzsList\" id_list = [] # 存储企业id all_data_list = [] #参数封装 for page in range(1,6): data = { 'on': 'true', 'page': page, 'pageSize': ' 15', 'productName': '', 'conditionType': ' 1', 'applyname': '', 'applysn': '' } json_ids = requests.post(url=url, headers=headers,data=data).json() for i in json_ids['list']: id_list.append(i['ID']) # 存储所有企业详情数据 post_url = \"http://125.35.6.84:81/xk/itownet/portalAction.do?method=getXkzsList\" for id in id_list: data = { 'id': id } detail_json = requests.post(url=post_url, headers=headers, data=data).json() all_data_list.append(detail_json) #持久化存储 fp = open('./alldata.json','w',encoding='utf-8') json.dump(all_data_list, fp=fp, ensure_ascii=False) print('over') a = False 总结：爬虫检查网页的传输方式，选择get请求还是post请求，注意是否为ajax请求，注意解析数据包的格式 ","date":"2020-04-26","objectID":"/20200427/:0:1","tags":["python","爬虫"],"title":"爬虫流程及方法09(动态加载页面)(ajax请求)(Json实例)","uri":"/20200427/"},{"categories":["博客建站相关"],"content":"1. 前言 本markdown文档初版下载链接： (建议看初版文档理解书写格式，书写标准以本网站本页面为主) https://pan.baidu.com/s/1z_2IsuaRh8cYmtssepvIXQ 提取码：0a83 本篇鸣谢胡国磊学长整理，由我进行加工发布 ","date":"2020-04-25","objectID":"/20200425/:1:0","tags":["hugo"],"title":"撰写hugo博客的markdown格式","uri":"/20200425/"},{"categories":["博客建站相关"],"content":"2. 示例文章 橙心：终于等到你，公众号排版神器 姹紫：JavaScript 数据结构与算法之美 绿意：前端硬核面试专题之 CSS 55 问 红绯：日常 | 我用什么工具写作？ Wechat-Format：Markdown Nice 新特性：阿里云图床 科技蓝：2019 前端秋季社招面试经历总结（二年多经验） 效果及代码图如下: ","date":"2020-04-25","objectID":"/20200425/:2:0","tags":["hugo"],"title":"撰写hugo博客的markdown格式","uri":"/20200425/"},{"categories":["博客建站相关"],"content":"3 通用语法 ","date":"2020-04-25","objectID":"/20200425/:3:0","tags":["hugo"],"title":"撰写hugo博客的markdown格式","uri":"/20200425/"},{"categories":["博客建站相关"],"content":"3.0 分割线 在markdown语法中,一行连用三个或者三个以上的星号,减号,或者下划线,就可以表示分割线。 例如:*** — __ 为方便记忆,只需记住三个减号\"—“可以表示分割线即可。 另外,分割线可以起到把分割线上下的内容分割成两个段落的作用。 ","date":"2020-04-25","objectID":"/20200425/:3:1","tags":["hugo"],"title":"撰写hugo博客的markdown格式","uri":"/20200425/"},{"categories":["博客建站相关"],"content":"3.1 标题 在文字写书写不同数量的#可以完成不同的标题，一行开头打上不同数目的#最后在#末尾加上空格再书写标题内容，效果如下： 一级标题 ","date":"2020-04-25","objectID":"/20200425/:3:2","tags":["hugo"],"title":"撰写hugo博客的markdown格式","uri":"/20200425/"},{"categories":["博客建站相关"],"content":"二级标题 ","date":"2020-04-25","objectID":"/20200425/:4:0","tags":["hugo"],"title":"撰写hugo博客的markdown格式","uri":"/20200425/"},{"categories":["博客建站相关"],"content":"三级标题 ","date":"2020-04-25","objectID":"/20200425/:4:1","tags":["hugo"],"title":"撰写hugo博客的markdown格式","uri":"/20200425/"},{"categories":["博客建站相关"],"content":"3.2 无序列表 无序列表的使用，在符号-后加空格使用。如下： 无序列表 1 无序列表 2 无序列表 3 如果要控制列表的层级，则需要在符号-前使用空格。如下： 无序列表 1 无序列表 2 无序列表 2.1 无序列表 2.2 ","date":"2020-04-25","objectID":"/20200425/:4:2","tags":["hugo"],"title":"撰写hugo博客的markdown格式","uri":"/20200425/"},{"categories":["博客建站相关"],"content":"3.3 有序列表 有序列表的使用，在数字及符号.后加空格后再输入内容，如下： 有序列表 1 有序列表 2 有序列表 3 ","date":"2020-04-25","objectID":"/20200425/:4:3","tags":["hugo"],"title":"撰写hugo博客的markdown格式","uri":"/20200425/"},{"categories":["博客建站相关"],"content":"3.4 引用 引用的格式是在符号\u003e后面书写文字。效果如下： 读一本好书，就是在和高尚的人谈话。 ——歌德 雇用制度对工人不利，但工人根本无力摆脱这个制度。 ——阮一峰 ","date":"2020-04-25","objectID":"/20200425/:4:4","tags":["hugo"],"title":"撰写hugo博客的markdown格式","uri":"/20200425/"},{"categories":["博客建站相关"],"content":"3.5 粗体和斜体 粗体的使用是在需要加粗的文字前后各加两个*。 而斜体的使用则是在需要斜体的文字前后各加一个*。 如果要使用粗体和斜体，那么就是在需要操作的文字前后加三个*。效果如下： 这个是粗体 这个是斜体 这个是粗体加斜体 注：由于 commonmark 标准，可能会导致加粗与想象不一致，如下 **今天天气好晴朗，**处处好风光。 这个是正常现象，请参考加粗 Issue。 ","date":"2020-04-25","objectID":"/20200425/:4:5","tags":["hugo"],"title":"撰写hugo博客的markdown格式","uri":"/20200425/"},{"categories":["博客建站相关"],"content":"3.6 链接 代码图： 效果如下： 文章链接你是《未来世界的幸存者》么？ ","date":"2020-04-25","objectID":"/20200425/:4:6","tags":["hugo"],"title":"撰写hugo博客的markdown格式","uri":"/20200425/"},{"categories":["博客建站相关"],"content":"3.7 分割线 代码图： 可以在一行中用三个以上的减号来建立一个分隔线，同时需要在分隔线的上面空一行。效果如下： ","date":"2020-04-25","objectID":"/20200425/:4:7","tags":["hugo"],"title":"撰写hugo博客的markdown格式","uri":"/20200425/"},{"categories":["博客建站相关"],"content":"3.8 删除线 删除线的使用，在需要删除的文字前后各使用两个~，效果如下： 这是要被删除的内容。 ","date":"2020-04-25","objectID":"/20200425/:4:8","tags":["hugo"],"title":"撰写hugo博客的markdown格式","uri":"/20200425/"},{"categories":["博客建站相关"],"content":"3.9 表格 可以使用冒号来定义表格的对齐方式，格式如下： 效果如下： 姓名 年龄 工作 小可爱 18 吃可爱多 小小勇敢 20 爬棵勇敢树 小小小机智 22 看一本机智书 ","date":"2020-04-25","objectID":"/20200425/:4:9","tags":["hugo"],"title":"撰写hugo博客的markdown格式","uri":"/20200425/"},{"categories":["博客建站相关"],"content":"3.10 图片 插入图片，如果是行内图片则无图例，否则有图例，格式图如下： 效果如下： 支持 jpg、png、gif 等图片格式， 支持图片拖拽和截图粘贴到编辑器中上传，上传时使用当前选择的图床。 可使用格式-\u003e图片上传本地图片，网站仅支持「图壳」图床，失败率低可长久保存！ ","date":"2020-04-25","objectID":"/20200425/:4:10","tags":["hugo"],"title":"撰写hugo博客的markdown格式","uri":"/20200425/"},{"categories":["博客建站相关"],"content":"4.1 代码块 如果在一个行内需要引用代码，只要用反引号引起来就好，如下： Use the printf() function. 在需要高亮的代码块的前一行及后一行使用三个反引号，同时第一行反引号后面表示代码块所使用的语言 格式图如下： 效果如下： // FileName: HelloWorld.java public class HelloWorld { // Java 入口程序，程序从此入口 public static void main(String[] args) { System.out.println(\"Hello,World!\"); // 向控制台打印一条语句 } } 支持以下语言种类： bash clojure，cpp，cs，css dart，dockerfile, diff erlang go，gradle，groovy haskell java，javascript，json，julia kotlin lisp，lua makefile，markdown，matlab objectivec perl，php，python r，ruby，rust scala，shell，sql，swift tex，typescript verilog，vhdl xml yaml 如果想要更换代码主题，可在上方挑选，不支持代码主题自定义。 ","date":"2020-04-25","objectID":"/20200425/:4:11","tags":["hugo"],"title":"撰写hugo博客的markdown格式","uri":"/20200425/"},{"categories":["博客建站相关"],"content":"5 其他语法 ","date":"2020-04-25","objectID":"/20200425/:5:0","tags":["hugo"],"title":"撰写hugo博客的markdown格式","uri":"/20200425/"},{"categories":["博客建站相关"],"content":"5.1 HTML 支持原生 HTML 语法，请写内联样式，格式图如下： 效果如下： 橙色居右 橙色居中 ","date":"2020-04-25","objectID":"/20200425/:5:1","tags":["hugo"],"title":"撰写hugo博客的markdown格式","uri":"/20200425/"},{"categories":["博客建站相关"],"content":"5.2 UML 不支持，推荐使用开源工具https://draw.io/制作后再导入图片 ","date":"2020-04-25","objectID":"/20200425/:5:2","tags":["hugo"],"title":"撰写hugo博客的markdown格式","uri":"/20200425/"},{"categories":["博客建站相关"],"content":"5.3 组件图床 组件目前共支持 3 种图床和 1 种自定义图床，主要特点如下： 图床 费用 有效期 失败率 SM.MS 免费 长期 高 阿里云 付费 自定义 低 七牛云 10G 免费 自定义 低 自定义 高昂 自定义 自定义 4 个图床的缺点： 图床 缺点 SM.MS 失败率高可用性很差 阿里云 配置繁琐，费用昂贵 七牛云 配置繁琐，需购买长期域名 自定义 搭建后台繁琐 这里我推荐我经常用的一个图源保存网站： https://pic./ ","date":"2020-04-25","objectID":"/20200425/:5:3","tags":["hugo"],"title":"撰写hugo博客的markdown格式","uri":"/20200425/"},{"categories":["博客建站相关"],"content":"5.4 下拉列表(部分主题支持本格式) 代码如下 \u003cdetails\u003e \u003csummary\u003e展开查看\u003c/summary\u003e \u003cpre\u003e\u003ccode\u003e 内容 \u003c/code\u003e\u003c/pre\u003e \u003c/details\u003e 效果如下： 展开查看\r内容\r","date":"2020-04-25","objectID":"/20200425/:5:4","tags":["hugo"],"title":"撰写hugo博客的markdown格式","uri":"/20200425/"},{"categories":["博客建站相关"],"content":"5.5 更多文档 更多文档请参考 markdown-nice-docs ","date":"2020-04-25","objectID":"/20200425/:5:5","tags":["hugo"],"title":"撰写hugo博客的markdown格式","uri":"/20200425/"},{"categories":["python","爬虫"],"content":"技术路线 1.requests-BeautifulSoup 2.scrapy(5+2结构) 3.scrapy + requests-Beautiful-re + PhantomJS —\u003e表单提交、爬取周期、入库存储(js处理) 4.requests-xpath 5.requests-ccs 6.requests库可与urllib库互换 ","date":"2020-04-22","objectID":"/20200422/:0:1","tags":["python","爬虫"],"title":"爬虫流程及方法07(爬虫技术路线整理)(实时更新)","uri":"/20200422/"},{"categories":["python","爬虫"],"content":"提高爬取速度的方法 1.在setting.py文件里修改并发选项 2.使用scrapy-*的高级补充库，特化某方面，提升速度 3.选择合适的技术路线进行爬虫 ","date":"2020-04-21","objectID":"/20200421/:0:1","tags":["python","爬虫"],"title":"爬虫流程及方法06(Scrapy进阶爬虫)(实时更新)","uri":"/20200421/"},{"categories":["python","爬虫"],"content":"Request类 class scrapy.http.Request() Request对象表示一个HTTP请求。 由Spider生成，由Downloader执行。 常用属性： ","date":"2020-04-20","objectID":"/20200420/:0:1","tags":["python","爬虫"],"title":"爬虫流程及方法05(Scrapy入门级爬虫)","uri":"/20200420/"},{"categories":["python","爬虫"],"content":"Response类 class scrapy.http.Response() Response对象表示一个HTTP响应。 由Downloader生成，由Spider处理。 常用属性与方法： ","date":"2020-04-20","objectID":"/20200420/:0:2","tags":["python","爬虫"],"title":"爬虫流程及方法05(Scrapy入门级爬虫)","uri":"/20200420/"},{"categories":["python","爬虫"],"content":"Item类 class scrapy.item.Item() Item对象表示一个从HTML页面中提取的信息内容。 由Spider生成，由Item Pipeline处理。 Item类似字典类型，可以按照字典类型操作。 ","date":"2020-04-20","objectID":"/20200420/:0:3","tags":["python","爬虫"],"title":"爬虫流程及方法05(Scrapy入门级爬虫)","uri":"/20200420/"},{"categories":["python","爬虫"],"content":"Scrapy爬虫支持多种HTML信息提取方法 Beautiful Soup lxml re XPath Selector CSS Selector CSS Selector的基本形式: ","date":"2020-04-20","objectID":"/20200420/:0:4","tags":["python","爬虫"],"title":"爬虫流程及方法05(Scrapy入门级爬虫)","uri":"/20200420/"},{"categories":["python","爬虫"],"content":"步骤 步骤1:建立工程和Spider模板 步骤2:编写Spider(实际爬虫) 步骤3:编写ITEM Pipelines(爬虫数据处理) 步骤3:编写Pipelines: 配置pipelines.py文件 定义对爬取项(Scraped Item)的处理类 配置ITEM PIPELINES选项(配置setting.py文件) ","date":"2020-04-20","objectID":"/20200420/:0:5","tags":["python","爬虫"],"title":"爬虫流程及方法05(Scrapy入门级爬虫)","uri":"/20200420/"},{"categories":["python","爬虫"],"content":"PS：以下代码仅供参考，不具备运行基础 #工程文档为以下内容 import scrapy import re class StocksSpider (scrapy . Spider) : name = \"stock s\" start_urls = ['http://quote.eastmoney.com/stocklist.html'] def parse(self, response): for href in response.css ('a: :attr (href) ').extract(): try: stock = re.findall(r\"[s][hz]\\d{6}\", href)[0] url = 'https://gupiao.baidu.com/stock/' + stock + '.html' yield scrapy.Request(url, callback=self.parse_stock) except: continue def parse_stock(self, response): infoDict = { } stockInfo = response.css('.stock-bets') name = stockInfo.css('.bets-name').extract()[0] keyList = stockInfo.css('dt').extract() valueList = stockInfo.css('dd').extract() for i in range(len(keyList)): key = re.findall(r'\u003e.*\u003c/dt\u003e', keyList[i])[0][1:-5] try: val = re.findall(r'\\d+\\.?.*\u003c/dd\u003e', valueList[1])[0][0:-5] except: val = '----' infoDict[key] = val infoDict.update({'股票名称': re.findall('\\s.*\\(', name)[0].split()[0] + re.findall('\\\u003e.*\\\u003c', name)[0][1:-1]}) yield infoDict #pipeline文档下的内容 class BaidustocksPipeline(object): def process_item(self, item, spider): return item class BaidustocksInfoPipeline(object): def open_spider(self, spider): self.f = open('BaidustockInfo.txt', 'W') def close_spider(self, spider): self.f.close() def process_item(self, item, spider): try: line = str(dict(item)) + '\\n' self.f.write(line) except: pass return item ","date":"2020-04-20","objectID":"/20200420/:1:0","tags":["python","爬虫"],"title":"爬虫流程及方法05(Scrapy入门级爬虫)","uri":"/20200420/"},{"categories":["python","爬虫"],"content":"总结： 技术路线： requests-bs4-re scrapy(5+2结构) scrapy + requests-bs4-re + PhantomJS —\u003e表单提交、爬取周期、入库存储(js处理) ","date":"2020-04-20","objectID":"/20200420/:1:1","tags":["python","爬虫"],"title":"爬虫流程及方法05(Scrapy入门级爬虫)","uri":"/20200420/"},{"categories":["python","爬虫"],"content":"安装scrapy pycharm安装步骤: 1.打开左上角file 2.打开Other Setting下的Setting for New Project 3.在Project Interpreter选择Project Interpreter里你使用的编译器后，点击加号(+)添加包 4.修改Manage Repositories(参考第三方下载包修改篇) 5.在搜索框里搜索以下包名xxx(注意字母大小写不同) Scrapy Twisted pywin32 wheel 6.在terminal窗口输入scrapy确认出现版本信息及命令提示 ","date":"2020-04-17","objectID":"/20200417/:0:1","tags":["python","爬虫"],"title":"爬虫流程及方法04(Scrapy框架)","uri":"/20200417/"},{"categories":["python","爬虫"],"content":"step1: 建立工程文档 终端terminal输入： scrapy startproject 工程文档名 创建得到的文档结构： 工程文档名/ -----\u003e外层目录\rscrapy.cfg -----\u003e部署scrapy爬虫的配置文件\r工程文档名/ ----\u003escrapy框架的用户自定义的python代码\r_init_.py -----\u003e初始化脚本\ritems.py -----\u003eitems代码模块（继承类）\rmiddlewares.py -----\u003emiddlewares代码模块（继承类）\rpipelines.py ------\u003epipelines代码模板（继承类）\rsetting.py ------\u003escrapy爬虫的配置文件\rspiders/ ------\u003e代码模板目录(继承类)\r","date":"2020-04-17","objectID":"/20200417/:0:2","tags":["python","爬虫"],"title":"爬虫流程及方法04(Scrapy框架)","uri":"/20200417/"},{"categories":["python","爬虫"],"content":"step2: 产生爬虫 终端terminal输入：(cmd内或pycharm里面的terminal) cd 工程文档名 scrapy genspider demo 爬取页面的url 或者： 直接在含spider的目录下新建demo.py文件 写入以下代码 import scrapy class DemoSpider(scrapy.Spider): name = \"demo\" allowed_domain = [\"python123.io\"]#爬取该域名下的链接 start_urls = ['https://python123.io/']#爬取页面的初始页面 def parse(self, response):#解析页面方法类，形成字典类型或发现新链接 pass ","date":"2020-04-17","objectID":"/20200417/:0:3","tags":["python","爬虫"],"title":"爬虫流程及方法04(Scrapy框架)","uri":"/20200417/"},{"categories":["python","爬虫"],"content":"step3: 配置产生的spider爬虫(具体修改demo文件) eg： def parse(self, response): fname = response.url.split('/')[-1] with open(fname, 'wb') as f: f.write(response.body) self.log('Saved file %s.' % fname) ","date":"2020-04-17","objectID":"/20200417/:0:4","tags":["python","爬虫"],"title":"爬虫流程及方法04(Scrapy框架)","uri":"/20200417/"},{"categories":["python","爬虫"],"content":"step4: 终端terminal运行： 输入以下代码 scrapy crawl 文件名 eg：scrapy crawl demo ps:(爬虫的另一种框架) import scrapy: class DemoSpider(scrapy.Spider): name = \"demo\" def start requests(se1f): urls = [ 'http://python123.io/ws/demo.html ' ] for url in urls: yield scrapy.Request(ur1=ur1,callback=self.parse) def parse(self,response): fname = response.url.split('/')[-1] with open (fname,'wb') as f: f. write (response.body) self.log('Saved file %s.' % fname) yield关键字 yield —-\u003e生成器 优势：占用存储少，响应速度快 生成器是一个不断产生值的函数，包含yield语句的函数是一个生成器 生成器每次产生一个值(yield语句)，函数被冻结，被唤醒后再产生一个值。 生成器写法 def gen(n): for i in range(n): yield i**2 for 1 in gen(5): print(1,\" \",end=\"\") 结果 \u003e\u003e\u003e0 1 4 9 16 一般写法 def square(n) : ls =[i**2 for i in range (n) ] return ls for i in square (5) : print(i,\" \",end=\"\") 结果 \u003e\u003e\u003e0 1 4 9 16 ","date":"2020-04-17","objectID":"/20200417/:0:5","tags":["python","爬虫"],"title":"爬虫流程及方法04(Scrapy框架)","uri":"/20200417/"},{"categories":["电脑技巧"],"content":"个人收集，网站有可能不安全 ","date":"2020-04-12","objectID":"/20200412/:1:0","tags":["windows"],"title":"百度云盘加速","uri":"/20200412/"},{"categories":["电脑技巧"],"content":"建议浏览器隐私模式下使用，避免用户信息被盗窃 该页面下载共享提取码： QLHL 该页面解析地址由个人收集，替代网页插件版的直链解析，原理是pandownload的网页版，需要百度云盘的文件共享链接。 解析后的直链用idm下载即可跑满网速，idm下载地址：点我跳转下载页面 下面这个下载包含IDM和解析页面使用教程(教程的解析用的插件，可以用该网页的解析页面代替) IDM教程与配套软件 ↑↑↑看在资源的份上，麻烦点赞投币收藏我的文章—\u003ehttps://www.bilibili.com/read/cv6826074↑↑↑ 下面是解析网站，点击后会跳转到自动解析页面，后续步骤请按提示操作 ","date":"2020-04-12","objectID":"/20200412/:2:0","tags":["windows"],"title":"百度云盘加速","uri":"/20200412/"},{"categories":["电脑技巧"],"content":"个人推荐前五个 ","date":"2020-04-12","objectID":"/20200412/:3:0","tags":["windows"],"title":"百度云盘加速","uri":"/20200412/"},{"categories":["电脑技巧"],"content":"后面的安全性未知，可能会盗取信息 高速解析，同一ip每日三次解析机会 普通解析，每个IP每天一次免费解析，解析后的下载地址会在数据库中保存8小时，在8小时内再次解析不消耗次数 普通解析，不限次数 ↑↑↑账户密码都是hostloc https://betterman.xyz/wp/ 密码：bettermanxyz https://betterman.xyz/pan/ 密码：bettermanxyz666 普通解析(盗版搭建)01，安全性未知 普通解析(盗版搭建)02，安全性未知 普通解析(盗版搭建)03，安全性未知 普通解析(盗版搭建)04，安全性未知 普通解析(盗版搭建)05，危险性高 普通解析(盗版搭建)06，危险性高 ","date":"2020-04-12","objectID":"/20200412/:4:0","tags":["windows"],"title":"百度云盘加速","uri":"/20200412/"},{"categories":["电脑技巧"],"content":"后言 上述链接失效，请在-\u003e我的文章评论区\u003c-里留言，我会及时更新解析地址。(2021.6开始上述网址已过期，剩下下面几个) 自己搭的直链解析，如果有会员欢迎联系我捐赠进行高速解析：百度云盘直链解析站点。 解析密码：spiritlhl 不安全的解析： 不安全站点1 恶意篡改后台并加密 不安全站点2 此网站盗用其他网站的接口获取下载地址 建议支持正版。 正版web解析的作者不做演示站点 正版的仓库链接如下 https://github.com/yuantuo666/baiduwp-php 可以按照作者仓库自己搭建个人版Pandownload网页版。 2021.4.17新增天翼云盘不限速解析 站点1 站点2 站点3 该页面的资源均由网络收集。 本人不负任何法律责任，仅作为个人学习使用。 ","date":"2020-04-12","objectID":"/20200412/:5:0","tags":["windows"],"title":"百度云盘加速","uri":"/20200412/"},{"categories":["博客建站相关"],"content":"本地搭建博客 创建新文章 hugo new 你的文档名/你的文章名.md ","date":"2020-04-11","objectID":"/20200411/:0:0","tags":["hugo"],"title":"hugo博客部署码云","uri":"/20200411/"},{"categories":["博客建站相关"],"content":"在码云中创建库 1.链接一定是：/(填你的用户名) 2.选择公开/私有都行 3.注意不要初始化库(三个选项都不要选) 4.创建库 5.复制库链接(https类型) ","date":"2020-04-11","objectID":"/20200411/:0:1","tags":["hugo"],"title":"hugo博客部署码云","uri":"/20200411/"},{"categories":["博客建站相关"],"content":"部署到云端 1.在config.toml中改参数:baseURL = “https://你的用户名.gitee.io” 2.生成public: (初始化你的博客) 打开文件根目录的cmd或git bash here输入 hugo --theme=你的主题 3.进入public的文档，在该文档下打开git bash here 4.相继输入以下代码： git init git add . git commit -m \"first commit\" git remote add origin (https://gitee.com/......)(刚才复制的网址填这里) (假如是我就会填入https://gitee.com/spiritlhl/spiritLHL.git) git push -u origin master (无响应则再次运行同一代码) 5.进入之前你创建的库所在页面，刷新 6.鼠标打开服务，选择Gitee Pages，点击进入 7.选择强制使用HTTPS 8.启用服务 9.等待你的博客链接创建出来 你的博客:https://你的用户名.gitee.io/ 假如是我的博客:https://spiritlhl.gitee.io/ ","date":"2020-04-11","objectID":"/20200411/:0:2","tags":["hugo"],"title":"hugo博客部署码云","uri":"/20200411/"},{"categories":["博客建站相关"],"content":"注意，你的每一次提交都需要在Gitee Pages中手动更新，自动更新需要购买，这一点上我推荐使用Github ","date":"2020-04-11","objectID":"/20200411/:1:0","tags":["hugo"],"title":"hugo博客部署码云","uri":"/20200411/"},{"categories":["博客建站相关"],"content":"Github只需要你上传就自动更新页面了，免费给你使用该功能 欢迎访问 10分钟教你简单搭建个人博客hugo篇 8分钟教你简单部署hugo博客到码云gitee–含github博客转码云gitee的方法 里面有我搭建博客和部署云端的流程及效果。 ","date":"2020-04-11","objectID":"/20200411/:2:0","tags":["hugo"],"title":"hugo博客部署码云","uri":"/20200411/"},{"categories":["机器学习"],"content":"教计算机识别手写数字 (转载自YouTube) 人工神经网络是在现代神经科学的基础上提出和发展起来的，旨在反映人脑结构及功能的一种抽象数学模型。自1943 年美国心理学家 W. McCulloch 和数学家 W. Pitts 提 出形式神经元的抽象数学模型—MP 模型以来，人工神经网络理论技术经过了 50 多年 曲折的发展。特别是 20 世纪 80 年代，人工神经网络的研究取得了重大进展，有关的理论和方法已经发展成一门界于物理学、数学、计算机科学和神经生物学之间的交叉学科。希望阅读本篇，能使你对神经网络有一个大概的了解，明白其大概的工作原理。 神经网络之名来源自人的大脑结构。为什么叫做神经网络？我们来剖析一下，它的神经元是什么，神经元又是如何链接起来的，相信你就能得到答案了。目前说到神经元，我希望你把它暂时理解成一个用来装数字的容器，装着一个0到1之间的数字，仅此而已。 看这个例子，这个网络一开始的地方有很多神经元，分别对应了28×28的输入图像里的每一个像素，总计784个神经元，神经元中装着的数字代表对应像素的灰度值，0表示纯黑橡素，1表示纯白像素，我们把神经元里装着的数叫做“激活值”。你可以想象这么一个画面，激活值越大，神经元就点着越亮。那么这些784个神经元就组成了网络的第一层，现在我们跳到网络的最后一层，这一层的十个神经元分别代表0到9这十个数字，它们的激活值，同理都处在0到1之间，这些值表示系统认为输入的图像对应着哪个数字的可能性，网络中还有几层“隐含层”，暂时我们就把它看作一个大黑箱，里面就进行着处理识别数字的具体工作。 这个网络中，我选择加两层隐含层，每层有16个神经元，但其实这些设置都是随便选的，结构选择两层的原因在后续的介绍中我会解释，而选择16个神经元无非是显得好看罢了。(ಡωಡ)实际应用中，在网络结构上，我们有很大的调整实验的余地。 在神经网络的实验中，上一层的激活值将决定下一层的激活值。所以说，神经网络处理信息的核心机制正是一层激活值是通过怎样的运算算出下一层的激活值的。某种程度上讲，它想模仿的是生物神经元组成的网络。某些神经元的激发，就会促使另一些神经元激发。如果这个神经元网络被训练成熟，你在网络输入层的784个神经元处，输入了784个代表图像像素的灰度值。那么，随着一层层神经元的激活，会产生某些特殊的图案，最终在输出层得到某种结果。那我们首先要讨论的是：我们到底希望这些中间层最好能做什么呢？ 当我们人类在识别数字的时候，我们其实是在组合数字的各个部件。 在理想的情况下，我们希望倒数第二层的各个神经元能分别对应上一个笔画部件。这样一来，当我们输入一个9或8这种带圈数字时，某个神经元的激活值就会接近于1，而且我兵部特指某种样子的圈，我是希望所有这种位于图像顶部的圆圈图案都能点亮这个神经元。这样一来，从第三层到最后一层，我们只需要学习哪些部件能组合出哪个数字即可。当然，这样一来我们就引来了更多的问题。例如，要如何识别这些部件？其实，识别圆圈还可以细分成很多部分： 于是我们希望在网络第二层的各个神经元就能对应上这些各种各样的短边，没准当这样的图像输入进来的时候，它就能把所有关联的八到十个神经元都给点亮，接着就能点亮对应顶部圆圈和长竖条的神经元，最后就能点亮对应9字的神经元👇👇👇👇👇👇👇👇👇👇 至于我们的网络是否真的能做到这一步，需要我们对网络进行训练，但这就是我们的希望，希望这种层状结构能完成的目标。更进一步的讲，假如神经网络真能识别出这类边缘和图案，它就能更好的运用到其他的图像识别上来。 甚至不光是图像识别，世界上各种人工智能的任务，都可以转化为抽象元素，一层层的抽丝剥茧，就比如语言识别，就是要从原音频中识别出特殊的声音，组合成特定的音节，组合成单词，再组合成短语，以及更抽象的概念。回到神经网络工作原理上来，试想一下，你要设计上一层中的激活值到底如何决定下一层中的激活值。我们需要设计一个机制，可以把像素拼成短边，把短边拼成图案，或把图案拼成数字等等。在这个例子里，我们来放大关注其中的一个。我们来设计，让第二层中的这一个神经元能够正确识别出图像的这快区域里是否存在一条边。 现在我们就需要知道这个网络的参数，以及如何调整网络上的旋钮开关，才能让它足以表示出特殊的图案。我们需要给这个神经元和第一层所有神经元间的每一条接线都赋上一个权重值，这些权重都不过是数字数字而已。 然后，我们拿起第一层所有的激活值值和它们对应的权重值一起，算出它们的加权和。 我觉得把这些权重值做成一个表格更好理解，让我们把正的权重标记为绿色，负的标记成红色，颜色越暗，就大致表示它的权重越接近于0。现在我们把关注区域的权重赋为正值，而其他所有的权重一律赋为0，这样一来，对所有的像素取加权和，就只会累加我们关注区域的像素值了。此时如果你真的想识别出这里是否存在一条边，你只需要给周围一圈的像素赋予负的权重。这样，当中间的像素量，周围的像素暗时，加权和就能达到最大。 这样计算出来的加权和可以是任意大小，但在这个网络中，我们需要激活值处在0与1之间。那么，我们就可以顺其自然把这个加权和输入进某个函数，把这条实数轴挤压进0到1的区间内，其中一个叫sigmoid的函数非常常用，它又叫logistic/逻辑斯蒂曲线。 简而言之，它能把非常大的负值变成接近0，非常大的正值变成接近于1，而在取值0附近则是平稳增长的。 所以这个神经元中的激活值，实际上就是对加权和到底有多正的打分。但有时候，即使加权和大于0时，你也不想把神经元点亮，可能只有当和大于例如10的时候才让它激发。此时，你就需要加上一个偏置值·，保证不能随便激发。（当加权值大于10时，激发才有意义，过早激发会出现偏差）而我们只需要在加权和之后加上一个负10之类的数，再把它送进sigmoid函数即可，这个附加的数就叫偏置。总而言之，权重告诉你这个第二层的神经元关注什么样的像素图案，偏置告诉你加权和得有多大，才能让神经元的激发变得有意义。我们这就解说完了其中一个神经元，但这每一层的每一个神经元，都会和第一层全部的784个神经元相连接，每个神经元各带784个权重，而且每一个神经元都会在计算自己的加权后加上自己的偏置，再通过sigmoid压缩输出自己的结果。 这一下子要考虑的东西就多了起来，这层隐含层的16个神经元，就需要总计784×16个权重值和16个偏置值，而且这还是单单第一层和第二层之间的连接，别的层之间还有它们分别自带的权重和偏置，一整套下来整个网络一共会用上将近13000个权重加偏置，相当于这个网络上有将近13000多个旋钮开关让你调整，从而带来不一样的结果。所以当我们讨论机器如何学习的时候，我们其实在讲，电脑应该如何设置这一大坨数字参数，才能让它正确地解决问题。这里有一个细思极恐的###思想实验，想象一下你自己手动调整这些权重还有偏置参数，让第二层识别短边，第三层识别图案。 思想实验2 比起把网络完全当作一个黑箱，我个人觉得这么考虑更加令人满意，毕竟当网络的输出和期望出了偏差的时候，如果你一定程度上了解了这些权重和偏置的意义，那么你再尝试对结构进行修正就有出发点了。或许你的神经网络能输出正确的结果，但过程和你想象的不一样，那么深挖权重和偏置的实际意义，就可能对你的假设提出挑战（即使正确工作，也要追究缘由，进而探索出所有可能的解决方案。） 让我们把某一层中所有的激活值统一成一列向量，再把它和下一层检索有的权重放到一个矩阵中，矩阵第n行就是这一层的所有神经元和下一层第n个神经元间所有的连线的权重，这样权重和向量乘积的第n项就是这一层所有的激活值和下一层第n个神经元间连线权重的加权和。 表达偏置值的时候，我们并不会把一个个值都拎出来单独讨论。相反，我们会把它们都放到一个向量里然后和它们之前的矩阵乘法相加。最后一步，我们把整个表达式用一个sigmoid包起来。所谓包起来就是指对表达式结果向量中的每一项都取一次sigmoid。 现在，只要我们一写下权重矩阵和相应向量的符号，神经网络各层之间激活值的转化就可以表达得清晰简明明了了。 这种表达也让我们写程序变得简便了许多，因为很多库在矩阵乘法方面做了十足的优化。 还记得之前，我叫你把神经元看作数字的容器吗？实际上，神经元中装着的值是取决于你的输入图像的，所以我们把神经元看作一个函数才更加准确， 它的输入是上层所有的神经元的输出，它的输出是一个0到1之间的值。其实整个神经网络就是一个函数，一个输入784个值，输出10个值的函数。不过这个函数极其复杂，使用了13000个权重参数偏置参数来识别特定的图案，又要循环不停地用到矩阵乘法和sigmoid映射运算，但它终究是个函数而已，而且它的复杂程度可以稍微让人安点心。如果它没有那么复杂的话，我们恐怕就不大能指望它数字识别能有多准了。说到这里，你明白神经网络是怎么运算了吗？ 狮子图片来自Kevin Pluck 参考文献： [1]Seltzer, Michael L.,Droppo, Jasha. Multi-task learning in deep neural networks for improved phoneme recognition[P]. ,2013. [2]Jeff Heaton. Ian Goodfellow, Yoshua Bengio, and Aaron Courville: Deep learning[J]. Genetic Programming and Evolvable Machines,2018,19(1-2). （本篇鸣谢3Blue1Brown的图文支持） ","date":"2020-04-09","objectID":"/20200409/:0:0","tags":["机器学习","深度学习","Python","神经网络"],"title":"深度学习之神经网络","uri":"/20200409/"},{"categories":["博客建站相关"],"content":"本地搭建博客 创建新文章 hugo new 你的文档名/你的文章名.md 创建库 1.名称一定是：你的用户名.github.io 2.选择本地存储复制 部署到云端 1.在config.toml中改参数 2.生成public: 打开文件根目录的cmd或git bash here输入 hugo 3.进入public 4.在该页面下打开git bash here 5.相继输入以下代码 git init git add -A git commit -am\"init\" git remote add origin https://github.com/你的用户名/你的用户名.github.io.git （假如是我：git remote add origin https://github.com/spiritLHL/spiritLHL.github.io.git） git push -f origin master （无响应则再次运行同一代码，最多两次） 你的博客:https://你的用户名.github.io/ 假如是我的博客：https://spiritLHL.github.io/ 欢迎访问 10分钟教你简单搭建个人博客hugo篇 10分钟教你简单部署hugo博客(github篇) 里面有我搭建博客和部署云端的流程及效果。 下载资源链接: https://pan.baidu.com/s/1As27iCyZ5-q3QvgOE4zdPw 提取码：f34x 注意 如果要绑定第三方域名给github-pages，每次更新博客都需要重新绑定！ ","date":"2020-04-04","objectID":"/20200404/:0:0","tags":["hugo"],"title":"hugo博客在GitHub上进行部署","uri":"/20200404/"},{"categories":["python","爬虫"],"content":" #!/usr/bin/env python3 #本篇介绍抓取含搜索引擎的爬虫 #UA检测：门户网站检测对应请求的身份标识 #UA：useragent（请求载体的身份标识） #UA伪装：伪装游览器 import requests a = True while a: # UA伪装：伪装游览器,将对应user-agent封装到字典headers中 headers = { 'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.122 Safari/537.36' }#这里可以使用各种headers，包括ios或者安卓，模拟手机或平板登录 url = \"https://www.sogou.com/web?\" kw = input('key words:')#输入搜索所需要的关键词 # step1:处理url携带的参数：封装到字典中 param = { 'query': kw } res = requests.get(url=url, params=param, headers=headers)#几乎所有大型搜索引擎都是get请求，若属于某些私密的网址搜索可能需要post请求等加密传输方式 # 对指定url发起的请求对应的url是带参数的，请求过程中处理了参数 page_text = res.text #text处理数据 filename = kw + '.html'#命名文件 with open(filename,'w',encoding='utf-8') as fp: #该语法自动创建文件并自动打开关闭文件，需要注意的是该文件在本爬虫文件所在文档内，需要更精确的存储位置推荐使用os库 fp.write(page_text)#输入数据 print(filename, '保存成功') a = False ","date":"2020-04-01","objectID":"/20200401/:0:0","tags":["python","爬虫"],"title":"爬虫流程及方法03(搜索引擎爬取)","uri":"/20200401/"},{"categories":["python","爬虫"],"content":" #!/usr/bin/env python3 #对某论坛的爬取 import requests from bs4 import BeautifulSoup import time #需求：爬取网站标题及详情页的文本 a = True while a:#可转变成实时循环#对首页的页面数据进行爬取 url = \"https://www.lolichan.vip/\" headers = { 'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.122 Safari/537.36' } page_text = requests.get(url=url, headers=headers).text#获取响应数据得加text，不然获取的是响应对象 #在首页中解析出章节标题和详情页URL #1.实例化BeautifulSoup对象，需要将页面源码加载到该对象中 soup = BeautifulSoup(page_text, 'lxml') #解析章节标题与详情页url div_list = soup.select('.node-body \u003e div \u003e h3 \u003e a')#使用select层级选择器 fp = open('./xiangqing.text','w',encoding='utf-8')#创建文档及设定只写w和编码utf-8 for div in div_list: time.sleep(填入休息时间)#防止频繁的请求链接失去响应 title = div.string#获得该标签下的所有文本 detail_url = 'https://www.lolichan.vip/' + div['href']#获得详情页的url #对详情页发起请求，解析出章节内容 detail_page_text = requests.get(url=detail_url, headers=headers).text #解析出详情页中相关的章节内容 detail_soup = BeautifulSoup(detail_page_text,'lxml') div_tag = detail_soup.select('.structItem-title \u003e a') #原来的class属性得用class_表示，不然会报错（class是保留字） content = []#设定空列表 for a in div_tag: content.append(a.text)#往空列表内装填 fp.write(title+':'+str(content)+'\\n')#str()使content对象变为字符串形式 print(title, '爬取成功')#响应成功 a = False #号符号是python注释的前置符号 pycharm的热键： ctrl+z 键回撤你的对代码的改动 ctrl+/键注释与代码的转换 ctrl+c复制 ctrl+v粘贴 #!/usr/bin/env python3 soup.tagName print(soup.meta)#第一组a标签 soup.tagName返回的是html中第一次出现的tagName标签 #!/usr/bin/env python3 soup.find print(soup.find('meta'))=print(soup.meta) 属性定位,定位一定class加空格再= #属性可以是class 或id 或attr\r#!/usr/bin/env python3 print(soup.find('div', class = 'song')) #!/usr/bin/env python3 soup.find_all('tagName') 找到符合标准的所有标签,返回一个列表 #!/usr/bin/env python3 print(soup.find_all('meta')) #!/usr/bin/env python3 select('某种选择器'). 表示class类选择器 id选择器 标签选择器 返回的是一个列表 #!/usr/bin/env python3 soup.select('xx \u003e xx xx') 或 #!/usr/bin/env python3 soup.select('xx \u003e xx \u003e xx') #!/usr/bin/env python3 print(soup.select('.tang'))#\u003cdiv class='tang'\u003e 部分html代码 \u003cdiv class='tang'\u003e \u003cul\u003e \u003cli\u003e\u003ca href=\"http://....\" title=\"qingming\"\u003emutongyao\u003c/a\u003e\u003c/li\u003e \u003cli\u003e\u003ca href=\"http://....\" title=\"chunjie\"\u003e...\u003c/a\u003e\u003c/li\u003e \u003cul\u003e print(soup.select('.tang \u003e ul \u003e li \u003e a')) 结果： \u003ca href=\"http://....\" title=\"qingming\"\u003e...\u003c/a\u003e， \u003ca href=\"http://....\" title=\"chunjie\"\u003e...\u003c/a\u003e 层级选择器：此时返回一个列表，此时’.class的内容 \u003e ul \u003e li \u003e a’中大于号\u003e表示一个层级 #!/usr/bin/env python3 print(soup.select('.tang \u003e ul \u003e li \u003e a')[0]) #结果：\u003ca href=\"http://....\" title=\"qingming\"\u003emutongyao\u003c/a\u003e #多个层级'.tang \u003e ul a' 这里空格表示多个层级，大于号\u003e表示一个层级 #!/usr/bin/env python3 print(soup.select('.tang \u003e ul \u003e li \u003e a')[0])=print(soup.select('.tang \u003e ul a')[0]) 获取标签之间的文本数据 #!/usr/bin/env python3 soup.a.text/string/get_text() print(soup.select('. class的内容\u003e ul a')[0].text) 结果： mutongyao #!/usr/bin/env python3 text/get_text() get_text()可以获取一个标签中‘所有的’文本内容（即使不属于该标签直系文本内容） string:只可以获得该标签下直系文本内容 获取标签中的属性值 #!/usr/bin/env python3 print(soup.select('.class的内容 \u003e ul a')[0]['href']) ","date":"2020-03-31","objectID":"/20200331/:0:0","tags":["python","爬虫"],"title":"爬虫流程及方法02(Beautiful Soup解析页面)","uri":"/20200331/"},{"categories":["python","爬虫"],"content":"下行遍历（这里两个方法必须是循环中使用） #!/usr/bin/env python3 for child in soup.body.children: print(child) 遍历儿子节点 #!/usr/bin/env python3 for child in soup.body.descendants: print(child) 遍历子孙节点 ","date":"2020-03-31","objectID":"/20200331/:0:1","tags":["python","爬虫"],"title":"爬虫流程及方法02(Beautiful Soup解析页面)","uri":"/20200331/"},{"categories":["python","爬虫"],"content":"上行遍历 #!/usr/bin/env python3 for sibling in soup.a.next_siblings: print(sibling) 遍历后续节点 #!/usr/bin/env python3 for sibling in soup.a.previous_siblings: print(sibling) 遍历前续节点 soup.prettify() 每个节点一个换行符 \u003c\u003e .find_all(name, attrs, recursive, string, **kwargs） 返回一个列表类型，存储查找的结果。 name:对标签名称的检索字符串。 attrs:对标签属性值的检索字符串，可标注属性检索。 recursive:是否对子孙全部检索，默认True。 string: \u003c\u003e…\u003c/\u003e中字符串区域的检索字符串。 ","date":"2020-03-31","objectID":"/20200331/:0:2","tags":["python","爬虫"],"title":"爬虫流程及方法02(Beautiful Soup解析页面)","uri":"/20200331/"},{"categories":["python","爬虫"],"content":"爬虫究竟是合法还是违法的? 在法律中是不被禁止 具有违法风险 请善意爬虫 切勿恶意爬虫 ","date":"2020-03-20","objectID":"/20200320/:0:1","tags":["python","爬虫"],"title":"爬虫流程及方法01(入门准备及Request库使用)","uri":"/20200320/"},{"categories":["python","爬虫"],"content":"爬虫带来的风险可以体现在如下2方面: 爬虫干扰了被访问网站的正常运营 爬虫抓取了受到法律保护的特定类型的数据或信息 ","date":"2020-03-20","objectID":"/20200320/:0:2","tags":["python","爬虫"],"title":"爬虫流程及方法01(入门准备及Request库使用)","uri":"/20200320/"},{"categories":["python","爬虫"],"content":"如何在使用编写爬虫的过程中避免进入局子的厄运呢? 时常的优化自己的程序，避免干扰被访问网站的正常运行 在使用传播爬取到的数据时，审查抓取到的内容，如果发现了涉及到用户的商业机密等敏感内容需要及时停止爬取或传播 ","date":"2020-03-20","objectID":"/20200320/:0:3","tags":["python","爬虫"],"title":"爬虫流程及方法01(入门准备及Request库使用)","uri":"/20200320/"},{"categories":["python","爬虫"],"content":"爬虫的矛与盾 反爬机制:门户网站，可以通过制定相应的策略或者技术手段，防止爬虫程序进行网站数据的爬取。 反反爬策略:爬虫程序可以通过制定相关的策略或者技术手段，破解]户网站中具备的反爬机制，从而可以获取门户网 ","date":"2020-03-20","objectID":"/20200320/:0:4","tags":["python","爬虫"],"title":"爬虫流程及方法01(入门准备及Request库使用)","uri":"/20200320/"},{"categories":["python","爬虫"],"content":"robots. txt协议:? 君子协议:规定了网站中哪些数据可以被爬虫爬取哪些数据不可以被爬取。 例如这个：https://www.bilibili.com/robots.txt 正文： ","date":"2020-03-20","objectID":"/20200320/:0:5","tags":["python","爬虫"],"title":"爬虫流程及方法01(入门准备及Request库使用)","uri":"/20200320/"},{"categories":["python","爬虫"],"content":" 软件：pycharm/thonny/自带IDLE,明白python的基本语法，缩进/字典/元组/列表/循环结构/函数运用/文件存储（绝对路径/相对路径） step1.安装第三方模块：调出cmd窗口输入以下字符 （每一行是一个包，等待下载完后再进行下一个包的下载） python -m pip install --upgrade pip pip install requests pip install bs4 pip install lxml pip install urllib step2.确认爬虫流程： 1.指定url\r2.请求前进行UA伪装（模拟游览器发出请求）\r3.选择post还是get请求\r4.请求发送\r5.获取响应数据\r6.进行存储\rstep3.实际代码的编写： import requests #每使用一个包的方法就得导入一个包 #（引入包后空两行，语法的正确书写习惯） a = True while a: #这里可以改成循环结构对网页进行实时爬取，每次爬取覆盖上次的成果 url = \"网址\" #指定所爬取页面的网址 headers = { 'user-agent':'粘贴1处' } #在页面中点击右键选择检查，调出网页自带的抓包工具，在network中刷新当前页面抓包找到user-agent的项复制粘贴1，找到Query String Parameters的项复制粘贴2（记得加符号’粘贴2‘） params = { '某名字':'某值', '粘贴2':'黏贴2' } res = requests.get(url=url,params=params,headers=headers) #这里是对网页发起请求并内置参数 dict_object = res.text #对返回内容进行text处理并赋值给一个字典 with open(\"./lolichan.html\",\"w\",encoding='utf-8') as fp: #打开或生成一个文档并选定为写w的状态，转换字符的编码为utf-8 fp.write(dict_object)#往文档内存储爬取的网页源码 print('over') #存储成功提示 a = False step4.实际运用： 安装而未用到的包下次再讲，剩下的包用于数据的解析定位 如果想要看效果视频，参照B站视频av92683334 更多内容: 【官方文档】opencv-python中文文档 ","date":"2020-03-20","objectID":"/20200320/:0:6","tags":["python","爬虫"],"title":"爬虫流程及方法01(入门准备及Request库使用)","uri":"/20200320/"},{"categories":["python"],"content":"直接放代码 import os libs = { \"requests\",\"jieba\",\"beautifulsoup4\",\\ \"django\",\"flask\",\\ \"此处填写你需要下载的库的名称，注意大小写并拼写正确，样式如上面例子\",\"pandas\" } try: for lib in libs: os.system('pip install '+lib) print(\"Successful\") except: print('error') os.system(command) command 为要执行的命令，近似于Windows下cmd窗口中输入的命令。 ","date":"2020-03-15","objectID":"/20200315/:0:1","tags":["python"],"title":"安装python第三方库的小技巧","uri":"/20200315/"},{"categories":["博客建站相关"],"content":"更多学习资料欢迎访问吾爱破解论坛，本人工作向GitHub账户，本人娱乐向Github账户获取。 本站用于本人的学习笔记展出，以及部分个人兴趣使然的项目展出。 ","date":"2020-02-01","objectID":"/about/about/:0:0","tags":["hugo"],"title":"关于本站","uri":"/about/about/"},{"categories":["博客建站相关"],"content":"创建新文档 hugo new posts/名字.md 引用B站视频 注意 如果要绑定第三方域名给github-pages，每次更新博客都需要重新绑定！ ","date":"2019-01-01","objectID":"/20190101/:0:0","tags":["hugo"],"title":"本主题使用小技巧","uri":"/20190101/"},{"categories":null,"content":"google-site-verification: google9217a97bfdec3a8f.html","date":"0001-01-01","objectID":"/static/google9217a97bfdec3a8f/:0:0","tags":null,"title":"","uri":"/static/google9217a97bfdec3a8f/"}]